{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from scipy.stats import binned_statistic\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from time import perf_counter\n",
    "from scipy.stats import circmean\n",
    "\n",
    "from src.network import Network\n",
    "from src.plot_utils import plot_con\n",
    "from src.decode import *\n",
    "from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor\n",
    "from src.utils import clear_cache\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import pickle as pkl\n",
    "\n",
    "#+RESULTS:\n",
    "\n",
    "import os\n",
    "\n",
    "def pkl_save(obj, name, path=\".\"):\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            destination = path + \"/\" + name + \".pkl\"\n",
    "            print(\"saving to\", destination)\n",
    "            pkl.dump(obj, open(destination, \"wb\"))\n",
    "\n",
    "\n",
    "def pkl_load(name, path=\".\"):\n",
    "            source = path + \"/\" + name + '.pkl'\n",
    "            # print('loading from', source)\n",
    "            return pkl.load(open( source, \"rb\"))\n",
    "```\n",
    "\n",
    "Notebook Settings\n",
    "=================\n",
    "\n",
    "``` ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "%run ../../../notebooks/setup.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "pal = sns.color_palette(\"tab10\")\n",
    "```\n",
    "\n",
    "Helpers\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "def map2center(angles):\n",
    "    \"\"\"Map angles from [0, 2π] to [-π, π] using PyTorch tensors.\"\"\"\n",
    "    return np.where(angles > np.pi, angles - 2 * np.pi, angles)\n",
    "\n",
    "def map2pos(angles):\n",
    "    \"\"\"Map angles from [-π, π] to [0, 2π] using PyTorch tensors.\"\"\"\n",
    "    return np.where(angles < 0, angles + 2 * np.pi, angles)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def maptens2center(angles):\n",
    "    \"\"\"Map angles from [0, 2π] to [-π, π] using PyTorch tensors.\"\"\"\n",
    "    return torch.where(angles > torch.pi, angles - 2 * torch.pi, angles)\n",
    "\n",
    "def maptens2pos(angles):\n",
    "    \"\"\"Map angles from [-π, π] to [0, 2π] using PyTorch tensors.\"\"\"\n",
    "    return torch.where(angles < 0, angles + 2 * torch.pi, angles)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def add_vlines(model, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        for i in range(len(model.T_STIM_ON)):\n",
    "            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)\n",
    "    else:\n",
    "        for i in range(len(model.T_STIM_ON)):\n",
    "            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)\n",
    "\n",
    "```\n",
    "\n",
    "Model\n",
    "=====\n",
    "\n",
    "``` ipython\n",
    "IF_LOAD = 0\n",
    "IF_SAVE = 1\n",
    "IF_SAVE_POPT = 0\n",
    "\n",
    "name = 'controls'\n",
    "# name = 'patients_B'\n",
    "if IF_LOAD:\n",
    "    groups = ['controls', 'patients_A', 'patients_B']\n",
    "else:\n",
    "    groups = [name]\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "kwargs = {\n",
    "    'N_TRIALS': 100,\n",
    "    'GAIN_NMDA': [1.0, 1.0],\n",
    "    'GAIN_SZ': [1., 1.],\n",
    "\n",
    "    'GAIN': 1.2,\n",
    "    'DURATION': 9.0,\n",
    "    'T_STEADY': 1.0,\n",
    "\n",
    "    'T_STIM_ON': [1.0, 2.0],\n",
    "    'T_STIM_OFF': [2.0, 3.0],\n",
    "\n",
    "    'I0': [1.0, -10.0],\n",
    "    'PHI0': [180.0, 180],\n",
    "    'SIGMA0': [4.0, 0.0],\n",
    "    'M0': 1.0,\n",
    "    'VAR_FF': [0.3, 0.3],\n",
    "\n",
    "    'RANDOM_DELAY': 1,\n",
    "    'MIN_DELAY': 0,\n",
    "    'MAX_DELAY': 6,\n",
    "\n",
    "    'RANDOM_ITI': 0,\n",
    "    'MAX_ITI': 6,\n",
    "    'MIN_ITI': 0,\n",
    "    'ITI_LIST': [0, 2, 4, 6],\n",
    "\n",
    "    'TAU': [0.2, 0.1],\n",
    "\n",
    "    'SYN_DYN': 0,\n",
    "\n",
    "    'IF_NMDA': 1,\n",
    "    'R_NMDA': 1.0,\n",
    "    'TAU_NMDA': [0.5, 0.5],\n",
    "\n",
    "    'IF_FF_STP': 0,\n",
    "    'FF_USE': 0.5,\n",
    "    'TAU_FF_FAC': 0.0,\n",
    "    'TAU_FF_REC': 0.5,\n",
    "\n",
    "    'Jab': [1.0, -1.4, 1.0, -1],\n",
    "\n",
    "    'IS_STP': [1, 0, 0, 0],\n",
    "    'USE': [0.06, 0.03, 0.03, 0.1],\n",
    "    'TAU_FAC': [4.0, 2.0, 2.0, 0.0],\n",
    "    'TAU_REC': [0.4, 0.2, 0.2, 0.1],\n",
    "    'W_STP': [1.0, 3.0, 4.0, 1.0],\n",
    "\n",
    "    'IF_FF_ADAPT': 0,\n",
    "    'A_FF_ADAPT': 1.0,\n",
    "    'TAU_FF_ADAPT': 150.0,\n",
    "\n",
    "    'IF_ADAPT': 1,\n",
    "    'A_ADAPT': 1.5, # 4 or 0.5 0.15 or 1.5\n",
    "    'TAU_ADAPT': 10.0,\n",
    "\n",
    "    'REP_BIAS': 2.0, # 1.25\n",
    "    'REP_VAR': 0.0,\n",
    "    'REP_SIG': 90,\n",
    "}\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "conf_name = \"train_odr_EI.yml\"\n",
    "DEVICE = 'cuda:1'\n",
    "seed = np.random.randint(0, 1e6)\n",
    "\n",
    "seed = 1\n",
    "print('seed', seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "N_BATCH = 768\n",
    "model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH, **kwargs)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model_state_dict = torch.load('../models/odr/odr_%d.pth' % seed)\n",
    "model.load_state_dict(model_state_dict);\n",
    "model.eval();\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.J_STP = torch.nn.Parameter(model.J_STP.detach() / kwargs['GAIN_SZ'][0])\n",
    "model.USE[0] = model.USE[0] * kwargs['GAIN_SZ'][0]\n",
    "\n",
    "model.J_STP = torch.nn.Parameter(kwargs['GAIN_NMDA'][0] * model.J_STP.detach())\n",
    "model.Wab_T[model.slices[0], model.slices[1]] *= kwargs['GAIN_NMDA'][1]\n",
    "print(model.J_STP)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "\n",
    "def torch_dog(x, A, mu, sigma, C):\n",
    "       return A * (-(x - mu)/sigma**2) * torch.exp(-(x - mu)**2/(2*sigma**2)) + C\n",
    "\n",
    "def shifted_phase(phase1, phase2, bias_strength, bias_var, direction='repulsive', sigma=50, order=1, popt=None):\n",
    "    \"\"\"\n",
    "    Shift phase2 away/toward phase1 by bias_strength (degrees).\n",
    "    direction: 'repulsive' (away) or 'attractive' (toward).\n",
    "    All phases and sigma in degrees!\n",
    "    \"\"\"\n",
    "    # Minimal difference, wrapped to [-180, 180]\n",
    "    delta = (phase1 - phase2 + 180) % 360 - 180\n",
    "\n",
    "    sign = -1 if direction == 'repulsive' else 1\n",
    "\n",
    "    if popt is not None:\n",
    "\n",
    "           kernel = torch_dog(delta, popt[0], popt[1], popt[2], popt[3])\n",
    "    else:\n",
    "           kernel = torch.sin(torch.deg2rad(delta)) * torch.exp(-torch.abs(delta)**order / sigma**order / order)\n",
    "\n",
    "    phase2_biased = (\n",
    "           phase2 + sign * bias_strength * kernel + bias_var * torch.randn_like(phase2)\n",
    "    )\n",
    "\n",
    "    # wrap output to [0, 360)\n",
    "    return phase2_biased % 360.0\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "if IF_SAVE_POPT:\n",
    "    model.REP_BIAS=0\n",
    "    popt = None\n",
    "else:\n",
    "     model.REP_BIAS = kwargs['REP_BIAS']\n",
    "     popt = pkl_load('popt_%s' % name, './models/nih/rand_delay')\n",
    "\n",
    "phase1 = torch.randint(low=0, high=360, size=(100,), device=DEVICE, dtype=torch.float)\n",
    "phase2 = torch.randint(low=0, high=360, size=(100,), device=DEVICE, dtype=torch.float)\n",
    "\n",
    "delta = phase1 - phase2\n",
    "rel_loc = (delta + 180) % 360 - 180\n",
    "shift =  shifted_phase(phase1, phase2, model.REP_BIAS, model.REP_VAR, sigma=kwargs['REP_SIG'], popt=popt)\n",
    "error =  (shift-phase2).cpu().numpy()\n",
    "error = (error + 180) %360 - 180\n",
    "\n",
    "plt.plot(rel_loc.cpu().numpy(), error, 'o')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "if kwargs['RANDOM_DELAY']:\n",
    "    name += '_delay_rand'\n",
    "print(name)\n",
    "```\n",
    "\n",
    "Simulating Consecutive Trials\n",
    "=============================\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = N_BATCH\n",
    "# runing a baseline trial with no task\n",
    "model.TASK: 'None'\n",
    "model.I0 = [0.0, 0.0]\n",
    "model.RANDOM_DELAY = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    ff_input = model.init_ff_input()\n",
    "    rates_tensor = model.forward(ff_input=ff_input)\n",
    "    clear_cache()\n",
    "print(ff_input.shape, rates_tensor.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = N_BATCH\n",
    "\n",
    "model.I0 = kwargs['I0']\n",
    "\n",
    "model.TASK: 'odr'\n",
    "model.RANDOM_DELAY = kwargs['RANDOM_DELAY']\n",
    "model.PHI0 = torch.randint(low=0, high=360, size=(N_BATCH, len(model.I0), 1), device=DEVICE, dtype=torch.float)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ff_input = model.init_ff_input()\n",
    "    rates_tensor = model.forward(ff_input=ff_input, IF_INIT=0)\n",
    "    # del ff_input\n",
    "    clear_cache()\n",
    "print(ff_input.shape, rates_tensor.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "from src.configuration import init_time_const\n",
    "\n",
    "N_TRIALS = 100\n",
    "\n",
    "rates_list = []\n",
    "prev_list = [model.PHI0[:, 0].cpu().detach()]\n",
    "curr_list = []\n",
    "\n",
    "start_list = torch.ones((N_TRIALS, 2, model.N_BATCH))\n",
    "end_list = torch.ones((N_TRIALS, 2, model.N_BATCH))\n",
    "delay_list = torch.ones((N_TRIALS, model.N_BATCH))\n",
    "\n",
    "iti_list = torch.ones((N_TRIALS, model.N_BATCH))\n",
    "min_iti = model.DURATION - model.T_STIM_OFF[-1]\n",
    "interval = N_TRIALS // len(model.ITI_LIST)\n",
    "\n",
    "for trial in tqdm(range(N_TRIALS)):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # if IF_ITI:\n",
    "        #     if trial % interval == 0:\n",
    "        #         model.T_STEADY = model.ITI_LIST[trial // interval]\n",
    "\n",
    "        if model.RANDOM_ITI or model.RANDOM_DELAY:\n",
    "            init_time_const(model)\n",
    "\n",
    "        delay_list[trial] = model.random_shifts\n",
    "        iti_list[trial] = model.N_STEADY * model.DT + min_iti\n",
    "\n",
    "        start_list[trial] = model.start_idx\n",
    "        end_list[trial] = model.end_idx\n",
    "\n",
    "        model.PHI0 = torch.randint(low=0, high=360, size=(N_BATCH, len(model.I0), 1), device=DEVICE, dtype=torch.float)\n",
    "        model.PHI0_UNBIASED = torch.deg2rad(model.PHI0.clone())\n",
    "\n",
    "        if model.REP_BIAS>0:\n",
    "            model.PHI0[:, 0] = shifted_phase(prev_list[-1].to(DEVICE)*180.0 / torch.pi, model.PHI0[:, 0], model.REP_BIAS, model.REP_VAR, popt=popt)\n",
    "\n",
    "        ff_input = model.init_ff_input()\n",
    "\n",
    "        rates = model.forward(ff_input=ff_input, IF_INIT=0)\n",
    "\n",
    "        curr_list.append(model.PHI0_UNBIASED[:, 0].cpu().detach())\n",
    "        prev_list.append(model.PHI0_UNBIASED[:, 0].cpu().detach())\n",
    "\n",
    "        rates_list.append(rates.cpu().detach())\n",
    "\n",
    "        del ff_input, rates\n",
    "        clear_cache()\n",
    "\n",
    "rates_list = torch.stack(rates_list).cpu().numpy()\n",
    "prev_list = torch.stack(prev_list).cpu().numpy()[:-1]\n",
    "curr_list = torch.stack(curr_list).cpu().numpy()\n",
    "\n",
    "delay_list = np.hstack(delay_list.cpu().numpy()) * model.DT\n",
    "iti_list = np.hstack(iti_list.cpu().numpy())\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print('rates', rates_list.shape)\n",
    "print('curr', curr_list.shape, 'prev', prev_list.shape, 'iti', iti_list.shape)\n",
    "print('start', start_list.shape, 'end', end_list.shape, 'delay', delay_list.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "start_idx = model.start_idx.cpu().numpy()\n",
    "end_idx = model.end_idx.cpu().numpy()\n",
    "print(start_idx.shape, end_idx.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "m0_list, m1_list, phi_list = decode_bump_torch(rates_list, axis=-1, RET_TENSOR=0)\n",
    "\n",
    "print(phi_list.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "DURATION = rates_list.shape[2] / 10\n",
    "N_NEURONS = rates_list.shape[-1]\n",
    "N_SESSION = rates_list.shape[1]\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 1, figsize=[3*width, height])\n",
    "\n",
    "n_trials = 4\n",
    "idx = np.random.randint(0, 100)\n",
    "rates = np.vstack(rates_list[:n_trials, idx]).T\n",
    "vmin, vmax = np.percentile(rates.reshape(-1), [5, 95])\n",
    "print(vmax)\n",
    "plt.imshow(rates, aspect='auto', cmap='jet', vmin=vmin, vmax=vmax, origin='lower', extent=[0, n_trials * DURATION, 0, N_NEURONS])\n",
    "plt.ylabel('Pref. Location (°)')\n",
    "plt.yticks(np.linspace(0, N_NEURONS, 5), np.linspace(0, 360, 5).astype(int))\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 3, figsize=[3*width, height])\n",
    "\n",
    "idx = np.random.randint(0, 100)\n",
    "\n",
    "m0 = np.hstack(m0_list[:n_trials, idx]).T\n",
    "m1 = np.hstack(m1_list[:n_trials, idx]).T\n",
    "phi = np.hstack(phi_list[:n_trials, idx]).T\n",
    "\n",
    "xtime = np.linspace(0, n_trials*DURATION, phi.shape[-1])\n",
    "idx = np.random.randint(0, model.N_BATCH, 8)\n",
    "\n",
    "ax[0].plot(xtime, m0)\n",
    "ax[0].set_ylabel('$\\mathcal{F}_0$ (Hz)')\n",
    "ax[0].set_xlabel('Time (s)')\n",
    "\n",
    "ax[1].plot(xtime, m1)\n",
    "ax[1].set_ylabel('$\\mathcal{F}_1$ (Hz)')\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "\n",
    "ax[2].plot(xtime, phi * 180 / np.pi)\n",
    "ax[2].set_yticks(np.linspace(0, 360, 5).astype(int), np.linspace(0, 360, 5).astype(int))\n",
    "ax[2].set_ylabel('Bump Center (°)')\n",
    "ax[2].set_xlabel('Time (s)')\n",
    "\n",
    "# for i in range(n_trials):\n",
    "#     ax[2].axhline(model.PHI0[i, 0, 0].cpu().detach(), xmin=0, xmax=int(1.0/n_trials), ls='--', color=colors[i])\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "if IF_SAVE:\n",
    "    pkl_save(rates_list, 'rates_list_%s' % name, './models/nih/')\n",
    "\n",
    "    pkl_save(curr_list, 'curr_list_%s' % name, './models/nih/')\n",
    "    pkl_save(prev_list, 'prev_list_%s' % name, './models/nih/')\n",
    "\n",
    "    pkl_save(delay_list, 'delay_list_%s' % name, './models/nih/')\n",
    "\n",
    "    pkl_save(start_idx, 'start_idx_%s' % name, './models/nih/')\n",
    "    pkl_save(end_idx, 'end_idx_%s' % name, './models/nih/')\n",
    "    pkl_save(phi_list, 'phi_list_%s' % name, './models/nih/')\n",
    "```\n",
    "\n",
    "Errors\n",
    "======\n",
    "\n",
    "``` ipython\n",
    "n_half = N_TRIALS // 2\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "curr_ini =  curr_list[:n_half]\n",
    "curr_last = curr_list[-n_half:]\n",
    "\n",
    "prev_ini =  prev_list[:n_half]\n",
    "prev_last = prev_list[-n_half:]\n",
    "print(curr_ini.shape, prev_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "phi_ini = phi_list[:n_half]\n",
    "phi_last = phi_list[n_half:]\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(phi_ini.shape, prev_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_error_curr_prev(phi, curr, prev):\n",
    "    target_loc = curr  * 180.0 / np.pi\n",
    "\n",
    "    rel_loc = prev - curr\n",
    "    rel_loc = (rel_loc + np.pi) % (2 * np.pi) - np.pi\n",
    "    rel_loc *= 180 / np.pi\n",
    "\n",
    "    error_curr = phi - curr\n",
    "    error_curr = (error_curr + np.pi) % (2 * np.pi) - np.pi\n",
    "    error_curr *= 180 / np.pi\n",
    "\n",
    "    return np.vstack(target_loc), np.vstack(rel_loc), np.array(error_curr)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_end_point(start_idx, errors):\n",
    "\n",
    "    # stim_idx = ((model.start_indices - model.N_STEADY) / model.N_WINDOW).to(int).cpu().numpy()\n",
    "\n",
    "    end_point = []\n",
    "\n",
    "    for k in range(errors.shape[1]): # sessions\n",
    "            idx = start_idx[1][k]-1\n",
    "            end_point.append(errors[:, k, idx])\n",
    "\n",
    "    return np.array(end_point).T.reshape(-1, 1)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "targ_ini, rel_ini, errors_ini = get_error_curr_prev(phi_ini, curr_ini, prev_ini)\n",
    "targ_last, rel_last, errors_last = get_error_curr_prev(phi_last, curr_last, prev_last)\n",
    "print(targ_ini.shape, rel_ini.shape, errors_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(start_list.shape)\n",
    "start_ini = np.swapaxes(start_list[:n_half]-1, 0, 1).cpu().numpy()\n",
    "start_ini = (start_ini).astype(int)\n",
    "\n",
    "i, j = np.indices(start_ini[1].shape)\n",
    "\n",
    "# end_point_ini = errors_ini[i, j, start_ini[1]]\n",
    "end_point_ini = np.hstack(errors_ini[i, j, start_ini[1]])[:, np.newaxis]\n",
    "print(end_point_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(start_list.shape)\n",
    "start_last = np.swapaxes(start_list[:n_half]-1, 0, 1).cpu().numpy()\n",
    "start_last = (start_last).astype(int)\n",
    "\n",
    "i, j = np.indices(start_last[1].shape)\n",
    "\n",
    "end_point_last = np.hstack(errors_last[i, j, start_last[1]])[:, np.newaxis]\n",
    "print(end_point_last.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "# end_point_ini = get_end_point(start_idx, errors_ini)\n",
    "# end_point_last = get_end_point(start_idx, errors_last)\n",
    "# print(end_point_ini.shape, end_point_last.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "ax[0].hist(end_point_ini[:, 0], bins=50)\n",
    "ax[1].hist(end_point_last[:, 0], bins=50)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "time_points = np.linspace(0, model.DURATION, errors_ini.shape[-1])\n",
    "idx = np.random.randint(errors_ini.shape[1], size=100)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "ax[0].plot(time_points, errors_ini[0][idx].T, alpha=.4)\n",
    "add_vlines(model, ax[0])\n",
    "\n",
    "ax[0].set_xlabel('t')\n",
    "ax[0].set_ylabel('error first half(°)')\n",
    "\n",
    "ax[1].plot(time_points, errors_last[0][idx].T, alpha=.4)\n",
    "add_vlines(model, ax[1])\n",
    "\n",
    "ax[1].set_xlabel('t')\n",
    "ax[1].set_ylabel('error last half (°)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Biases\n",
    "======\n",
    "\n",
    "``` ipython\n",
    "print(targ_ini.shape, rel_ini.shape, end_point_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "n_bins = 32\n",
    "data_ini = pd.DataFrame({'target_loc': targ_ini[:, -1], 'rel_loc': rel_ini[:, -1], 'errors': end_point_ini[:, 0]})\n",
    "data_last = pd.DataFrame({'target_loc': targ_last[:, -1], 'rel_loc': rel_last[:, -1], 'errors': end_point_last[:, 0]})\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_correct_error(nbins, df, thresh=None):\n",
    "    if thresh is not None:\n",
    "        data = df[(df['errors'] >= -thresh) & (df['errors'] <= thresh)].copy()\n",
    "    else:\n",
    "        data = df.copy()\n",
    "\n",
    "    # 1. Bias-correct both error and error_half\n",
    "    bin_edges = np.linspace(0, 360, n_bins + 1)\n",
    "    data['bin_target'] = pd.cut(data['target_loc'], bins=bin_edges, include_lowest=True)\n",
    "    mean_errors_per_bin = data.groupby('bin_target')['errors'].mean()\n",
    "    data['adjusted_errors'] = data['errors'] - data['bin_target'].map(mean_errors_per_bin).astype(float)\n",
    "\n",
    "\n",
    "    # 2. Bin by relative location for both sessions (full version, [-180, 180])\n",
    "    data['bin_rel'] = pd.cut(data['rel_loc'], bins=n_bins)\n",
    "    bin_rel = data.groupby('bin_rel')['adjusted_errors'].agg(['mean', 'sem']).reset_index()\n",
    "    edges = bin_rel['bin_rel'].cat.categories\n",
    "    centers = (edges.left + edges.right) / 2\n",
    "\n",
    "    # 3. FLIP SIGN for abs(rel_loc): defects on the left (-) are flipped so all bins reflect the same \"direction\"\n",
    "    data['rel_loc_abs'] = np.abs(data['rel_loc'])\n",
    "    data['bin_rel_abs'] = pd.cut(data['rel_loc_abs'], bins=n_bins, include_lowest=True)\n",
    "\n",
    "    # Flip errors for abs plot:\n",
    "    data['adjusted_errors_abs'] = data['adjusted_errors'] * np.sign(data['rel_loc'])\n",
    "\n",
    "    bin_rel_abs = data.groupby('bin_rel_abs')['adjusted_errors_abs'].agg(['mean', 'sem']).reset_index()\n",
    "    edges_abs = bin_rel_abs['bin_rel_abs'].cat.categories\n",
    "    centers_abs = (edges_abs.left + edges_abs.right) / 2\n",
    "\n",
    "    # 4. Bin by target location for target-centered analysis (optional)\n",
    "    bin_target = data.groupby('bin_target')['adjusted_errors'].agg(['mean', 'sem']).reset_index()\n",
    "    edges_target = bin_target['bin_target'].cat.categories\n",
    "    target_centers = (edges_target.left + edges_target.right) / 2\n",
    "\n",
    "    return centers, bin_rel, centers_abs, bin_rel_abs\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "centers_ini, bin_rel_ini, centers_abs_ini, bin_rel_abs_ini = get_correct_error(n_bins, data_ini)\n",
    "centers_last, bin_rel_last, centers_abs_last, bin_rel_abs_last = get_correct_error(n_bins, data_last)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "# Panel 2: By Relative Location (Full vs Half session, -180..180)\n",
    "ax[0].plot(centers_ini, bin_rel_ini['mean'], 'r', label='First half')\n",
    "ax[0].fill_between(centers_ini, bin_rel_ini['mean'] - bin_rel_ini['sem'], bin_rel_ini['mean'] + bin_rel_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[0].plot(centers_last, bin_rel_last['mean'], 'b', label='Second half')\n",
    "ax[0].fill_between(centers_last, bin_rel_last['mean'] - bin_rel_last['sem'], bin_rel_last['mean'] + bin_rel_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[0].axhline(0, color='k', linestyle=\":\")\n",
    "ax[0].set_xlabel('Rel. Loc. (°)')\n",
    "ax[0].set_ylabel('Corrected Error (°)')\n",
    "\n",
    "\n",
    "# Panel 3: By |Relative Location| (Full and Half)\n",
    "ax[1].plot(centers_abs_ini, bin_rel_abs_ini['mean'], 'r', label='First half')\n",
    "ax[1].fill_between(centers_abs_ini, bin_rel_abs_ini['mean'] - bin_rel_abs_ini['sem'], bin_rel_abs_ini['mean'] + bin_rel_abs_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[1].plot(centers_abs_last, bin_rel_abs_last['mean'], 'b', label='Second half')\n",
    "ax[1].fill_between(centers_abs_last, bin_rel_abs_last['mean'] - bin_rel_abs_last['sem'], bin_rel_abs_last['mean'] + bin_rel_abs_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[1].axhline(0, color='k', linestyle=\":\")\n",
    "ax[1].set_xlabel('|Rel. Loc.| (°)')\n",
    "ax[1].set_ylabel('Corrected Error (°)')\n",
    "ax[1].legend(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('./figures/NIH/10_25/sb_half_%s.svg' % name)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Delay Dependency\n",
    "================\n",
    "\n",
    "``` ipython\n",
    "def get_delay_points(errors_list, start_idx, end_idx):\n",
    "    delay_point = []\n",
    "\n",
    "    for i in range(errors_list.shape[1]): # loop over sessions\n",
    "        idx_start = end_idx[0][i] # delay start\n",
    "        idx_end = start_idx[1][i] # delay stops\n",
    "\n",
    "        end_ = []\n",
    "\n",
    "        for idx in range(idx_start, idx_end): # loop over delay idx\n",
    "            end__ = []\n",
    "            for j in range(errors_list.shape[0]): # loop over trials\n",
    "                end__.append(errors_list[j, i, idx]) # append all delay errors\n",
    "\n",
    "            end_.append(end__)\n",
    "        delay_point.append(end_)\n",
    "\n",
    "    return np.vstack(np.array(delay_point).T.swapaxes(-1, 1))\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "targ_list, rel_list, errors_list = get_error_curr_prev(phi_list, curr_list, prev_list)\n",
    "\n",
    "print(start_list.shape)\n",
    "\n",
    "end_points = np.swapaxes(start_list-1, 0, 1).cpu().numpy()\n",
    "end_points = (end_points).astype(int)\n",
    "\n",
    "i, j = np.indices(end_points[1].shape)\n",
    "\n",
    "errors_end_point = np.hstack(errors_list[i, j, end_points[1]])[:, np.newaxis]\n",
    "print(errors_end_point.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "prev_delay = delay_list.reshape(N_TRIALS, 768)\n",
    "prev_delay = np.hstack(np.roll(prev_delay, shift=1, axis=0))\n",
    "\n",
    "data = pd.DataFrame({'target_loc': targ_list[:, -1], 'rel_loc': rel_list[:, -1], 'errors': errors_end_point[:, -1], 'delay': delay_list, 'prev_delay': prev_delay})\n",
    "print(data.head())\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "unique_delay = np.unique(delay_list)\n",
    "print(len(delay_list), unique_delay)\n",
    "plt.hist(delay_list)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "n_bins = 16\n",
    "\n",
    "cmap = plt.get_cmap('Blues')\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "for i_name, name in enumerate(groups):\n",
    "    serial_list = []\n",
    "\n",
    "    if IF_LOAD:\n",
    "        name = name + '_delay_rand'\n",
    "\n",
    "        phi_list = pkl_load('phi_list_%s' % name, './models/nih/')\n",
    "        curr_list = pkl_load('curr_list_%s' % name, './models/nih/')\n",
    "        prev_list = pkl_load('prev_list_%s' % name, './models/nih/')\n",
    "        start_idx = pkl_load('start_idx_%s' % name, './models/nih/')\n",
    "        delay_list = pkl_load('delay_list_%s' % name, './models/nih/')\n",
    "\n",
    "    serial_list = []\n",
    "    unique_delay = np.unique(delay_list)\n",
    "    print(unique_delay, len(delay_list))\n",
    "    n_unique = len(unique_delay)\n",
    "    colors = [cmap((i+1)/ n_unique) for i in range(n_unique+1)]\n",
    "\n",
    "    for i, delay in enumerate(unique_delay):\n",
    "        centers, bin_rel, centers_abs, bin_rel_abs = get_correct_error(n_bins, data[data.delay==delay])\n",
    "\n",
    "        if i==0:\n",
    "            centers_0 = centers\n",
    "            bin_rel_0 = bin_rel\n",
    "\n",
    "        ax[0].plot(centers_abs, bin_rel_abs['mean'], color=pal[i_name], alpha=(i+1) / len(unique_delay))\n",
    "\n",
    "        loc = (centers_abs>=0) & (centers_abs<=90)\n",
    "        serial_max = bin_rel_abs['mean'][loc].mean()\n",
    "        serial_std = bin_rel_abs['mean'][loc].std(ddof=1) / np.sqrt(len(bin_rel_abs['mean'][loc]))\n",
    "\n",
    "        serial_list.append([serial_max, serial_std])\n",
    "\n",
    "    serial_list = np.array(serial_list).T\n",
    "\n",
    "    xdelay = np.linspace(unique_delay[0], unique_delay[-1], serial_list.shape[1])\n",
    "\n",
    "    ax[1].plot(xdelay, serial_list[0], '-', color=pal[i_name])\n",
    "    ax[1].fill_between(xdelay, serial_list[0] - serial_list[1], serial_list[0] + serial_list[1], alpha=0.2, color=pal[i_name])\n",
    "\n",
    "ax[0].set_xlabel('Rel. Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "ax[0].axhline(0, ls=\"--\", color='k')\n",
    "ax[0].set_xticks(np.linspace(0, 180, 5))\n",
    "\n",
    "ax[1].set_xlabel('Delay (s)')\n",
    "ax[1].set_ylabel('Serial Bias (°)')\n",
    "ax[1].axhline(0, ls='--', color='k')\n",
    "ax[1].set_xticks(model.DELAY_LIST)\n",
    "\n",
    "if IF_LOAD:\n",
    "    plt.savefig('./figures/NIH/delay/sb_delay_all.svg')\n",
    "else:\n",
    "    plt.savefig('./figures/NIH/delay/sb_delay_%s.svg' % name)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def dog(x, A, mu, sigma, C):\n",
    "    return A * (-(x - mu)/sigma**2) * np.exp(-(x - mu)**2/(2*sigma**2)) + C\n",
    "\n",
    "x = centers_0.values\n",
    "y = bin_rel_0['mean'].values\n",
    "sem = bin_rel_0['sem'].values\n",
    "\n",
    "p0 = [max(y)-min(y), 0, 40, np.mean(y)]\n",
    "if IF_SAVE_POPT:\n",
    "    print('save')\n",
    "    popt, _ = curve_fit(dog, x, y, p0)\n",
    "    pkl_save(popt, 'popt_%s' % name, './models/nih/rand_delay')\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.errorbar(x, y, yerr=sem, fmt='o', label='Data', capsize=3)\n",
    "\n",
    "# 2. Dense x values for smooth fit curve\n",
    "xfit = np.linspace(np.min(x), np.max(x), 200)\n",
    "\n",
    "# 3. Your DoG function (same as used for fitting)\n",
    "def dog(x, A, mu, sigma, C):\n",
    "    return A * (-(x - mu)/sigma**2) * np.exp(-(x - mu)**2/(2*sigma**2)) + C\n",
    "\n",
    "# 4. Plot the fit\n",
    "plt.plot(xfit, dog(xfit, *popt), 'r-', label='DoG fit', linewidth=2)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Serial bias')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "n_bins = 8\n",
    "\n",
    "cmap = plt.get_cmap('Blues')\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "for i_name, name in enumerate(groups):\n",
    "    serial_list = []\n",
    "\n",
    "    if IF_LOAD:\n",
    "        name = name + '_delay_rand'\n",
    "\n",
    "        phi_list = pkl_load('phi_list_%s' % name, './models/nih/')\n",
    "        curr_list = pkl_load('curr_list_%s' % name, './models/nih/')\n",
    "        prev_list = pkl_load('prev_list_%s' % name, './models/nih/')\n",
    "        start_idx = pkl_load('start_idx_%s' % name, './models/nih/')\n",
    "        delay_list = pkl_load('delay_list_%s' % name, './models/nih/')\n",
    "\n",
    "    serial_list = []\n",
    "    unique_delay = np.unique(delay_list)\n",
    "    print(unique_delay, len(delay_list))\n",
    "    n_unique = len(unique_delay)\n",
    "    colors = [cmap((i+1)/ n_unique) for i in range(n_unique+1)]\n",
    "\n",
    "    for i, delay in enumerate(unique_delay):\n",
    "        # idx = np.where(delay_list == delay)[0]\n",
    "\n",
    "        centers, bin_rel, centers_abs, bin_rel_abs = get_correct_error(n_bins, data[data.prev_delay==delay])\n",
    "\n",
    "        ax[0].plot(centers_abs, bin_rel_abs['mean'], color=pal[i_name], alpha=(i+1) / len(unique_delay))\n",
    "\n",
    "        loc = (centers_abs>=0) & (centers_abs<=90)\n",
    "        serial_max = bin_rel_abs['mean'][loc].mean()\n",
    "        serial_std = bin_rel_abs['mean'][loc].std(ddof=1) / np.sqrt(len(bin_rel_abs['mean'][loc]))\n",
    "\n",
    "        serial_list.append([serial_max, serial_std])\n",
    "\n",
    "    serial_list = np.array(serial_list).T\n",
    "\n",
    "    xdelay = np.linspace(unique_delay[0], unique_delay[-1], serial_list.shape[1])\n",
    "\n",
    "    ax[1].plot(xdelay, serial_list[0], '-', color=pal[i_name])\n",
    "    ax[1].fill_between(xdelay, serial_list[0] - serial_list[1], serial_list[0] + serial_list[1], alpha=0.2, color=pal[i_name])\n",
    "\n",
    "ax[0].set_xlabel('Rel. Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "ax[0].axhline(0, ls=\"--\", color='k')\n",
    "ax[0].set_xticks(np.linspace(0, 180, 5))\n",
    "\n",
    "ax[1].set_xlabel('Prev. Delay (s)')\n",
    "ax[1].set_ylabel('Serial Bias (°)')\n",
    "ax[1].axhline(0, ls='--', color='k')\n",
    "ax[1].set_xticks(model.DELAY_LIST)\n",
    "\n",
    "if IF_LOAD:\n",
    "    plt.savefig('./figures/NIH/delay/sb_prev_delay_all.svg')\n",
    "else:\n",
    "    plt.savefig('./figures/NIH/delay/sb_prev_delay_%s.svg' % name)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
