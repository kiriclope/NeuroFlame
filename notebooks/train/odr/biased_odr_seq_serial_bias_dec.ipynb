{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Settings\n",
    "=================\n",
    "\n",
    "``` ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "%run ../../../notebooks/setup.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "pal = sns.color_palette(\"tab10\")\n",
    "```\n",
    "\n",
    "Imports\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from scipy.stats import binned_statistic\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from time import perf_counter\n",
    "from scipy.stats import circmean\n",
    "\n",
    "from src.network import Network\n",
    "from src.plot_utils import plot_con\n",
    "from src.decode import decode_bump, circcvl, decode_bump_torch\n",
    "from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor\n",
    "from src.utils import clear_cache\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "def pkl_save(obj, name, path=\".\"):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    destination = path + \"/\" + name + \".pkl\"\n",
    "    print(\"saving to\", destination)\n",
    "    pkl.dump(obj, open(destination, \"wb\"))\n",
    "\n",
    "\n",
    "def pkl_load(name, path=\".\"):\n",
    "    source = path + \"/\" + name + '.pkl'\n",
    "    print('loading from', source)\n",
    "    return pkl.load(open( source, \"rb\"))\n",
    "\n",
    "```\n",
    "\n",
    "Helpers\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "def map2center(angles):\n",
    "    \"\"\"Map angles from [0, 2π] to [-π, π] using PyTorch tensors.\"\"\"\n",
    "    return np.where(angles > np.pi, angles - 2 * np.pi, angles)\n",
    "\n",
    "def map2pos(angles):\n",
    "    \"\"\"Map angles from [-π, π] to [0, 2π] using PyTorch tensors.\"\"\"\n",
    "    return np.where(angles < 0, angles + 2 * np.pi, angles)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def maptens2center(angles):\n",
    "    \"\"\"Map angles from [0, 2π] to [-π, π] using PyTorch tensors.\"\"\"\n",
    "    return torch.where(angles > torch.pi, angles - 2 * torch.pi, angles)\n",
    "\n",
    "def maptens2pos(angles):\n",
    "    \"\"\"Map angles from [-π, π] to [0, 2π] using PyTorch tensors.\"\"\"\n",
    "    return torch.where(angles < 0, angles + 2 * torch.pi, angles)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def add_vlines(model, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        for i in range(len(model.T_STIM_ON)):\n",
    "            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)\n",
    "    else:\n",
    "        for i in range(len(model.T_STIM_ON)):\n",
    "            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def generate_weighted_phase_samples(N_BATCH, angles, preferred_angle, sigma):\n",
    "    # Convert angles list to a tensor\n",
    "    angles_tensor = torch.tensor(angles)\n",
    "\n",
    "    # Calculate Gaussian probability distribution centered at preferred_angle\n",
    "    probs = np.exp(-0.5 * ((angles - preferred_angle) / sigma) ** 2)\n",
    "    probs /= probs.sum()  # Normalize to get probabilities\n",
    "\n",
    "    # Create a categorical distribution from the computed probabilities\n",
    "    distribution = torch.distributions.Categorical(torch.tensor(probs))\n",
    "\n",
    "    # Sample from the distribution\n",
    "    indices = distribution.sample((N_BATCH,))\n",
    "\n",
    "    # Map indices to angles and reshape to (N_BATCH, 1)\n",
    "    phase_samples = angles_tensor[indices].reshape(N_BATCH, 1)\n",
    "\n",
    "    return phase_samples\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def continuous_biased_phases(N_BATCH, preferred_angle, sigma):\n",
    "    # Generate samples from a normal distribution using PyTorch\n",
    "    phase_samples = torch.normal(mean=preferred_angle, std=sigma, size=(N_BATCH, 1))\n",
    "\n",
    "    # Normalize angles to the range [0, 360)\n",
    "    phase_samples = phase_samples % 360\n",
    "\n",
    "    return phase_samples\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def continuous_bimodal_phases(N_BATCH, preferred_angle, sigma):\n",
    "    # Sample half from preferred_angle and half from preferred_angle + 180\n",
    "    half_batch = N_BATCH // 2\n",
    "\n",
    "    # Sample from preferred_angle\n",
    "    samples_1 = torch.normal(mean=preferred_angle, std=sigma, size=(half_batch, 1))\n",
    "\n",
    "    # Sample from preferred_angle + 180\n",
    "    samples_2 = torch.normal(mean=(preferred_angle + 180) % 360, std=sigma, size=(N_BATCH - half_batch, 1))\n",
    "\n",
    "    # Combine samples and wrap around 360\n",
    "    phase_samples = torch.cat((samples_1, samples_2), dim=0) % 360\n",
    "\n",
    "    return phase_samples\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def continuous_bimodal_phases(N_BATCH, reference, sigma):\n",
    "\n",
    "    ref_copy = reference.clone()\n",
    "    idx = torch.rand(N_BATCH, 1) > 0.5\n",
    "    ref_copy[idx] = (reference[idx] + 180.0) % 360.0\n",
    "    samples = ref_copy + sigma * torch.randn(N_BATCH, 1)\n",
    "\n",
    "    return samples % 360.0\n",
    "```\n",
    "\n",
    "Model\n",
    "=====\n",
    "\n",
    "``` ipython\n",
    "kwargs = {\n",
    "    'GAIN': 1.0,\n",
    "    'DURATION': 12.0,\n",
    "    'T_STEADY': 2,\n",
    "    'T_STIM_ON': [1.0, 5.0, 7.0, 11.0],\n",
    "    'T_STIM_OFF': [2.0, 6.0, 8.0, 12.0],\n",
    "    'I0': [1.0, -2.0, 1.0, -2.0],\n",
    "    'PHI0': [180.0, 180, 180, 180],\n",
    "    'SIGMA0': [1.0, 0.0, 1.0, 0.0],\n",
    "    'RANDOM_DELAY': 0,\n",
    "    'MIN_DELAY': 2,\n",
    "    'MAX_DELAY': 5,\n",
    "    'TAU_FAC': [2],\n",
    "    'IF_ADAPT': 1,\n",
    "    'A_ADAPT': 0.5,\n",
    "    'TAU_ADAPT': 100.0,\n",
    "    'IF_FF_ADAPT': 0,\n",
    "    'A_FF_ADAPT': 0.3,\n",
    "    'TAU_FF_ADAPT': 100.0,\n",
    "}\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "conf_name = \"train_odr_EI.yml\"\n",
    "DEVICE = 'cuda:1'\n",
    "# seed = np.random.randint(0, 1e6)\n",
    "\n",
    "seed = 3\n",
    "print('seed', seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "N_BATCH = 128 * 6\n",
    "print(N_BATCH)\n",
    "model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH, **kwargs)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model_state_dict = torch.load('../models/odr/odr_%d.pth' % seed)\n",
    "model.load_state_dict(model_state_dict);\n",
    "model.eval();\n",
    "```\n",
    "\n",
    "Simulating Consecutive Trials\n",
    "=============================\n",
    "\n",
    "``` ipython\n",
    "reference = 360.0 * torch.rand(N_BATCH, 1)\n",
    "sigma = 45\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = N_BATCH\n",
    "\n",
    "model.PHI0 = torch.zeros(size=(N_BATCH, len(model.I0), 1), device=DEVICE, dtype=torch.float)\n",
    "model.PHI0[:, 0] = continuous_bimodal_phases(N_BATCH, reference, sigma)\n",
    "model.PHI0[:, 2] = continuous_bimodal_phases(N_BATCH, reference, sigma)\n",
    "\n",
    "print(reference.shape, model.PHI0.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ff_input = model.init_ff_input()\n",
    "    rates_tensor = model.forward(ff_input=ff_input)\n",
    "    del ff_input\n",
    "    clear_cache()\n",
    "\n",
    "print(rates_tensor.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "num_epochs = 49\n",
    "\n",
    "rates_list = [rates_tensor.cpu().detach()]\n",
    "phi0_list = [model.PHI0.cpu().detach()]\n",
    "thresh_list = [model.thresh_last.cpu().detach()]\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # here we run two consecutive trial at a time (epoch)\n",
    "    with torch.no_grad():\n",
    "        model.PHI0 = torch.zeros(size=(N_BATCH, len(model.I0), 1), device=DEVICE, dtype=torch.float)\n",
    "        model.PHI0[:, 0] = continuous_bimodal_phases(N_BATCH, reference, sigma)\n",
    "        model.PHI0[:, 2] = continuous_bimodal_phases(N_BATCH, reference, sigma)\n",
    "\n",
    "        ff_input = model.init_ff_input()\n",
    "        rates = model.forward(ff_input=ff_input, IF_INIT=0)\n",
    "\n",
    "        phi0_list.append(model.PHI0.cpu().detach())\n",
    "        rates_list.append(rates.cpu().detach())\n",
    "        thresh_list.append(model.thresh_last.cpu().detach())\n",
    "\n",
    "        del ff_input, model.PHI0, rates\n",
    "        clear_cache()\n",
    "\n",
    "rates_list = np.stack(rates_list)\n",
    "thresh_list = np.stack(thresh_list)\n",
    "phi0_list = np.stack(phi0_list)\n",
    "\n",
    "print('rates', rates_list.shape, 'thresh', thresh_list.shape, 'phi0', phi0_list.shape, reference.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plt.hist(phi0_list[:, 0, 0, 0] * 180 / np.pi, bins=20)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plt.imshow(thresh_list[:,0, :750].T, aspect='auto', cmap='jet', vmin=0)\n",
    "plt.xlabel('Trial Pair')\n",
    "plt.ylabel('Neuron #')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "ax[0].scatter(rates_list[0, 0, -1], rates_list[-1, 0, -1])\n",
    "ax[1].scatter(thresh_list[0, 0], thresh_list[-1, 0])\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plt.plot(thresh_list[:, 0, :10])\n",
    "plt.xlabel('Trial Pair')\n",
    "plt.ylabel('Threshold')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Errors\n",
    "======\n",
    "\n",
    "Errors\n",
    "------\n",
    "\n",
    "``` ipython\n",
    "n_half = num_epochs // 4\n",
    "# n_half = 1\n",
    "phi0_ini =  phi0_list[:n_half]\n",
    "phi0_last = phi0_list[-n_half:]\n",
    "\n",
    "print(phi0_ini.shape, phi0_last.shape, reference.shape, rates_list.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "_, _, phi_ini = decode_bump_torch(rates_list[:n_half, ...], axis=-1)\n",
    "print(phi_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "_, _, phi_last = decode_bump_torch(rates_list[-n_half:, ...], axis=-1)\n",
    "print(phi_last.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_rel_tar_error(phi, phi0, reference):\n",
    "    target_loc = phi0[:, :, 2]  * 180.0 / np.pi\n",
    "\n",
    "    rel_loc = phi0[:, :, 0] - phi0[:, :, 2]\n",
    "    rel_loc = (rel_loc + np.pi) % (2 * np.pi) - np.pi\n",
    "    rel_loc *= 180 / np.pi\n",
    "\n",
    "    ref_loc = reference[np.newaxis] - phi0[:, :, 2]\n",
    "    ref_loc = (ref_loc + np.pi) % (2 * np.pi) - np.pi\n",
    "    ref_loc *= 180 / np.pi\n",
    "\n",
    "    error_curr = phi - phi0[:, :, 2]\n",
    "    error_curr = (error_curr + np.pi) % (2 * np.pi) - np.pi\n",
    "    error_curr *= 180 / np.pi\n",
    "\n",
    "    error_prev = phi - phi0[:, :,0]\n",
    "    error_prev = (error_prev + np.pi) % (2 * np.pi) - np.pi\n",
    "    error_prev *= 180 / np.pi\n",
    "\n",
    "    errors = np.stack((error_prev, error_curr), 1)\n",
    "\n",
    "    return np.vstack(target_loc), np.vstack(rel_loc), np.vstack(ref_loc), errors\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_end_point(model, errors):\n",
    "\n",
    "    stim_start_idx = ((model.start_indices - model.N_STEADY) / model.N_WINDOW).to(int).cpu().numpy()\n",
    "\n",
    "    end_point = []\n",
    "    for i, j in enumerate([1, 3]):\n",
    "        end_ = []\n",
    "        for k in range(errors.shape[2]):\n",
    "            idx = stim_start_idx[j][k]\n",
    "            end_.append(errors[:, i, k, idx])\n",
    "\n",
    "        end_point.append(end_)\n",
    "\n",
    "    return np.vstack(np.array(end_point).T).T\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "targ_ini, rel_ini, ref_ini, errors_ini = get_rel_tar_error(phi_ini, phi0_ini, reference * np.pi / 180.0)\n",
    "targ_last, rel_last, ref_last, errors_last = get_rel_tar_error(phi_last, phi0_last, reference * np.pi / 180.0)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(ref_ini.shape, rel_ini.shape, errors_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "end_point_ini = get_end_point(model, errors_ini)\n",
    "end_point_last = get_end_point(model, errors_last)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 3, figsize=[3*width, height])\n",
    "\n",
    "ax[0].hist(reference[:, 0])\n",
    "ax[1].hist(end_point_ini[1], bins='auto')\n",
    "ax[2].hist(end_point_last[1], bins='auto')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Biases\n",
    "======\n",
    "\n",
    "Serial Bias Curves\n",
    "------------------\n",
    "\n",
    "``` ipython\n",
    "print(targ_ini.shape, rel_ini.shape, ref_ini.shape, end_point_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "n_bins = 8\n",
    "data_ini = pd.DataFrame({'target_loc': targ_ini[:, -1], 'rel_loc': rel_ini[:, -1], 'ref_loc': ref_ini[:, -1], 'errors': end_point_ini[1]})\n",
    "data_last = pd.DataFrame({'target_loc': targ_last[:, -1], 'rel_loc': rel_last[:, -1], 'ref_loc': ref_last[:, -1], 'errors': end_point_last[1]})\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_correct_error(n_bins, df, error_type='rel_loc', thresh=25):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # 1. Threshold errors\n",
    "    if thresh is not None:\n",
    "        data = df[(df['errors'] >= -thresh) & (df['errors'] <= thresh)].copy()\n",
    "    else:\n",
    "        data = df.copy()\n",
    "\n",
    "    # 2. Bin target locations\n",
    "    bin_edges = np.linspace(0, 360, n_bins + 1)\n",
    "    data['bin_target'] = pd.cut(data['target_loc'], bins=bin_edges, include_lowest=True)\n",
    "    mean_errors_per_bin = data.groupby('bin_target')['errors'].mean()\n",
    "\n",
    "    # 3. Remove mean error per target location (for rel_loc)\n",
    "    if error_type == 'rel_loc':\n",
    "        data['adjusted_errors'] = data['errors'] - data['bin_target'].map(mean_errors_per_bin).astype(float)\n",
    "    else:\n",
    "        data['adjusted_errors'] = data['errors']\n",
    "\n",
    "    # 4. Bin by error_type for both full versions\n",
    "    data['bin_error'] = pd.cut(data[error_type], bins=n_bins)\n",
    "    bin_error = data.groupby('bin_error')['adjusted_errors'].agg(['mean', 'sem']).reset_index()\n",
    "    edges = bin_error['bin_error'].cat.categories\n",
    "    centers = (edges.left + edges.right) / 2\n",
    "\n",
    "    # 5. Flipped error absolute analysis\n",
    "    if error_type == 'rel_loc':\n",
    "        # Bin abs(rel_loc) from 0 to 180\n",
    "        data['error_abs'] = np.abs(data[error_type])\n",
    "        data['bin_error_abs'] = pd.cut(data['error_abs'], bins=n_bins, include_lowest=True)\n",
    "        # Flip so all directions use same sign\n",
    "        data['adjusted_errors_abs'] = data['adjusted_errors'] * np.sign(data[error_type])\n",
    "    else:\n",
    "        # Bin abs(ref_loc) from 0 to 90\n",
    "        data['error_abs'] = np.abs(data[error_type])\n",
    "        data = data[data['error_abs'] <= 90.0]  # Only 0-90\n",
    "        data['bin_error_abs'] = pd.cut(data['error_abs'], bins=n_bins, include_lowest=True)\n",
    "        # Flip so all directions use same sign for ref_loc\n",
    "        data['adjusted_errors_abs'] = data['adjusted_errors'] * np.sign(data[error_type])\n",
    "\n",
    "    bin_error_abs = data.groupby('bin_error_abs')['adjusted_errors_abs'].agg(['mean', 'sem']).reset_index()\n",
    "    edges_abs = bin_error_abs['bin_error_abs'].cat.categories\n",
    "    centers_abs = (edges_abs.left + edges_abs.right) / 2\n",
    "\n",
    "    return centers, bin_error, centers_abs, bin_error_abs\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "centers_ini, bin_rel_ini, centers_abs_ini, bin_rel_abs_ini = get_correct_error(n_bins, data_ini)\n",
    "centers_last, bin_rel_last, centers_abs_last, bin_rel_abs_last = get_correct_error(n_bins, data_last)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].plot(centers_ini, bin_rel_ini['mean'], 'r', label='First half')\n",
    "ax[0].fill_between(centers_ini, bin_rel_ini['mean'] - bin_rel_ini['sem'], bin_rel_ini['mean'] + bin_rel_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[0].plot(centers_last, bin_rel_last['mean'], 'b', label='Last half')\n",
    "ax[0].fill_between(centers_last, bin_rel_last['mean'] - bin_rel_last['sem'], bin_rel_last['mean'] + bin_rel_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[0].axhline(0, color='k', linestyle=\":\")\n",
    "ax[0].set_xlabel('Rel. Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "ax[0].set_xticks(np.linspace(-180, 180, 5))\n",
    "\n",
    "ax[1].plot(centers_abs_ini, bin_rel_abs_ini['mean'], 'r', label='First half')\n",
    "ax[1].fill_between(centers_abs_ini, bin_rel_abs_ini['mean'] - bin_rel_abs_ini['sem'], bin_rel_abs_ini['mean'] + bin_rel_abs_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[1].plot(centers_abs_last, bin_rel_abs_last['mean'], 'b', label='Last half')\n",
    "ax[1].fill_between(centers_abs_last, bin_rel_abs_last['mean'] - bin_rel_abs_last['sem'], bin_rel_abs_last['mean'] + bin_rel_abs_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[1].axhline(0, color='k', linestyle=\":\")\n",
    "ax[1].set_xlabel('Rel. Loc. (°)')\n",
    "ax[1].set_ylabel('Flip. Error (°)')\n",
    "ax[1].legend(fontsize=12)\n",
    "ax[1].set_xticks(np.linspace(0, 180, 3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "centers_ref_ini, bin_ref_ini, centers_ref_abs_ini, bin_ref_abs_ini = get_correct_error(n_bins, data_ini, error_type='ref_loc')\n",
    "centers_ref_last, bin_ref_last, centers_ref_abs_last, bin_ref_abs_last = get_correct_error(n_bins, data_last, error_type='ref_loc')\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].plot(centers_ref_ini, bin_ref_ini['mean'], 'r', label='First half')\n",
    "ax[0].fill_between(centers_ref_ini, bin_ref_ini['mean'] - bin_ref_ini['sem'], bin_ref_ini['mean'] + bin_ref_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[0].plot(centers_ref_last, bin_ref_last['mean'], 'b', label='Last half')\n",
    "ax[0].fill_between(centers_ref_last, bin_ref_last['mean'] - bin_ref_last['sem'], bin_ref_last['mean'] + bin_ref_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[0].axhline(0, color='k', linestyle=\":\")\n",
    "ax[0].set_xlabel('Ref. Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "ax[0].set_xticks(np.linspace(-180, 180, 5))\n",
    "\n",
    "ax[1].plot(centers_ref_abs_ini, bin_ref_abs_ini['mean'], 'r', label='First half')\n",
    "ax[1].fill_between(centers_ref_abs_ini, bin_ref_abs_ini['mean'] - bin_ref_abs_ini['sem'], bin_ref_abs_ini['mean'] + bin_ref_abs_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[1].plot(centers_ref_abs_last, bin_ref_abs_last['mean'], 'b', label='Last half')\n",
    "ax[1].fill_between(centers_ref_abs_last, bin_ref_abs_last['mean'] - bin_ref_abs_last['sem'], bin_ref_abs_last['mean'] + bin_ref_abs_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[1].axhline(0, color='k', linestyle=\":\")\n",
    "ax[1].set_xlabel('Ref. Loc. (°)')\n",
    "ax[1].set_ylabel('Flip. Error (°)')\n",
    "ax[1].legend(fontsize=12)\n",
    "ax[1].set_xticks(np.linspace(0, 90, 3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Bias Evolution along a session\n",
    "------------------------------\n",
    "\n",
    "``` ipython\n",
    "_, _, phi_list = decode_bump_torch(rates_list, axis=-1)\n",
    "print(phi_list.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(phi0_list.shape, reference.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "cmap = plt.get_cmap('Blues')\n",
    "colors = [cmap((i+1)/ phi_list.shape[0]) for i in range(phi_list.shape[0])]\n",
    "\n",
    "n_bins = 8\n",
    "\n",
    "serial_list = []\n",
    "ref_list = []\n",
    "\n",
    "for i in range(phi_list.shape[0]):\n",
    "    targ_trial, rel_trial, ref_trial, errors_trial = get_rel_tar_error(phi_list[i, np.newaxis], phi0_list[i, np.newaxis], reference * np.pi / 180.0)\n",
    "    end_point_trial = get_end_point(model, errors_trial)\n",
    "\n",
    "    # print(targ_trial.shape, rel_trial.shape, ref_trial.shape, errors_trial.shape, end_point_trial.shape)\n",
    "\n",
    "    data = pd.DataFrame({'target_loc': targ_trial[:, -1], 'rel_loc': rel_trial[:, -1], 'ref_loc': ref_trial[:, -1], 'errors': end_point_trial[1]})\n",
    "\n",
    "    centers, bin_rel, centers_abs, bin_rel_abs = get_correct_error(n_bins, data)\n",
    "    centers, bin_ref, centers_abs, bin_ref_abs = get_correct_error(n_bins, data, error_type='ref_loc')\n",
    "\n",
    "    plt.plot(centers, bin_ref['mean'], color=colors[i])\n",
    "\n",
    "    idx_max = np.argmax(abs(bin_rel_abs['mean']))\n",
    "    serial_max = bin_rel_abs['mean'][idx_max]\n",
    "    serial_std = bin_rel_abs['sem'][idx_max]\n",
    "\n",
    "    serial_list.append([serial_max, serial_std])\n",
    "\n",
    "    idx_max = np.argmax(abs(bin_ref_abs['mean']))\n",
    "    ref_max = bin_ref_abs['mean'][idx_max]\n",
    "    ref_std = bin_ref_abs['sem'][idx_max]\n",
    "\n",
    "    ref_list.append([ref_max, ref_std])\n",
    "\n",
    "serial_list = np.array(serial_list).T\n",
    "ref_list = np.array(ref_list).T\n",
    "print(serial_list.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "delay_duration = 100\n",
    "xdelay = np.linspace(0, delay_duration, serial_list.shape[1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "\n",
    "s0 = 5\n",
    "ax[0].plot(xdelay, gaussian_filter1d(serial_list[0], s0), '-')\n",
    "ax[0].fill_between(xdelay, gaussian_filter1d(serial_list[0] - serial_list[1], s0), gaussian_filter1d(serial_list[0] + serial_list[1], s0), color='b', alpha=0.2)\n",
    "ax[0].axhline(0, ls='--', color='k')\n",
    "\n",
    "ax[0].set_xlabel('Trial #')\n",
    "ax[0].set_ylabel('Serial Bias (°)')\n",
    "\n",
    "ax[1].plot(xdelay, gaussian_filter1d(ref_list[0], s0), '-')\n",
    "ax[1].fill_between(xdelay, gaussian_filter1d(ref_list[0] - ref_list[1], s0), gaussian_filter1d(ref_list[0] + ref_list[1], s0), color='b', alpha=0.2)\n",
    "ax[1].axhline(0, ls='--', color='k')\n",
    "\n",
    "ax[1].set_xlabel('Trial #')\n",
    "ax[1].set_ylabel('Ref. Bias (°)')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Decoder\n",
    "=======\n",
    "\n",
    "Pref loc\n",
    "--------\n",
    "\n",
    "``` ipython\n",
    "from astropy.stats.circstats import circmean\n",
    "\n",
    "def get_pref_locs(nbins, mean_rates, angles):\n",
    "    pref_locs = []\n",
    "\n",
    "    bins = np.linspace(0, 2*np.pi, nbins + 1)\n",
    "    counts, _ = np.histogram(angles, bins=bins)\n",
    "    bin_indices = np.digitize(angles, bins) - 1\n",
    "\n",
    "    normalized_rates = np.zeros_like(mean_rates, dtype=float)\n",
    "\n",
    "    for i in range(mean_rates.shape[0]):\n",
    "            bin_index = bin_indices[i]\n",
    "            if 0 <= bin_index < nbins:  # Ensure index is within valid range\n",
    "                    normalized_rates[i] = mean_rates[i] / counts[bin_index] if counts[bin_index] > 0 else 0\n",
    "\n",
    "    pref_locs = []\n",
    "    for i in range(mean_rates.shape[1]):\n",
    "            pref_locs.append(circmean(angles, weights=normalized_rates[:, i], axis=0))\n",
    "\n",
    "    pref_locs = np.array(pref_locs) # + 2.0 * np.pi) % (2.0 * np.pi)\n",
    "\n",
    "    return pref_locs\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "from astropy.stats.circstats import circmean\n",
    "import numpy as np\n",
    "\n",
    "def get_pref_locs(nbins, mean_rates, angles):\n",
    "    # Bin the angles\n",
    "    bins = np.linspace(0, 2*np.pi, nbins + 1)\n",
    "    bin_indices = np.digitize(angles, bins) - 1\n",
    "\n",
    "    # For each bin: how many samples fall there\n",
    "    counts = np.bincount(bin_indices, minlength=nbins)\n",
    "    # Avoid division by zero\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        weights = 1.0 / np.where(counts > 0, counts, 1)  # [nbins]\n",
    "        weights[counts == 0] = 0\n",
    "\n",
    "    # For each sample, apply weight by the bin it's in:\n",
    "    sample_weights = weights[bin_indices]  # [n_samples]\n",
    "\n",
    "    # Now, for each neuron:\n",
    "    pref_locs = []\n",
    "    for n in range(mean_rates.shape[1]):\n",
    "        # Weight mean_rates[:, n] by sample_weights\n",
    "        w = mean_rates[:, n] * sample_weights\n",
    "        # circmean over all angles, weighted\n",
    "        mu = circmean(angles, weights=w, axis=0)\n",
    "        pref_locs.append(mu % (2*np.pi))\n",
    "    return np.array(pref_locs)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(rates_list.shape, phi0_list.shape)\n",
    "stim_start_idx = ((model.start_indices - model.N_STEADY) / model.N_WINDOW).to(int).cpu().numpy()\n",
    "stim_end_idx = ((model.end_indices - model.N_STEADY) / model.N_WINDOW).to(int).cpu().numpy()\n",
    "print(stim_start_idx.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(phi0_list.shape)\n",
    "phi0_ini = np.vstack(phi0_list[:n_half, ..., 0])\n",
    "phi0_last = np.vstack(phi0_list[-n_half:, ..., 0])\n",
    "print(phi0_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "mean_rates_ini = np.vstack(rates_list[:n_half, :, stim_start_idx[2, 0]:stim_end_idx[2, 0], :].mean(2))\n",
    "mean_rates_last = np.vstack(rates_list[-n_half:, :, stim_start_idx[2,0]:stim_end_idx[2, 0], :].mean(2))\n",
    "print(mean_rates_ini.shape, phi0_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "nbins = 120\n",
    "pref_locs_ini = get_pref_locs(nbins, mean_rates_ini, phi0_ini[:, 2])\n",
    "pref_locs_last = get_pref_locs(nbins, mean_rates_last, phi0_last[:, 2])\n",
    "print(pref_locs_ini.shape, pref_locs_last.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "idx_ini = np.argsort(pref_locs_ini)\n",
    "idx_last = np.argsort(pref_locs_last)\n",
    "```\n",
    "\n",
    "Decoding Bump Location\n",
    "----------------------\n",
    "\n",
    "``` ipython\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "def weights_from_pdf(angles_rad, bandwidth=0.5, beta=0.5):\n",
    "    angles_rad_2d = angles_rad.reshape(-1, 1)\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth).fit(angles_rad_2d)\n",
    "    log_dens = kde.score_samples(angles_rad_2d)\n",
    "    densities = np.exp(log_dens)\n",
    "\n",
    "    if beta == 0:\n",
    "        weights = 1 / (np.exp(log_dens) + 1e-8)\n",
    "        weights /= weights.mean()\n",
    "    else:\n",
    "        # Softmax-normalized inverse density (avoids extreme weights)\n",
    "        # Temperature parameter: lower beta → more uniform weighting\n",
    "        weights = np.exp(-beta * densities)\n",
    "        weights = weights / weights.mean()  # Normalize\n",
    "\n",
    "    return weights\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def weights_from_hist(angles_rad, n_bins=32):\n",
    "     hist, bin_edges = np.histogram(angles_rad, bins=n_bins)\n",
    "     bin_indices = np.digitize(angles_rad, bins=bin_edges[:-1], right=True)\n",
    "\n",
    "     weights = 1.0 / (np.sqrt(hist[bin_indices - 1]) + 1e-6)\n",
    "     weights /= np.mean(weights)\n",
    "\n",
    "     return weights\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, MultiTaskLassoCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "class AngleDecoder(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, penalty=None, scaler=True, class_weight=None):\n",
    "        self.penalty = penalty\n",
    "        self.scaler = scaler\n",
    "        self.class_weight = class_weight\n",
    "        self.reg_ = None\n",
    "        self.pipe_ = None\n",
    "        self._initialize_regressor()\n",
    "\n",
    "    def _initialize_regressor(self):\n",
    "        if self.penalty is None:\n",
    "            self.reg_ = LinearRegression()\n",
    "        elif self.penalty == 'l2':\n",
    "            self.reg_ = RidgeCV()\n",
    "        elif self.penalty == 'l1':\n",
    "            self.reg_ = MultiTaskLassoCV()\n",
    "        elif self.penalty == 'multi':\n",
    "            self.reg_ = MultiOutputRegressor(LinearSVR())\n",
    "        elif self.penalty == 'rbf':\n",
    "            self.reg_ = MultiOutputRegressor(SVR(kernel='rbf', C=1e3, gamma=0.1))\n",
    "\n",
    "        pipe = []\n",
    "        if self.scaler:\n",
    "            pipe.append(('scaler', StandardScaler()))\n",
    "\n",
    "        pipe.append(('reg', self.reg_))\n",
    "\n",
    "        self.pipe_ = Pipeline(pipe)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Y = np.column_stack((np.cos(y), np.sin(y)))\n",
    "\n",
    "        weights = None\n",
    "        if self.class_weight=='balanced' or self.class_weight is not None:\n",
    "            # weights = weights_from_hist(angles, n_bins=32)\n",
    "            weights = weights_from_pdf(y, bandwidth=1.0, beta=0.1)\n",
    "\n",
    "        self.pipe_.fit(X, Y, reg__sample_weight=weights)\n",
    "\n",
    "        if self.penalty == 'rbf':\n",
    "            pref_locs = np.nan\n",
    "        else:\n",
    "            pred_cos = self.pipe_.named_steps['reg'].coef_[0]\n",
    "            pred_sin = self.pipe_.named_steps['reg'].coef_[1]\n",
    "            pref_locs = np.arctan2(pred_sin, pred_cos)\n",
    "\n",
    "        self.pref_locs_ = (pref_locs + 2.0 * np.pi) % (2.0 * np.pi)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = self.pipe_.predict(X)\n",
    "        pred_cos, pred_sin = preds[:, 0], preds[:, 1]\n",
    "        pred_loc = np.arctan2(pred_sin, pred_cos)\n",
    "        return (pred_loc + 2.0 * np.pi) % (2.0 * np.pi)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print('rates', rates_list.shape, 'phi0', phi0_list.shape)\n",
    "```\n",
    "\n",
    "Decoding trial by trial for all session\n",
    "\n",
    "\\#+begin<sub>x²src</sub> ipython from mne.decoding import\n",
    "SlidingEstimator, GeneralizingEstimator from\n",
    "sklearn.model<sub>selection</sub> import cross<sub>valpredict</sub>,\n",
    "LeaveOneOut\n",
    "\n",
    "regressor = AngleDecoder(penalty=None, scaler=True,\n",
    "class<sub>weight</sub>='balanced') mne<sub>estimator</sub> =\n",
    "SlidingEstimator(regressor, n<sub>jobs</sub>=-1, verbose=False)\n",
    "\n",
    "half<sub>trial</sub> = rates<sub>list</sub>.shape\\[2\\] // 2\n",
    "\n",
    "pred<sub>list</sub> = \\[\\] for epoch in tqdm(\\[0, -1\\]):\n",
    "\n",
    "rates = rates<sub>list</sub>\\[epoch, :,\n",
    ":half<sub>trial</sub>\\].swapaxes(1, 2) angles =\n",
    "phi0<sub>list</sub>\\[epoch, :, 0, 0\\]\n",
    "\n",
    "rates = rates<sub>list</sub>\\[epoch, :,\n",
    "half<sub>trial</sub>:\\].swapaxes(1, 2) angles =\n",
    "phi0<sub>list</sub>\\[epoch, :, 2, 0\\]\n",
    "\n",
    "pred<sub>list</sub> = np.array(pred<sub>list</sub>) print('',\n",
    "pred<sub>list</sub>.shape)\n",
    "\n",
    "\\#+end<sub>src</sub>\n",
    "\n",
    "``` example\n",
    "100% 2/2 [00:00<00:00, 35544.95it/s]\n",
    " (0,)\n",
    "```\n",
    "\n",
    ":\n",
    "\n",
    "Decoding session by session for all trial\n",
    "\n",
    "``` ipython\n",
    "from mne.decoding import SlidingEstimator, GeneralizingEstimator\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut\n",
    "\n",
    "regressor = AngleDecoder(penalty=None, scaler=True, class_weight=True)\n",
    "mne_estimator = SlidingEstimator(regressor, n_jobs=64, verbose=False)\n",
    "# mne_estimator = GeneralizingEstimator(regressor, n_jobs=-1, verbose=False)\n",
    "\n",
    "half_trial = rates_list.shape[2] // 2\n",
    "N_SESSIONS = 768\n",
    "\n",
    "pred_list = []\n",
    "for session in tqdm(range(N_SESSIONS)):\n",
    "\n",
    "    rates = rates_list[:, session, :half_trial].swapaxes(1, 2)\n",
    "    angles = phi0_list[:, session, 0, 0]\n",
    "    # pred_locs1 = cross_val_predict(mne_estimator, rates, angles, cv=5, n_jobs=64)\n",
    "\n",
    "    rates = rates_list[:, session, half_trial:].swapaxes(1, 2)\n",
    "    angles = phi0_list[:, session, 2, 0]\n",
    "    # pred_locs2 = cross_val_predict(mne_estimator, rates, angles, cv=5, n_jobs=64)\n",
    "\n",
    "    # pred_locs = np.concatenate((pred_locs1, pred_locs2), axis=-1)\n",
    "    pred_locs = None\n",
    "    pred_list.append(pred_locs)\n",
    "\n",
    "pred_list = np.array(pred_list)\n",
    "# pred_list = pred_list.swapaxes(0,1)\n",
    "# pkl_save(pred_list, './pred_list')\n",
    "print('\\n', pred_list.shape)\n",
    "```\n",
    "\n",
    ":\n",
    "\n",
    "``` ipython\n",
    "pred_list = pkl_load('./pred_list')\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import matplotlib.cm as cm\n",
    "colors = cm.tab10.colors  # or cm.viridis.colors, etc.\n",
    "xtime = np.linspace(0, model.DURATION, 121)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=[3*width, height])\n",
    "\n",
    "for i in range(5):\n",
    "    idx = np.random.randint(0, angles.shape[0])\n",
    "    ax[0].plot(xtime, pred_list[0, idx] * 180 / np.pi, color=colors[i])\n",
    "\n",
    "    ax[0].axhline(phi0_list[0, idx, 0, 0] * 180 / np.pi, xmax=0.5, ls='--', color=colors[i])\n",
    "    ax[0].axhline(phi0_list[0, idx, 2, 0] * 180 / np.pi, xmin=0.5, ls='--', color=colors[i])\n",
    "\n",
    "add_vlines(model, ax[0])\n",
    "ax[0].set_ylabel('Prediction (°)')\n",
    "ax[0].set_xlabel('Time (s)')\n",
    "\n",
    "error_prev = (pred_list[0, :] - phi0_list[0, :N_SESSIONS, 0]).T\n",
    "error_prev = (error_prev + np.pi) % (2 * np.pi) - np.pi\n",
    "error_prev *= 180 / np.pi\n",
    "\n",
    "ax[1].plot(xtime, error_prev, alpha=0.5)\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "ax[1].set_ylabel('Prev. Error (°)')\n",
    "\n",
    "error_curr = (pred_list[0, :] - phi0_list[0, :N_SESSIONS, 2]).T\n",
    "error_curr = (error_curr + np.pi) % (2 * np.pi) - np.pi\n",
    "error_curr *= 180 / np.pi\n",
    "\n",
    "ax[2].plot(xtime, error_curr, alpha=0.5)\n",
    "ax[2].set_xlabel('Time (s)')\n",
    "ax[2].set_ylabel('Curr. Error (°)')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Errors\n",
    "------\n",
    "\n",
    "``` ipython\n",
    "n_half = num_epochs // 2\n",
    "# n_half = 5\n",
    "\n",
    "phi0_ini =  phi0_list[:n_half, :N_SESSIONS]\n",
    "phi0_last = phi0_list[-n_half:, :N_SESSIONS]\n",
    "\n",
    "phi_ini =  (pred_list[:n_half])\n",
    "phi_last = (pred_list[-n_half:])\n",
    "\n",
    "refs = reference[:N_SESSIONS] * np.pi / 180.0\n",
    "print(phi_ini.shape, phi0_last.shape, refs.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "targ_ini, rel_ini, ref_ini, errors_ini = get_rel_tar_error(phi_ini, phi0_ini, refs)\n",
    "targ_last, rel_last, ref_last, errors_last = get_rel_tar_error(phi_last, phi0_last, refs)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(ref_ini.shape, rel_ini.shape, errors_ini.shape)\n",
    "plt.plot(errors_ini[0, 1, :20].T)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "end_point_ini = get_end_point(model, errors_ini)\n",
    "end_point_last = get_end_point(model, errors_last)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 3, figsize=[3*width, height])\n",
    "\n",
    "ax[0].hist(reference[:, 0])\n",
    "ax[0].set_xlabel('References')\n",
    "\n",
    "ax[1].hist(end_point_ini[1], bins=100)\n",
    "ax[1].set_xlabel('Prev. Error (°)')\n",
    "\n",
    "ax[2].hist(end_point_last[1], bins=100)\n",
    "ax[2].set_xlabel('Curr. Error (°)')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Biases\n",
    "------\n",
    "\n",
    "``` ipython\n",
    "print(targ_ini.shape, rel_ini.shape, ref_ini.shape, end_point_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "n_bins = 8\n",
    "data_ini = pd.DataFrame({'target_loc': targ_ini[:, -1], 'rel_loc': rel_ini[:, -1], 'ref_loc': ref_ini[:, -1], 'errors': end_point_ini[1]})\n",
    "data_last = pd.DataFrame({'target_loc': targ_last[:, -1], 'rel_loc': rel_last[:, -1], 'ref_loc': ref_last[:, -1], 'errors': end_point_last[1]})\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "centers_ini, bin_rel_ini, centers_abs_ini, bin_rel_abs_ini = get_correct_error(n_bins, data_ini)\n",
    "centers_last, bin_rel_last, centers_abs_last, bin_rel_abs_last = get_correct_error(n_bins, data_last)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].plot(centers_ini, bin_rel_ini['mean'], 'r', label='First half')\n",
    "ax[0].fill_between(centers_ini, bin_rel_ini['mean'] - bin_rel_ini['sem'], bin_rel_ini['mean'] + bin_rel_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[0].plot(centers_last, bin_rel_last['mean'], 'b', label='Last half')\n",
    "ax[0].fill_between(centers_last, bin_rel_last['mean'] - bin_rel_last['sem'], bin_rel_last['mean'] + bin_rel_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[0].axhline(0, color='k', linestyle=\":\")\n",
    "ax[0].set_xlabel('Rel. Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "ax[0].set_xticks(np.linspace(-180, 180, 5))\n",
    "\n",
    "ax[1].plot(centers_abs_ini, bin_rel_abs_ini['mean'], 'r', label='First half')\n",
    "ax[1].fill_between(centers_abs_ini, bin_rel_abs_ini['mean'] - bin_rel_abs_ini['sem'], bin_rel_abs_ini['mean'] + bin_rel_abs_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[1].plot(centers_abs_last, bin_rel_abs_last['mean'], 'b', label='Last half')\n",
    "ax[1].fill_between(centers_abs_last, bin_rel_abs_last['mean'] - bin_rel_abs_last['sem'], bin_rel_abs_last['mean'] + bin_rel_abs_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[1].axhline(0, color='k', linestyle=\":\")\n",
    "ax[1].set_xlabel('Rel. Loc. (°)')\n",
    "ax[1].set_ylabel('Flip. Error (°)')\n",
    "ax[1].legend(fontsize=12)\n",
    "ax[1].set_xticks(np.linspace(0, 180, 3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "centers_ref_ini, bin_ref_ini, centers_ref_abs_ini, bin_ref_abs_ini = get_correct_error(n_bins, data_ini, error_type='ref_loc')\n",
    "centers_ref_last, bin_ref_last, centers_ref_abs_last, bin_ref_abs_last = get_correct_error(n_bins, data_last, error_type='ref_loc')\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].plot(centers_ref_ini, bin_ref_ini['mean'], 'r', label='First half')\n",
    "ax[0].fill_between(centers_ref_ini, bin_ref_ini['mean'] - bin_ref_ini['sem'], bin_ref_ini['mean'] + bin_ref_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[0].plot(centers_ref_last, bin_ref_last['mean'], 'b', label='Last half')\n",
    "ax[0].fill_between(centers_ref_last, bin_ref_last['mean'] - bin_ref_last['sem'], bin_ref_last['mean'] + bin_ref_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[0].axhline(0, color='k', linestyle=\":\")\n",
    "ax[0].set_xlabel('Ref. Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "ax[0].set_xticks(np.linspace(-180, 180, 5))\n",
    "\n",
    "ax[1].plot(centers_ref_abs_ini, bin_ref_abs_ini['mean'], 'r', label='First half')\n",
    "ax[1].fill_between(centers_ref_abs_ini, bin_ref_abs_ini['mean'] - bin_ref_abs_ini['sem'], bin_ref_abs_ini['mean'] + bin_ref_abs_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[1].plot(centers_ref_abs_last, bin_ref_abs_last['mean'], 'b', label='Last half')\n",
    "ax[1].fill_between(centers_ref_abs_last, bin_ref_abs_last['mean'] - bin_ref_abs_last['sem'], bin_ref_abs_last['mean'] + bin_ref_abs_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[1].axhline(0, color='k', linestyle=\":\")\n",
    "ax[1].set_xlabel('Ref. Loc. (°)')\n",
    "ax[1].set_ylabel('Flip. Error (°)')\n",
    "ax[1].legend(fontsize=12)\n",
    "ax[1].set_xticks(np.linspace(0, 90, 3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Bias Evolution along a session\n",
    "------------------------------\n",
    "\n",
    "``` ipython\n",
    "#_, _, phi_list = decode_bump_torch(rates_list, axis=-1)\n",
    "# print(phi_list.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(phi0_list.shape, reference.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "n_bins = 8\n",
    "\n",
    "serial_list = []\n",
    "ref_list = []\n",
    "\n",
    "for i in range(phi_list.shape[0]):\n",
    "    targ_trial, rel_trial, ref_trial, errors_trial = get_rel_tar_error(pred_list[i, np.newaxis], phi0_list[i, np.newaxis], reference * np.pi / 180.0)\n",
    "    end_point_trial = get_end_point(model, errors_trial)\n",
    "\n",
    "    # print(targ_trial.shape, rel_trial.shape, ref_trial.shape, errors_trial.shape, end_point_trial.shape)\n",
    "\n",
    "    data = pd.DataFrame({'target_loc': targ_trial[:, -1], 'rel_loc': rel_trial[:, -1], 'ref_loc': ref_trial[:, -1], 'errors': end_point_trial[1]})\n",
    "\n",
    "    centers, bin_rel, centers_abs, bin_rel_abs = get_correct_error(n_bins, data)\n",
    "    centers, bin_ref, centers_abs, bin_ref_abs = get_correct_error(n_bins, data, error_type='ref_loc')\n",
    "\n",
    "    idx_max = np.argmax(abs(bin_rel_abs['mean']))\n",
    "    serial_max = bin_rel_abs['mean'][idx_max]\n",
    "    serial_std = bin_rel_abs['sem'][idx_max]\n",
    "\n",
    "    serial_list.append([serial_max, serial_std])\n",
    "\n",
    "    idx_max = np.argmax(abs(bin_ref_abs['mean']))\n",
    "    ref_max = bin_ref_abs['mean'][idx_max]\n",
    "    ref_std = bin_ref_abs['sem'][idx_max]\n",
    "\n",
    "    ref_list.append([ref_max, ref_std])\n",
    "\n",
    "serial_list = np.array(serial_list).T\n",
    "ref_list = np.array(ref_list).T\n",
    "print(serial_list.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "delay_duration = 100\n",
    "xdelay = np.linspace(0, delay_duration, serial_list.shape[1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "\n",
    "s0 = 5\n",
    "ax[0].plot(xdelay, gaussian_filter1d(serial_list[0], s0), '-')\n",
    "ax[0].fill_between(xdelay, gaussian_filter1d(serial_list[0] - serial_list[1], s0), gaussian_filter1d(serial_list[0] + serial_list[1], s0), color='b', alpha=0.2)\n",
    "\n",
    "ax[0].set_xlabel('Trial #')\n",
    "ax[0].set_ylabel('Serial Bias (°)')\n",
    "\n",
    "ax[1].plot(xdelay, gaussian_filter1d(ref_list[0], s0), '-')\n",
    "ax[1].fill_between(xdelay, gaussian_filter1d(ref_list[0] - ref_list[1], s0), gaussian_filter1d(ref_list[0] + ref_list[1], s0), color='b', alpha=0.2)\n",
    "\n",
    "ax[1].set_xlabel('Trial #')\n",
    "ax[1].set_ylabel('Ref. Bias (°)')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
