{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Settings\n",
    "=================\n",
    "\n",
    "``` ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "%run ../../../notebooks/setup.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "pal = sns.color_palette(\"tab10\")\n",
    "```\n",
    "\n",
    "Imports\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from scipy.stats import binned_statistic\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from time import perf_counter\n",
    "from scipy.stats import circmean\n",
    "\n",
    "from src.network import Network\n",
    "from src.plot_utils import plot_con\n",
    "from src.decode import decode_bump, circcvl, decode_bump_torch\n",
    "from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "def pkl_save(obj, name, path=\".\"):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    destination = path + \"/\" + name + \".pkl\"\n",
    "    print(\"saving to\", destination)\n",
    "    pkl.dump(obj, open(destination, \"wb\"))\n",
    "\n",
    "\n",
    "def pkl_load(name, path=\".\"):\n",
    "    source = path + \"/\" + name + '.pkl'\n",
    "    print('loading from', source)\n",
    "    return pkl.load(open( source, \"rb\"))\n",
    "\n",
    "```\n",
    "\n",
    "Helpers\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "def map2center(angles):\n",
    "    \"\"\"Map angles from [0, 2π] to [-π, π] using PyTorch tensors.\"\"\"\n",
    "    return np.where(angles > np.pi, angles - 2 * np.pi, angles)\n",
    "\n",
    "def map2pos(angles):\n",
    "    \"\"\"Map angles from [-π, π] to [0, 2π] using PyTorch tensors.\"\"\"\n",
    "    return np.where(angles < 0, angles + 2 * np.pi, angles)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def maptens2center(angles):\n",
    "    \"\"\"Map angles from [0, 2π] to [-π, π] using PyTorch tensors.\"\"\"\n",
    "    return torch.where(angles > torch.pi, angles - 2 * torch.pi, angles)\n",
    "\n",
    "def maptens2pos(angles):\n",
    "    \"\"\"Map angles from [-π, π] to [0, 2π] using PyTorch tensors.\"\"\"\n",
    "    return torch.where(angles < 0, angles + 2 * torch.pi, angles)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def add_vlines(model, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        for i in range(len(model.T_STIM_ON)):\n",
    "            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)\n",
    "    else:\n",
    "        for i in range(len(model.T_STIM_ON)):\n",
    "            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def generate_weighted_phase_samples(N_BATCH, angles, preferred_angle, sigma):\n",
    "    # Convert angles list to a tensor\n",
    "    angles_tensor = torch.tensor(angles)\n",
    "\n",
    "    # Calculate Gaussian probability distribution centered at preferred_angle\n",
    "    probs = np.exp(-0.5 * ((angles - preferred_angle) / sigma) ** 2)\n",
    "    probs /= probs.sum()  # Normalize to get probabilities\n",
    "\n",
    "    # Create a categorical distribution from the computed probabilities\n",
    "    distribution = torch.distributions.Categorical(torch.tensor(probs))\n",
    "\n",
    "    # Sample from the distribution\n",
    "    indices = distribution.sample((N_BATCH,))\n",
    "\n",
    "    # Map indices to angles and reshape to (N_BATCH, 1)\n",
    "    phase_samples = angles_tensor[indices].reshape(N_BATCH, 1)\n",
    "\n",
    "    return phase_samples\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def continuous_biased_phases(N_BATCH, preferred_angle, sigma):\n",
    "    # Generate samples from a normal distribution using PyTorch\n",
    "    phase_samples = torch.normal(mean=preferred_angle, std=sigma, size=(N_BATCH, 1))\n",
    "\n",
    "    # Normalize angles to the range [0, 360)\n",
    "    phase_samples = phase_samples % 360\n",
    "\n",
    "    return phase_samples\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def continuous_bimodal_phases(N_BATCH, preferred_angle, sigma):\n",
    "    # Sample half from preferred_angle and half from preferred_angle + 180\n",
    "    half_batch = N_BATCH // 2\n",
    "\n",
    "    # Sample from preferred_angle\n",
    "    samples_1 = torch.normal(mean=preferred_angle, std=sigma, size=(half_batch, 1))\n",
    "\n",
    "    # Sample from preferred_angle + 180\n",
    "    samples_2 = torch.normal(mean=(preferred_angle + 180) % 360, std=sigma, size=(N_BATCH - half_batch, 1))\n",
    "\n",
    "    # Combine samples and wrap around 360\n",
    "    phase_samples = torch.cat((samples_1, samples_2), dim=0) % 360\n",
    "\n",
    "    return phase_samples\n",
    "\n",
    "# Example usage\n",
    "# N_BATCH = 500\n",
    "# preferred_angle = 45\n",
    "# sigma = 45\n",
    "\n",
    "# samples = continuous_bimodal_phases(N_BATCH, preferred_angle, sigma)\n",
    "\n",
    "# plt.hist(samples.numpy(), bins='auto', density=True)\n",
    "# plt.xlabel('Phase (degrees)')\n",
    "# plt.ylabel('Probability Density')\n",
    "# plt.title('Bimodal Distribution of Phases')\n",
    "# plt.show()\n",
    "```\n",
    "\n",
    "Model\n",
    "=====\n",
    "\n",
    "``` ipython\n",
    "kwargs = {\n",
    "    'DURATION': 15.0,\n",
    "    'T_STIM_ON': [1.0, 5.0, 7.0, 11.0],\n",
    "    'T_STIM_OFF': [2.0, 6.0, 8.0, 12.0],\n",
    "    'I0': [1.0, -10.0, 1.0, -10.0],\n",
    "    'PHI0': [180.0, 180, 180, 180],\n",
    "    'SIGMA0': [1.0, 0.0, 1.0, 0.0],\n",
    "}\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "conf_name = \"train_odr_EI.yml\"\n",
    "DEVICE = 'cuda:1'\n",
    "seed = np.random.randint(0, 1e6)\n",
    "\n",
    "seed = 1\n",
    "print('seed', seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "N_BATCH = 128*4\n",
    "model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH, **kwargs)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model_state_dict = torch.load('../models/odr/odr_%d.pth' % seed)\n",
    "model.load_state_dict(model_state_dict);\n",
    "model.eval();\n",
    "```\n",
    "\n",
    "Batching Inputs\n",
    "===============\n",
    "\n",
    "``` ipython\n",
    "print(N_BATCH)\n",
    "model.N_BATCH = N_BATCH\n",
    "model.PHI0 = torch.randint(low=0, high=360, size=(N_BATCH, len(model.I0), 1), device=DEVICE, dtype=torch.float)\n",
    "\n",
    "ff_input = model.init_ff_input()\n",
    "m0, m1, phase = decode_bump_torch(ff_input[..., model.slices[0]], axis=-1)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(model.start_indices.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rates_tensor = model.forward(ff_input=ff_input)# [..., ::3]\n",
    "rates = rates_tensor.cpu().detach().numpy()\n",
    "print('rates', rates.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "m0, m1, phi = decode_bump(rates, axis=-1)\n",
    "```\n",
    "\n",
    "Results\n",
    "=======\n",
    "\n",
    "Rates\n",
    "-----\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 3, figsize=[2.5*width, height])\n",
    "\n",
    "idx = np.random.randint(0, model.N_BATCH)\n",
    "ax[0].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=2, origin='lower', extent=[0, model.DURATION, 0, model.Na[0].cpu()])\n",
    "ax[0].set_ylabel('Pref. Location (°)')\n",
    "ax[0].set_yticks(np.linspace(0, model.Na[0].cpu(), 5), np.linspace(0, 360, 5).astype(int))\n",
    "ax[0].set_xlabel('Time (s)')\n",
    "\n",
    "xtime = np.linspace(0, model.DURATION, phi.shape[-1])\n",
    "idx = np.random.randint(0, model.N_BATCH, 8)\n",
    "ax[1].plot(xtime, m1[idx].T)\n",
    "ax[1].set_ylabel('m1 (Hz)')\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "add_vlines(model, ax[1])\n",
    "\n",
    "ax[2].plot(xtime, phi[idx].T * 180 / np.pi, alpha=0.5)\n",
    "ax[2].set_yticks(np.linspace(0, 360, 5).astype(int), np.linspace(0, 360, 5).astype(int))\n",
    "ax[2].set_ylabel('Bump Center (°)')\n",
    "ax[2].set_xlabel('Time (s)')\n",
    "add_vlines(model, ax[2])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "PHI0 = model.PHI0.cpu().detach().numpy() * 180.0 / np.pi\n",
    "print(PHI0.shape)\n",
    "\n",
    "idx = np.random.randint(0, 32)\n",
    "print(PHI0[idx, 0, 0])\n",
    "window_size = int((model.N_STIM_ON[1]-model.N_STEADY) / model.N_WINDOW)\n",
    "print(phi[idx, window_size] * 180 / np.pi)\n",
    "```\n",
    "\n",
    "errors\n",
    "------\n",
    "\n",
    "``` ipython\n",
    "target_loc = PHI0[:, 2]\n",
    "\n",
    "rel_loc = (PHI0[:, 0] - PHI0[:, 2]) * np.pi / 180.0\n",
    "rel_loc = (rel_loc + np.pi) % (2 * np.pi) - np.pi\n",
    "rel_loc *= 180 / np.pi\n",
    "\n",
    "error_curr = (phi - PHI0[:, 2] * np.pi / 180.0)\n",
    "error_curr = (error_curr + np.pi) % (2 * np.pi) - np.pi\n",
    "error_curr *= 180 / np.pi\n",
    "\n",
    "error_prev = ((phi - PHI0[:, 0] * np.pi / 180.0))\n",
    "error_prev = (error_prev + np.pi) % (2 * np.pi) - np.pi\n",
    "error_prev *= 180 / np.pi\n",
    "\n",
    "errors = np.stack((error_prev, error_curr))\n",
    "print(errors.shape, target_loc.shape, rel_loc.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "time_points = np.linspace(0, model.DURATION, errors.shape[-1])\n",
    "idx = np.random.randint(errors.shape[1], size=100)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "ax[0].plot(time_points, errors[0][idx].T, alpha=.4)\n",
    "add_vlines(model, ax[0])\n",
    "\n",
    "ax[0].set_xlabel('t')\n",
    "ax[0].set_ylabel('prev. error (°)')\n",
    "\n",
    "ax[1].plot(time_points, errors[1][idx].T, alpha=.4)\n",
    "add_vlines(model, ax[1])\n",
    "\n",
    "ax[1].set_xlabel('t')\n",
    "ax[1].set_ylabel('curr. error (°)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(phi.shape, PHI0.shape, model.start_indices.shape)\n",
    "stim_start = (model.DT * (model.start_indices - model.N_STEADY)).cpu().numpy()\n",
    "stim_start_idx = ((model.start_indices - model.N_STEADY) / model.N_WINDOW - 1).to(int).cpu().numpy()\n",
    "print(stim_start[1][:5], model.T_STIM_ON)\n",
    "print(stim_start_idx[1][:5])\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "time_points = np.linspace(0, model.DURATION, errors.shape[-1])\n",
    "idx = np.random.randint(errors.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "ax[0].plot(time_points, errors[0][idx].T)\n",
    "ax[0].set_xlabel('t')\n",
    "ax[0].set_ylabel('prev. error (°)')\n",
    "\n",
    "ax[0].axvline(stim_start[0][idx], ls='--', c='k')\n",
    "ax[0].axvline(stim_start[1][idx], ls='--', c='k')\n",
    "ax[0].axvline(stim_start[2][idx], ls='--', c='k')\n",
    "ax[0].axvline(stim_start[3][idx], ls='--', c='k')\n",
    "\n",
    "ax[1].plot(time_points, errors[1][idx].T)\n",
    "\n",
    "ax[1].axvline(stim_start[0][idx], ls='--', c='k')\n",
    "ax[1].axvline(stim_start[1][idx], ls='--', c='k')\n",
    "ax[1].axvline(stim_start[2][idx], ls='--', c='k')\n",
    "ax[1].axvline(stim_start[3][idx], ls='--', c='k')\n",
    "\n",
    "ax[1].set_xlabel('t')\n",
    "ax[1].set_ylabel('curr. error (°)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "end_point = []\n",
    "for j in [1, 3]:\n",
    "    end_ = []\n",
    "    for i in range(errors.shape[1]):\n",
    "        idx = stim_start_idx[j][i]\n",
    "        end_.append(errors[1][i][idx])\n",
    "\n",
    "    end_point.append(end_)\n",
    "\n",
    "end_point = np.array(end_point)\n",
    "print(end_point.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 3, figsize=[3*width, height])\n",
    "ax[0].hist(target_loc, bins='auto')\n",
    "ax[0].set_xlabel('Targets (°)')\n",
    "\n",
    "ax[1].hist(end_point[0], bins='auto')\n",
    "ax[1].set_xlabel('Prev. Errors (°)')\n",
    "\n",
    "ax[2].hist(end_point[1], bins='auto')\n",
    "ax[2].set_xlabel('Curr. Errors (°)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "biases\n",
    "------\n",
    "\n",
    "``` ipython\n",
    "data = pd.DataFrame({'target_loc': target_loc[:, -1], 'rel_loc': rel_loc[:, -1], 'errors': end_point[1]})\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "n_bins=16\n",
    "ax[0].plot(data['target_loc'], data['errors'], 'o', alpha=.1)\n",
    "ax[0].set_xlabel('Target Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "\n",
    "stt = binned_statistic(data['target_loc'], data['errors'], statistic='mean', bins=n_bins, range=[0, 360])\n",
    "dstt = np.mean(np.diff(stt.bin_edges))\n",
    "ax[0].plot(stt.bin_edges[:-1]+dstt/2,stt.statistic,'r')\n",
    "\n",
    "ax[0].axhline(color='k', linestyle=\":\")\n",
    "\n",
    "ax[1].plot(data['rel_loc'], data['errors'], 'o', alpha=.1)\n",
    "ax[1].set_xlabel('Rel. Loc. (°)')\n",
    "ax[1].set_ylabel('Error (°)')\n",
    "\n",
    "stt = binned_statistic(data['rel_loc'], data['errors'], statistic='mean', bins=n_bins, range=[-180, 180])\n",
    "dstt = np.mean(np.diff(stt.bin_edges))\n",
    "ax[1].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')\n",
    "\n",
    "# plt.savefig('../figures/figs/christos/uncorr_biases.svg', dpi=300)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "n_bins = 16\n",
    "angle_min = 0\n",
    "angle_max = 360\n",
    "\n",
    "bin_edges = np.linspace(angle_min, angle_max, n_bins + 1)\n",
    "data['bin_target'] = pd.cut(data['target_loc'], bins=bin_edges, include_lowest=True)\n",
    "\n",
    "mean_errors_per_bin = data.groupby('bin_target')['errors'].mean()\n",
    "data['adjusted_errors'] = data.apply(\n",
    "    lambda row: row['errors'] - mean_errors_per_bin.loc[row['bin_target']],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "bin_target = data.groupby('bin_target')['adjusted_errors'].agg(['mean', 'sem']).reset_index()\n",
    "edges = bin_target['bin_target'].cat.categories\n",
    "target_centers = (edges.left + edges.right) / 2\n",
    "\n",
    "data['bin_rel'] = pd.cut(data['rel_loc'], bins=n_bins)\n",
    "bin_rel = data.groupby('bin_rel')['adjusted_errors'].agg(['mean', 'sem']).reset_index()\n",
    "\n",
    "edges = bin_rel['bin_rel'].cat.categories\n",
    "centers = (edges.left + edges.right) / 2\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "ax[0].plot(centers, bin_target['mean'], 'b')\n",
    "ax[0].fill_between(centers,\n",
    "                   bin_target['mean'] - bin_target['sem'],\n",
    "                   bin_target['mean'] + bin_target['sem'],\n",
    "                   color='b', alpha=0.2)\n",
    "\n",
    "ax[0].axhline(color='k', linestyle=\":\")\n",
    "ax[0].set_xlabel('Target Loc. (°)')\n",
    "ax[0].set_ylabel('Corrected Error (°)')\n",
    "\n",
    "ax[1].plot(centers, bin_rel['mean'], 'b')\n",
    "ax[1].fill_between(centers,\n",
    "                bin_rel['mean'] - bin_rel['sem'],\n",
    "                bin_rel['mean'] + bin_rel['sem'],\n",
    "                color='b', alpha=0.2)\n",
    "\n",
    "ax[1].axhline(color='k', linestyle=\":\")\n",
    "ax[1].set_xlabel('Rel. Loc. (°)')\n",
    "ax[1].set_ylabel('Corrected Error (°)')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "#pkl_save(data, 'df_naive_%d' %seed, path=\"./figures/odr\")\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
