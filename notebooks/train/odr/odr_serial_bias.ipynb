{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Settings\n",
    "=================\n",
    "\n",
    "``` ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "%run ../../../notebooks/setup.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "pal = sns.color_palette(\"tab10\")\n",
    "```\n",
    "\n",
    "Imports\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from scipy.stats import binned_statistic\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from time import perf_counter\n",
    "from scipy.stats import circmean\n",
    "\n",
    "from src.network import Network\n",
    "from src.plot_utils import plot_con\n",
    "from src.decode import decode_bump, circcvl, decode_bump_torch\n",
    "from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "def pkl_save(obj, name, path=\".\"):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    destination = path + \"/\" + name + \".pkl\"\n",
    "    print(\"saving to\", destination)\n",
    "    pkl.dump(obj, open(destination, \"wb\"))\n",
    "\n",
    "\n",
    "def pkl_load(name, path=\".\"):\n",
    "    source = path + \"/\" + name + '.pkl'\n",
    "    print('loading from', source)\n",
    "    return pkl.load(open( source, \"rb\"))\n",
    "\n",
    "```\n",
    "\n",
    "Helpers\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "def map2center(angles):\n",
    "    \"\"\"Map angles from [0, 2π] to [-π, π] using PyTorch tensors.\"\"\"\n",
    "    return np.where(angles > np.pi, angles - 2 * np.pi, angles)\n",
    "\n",
    "def map2pos(angles):\n",
    "    \"\"\"Map angles from [-π, π] to [0, 2π] using PyTorch tensors.\"\"\"\n",
    "    return np.where(angles < 0, angles + 2 * np.pi, angles)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def maptens2center(angles):\n",
    "    \"\"\"Map angles from [0, 2π] to [-π, π] using PyTorch tensors.\"\"\"\n",
    "    return torch.where(angles > torch.pi, angles - 2 * torch.pi, angles)\n",
    "\n",
    "def maptens2pos(angles):\n",
    "    \"\"\"Map angles from [-π, π] to [0, 2π] using PyTorch tensors.\"\"\"\n",
    "    return torch.where(angles < 0, angles + 2 * torch.pi, angles)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def add_vlines(model, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        for i in range(len(model.T_STIM_ON)):\n",
    "            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)\n",
    "    else:\n",
    "        for i in range(len(model.T_STIM_ON)):\n",
    "            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)\n",
    "\n",
    "```\n",
    "\n",
    "Model\n",
    "=====\n",
    "\n",
    "``` ipython\n",
    "kwargs = {\n",
    "    'GAIN': 1.0,\n",
    "    'DURATION': 15.0,\n",
    "    'T_STEADY': 4,\n",
    "\n",
    "    'T_STIM_ON': [1.0, 5.0, 10.0, 14.0],\n",
    "    'T_STIM_OFF': [2.0, 6.0, 11.0, 15.0],\n",
    "\n",
    "    'I0': [0.25, -2.0, 0.25, -2.0],\n",
    "    'PHI0': [180.0, 180, 180, 180],\n",
    "    'SIGMA0': [2.0, 0.0, 2.0, 0.0],\n",
    "\n",
    "    'RANDOM_DELAY': 0,\n",
    "    'MIN_DELAY': 0,\n",
    "    'MAX_DELAY': 3,\n",
    "\n",
    "    'IF_FF_STP': 0,\n",
    "    'FF_USE': 0.5,\n",
    "    'TAU_FF_FAC': 0.0,\n",
    "    'TAU_FF_REC': 0.5,\n",
    "\n",
    "    'IS_STP': [1, 0, 0, 0],\n",
    "    'USE': [0.1, 0.03, 0.03, 0.1],\n",
    "    'TAU_FAC': [2.0, 2.0, 2.0, 0.0],\n",
    "    'TAU_REC': [0.2, 0.2, 0.2, 0.1],\n",
    "    'W_STP': [1.0, 3.0, 4.0, 1.0],\n",
    "\n",
    "    'IF_FF_ADAPT': 0,\n",
    "    'A_FF_ADAPT': 1.0,\n",
    "    'TAU_FF_ADAPT': 100.0,\n",
    "\n",
    "    'IF_ADAPT': 1,\n",
    "    'A_ADAPT': 1.0,\n",
    "    'TAU_ADAPT': 100.0,\n",
    "}\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "conf_name = \"train_odr_EI.yml\"\n",
    "DEVICE = 'cuda'\n",
    "seed = np.random.randint(0, 1e6)\n",
    "\n",
    "seed = 0\n",
    "print('seed', seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "N_BATCH = 128*7\n",
    "model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH, **kwargs)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model_state_dict = torch.load('../models/odr/odr_%d.pth' % seed)\n",
    "model.load_state_dict(model_state_dict);\n",
    "model.eval();\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(model.J_STP.item())\n",
    "# model.J_STP = nn.Parameter(0.98 * model.J_STP)\n",
    "# print(model.J_STP.item())\n",
    "```\n",
    "\n",
    "Simulations\n",
    "===========\n",
    "\n",
    "``` ipython\n",
    "def shifted_phase(phase1, phase2, bias_strength, bias_var, direction=-1):\n",
    "    \"\"\"\n",
    "    shift phase2_original away from phase1 by bias_strength (in radians)\n",
    "    direction='repulsive' for away, 'attractive' for toward\n",
    "    All phases in radians\n",
    "    \"\"\"\n",
    "    delta = (phase1 - phase2) * torch.pi / 180.0\n",
    "    # - for repulsion, + for attraction\n",
    "    phase2_biased = phase2 + direction * bias_strength * torch.sin(delta + bias_var * torch.randn_like(phase2))  + bias_var * torch.randn_like(phase2)\n",
    "    return torch.remainder(phase2_biased, 360.0)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = N_BATCH\n",
    "model.PHI0 = torch.randint(low=0, high=360, size=(N_BATCH, len(model.I0), 1), device=DEVICE, dtype=torch.float)\n",
    "model.PHI0_UNBIASED = torch.deg2rad(model.PHI0.clone())\n",
    "\n",
    "if model.REP_BIAS>0:\n",
    "   model.PHI0[:, 2] = shifted_phase(model.PHI0[:, 0], model.PHI0[:, 2], model.REP_BIAS, model.REP_VAR)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "with torch.no_grad():\n",
    "    ff_input = model.init_ff_input()\n",
    "    rates_tensor = model.forward(ff_input=ff_input, RET_STP=1)\n",
    "rates = rates_tensor.cpu().detach().numpy()\n",
    "print('rates', rates.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "m0, m1, phi = decode_bump_torch(rates, axis=-1, RET_TENSOR=0)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rel_loc = (model.PHI0_UNBIASED[:, 2, 0] - model.PHI0[:, 0, 0]) * 180.0 / torch.pi\n",
    "rel_loc = (rel_loc + 180) % (360) - 180\n",
    "\n",
    "error = (model.PHI0_UNBIASED[:, 2, 0] - model.PHI0[:, 2, 0]) * 180 / torch.pi\n",
    "error = (error + 180) % (360) - 180\n",
    "\n",
    "# plt.plot(rel_loc.cpu(), error.cpu(), 'o')\n",
    "# plt.xlabel('Rel. Loc.')\n",
    "# plt.ylabel('Input Bias (°)')\n",
    "# plt.show()\n",
    "```\n",
    "\n",
    "Dynamics\n",
    "========\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 1, figsize=[2.5*width, height])\n",
    "\n",
    "idx = np.random.randint(0, model.N_BATCH)\n",
    "vmin, vmax = np.percentile(rates[idx].reshape(-1), [5, 95])\n",
    "\n",
    "ax.imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=vmin, vmax=vmax, origin='lower', extent=[0, model.DURATION, 0, model.Na[0].cpu()])\n",
    "ax.set_ylabel('Pref. Location (°)')\n",
    "ax.set_yticks(np.linspace(0, model.Na[0].cpu(), 5), np.linspace(0, 360, 5).astype(int))\n",
    "ax.set_xlabel('Time (s)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 3, figsize=[2.5*width, height])\n",
    "\n",
    "idx = np.random.randint(0, model.N_BATCH)\n",
    "\n",
    "xtime = np.linspace(0, model.DURATION, phi.shape[-1])\n",
    "idx = np.random.randint(0, model.N_BATCH, 8)\n",
    "ax[1].plot(xtime, m1[idx].T)\n",
    "ax[1].set_ylabel('$\\mathcal{F}_1$ (Hz)')\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "add_vlines(model, ax[1])\n",
    "\n",
    "ax[2].plot(xtime, phi[idx].T * 180 / np.pi, alpha=0.5)\n",
    "ax[2].set_yticks(np.linspace(0, 360, 5).astype(int), np.linspace(0, 360, 5).astype(int))\n",
    "ax[2].set_ylabel('Bump Center (°)')\n",
    "ax[2].set_xlabel('Time (s)')\n",
    "add_vlines(model, ax[2])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "idx = np.random.randint(0, model.N_BATCH, 5)\n",
    "\n",
    "for i in idx:\n",
    "    ax[1].plot(xtime, model.x_list.cpu()[i, :, 0])\n",
    "    ax[0].plot(xtime, model.u_list.cpu()[i, :, 0])\n",
    "\n",
    "ax[0].set_xlabel('Time (s)')\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "\n",
    "add_vlines(model, ax[1])\n",
    "add_vlines(model, ax[0])\n",
    "\n",
    "ax[1].set_ylabel('x')\n",
    "ax[0].set_ylabel('u')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "m0_x, m1_x, phi_x = decode_bump_torch(model.x_list, axis=-1, RET_TENSOR=0)\n",
    "\n",
    "idx = np.random.randint(0, model.N_BATCH, 5)\n",
    "\n",
    "for i in idx:\n",
    "    ax[0].plot(xtime, m1_x[i])\n",
    "    ax[1].plot(xtime, phi_x[i])\n",
    "\n",
    "ax[0].set_xlabel('Time (s)')\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "\n",
    "add_vlines(model, ax[0])\n",
    "add_vlines(model, ax[1])\n",
    "\n",
    "ax[0].set_ylabel('$\\mathcal{F}_1(x)$')\n",
    "ax[1].set_ylabel('$\\\\theta_x$')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "m0_u, m1_u, phi_u = decode_bump_torch(model.u_list, axis=-1, RET_TENSOR=0)\n",
    "\n",
    "idx = np.random.randint(0, model.N_BATCH, 5)\n",
    "\n",
    "for i in idx:\n",
    "    ax[0].plot(xtime, m1_u[i])\n",
    "    ax[1].plot(xtime, phi_u[i])\n",
    "\n",
    "ax[0].set_xlabel('Time (s)')\n",
    "ax[1].set_xlabel('Time (s)')\n",
    "\n",
    "add_vlines(model, ax[0])\n",
    "add_vlines(model, ax[1])\n",
    "\n",
    "ax[0].set_ylabel('$\\mathcal{F}_1(u)$')\n",
    "ax[1].set_ylabel('$\\\\theta_u$')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Errors\n",
    "======\n",
    "\n",
    "``` ipython\n",
    "PHI0 = model.PHI0_UNBIASED.cpu().detach().numpy()\n",
    "\n",
    "target_loc = PHI0[:, 2] * 180 / np.pi\n",
    "\n",
    "rel_loc = (PHI0[:, 0] - PHI0[:, 2])\n",
    "rel_loc = (rel_loc + np.pi) % (2 * np.pi) - np.pi\n",
    "rel_loc *= 180 / np.pi\n",
    "\n",
    "error_curr = (phi - PHI0[:, 2])\n",
    "error_curr = (error_curr + np.pi) % (2 * np.pi) - np.pi\n",
    "error_curr *= 180 / np.pi\n",
    "\n",
    "error_prev = (phi - PHI0[:, 0])\n",
    "error_prev = (error_prev + np.pi) % (2 * np.pi) - np.pi\n",
    "error_prev *= 180 / np.pi\n",
    "\n",
    "errors = np.stack((error_prev, error_curr))\n",
    "print(errors.shape, target_loc.shape, rel_loc.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "time_points = np.linspace(0, model.DURATION, errors.shape[-1])\n",
    "idx = np.random.randint(errors.shape[1], size=100)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "# ax[0].plot(time_points, errors[0][idx].T, alpha=.4)\n",
    "# add_vlines(model, ax[0])\n",
    "\n",
    "# ax[0].set_xlabel('t')\n",
    "# ax[0].set_ylabel('prev. error (°)')\n",
    "\n",
    "# ax[1].plot(time_points, errors[1][idx].T, alpha=.4)\n",
    "# add_vlines(model, ax[1])\n",
    "\n",
    "ax[1].set_xlabel('t')\n",
    "ax[1].set_ylabel('curr. error (°)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(phi.shape, PHI0.shape, model.start_indices.shape, errors.shape)\n",
    "stim_start = (model.DT * (model.start_indices - model.N_STEADY)).cpu().numpy()\n",
    "stim_end = (model.DT * (model.end_indices - model.N_STEADY)).cpu().numpy()\n",
    "\n",
    "stim_start_idx = ((model.start_indices - model.N_STEADY) / model.N_WINDOW - 1).to(int).cpu().numpy()\n",
    "stim_end_idx = ((model.end_indices - model.N_STEADY) / model.N_WINDOW - 1).to(int).cpu().numpy()\n",
    "\n",
    "print(stim_start_idx.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "idx_half = np.array([stim_end_idx[0] + (stim_start_idx[1] - stim_end_idx[0]) / 2.0,stim_end_idx[-2] + (stim_start_idx[-1] - stim_end_idx[-2]) / 2.0], dtype=int)\n",
    "t_half = np.array([stim_end[0] + (stim_start[1] - stim_end[0]) / 2.0, stim_end[1] + (stim_start[2] - stim_end[1]) / 2.0], dtype=int)\n",
    "print(t_half+2)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "end_point = []\n",
    "for i, j in enumerate([1, 3]):\n",
    "    end_ = []\n",
    "    for k in range(errors.shape[1]):\n",
    "        idx = stim_start_idx[j][k]\n",
    "        end_.append(errors[i][k][idx])\n",
    "\n",
    "    end_point.append(end_)\n",
    "\n",
    "end_point = np.array(end_point)\n",
    "print(end_point.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "end_point_half = []\n",
    "for i, j in enumerate([1, 3]):\n",
    "    end_ = []\n",
    "    for k in range(errors.shape[1]):\n",
    "        idx = idx_half[i][k]\n",
    "        end_.append(errors[i][k][idx])\n",
    "\n",
    "    end_point_half.append(end_)\n",
    "\n",
    "end_point_half = np.array(end_point_half)\n",
    "print(end_point_half.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "end_point_zero = []\n",
    "for i, j in enumerate([0, 2]):\n",
    "    end_ = []\n",
    "    for k in range(errors.shape[1]):\n",
    "        idx = stim_end_idx[j][k]\n",
    "        end_.append(errors[i][k][idx])\n",
    "\n",
    "    end_point_zero.append(end_)\n",
    "\n",
    "end_point_zero = np.array(end_point_zero)\n",
    "print(end_point_zero.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "delay_duration = np.array([stim_start[1, 0] - stim_end[0, 0], stim_start[3, 0] - stim_end[2, 0]])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].hist(end_point[0], bins='auto', color='r', histtype='step', label='%.1f s' % delay_duration[0])\n",
    "ax[0].hist(end_point_half[0], bins='auto', color='g', histtype='step', label='%.1f s' % (delay_duration[0] / 2))\n",
    "ax[0].hist(end_point_zero[0], bins='auto', color='b', histtype='step', label='0s')\n",
    "\n",
    "ax[0].set_xlabel('Prev. Errors (°)')\n",
    "ax[0].legend(fontsize=12)\n",
    "\n",
    "ax[1].hist(end_point[1], bins='auto', color='r', histtype='step', label='%.1f s' % delay_duration[1])\n",
    "ax[1].hist(end_point_half[1], bins='auto', color='g', histtype='step', label='%.1f s' % (delay_duration[1] / 2))\n",
    "ax[1].hist(end_point_zero[1], bins='auto', color='b', histtype='step', label='0s')\n",
    "\n",
    "ax[1].set_xlabel('Curr. Errors (°)')\n",
    "ax[1].legend(fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Serial Bias\n",
    "===========\n",
    "\n",
    "Serial Curves\n",
    "-------------\n",
    "\n",
    "``` ipython\n",
    "def get_correct_error(nbins, df, thresh=25):\n",
    "    if thresh is not None:\n",
    "        data = df[(df['errors'] >= -thresh) & (df['errors'] <= thresh)].copy()\n",
    "    else:\n",
    "        data = df.copy()\n",
    "\n",
    "    # 1. Bias-correct both error and error_half\n",
    "    bin_edges = np.linspace(0, 360, n_bins + 1)\n",
    "    data['bin_target'] = pd.cut(data['target_loc'], bins=bin_edges, include_lowest=True)\n",
    "    mean_errors_per_bin = data.groupby('bin_target')['errors'].mean()\n",
    "    data['adjusted_errors'] = data['errors'] - data['bin_target'].map(mean_errors_per_bin).astype(float)\n",
    "\n",
    "    # 2. Bin by relative location for both sessions (full version, [-180, 180])\n",
    "    data['bin_rel'] = pd.cut(data['rel_loc'], bins=n_bins)\n",
    "    bin_rel = data.groupby('bin_rel')['adjusted_errors'].agg(['mean', 'sem']).reset_index()\n",
    "    edges = bin_rel['bin_rel'].cat.categories\n",
    "    centers = (edges.left + edges.right) / 2\n",
    "\n",
    "    # 3. FLIP SIGN for abs(rel_loc): defects on the left (-) are flipped so all bins reflect the same \"direction\"\n",
    "    data['rel_loc_abs'] = np.abs(data['rel_loc'])\n",
    "    data['bin_rel_abs'] = pd.cut(data['rel_loc_abs'], bins=n_bins, include_lowest=True)\n",
    "\n",
    "    # Flip errors for abs plot:\n",
    "    data['adjusted_errors_abs'] = data['adjusted_errors'] * np.sign(data['rel_loc'])\n",
    "\n",
    "    bin_rel_abs = data.groupby('bin_rel_abs')['adjusted_errors_abs'].agg(['mean', 'sem']).reset_index()\n",
    "    edges_abs = bin_rel_abs['bin_rel_abs'].cat.categories\n",
    "    centers_abs = (edges_abs.left + edges_abs.right) / 2\n",
    "\n",
    "    # 4. Bin by target location for target-centered analysis (optional)\n",
    "    bin_target = data.groupby('bin_target')['adjusted_errors'].agg(['mean', 'sem']).reset_index()\n",
    "    edges_target = bin_target['bin_target'].cat.categories\n",
    "    target_centers = (edges_target.left + edges_target.right) / 2\n",
    "\n",
    "    return centers, bin_rel, centers_abs, bin_rel_abs\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "n_bins = 16\n",
    "data = pd.DataFrame({'target_loc': target_loc[:, -1], 'rel_loc': rel_loc[:, -1], 'errors': end_point[1]})\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 3, figsize=[3*width, height])\n",
    "\n",
    "# ax[0].plot(data['target_loc'], data['errors'], 'o', alpha=.1)\n",
    "ax[0].set_xlabel('Target Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "\n",
    "stt = binned_statistic(data['target_loc'], data['errors'], statistic='mean', bins=n_bins, range=[0, 360])\n",
    "dstt = np.mean(np.diff(stt.bin_edges))\n",
    "ax[0].plot(stt.bin_edges[:-1]+dstt/2,stt.statistic,'r')\n",
    "\n",
    "ax[0].axhline(color='k', linestyle=\":\")\n",
    "\n",
    "# ax[1].plot(data['rel_loc'], data['errors'], 'o', alpha=.1)\n",
    "ax[1].set_xlabel('Rel. Loc. (°)')\n",
    "ax[1].set_ylabel('Error (°)')\n",
    "\n",
    "stt = binned_statistic(data['rel_loc'], data['errors'], statistic='mean', bins=n_bins, range=[-180, 180])\n",
    "dstt = np.mean(np.diff(stt.bin_edges))\n",
    "ax[1].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')\n",
    "\n",
    "data['rel_loc_abs'] = np.abs(data['rel_loc'])             # Map -180..180 -> 0..180\n",
    "data['errors_signed'] = data['errors'] * np.sign(data['rel_loc']) # error \"toward/away\": flip sign for >0\n",
    "\n",
    "# ax[2].plot(data['rel_loc_abs'], data['errors_signed'], 'o', alpha=0.1)\n",
    "ax[2].set_xlabel('|Rel. Loc.| (°)')\n",
    "ax[2].set_ylabel('Error (°)')\n",
    "\n",
    "bin_stat = binned_statistic(data['rel_loc_abs'], data['errors_signed'], statistic='mean', bins=n_bins, range=[0, 180])\n",
    "dstt = np.mean(np.diff(bin_stat.bin_edges))\n",
    "ax[2].plot(bin_stat.bin_edges[:-1] + dstt/2, bin_stat.statistic, 'b')\n",
    "ax[2].axhline(color='k', linestyle=\":\")\n",
    "\n",
    "# plt.savefig('../figures/figs/christos/uncorr_biases.svg', dpi=300)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "data = pd.DataFrame({'target_loc': target_loc[:, -1], 'rel_loc': rel_loc[:, -1], 'errors': end_point[1]})\n",
    "centers, bin_rel, centers_abs, bin_rel_abs = get_correct_error(n_bins, data)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "data = pd.DataFrame({'target_loc': target_loc[:, -1], 'rel_loc': rel_loc[:, -1], 'errors': end_point_half[1]})\n",
    "centers_half, bin_rel_half, centers_abs_half, bin_rel_abs_half = get_correct_error(n_bins, data)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "data = pd.DataFrame({'target_loc': target_loc[:, -1], 'rel_loc': rel_loc[:, -1], 'errors': end_point_zero[1]})\n",
    "centers_zero, bin_rel_zero, centers_abs_zero, bin_rel_abs_zero = get_correct_error(n_bins, data)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "delay_duration = stim_start[-1] - stim_end[-2]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].plot(centers, bin_rel['mean'], 'r', label='full')\n",
    "ax[0].fill_between(centers, bin_rel['mean'] - bin_rel['sem'], bin_rel['mean'] + bin_rel['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[0].plot(centers, bin_rel_half['mean'], 'g', label='half')\n",
    "ax[0].fill_between(centers, bin_rel_half['mean'] - bin_rel_half['sem'], bin_rel_half['mean'] + bin_rel_half['sem'], color='g', alpha=0.2)\n",
    "\n",
    "ax[0].plot(centers, bin_rel_zero['mean'], 'b', label='zero')\n",
    "ax[0].fill_between(centers, bin_rel_zero['mean'] - bin_rel_zero['sem'], bin_rel_zero['mean'] + bin_rel_zero['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[0].axhline(0, color='k', linestyle=\":\")\n",
    "ax[0].set_xlabel('Rel. Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "\n",
    "ax[0].set_xticks(np.linspace(-180, 180, 5))\n",
    "\n",
    "ax[1].plot(centers_abs, bin_rel_abs['mean'], 'r', label='%.1f s' % delay_duration[1])\n",
    "ax[1].fill_between(centers_abs, bin_rel_abs['mean'] - bin_rel_abs['sem'], bin_rel_abs['mean'] + bin_rel_abs['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[1].plot(centers_abs, bin_rel_abs_half['mean'], 'g', label='%.1f s' % (delay_duration[1] / 2.0))\n",
    "ax[1].fill_between(centers_abs, bin_rel_abs_half['mean'] - bin_rel_abs_half['sem'], bin_rel_abs_half['mean'] + bin_rel_abs_half['sem'], color='g', alpha=0.2)\n",
    "\n",
    "ax[1].plot(centers_abs, bin_rel_abs_zero['mean'], 'b', label='0s' )\n",
    "ax[1].fill_between(centers_abs, bin_rel_abs_zero['mean'] - bin_rel_abs_zero['sem'], bin_rel_abs_zero['mean'] + bin_rel_abs_zero['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[1].axhline(0, color='k', linestyle=\":\")\n",
    "ax[1].set_xlabel('Rel. Loc. (°)')\n",
    "ax[1].set_ylabel('Flip. Error (°)')\n",
    "\n",
    "ax[1].legend(fontsize=12, title='Delay', title_fontsize=12)\n",
    "ax[1].set_xticks(np.linspace(0, 180, 3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Delay Dependency\n",
    "----------------\n",
    "\n",
    "``` ipython\n",
    "delay_point = []\n",
    "for i in range(errors.shape[1]):\n",
    "        idx_start = stim_end_idx[2][i]+1\n",
    "        idx_end = stim_start_idx[3][i]\n",
    "\n",
    "        end_ = []\n",
    "        for idx in range(idx_start, idx_end):\n",
    "                end_.append(errors[1][i][idx])\n",
    "\n",
    "        delay_point.append(end_)\n",
    "\n",
    "delay_point = np.array(delay_point)\n",
    "print(delay_point.shape, errors.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def fit_deriv_gaussian_circular(df, n_bins, target_col='target_loc', error_col='errors', rel_col='rel_loc', n_tries=10, thresh=25):\n",
    "    if thresh is not None:\n",
    "        data = df[(df['errors'] >= -thresh) & (df['errors'] <= thresh)].copy()\n",
    "    else:\n",
    "        data = df.copy()\n",
    "\n",
    "    # 1. Compute \"adjusted_errors\"\n",
    "    bin_edges = np.linspace(0, 360, n_bins + 1)\n",
    "    data = data.copy()\n",
    "    data['bin_target'] = pd.cut(\n",
    "        data[target_col], bins=bin_edges, include_lowest=True, right=False)\n",
    "    mean_errors_per_bin = data.groupby('bin_target', observed=False)[error_col].mean()\n",
    "\n",
    "    data['adjusted_errors'] = (\n",
    "        data[error_col] - data['bin_target'].map(mean_errors_per_bin).astype(float)\n",
    "    )\n",
    "\n",
    "    # 2. Circular binning for kernel fitting\n",
    "    x = data[rel_col].values\n",
    "    y = data['adjusted_errors'].values\n",
    "    bins = np.linspace(-180, 180, n_bins + 1)\n",
    "    bin_indices = np.digitize(x, bins, right=False) - 1\n",
    "    bin_indices[bin_indices == n_bins] = 0\n",
    "\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    bin_means = np.array([\n",
    "        y[bin_indices == i].mean() if np.any(bin_indices == i) else np.nan\n",
    "        for i in range(n_bins)\n",
    "    ])\n",
    "\n",
    "    # Guess parameters from the data\n",
    "    ampl_guess = (np.nanmax(bin_means) - np.nanmin(bin_means)) / 2\n",
    "    sigma_guess = (np.nanmax(bin_centers) - np.nanmin(bin_centers)) / 4\n",
    "\n",
    "    # Model\n",
    "    def deriv_gaussian(x, A, sigma, mu=0):\n",
    "        return -A * (x - mu) * np.exp(-((x - mu) ** 2) / (2 * sigma ** 2)) / (sigma ** 2)\n",
    "\n",
    "    mask = np.isfinite(bin_means)\n",
    "    fit_centers = bin_centers[mask]\n",
    "    fit_means = bin_means[mask]\n",
    "\n",
    "    best_loss = np.inf\n",
    "    best_popt = None\n",
    "\n",
    "    for _ in range(n_tries):\n",
    "        # Vary around data-driven guess\n",
    "        p0 = [\n",
    "            ampl_guess * np.random.uniform(0.0, 10.0),\n",
    "            sigma_guess * np.random.uniform(1.0, 10.0),\n",
    "        ]\n",
    "        try:\n",
    "            popt, _ = curve_fit(\n",
    "                deriv_gaussian, fit_centers, fit_means, p0=p0, maxfev=5000)\n",
    "            residuals = fit_means - deriv_gaussian(fit_centers, *popt)\n",
    "            loss = np.sum(residuals**2)\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_popt = popt\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "\n",
    "    if best_popt is None:\n",
    "        raise RuntimeError(\"Fit did not converge in any of the tries.\")\n",
    "\n",
    "    result = {\n",
    "        'amplitude_at_90': -best_popt[0] * (90 - 0) * np.exp(-((90 - 0) ** 2) / (2 * best_popt[1] ** 2)) / (best_popt[1] ** 2),\n",
    "        'bin_centers': bin_centers,\n",
    "        'bin_means': bin_means,\n",
    "        'fit': lambda x: deriv_gaussian(x, *best_popt),\n",
    "        'data': data\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_amplitude_at_90(\n",
    "    data, n_bins, n_boot=100, n_jobs=-1, random_state=None, fit_kwargs=None\n",
    "):\n",
    "    # fit_kwargs: dict for extra arguments to fit_deriv_gaussian_circular\n",
    "    if fit_kwargs is None:\n",
    "        fit_kwargs = {}\n",
    "    rng = np.random.RandomState(random_state)\n",
    "\n",
    "    def _single_boot(random_seed):\n",
    "        import warnings\n",
    "        from scipy.optimize import OptimizeWarning\n",
    "        warnings.simplefilter(\"ignore\", OptimizeWarning)\n",
    "        np.random.seed(random_seed)\n",
    "        d_samp = data.sample(frac=1, replace=True, random_state=np.random.randint(0, 2**32))\n",
    "        try:\n",
    "            res = fit_deriv_gaussian_circular(d_samp, n_bins, **fit_kwargs)\n",
    "            return res['amplitude_at_90']\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "    seeds = rng.randint(0, 2**32, size=n_boot)\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_single_boot)(s) for s in seeds\n",
    "    )\n",
    "    results = np.array([r for r in results if np.isfinite(r)])\n",
    "    ci = np.percentile(results, [2.5, 97.5])\n",
    "    return ci\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "n_bins = 16\n",
    "\n",
    "cmap = plt.get_cmap('Blues')\n",
    "colors = [cmap((i+1)/ delay_point.shape[1]) for i in range(delay_point.shape[1])]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "serial_list = []\n",
    "for i in range(delay_point.shape[1]):\n",
    "    data = pd.DataFrame({'target_loc': target_loc[:, -1], 'rel_loc': rel_loc[:, -1], 'errors': delay_point[:, i]})\n",
    "\n",
    "    centers, bin_rel, centers_abs, bin_rel_abs = get_correct_error(n_bins, data)\n",
    "\n",
    "    ax[0].plot(centers, bin_rel['mean'], color=colors[i])\n",
    "\n",
    "    idx_max = np.argmax(np.abs(bin_rel['mean'][centers>0]))\n",
    "    dum = bin_rel['mean'][centers>0]\n",
    "    serial_max = dum.iloc[idx_max]\n",
    "\n",
    "    dum = bin_rel['sem'][centers>0]\n",
    "    serial_std = dum.iloc[idx_max]\n",
    "\n",
    "    serial_list.append([serial_max, serial_std])\n",
    "\n",
    "serial_list = np.array(serial_list).T\n",
    "print(serial_list.shape)\n",
    "ax[0].set_xlabel('Rel. Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "ax[0].axvline(-60, ls=':', color='k')\n",
    "ax[0].axvline(60, ls=':', color='k')\n",
    "\n",
    "delay_duration = stim_start[1, 0] - stim_end[0, 0]\n",
    "xdelay = np.linspace(0, delay_duration, serial_list.shape[1])\n",
    "\n",
    "ax[1].plot(xdelay, serial_list[0], '-', label=dum)\n",
    "ax[1].fill_between(xdelay, serial_list[0] - serial_list[1], serial_list[0] + serial_list[1], color='b', alpha=0.2)\n",
    "ax[1].set_xlabel('Delay Length (s)')\n",
    "ax[1].set_ylabel('Serial Bias (°)')\n",
    "\n",
    "ax[1].axhline(0, ls='--', color='k')\n",
    "ax[0].axhline(0, ls='--', color = 'k')\n",
    "# ax[1].legend(fontsize=12)\n",
    "# plt.savefig('./figures/NIH/10_25/sb_delay_%s.svg' % name)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import warnings\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.optimize import OptimizeWarning\n",
    "\n",
    "n_bins = 16\n",
    "\n",
    "cmap = plt.get_cmap('Blues')\n",
    "colors = [cmap((i+1)/ delay_point.shape[1]) for i in range(delay_point.shape[1])]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "serial_list = []\n",
    "serial_ci = []\n",
    "for i in range(delay_point.shape[1]):\n",
    "    data = pd.DataFrame({'target_loc': target_loc[:, -1], 'rel_loc': rel_loc[:, -1], 'errors': delay_point[:, i]})\n",
    "\n",
    "    result = fit_deriv_gaussian_circular(data, n_bins=n_bins)\n",
    "    ci = bootstrap_amplitude_at_90(data.copy(), n_bins=n_bins, n_boot=100)\n",
    "\n",
    "    ax[0].plot(result['bin_centers'], result['fit'](result['bin_centers']), alpha=1, color=colors[i])\n",
    "\n",
    "    serial_list.append(result['amplitude_at_90'])\n",
    "    serial_ci.append(ci)\n",
    "\n",
    "serial_list = np.array(serial_list)\n",
    "serial_ci = np.array(serial_ci)\n",
    "\n",
    "ax[0].set_xlabel('Rel. Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "ax[0].axhline(0, ls='--', color='k')\n",
    "ax[0].axvline(-60, ls=':', color='k')\n",
    "ax[0].axvline(60, ls=':', color='k')\n",
    "\n",
    "delay_duration = stim_start[3, 0] - stim_end[2, 0]\n",
    "xdelay = np.linspace(0, delay_duration, serial_list.shape[0])\n",
    "\n",
    "ax[1].plot(xdelay, serial_list, '-')\n",
    "ax[1].fill_between(xdelay, serial_ci[:,0], serial_ci[:,1], color='gray', alpha=0.3, label='95% CI')\n",
    "ax[1].axhline(0, ls='--', color='k')\n",
    "ax[1].set_xlabel('Delay Length (s)')\n",
    "ax[1].set_ylabel('Serial Bias (°)')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
