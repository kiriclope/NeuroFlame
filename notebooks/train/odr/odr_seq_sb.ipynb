{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from scipy.stats import binned_statistic\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from time import perf_counter\n",
    "from scipy.stats import circmean\n",
    "\n",
    "from src.network import Network\n",
    "from src.plot_utils import plot_con\n",
    "from src.decode import decode_bump, circcvl, decode_bump_torch\n",
    "from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor\n",
    "from src.utils import clear_cache\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "def pkl_save(obj, name, path=\".\"):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    destination = path + \"/\" + name + \".pkl\"\n",
    "    print(\"saving to\", destination)\n",
    "    pkl.dump(obj, open(destination, \"wb\"))\n",
    "\n",
    "\n",
    "def pkl_load(name, path=\".\"):\n",
    "    source = path + \"/\" + name + '.pkl'\n",
    "    print('loading from', source)\n",
    "    return pkl.load(open( source, \"rb\"))\n",
    "\n",
    "```\n",
    "\n",
    "Notebook Settings\n",
    "=================\n",
    "\n",
    "``` ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "golden_ratio = (5**.5 - 1) / 2\n",
    "width = 6\n",
    "height = width * golden_ratio\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "```\n",
    "\n",
    "Helpers\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "def pkl_save(obj, name, path=\".\"):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    destination = path + \"/\" + name + \".pkl\"\n",
    "    print(\"saving to\", destination)\n",
    "    pkl.dump(obj, open(destination, \"wb\"))\n",
    "\n",
    "\n",
    "def pkl_load(name, path=\".\"):\n",
    "    source = path + \"/\" + name + '.pkl'\n",
    "    print('loading from', source)\n",
    "    return pkl.load(open( source, \"rb\"))\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "T_STIM_ON = [1.0, 5.0]\n",
    "T_STIM_OFF = [2.0, 6.0]\n",
    "\n",
    "def add_vlines(ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        for i in range(len(T_STIM_ON)):\n",
    "            plt.axvspan(T_STIM_ON[i], T_STIM_OFF[i], alpha=0.25)\n",
    "    else:\n",
    "        for i in range(len(T_STIM_ON)):\n",
    "            ax.axvspan(T_STIM_ON[i], T_STIM_OFF[i], alpha=0.25)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def decode_bump_torch(signal, axis=-1, device=None, RET_TENSOR=1):\n",
    "\n",
    "    if not torch.is_tensor(signal):\n",
    "        signal = torch.as_tensor(signal, dtype=torch.float32, device=device or 'cpu')\n",
    "    else:\n",
    "        signal = signal.to(dtype=torch.float32, device=device or 'cpu')\n",
    "\n",
    "    if axis != -1 and signal.ndim != 1:\n",
    "        signal = signal.movedim(axis, -1)\n",
    "\n",
    "    m0 = torch.nanmean(signal, dim=-1)\n",
    "    N = signal.shape[-1]\n",
    "    k = 1\n",
    "    n = torch.arange(N, device=signal.device)\n",
    "    twiddle = torch.exp(2j * torch.pi * k * n / N) # my convention is + here\n",
    "\n",
    "    # | Input Signal           | DFT Exponent sign | Decoded phase is     |\n",
    "    # |-----------------------|-------------------|----------------------|\n",
    "    # | cos(θ + φ₀)           | e^{-2πikn/N}      |  +φ₀                 |\n",
    "    # | cos(θ - φ₀)           | e^{-2πikn/N}      |  –φ₀ |\n",
    "    # | cos(θ - φ₀)           | e^{+2πikn/N}      |  +φ₀                 |\n",
    "\n",
    "    dft1 = (signal * twiddle).sum(dim=-1) / N\n",
    "    m1 = 2 * torch.abs(dft1)\n",
    "    phi = torch.angle(dft1) % (2 * torch.pi)\n",
    "\n",
    "    if RET_TENSOR:\n",
    "        return m0, m1, phi\n",
    "\n",
    "    return m0.cpu().detach().numpy(), m1.cpu().detach().numpy(), phi.cpu().detach().numpy()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_error_curr_prev(phi, curr, prev, reference):\n",
    "    target_loc = curr  * 180.0 / np.pi\n",
    "\n",
    "    rel_loc = prev - curr\n",
    "    rel_loc = (rel_loc + np.pi) % (2 * np.pi) - np.pi\n",
    "    rel_loc *= 180 / np.pi\n",
    "\n",
    "    ref_loc = reference[np.newaxis] - curr\n",
    "    ref_loc = (ref_loc + np.pi) % (2 * np.pi) - np.pi\n",
    "    ref_loc *= 180 / np.pi\n",
    "\n",
    "    error_curr = phi - curr\n",
    "    error_curr = (error_curr + np.pi) % (2 * np.pi) - np.pi\n",
    "    error_curr *= 180 / np.pi\n",
    "\n",
    "    return np.vstack(target_loc), np.vstack(rel_loc), np.vstack(ref_loc), np.array(error_curr)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_end_point(errors, stim_start_idx):\n",
    "\n",
    "    end_point = []\n",
    "    for k in range(errors.shape[1]):\n",
    "            idx = stim_start_idx[1][k]-1\n",
    "            end_point.append(errors[:, k, idx])\n",
    "\n",
    "    return np.array(end_point).T.reshape(-1, 1)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_correct_error(n_bins, df, error_type='rel_loc', thresh=25):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # 1. Threshold errors\n",
    "    if thresh is not None:\n",
    "        data = df[(df['errors'] >= -thresh) & (df['errors'] <= thresh)].copy()\n",
    "    else:\n",
    "        data = df.copy()\n",
    "\n",
    "    # 2. Bin target locations\n",
    "    bin_edges = np.linspace(0, 360, n_bins + 1)\n",
    "    data['bin_target'] = pd.cut(data['target_loc'], bins=bin_edges, include_lowest=True)\n",
    "    mean_errors_per_bin = data.groupby('bin_target', observed=True)['errors'].mean()\n",
    "\n",
    "    # 3. Remove mean error per target location (for rel_loc)\n",
    "    if error_type == 'rel_loc':\n",
    "        data['adjusted_errors'] = data['errors'] - data['bin_target'].map(mean_errors_per_bin).astype(float)\n",
    "    else:\n",
    "        data['adjusted_errors'] = data['errors']\n",
    "\n",
    "    # 4. Bin by error_type for both full versions\n",
    "    data['bin_error'] = pd.cut(data[error_type], bins=n_bins)\n",
    "    bin_error = data.groupby('bin_error', observed=True)['adjusted_errors'].agg(['mean', 'sem']).reset_index()\n",
    "    edges = bin_error['bin_error'].cat.categories\n",
    "    centers = (edges.left + edges.right) / 2\n",
    "\n",
    "    # 5. Flipped error absolute analysis\n",
    "    if error_type == 'rel_loc':\n",
    "        # Bin abs(rel_loc) from 0 to 180\n",
    "        data['error_abs'] = np.abs(data[error_type])\n",
    "        data['bin_error_abs'] = pd.cut(data['error_abs'], bins=n_bins, include_lowest=True)\n",
    "        # Flip so all directions use same sign\n",
    "        data['adjusted_errors_abs'] = data['adjusted_errors'] * np.sign(data[error_type])\n",
    "    else:\n",
    "        # Bin abs(ref_loc) from 0 to 90\n",
    "        data['error_abs'] = np.abs(data[error_type])\n",
    "        data = data[data['error_abs'] <= 90.0]  # Only 0-90\n",
    "        data['bin_error_abs'] = pd.cut(data['error_abs'], bins=n_bins, include_lowest=True)\n",
    "        # Flip so all directions use same sign for ref_loc\n",
    "        data['adjusted_errors_abs'] = data['adjusted_errors'] * np.sign(data[error_type])\n",
    "\n",
    "    bin_error_abs = data.groupby('bin_error_abs', observed=True)['adjusted_errors_abs'].agg(['mean', 'sem']).reset_index()\n",
    "    edges_abs = bin_error_abs['bin_error_abs'].cat.categories\n",
    "    centers_abs = (edges_abs.left + edges_abs.right) / 2\n",
    "\n",
    "    return centers, bin_error, centers_abs, bin_error_abs\n",
    "```\n",
    "\n",
    "Model\n",
    "=====\n",
    "\n",
    "``` ipython\n",
    "kwargs = {\n",
    "    'GAIN': 1.0,\n",
    "    'DURATION': 6.0,\n",
    "    'T_STEADY': 2,\n",
    "    'T_STIM_ON': [1.0, 5.0],\n",
    "    'T_STIM_OFF': [2.0, 6.0],\n",
    "    'I0': [1.0, -2.0],\n",
    "    'PHI0': [180.0, 180],\n",
    "    'SIGMA0': [1.0, 0.0],\n",
    "    'RANDOM_DELAY': 0,\n",
    "    'MIN_DELAY': 2,\n",
    "    'MAX_DELAY': 5,\n",
    "    'TAU_FAC': [2],\n",
    "    'IF_ADAPT': 1,\n",
    "    'A_ADAPT': 1.0,\n",
    "    'TAU_ADAPT': 100.0,\n",
    "    'IF_FF_ADAPT': 1,\n",
    "    'A_FF_ADAPT': 0.2,\n",
    "    'TAU_FF_ADAPT': 100.0,\n",
    "    'REP_BIAS': 0.0,\n",
    "    'REP_VAR': 2.5,\n",
    "}\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "conf_name = \"train_odr_EI.yml\"\n",
    "DEVICE = 'cuda:1'\n",
    "# seed = np.random.randint(0, 1e6)\n",
    "\n",
    "seed = 3\n",
    "print('seed', seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "N_BATCH = 128\n",
    "print(N_BATCH)\n",
    "model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH, **kwargs)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model_state_dict = torch.load('../models/odr/odr_%d.pth' % seed)\n",
    "model.load_state_dict(model_state_dict);\n",
    "model.eval();\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "stim_start_idx = ((model.start_indices - model.N_STEADY) / model.N_WINDOW).to(int).cpu().numpy()\n",
    "pkl_save(stim_start_idx, 'stim_start_idx')\n",
    "```\n",
    "\n",
    "Simulating Consecutive Trials\n",
    "=============================\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = N_BATCH\n",
    "\n",
    "# continuous odr\n",
    "model.PHI0 = torch.randint(low=0, high=360, size=(N_BATCH, len(model.I0), 1), device=DEVICE, dtype=torch.float)\n",
    "\n",
    "# n target odr\n",
    "# angles = torch.linspace(0, 360, steps=8+1, device=DEVICE)[:-1]  # exclude 360\n",
    "# idx = torch.randint(0, 8, size=(N_BATCH, len(model.I0), 1), device=DEVICE)\n",
    "# model.PHI0 = angles[idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "    ff_input = model.init_ff_input()\n",
    "    rates_tensor = model.forward(ff_input=ff_input)\n",
    "    del ff_input\n",
    "    clear_cache()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "num_epochs = 100\n",
    "\n",
    "rates_list = []\n",
    "thresh_list = [model.thresh_last.cpu().detach()]\n",
    "\n",
    "prev_list = [model.PHI0[:, 0].cpu().detach()]\n",
    "curr_list = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.PHI0 = torch.randint(low=0, high=360, size=(N_BATCH, len(model.I0), 1), device=DEVICE, dtype=torch.float)\n",
    "\n",
    "        ff_input = model.init_ff_input()\n",
    "        rates = model.forward(ff_input=ff_input, IF_INIT=0)\n",
    "\n",
    "        curr_list.append(model.PHI0[:, 0].cpu().detach())\n",
    "        prev_list.append(model.PHI0[:, 0].cpu().detach())\n",
    "\n",
    "        rates_list.append(rates.cpu().detach())\n",
    "        thresh_list.append(model.thresh_last.cpu().detach())\n",
    "\n",
    "        del ff_input, model.PHI0, rates\n",
    "        clear_cache()\n",
    "\n",
    "rates_list = torch.stack(rates_list).cpu().numpy()\n",
    "thresh_list = torch.stack(thresh_list).cpu().numpy()\n",
    "\n",
    "prev_list = torch.stack(prev_list).cpu().numpy()[:-1]\n",
    "curr_list = torch.stack(curr_list).cpu().numpy()\n",
    "\n",
    "print('rates', rates_list.shape, 'thresh', thresh_list.shape)\n",
    "print('curr', curr_list.shape, 'prev', prev_list.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "ax[0].scatter(rates_list[0, 0, -1], rates_list[-1, 0, -1])\n",
    "ax[1].scatter(thresh_list[0, 0], thresh_list[-1, 0])\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plt.plot(thresh_list[:, 0, :10])\n",
    "plt.xlabel('Trial Pair')\n",
    "plt.ylabel('Threshold')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Errors\n",
    "======\n",
    "\n",
    "``` ipython\n",
    "N_TRIALS=100\n",
    "n_half = N_TRIALS // 2\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "curr_ini =  curr_list[:n_half]\n",
    "curr_last = curr_list[-n_half:]\n",
    "\n",
    "prev_ini =  prev_list[:n_half]\n",
    "prev_last = prev_list[-n_half:]\n",
    "print(curr_ini.shape, prev_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "_, _, phi_ini = decode_bump_torch(rates_list[:n_half, ...], axis=-1)\n",
    "print(phi_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "_, _, phi_last = decode_bump_torch(rates_list[-n_half:, ...], axis=-1)\n",
    "print(phi_last.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "targ_ini, rel_ini, errors_ini = get_error_curr_prev(phi_ini, curr_ini, prev_ini)\n",
    "targ_last, rel_last, ref_last, errors_last = get_error_curr_prev(phi_last, curr_last, prev_last)\n",
    "print(targ_ini.shape, rel_ini.shape, ref_ini.shape, errors_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(ref_ini.shape, rel_ini.shape, errors_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "end_point_ini = get_end_point(errors_ini, stim_start_idx)\n",
    "end_point_last = get_end_point(errors_last, stim_start_idx)\n",
    "print(end_point_ini.shape, end_point_last.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].hist(end_point_ini[:, 0], bins=30)\n",
    "ax[0].set_xlabel('Errors First Half(°)')\n",
    "\n",
    "ax[1].hist(end_point_last[:, 0], bins=30)\n",
    "ax[1].set_xlabel('Errors Second Half(°)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "time_points = np.linspace(0, DURATION, errors_ini.shape[-1])\n",
    "idx = np.random.randint(errors_ini.shape[1], size=100)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "ax[0].plot(time_points, errors_ini[0][idx].T, alpha=.4)\n",
    "add_vlines(ax[0])\n",
    "\n",
    "ax[0].set_xlabel('t')\n",
    "ax[0].set_ylabel('Error first Half(°)')\n",
    "\n",
    "ax[1].plot(time_points, errors_last[0][idx].T, alpha=.4)\n",
    "add_vlines(ax[1])\n",
    "\n",
    "ax[1].set_xlabel('t')\n",
    "ax[1].set_ylabel('Error 2nd Half (°)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Serial Bias Curves First/Second Half\n",
    "====================================\n",
    "\n",
    "``` ipython\n",
    "print(targ_ini.shape, rel_ini.shape, ref_ini.shape, end_point_ini.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "n_bins = 16\n",
    "data_ini = pd.DataFrame({'target_loc': targ_ini[:, -1], 'rel_loc': rel_ini[:, -1], 'ref_loc': ref_ini[:, -1], 'errors': end_point_ini[:, 0]})\n",
    "data_last = pd.DataFrame({'target_loc': targ_last[:, -1], 'rel_loc': rel_last[:, -1], 'ref_loc': ref_last[:, -1], 'errors': end_point_last[:, 0]})\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "centers_ini, bin_rel_ini, centers_abs_ini, bin_rel_abs_ini = get_correct_error(n_bins, data_ini)\n",
    "centers_last, bin_rel_last, centers_abs_last, bin_rel_abs_last = get_correct_error(n_bins, data_last)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].plot(centers_ini, bin_rel_ini['mean'], 'r', label='First half')\n",
    "ax[0].fill_between(centers_ini, bin_rel_ini['mean'] - bin_rel_ini['sem'], bin_rel_ini['mean'] + bin_rel_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[0].plot(centers_last, bin_rel_last['mean'], 'b', label='Last half')\n",
    "ax[0].fill_between(centers_last, bin_rel_last['mean'] - bin_rel_last['sem'], bin_rel_last['mean'] + bin_rel_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[0].axhline(0, color='k', linestyle=\":\")\n",
    "ax[0].set_xlabel('Rel. Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "ax[0].set_xticks(np.linspace(-180, 180, 5))\n",
    "\n",
    "ax[1].plot(centers_abs_ini, bin_rel_abs_ini['mean'], 'r', label='First half')\n",
    "ax[1].fill_between(centers_abs_ini, bin_rel_abs_ini['mean'] - bin_rel_abs_ini['sem'], bin_rel_abs_ini['mean'] + bin_rel_abs_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[1].plot(centers_abs_last, bin_rel_abs_last['mean'], 'b', label='Last half')\n",
    "ax[1].fill_between(centers_abs_last, bin_rel_abs_last['mean'] - bin_rel_abs_last['sem'], bin_rel_abs_last['mean'] + bin_rel_abs_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[1].axhline(0, color='k', linestyle=\":\")\n",
    "ax[1].set_xlabel('Rel. Loc. (°)')\n",
    "ax[1].set_ylabel('Flip. Error (°)')\n",
    "ax[1].legend(fontsize=12)\n",
    "ax[1].set_xticks(np.linspace(0, 180, 3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "centers_ref_ini, bin_ref_ini, centers_ref_abs_ini, bin_ref_abs_ini = get_correct_error(n_bins, data_ini, error_type='ref_loc')\n",
    "centers_ref_last, bin_ref_last, centers_ref_abs_last, bin_ref_abs_last = get_correct_error(n_bins, data_last, error_type='ref_loc')\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].plot(centers_ref_ini, bin_ref_ini['mean'], 'r', label='First half')\n",
    "ax[0].fill_between(centers_ref_ini, bin_ref_ini['mean'] - bin_ref_ini['sem'], bin_ref_ini['mean'] + bin_ref_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[0].plot(centers_ref_last, bin_ref_last['mean'], 'b', label='Last half')\n",
    "ax[0].fill_between(centers_ref_last, bin_ref_last['mean'] - bin_ref_last['sem'], bin_ref_last['mean'] + bin_ref_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[0].axhline(0, color='k', linestyle=\":\")\n",
    "ax[0].set_xlabel('Ref. Loc. (°)')\n",
    "ax[0].set_ylabel('Error (°)')\n",
    "ax[0].set_xticks(np.linspace(-180, 180, 5))\n",
    "\n",
    "ax[1].plot(centers_ref_abs_ini, bin_ref_abs_ini['mean'], 'r', label='First half')\n",
    "ax[1].fill_between(centers_ref_abs_ini, bin_ref_abs_ini['mean'] - bin_ref_abs_ini['sem'], bin_ref_abs_ini['mean'] + bin_ref_abs_ini['sem'], color='r', alpha=0.2)\n",
    "\n",
    "ax[1].plot(centers_ref_abs_last, bin_ref_abs_last['mean'], 'b', label='Last half')\n",
    "ax[1].fill_between(centers_ref_abs_last, bin_ref_abs_last['mean'] - bin_ref_abs_last['sem'], bin_ref_abs_last['mean'] + bin_ref_abs_last['sem'], color='b', alpha=0.2)\n",
    "\n",
    "ax[1].axhline(0, color='k', linestyle=\":\")\n",
    "ax[1].set_xlabel('Ref. Loc. (°)')\n",
    "ax[1].set_ylabel('Flip. Error (°)')\n",
    "ax[1].legend(fontsize=12)\n",
    "ax[1].set_xticks(np.linspace(0, 90, 3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Bias Evolution along a session\n",
    "==============================\n",
    "\n",
    "``` ipython\n",
    "_, _, phi_list = decode_bump_torch(rates_list, axis=-1)\n",
    "print(phi_list.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "cmap = plt.get_cmap('Blues')\n",
    "colors = [cmap( (i+1) / phi_list.shape[0] ) for i in range(phi_list.shape[0])]\n",
    "\n",
    "n_bins = 8\n",
    "\n",
    "serial_list = []\n",
    "ref_bias_list = []\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "for i in range(phi_list.shape[0]): # trial by trial\n",
    "    targ_trial, rel_trial, ref_trial, errors_trial = get_error_curr_prev(phi_list[i, np.newaxis], curr_list[i, np.newaxis], prev_list[i, np.newaxis], ref_list)\n",
    "\n",
    "    end_point_trial = get_end_point(errors_trial, stim_start_idx)\n",
    "\n",
    "    # print(targ_trial.shape, rel_trial.shape, ref_trial.shape, errors_trial.shape, end_point_trial.shape)\n",
    "\n",
    "    data = pd.DataFrame({'target_loc': targ_trial[:, -1], 'rel_loc': rel_trial[:, -1], 'ref_loc': ref_trial[:, -1], 'errors': end_point_trial[:, 0]})\n",
    "\n",
    "    centers, bin_rel, centers_abs, bin_rel_abs = get_correct_error(n_bins, data)\n",
    "    centers_ref, bin_ref, centers_abs, bin_ref_abs = get_correct_error(n_bins, data, error_type='ref_loc')\n",
    "\n",
    "    ax[0].plot(centers, bin_rel['mean'], color=colors[i], alpha=1)\n",
    "    ax[0].axhline(0, ls='--', color='k')\n",
    "    ax[0].set_xlabel('Rel. Loc. (°)')\n",
    "    ax[0].set_ylabel('Error (°)')\n",
    "    ax[0].set_xticks(np.linspace(-180, 180, 5))\n",
    "\n",
    "    ax[1].plot(centers_ref, bin_ref['mean'], color=colors[i], alpha=1)\n",
    "    ax[1].axhline(0, ls='--', color='k')\n",
    "    ax[1].set_xlabel('Ref. Loc. (°)')\n",
    "    ax[1].set_ylabel('Error (°)')\n",
    "    ax[1].set_xticks(np.linspace(-180, 180, 5))\n",
    "\n",
    "    idx_max = np.argmax(abs(bin_rel_abs['mean']))\n",
    "    serial_max = bin_rel_abs['mean'][idx_max]\n",
    "    serial_std = bin_rel_abs['sem'][idx_max]\n",
    "\n",
    "    serial_list.append([serial_max, serial_std])\n",
    "\n",
    "    idx_max = np.argmax(abs(bin_ref_abs['mean']))\n",
    "    ref_max = bin_ref_abs['mean'][idx_max]\n",
    "    ref_std = bin_ref_abs['sem'][idx_max]\n",
    "\n",
    "    ref_bias_list.append([ref_max, ref_std])\n",
    "\n",
    "serial_list = np.array(serial_list).T\n",
    "ref_bias_list = np.array(ref_bias_list).T\n",
    "print(serial_list.shape)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "xtrial = np.linspace(0, N_TRIALS, serial_list.shape[1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "s0 = 5\n",
    "ax[0].plot(xtrial, gaussian_filter1d(serial_list[0], s0), '-')\n",
    "ax[0].fill_between(xtrial, gaussian_filter1d(serial_list[0] - serial_list[1], s0), gaussian_filter1d(serial_list[0] + serial_list[1], s0), color='b', alpha=0.2)\n",
    "ax[0].axhline(0, ls='--', color='k')\n",
    "\n",
    "ax[0].set_xlabel('Trial #')\n",
    "ax[0].set_ylabel('Serial Bias (°)')\n",
    "\n",
    "ax[1].plot(xtrial, gaussian_filter1d(ref_bias_list[0], s0), '-')\n",
    "ax[1].fill_between(xtrial, gaussian_filter1d(ref_bias_list[0] - ref_bias_list[1], s0), gaussian_filter1d(ref_bias_list[0] + ref_bias_list[1], s0), color='b', alpha=0.2)\n",
    "ax[1].axhline(0, ls='--', color='k')\n",
    "\n",
    "ax[1].set_xlabel('Trial #')\n",
    "ax[1].set_ylabel('Ref. Bias (°)')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
