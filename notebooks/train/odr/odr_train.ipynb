{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Settings\n",
    "=================\n",
    "\n",
    "``` ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "%run ../../../notebooks/setup.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "pal = sns.color_palette(\"tab10\")\n",
    "```\n",
    "\n",
    "Imports\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "DEVICE = 'cuda:0'\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from time import perf_counter\n",
    "from scipy.stats import circmean\n",
    "\n",
    "from src.network import Network\n",
    "from src.plot_utils import plot_con\n",
    "from src.decode import decode_bump, circcvl, decode_bump_torch\n",
    "from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor\n",
    "```\n",
    "\n",
    "Helpers\n",
    "=======\n",
    "\n",
    "plots\n",
    "-----\n",
    "\n",
    "``` ipython\n",
    "def plot_rates_selec(rates, idx=0, thresh=0.5, figname='fig.svg'):\n",
    "        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "        r_max = thresh * np.max(rates[idx])\n",
    "\n",
    "        ax[0].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)\n",
    "        ax[0].set_ylabel('Neuron #')\n",
    "        ax[0].set_xlabel('Step')\n",
    "\n",
    "        plt.savefig(figname, dpi=300)\n",
    "        plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def plot_m0_m1_phi(rates, idx, figname='fig.svg'):\n",
    "\n",
    "    # m0, m1, phi = decode_bump(rates, axis=-1)\n",
    "    m0, m1, phi = get_fourier_moments(rates, axis=-1)\n",
    "    fig, ax = plt.subplots(1, 3, figsize=[2*width, height])\n",
    "\n",
    "    ax[0].plot(m0.T)\n",
    "    #ax[0].set_ylim([0, 360])\n",
    "    #ax[0].set_yticks([0, 90, 180, 270, 360])\n",
    "    ax[0].set_ylabel('$\\mathcal{F}_0$ (Hz)')\n",
    "    ax[0].set_xlabel('Step')\n",
    "\n",
    "    ax[1].plot(m1.T)\n",
    "    # ax[1].set_ylim([0, 360])\n",
    "    # ax[1].set_yticks([0, 90, 180, 270, 360])\n",
    "    ax[1].set_ylabel('$\\mathcal{F}_1$ (Hz)')\n",
    "    ax[1].set_xlabel('Step')\n",
    "\n",
    "    ax[2].plot(phi.T * 180 / np.pi, alpha=.5)\n",
    "    ax[2].set_ylim([0, 360])\n",
    "    ax[2].set_yticks([0, 90, 180, 270, 360])\n",
    "    ax[2].set_ylabel('Phase (Â°)')\n",
    "    ax[2].set_xlabel('Step')\n",
    "\n",
    "    plt.savefig(figname, dpi=300)\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "Data Split\n",
    "----------\n",
    "\n",
    "``` ipython\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "def split_data(X, Y, train_perc=0.8, batch_size=32):\n",
    "\n",
    "   X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                       train_size=train_perc,\n",
    "                                                       stratify=Y[:, 0].cpu().numpy(),\n",
    "                                                       shuffle=True)\n",
    "\n",
    "   print(X_train.shape, X_test.shape)\n",
    "   print(Y_train.shape, Y_test.shape)\n",
    "\n",
    "   train_dataset = TensorDataset(X_train, Y_train)\n",
    "   val_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "   # Create data loaders\n",
    "   train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "   val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "   return train_loader, val_loader\n",
    "```\n",
    "\n",
    "Optimization\n",
    "------------\n",
    "\n",
    "``` ipython\n",
    "def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=.001, clip_grad=0, zero_grad=0):\n",
    "    device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        rates = model(X)\n",
    "        loss = loss_fn(rates, y)\n",
    "\n",
    "        if penalty is not None:\n",
    "            reg_loss = 0\n",
    "            for param in model.parameters():\n",
    "                if penalty=='l1':\n",
    "                    reg_loss += torch.sum(torch.abs(param))\n",
    "                else:\n",
    "                    reg_loss += torch.sum(torch.square(param))\n",
    "\n",
    "                loss = loss + lbd * reg_loss\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients\n",
    "        if clip_grad:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "            #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def validation_step(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Validation loop.\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            rates = model(X)\n",
    "            loss = loss_fn(rates, y)\n",
    "\n",
    "            val_loss += loss.item() * X.size(0)\n",
    "\n",
    "        val_loss /= size\n",
    "    return val_loss\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def optimization(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=.005, zero_grad=0):\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "    # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    loss_list = []\n",
    "    val_loss_list = []\n",
    "    accuracies = []\n",
    "    angle_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, zero_grad=zero_grad)\n",
    "        val_loss = validation_step(val_loader, model, loss_fn)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        val_loss_list.append(val_loss)\n",
    "        # if epoch % int(num_epochs  / 10) == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        if val_loss < thresh and loss < thresh:\n",
    "            print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')\n",
    "            break\n",
    "\n",
    "        if val_loss > 300:\n",
    "            print(f'Stopping training as loss is too high: {val_loss}')\n",
    "            break\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            print(f'Stopping training as loss is NaN.')\n",
    "            break\n",
    "\n",
    "    return loss_list, val_loss_list\n",
    "```\n",
    "\n",
    "Loss\n",
    "----\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NanMeanMSELoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(NanMeanMSELoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # Element-wise difference\n",
    "        diff = input - target\n",
    "\n",
    "        # Squared difference\n",
    "        squared_diff = diff ** 2\n",
    "\n",
    "        # Initialize a tensor to store the errors\n",
    "        batch_errors = torch.zeros(input.size(0), device=input.device)\n",
    "\n",
    "        # Compute mean squared error for each batch\n",
    "        for i in range(input.size(0)):\n",
    "            batch_mask = ~torch.isnan(input[i])\n",
    "            if torch.sum(batch_mask) > 0:\n",
    "                batch_errors[i] = torch.nanmean(squared_diff[i])\n",
    "            else:\n",
    "                batch_errors[i] = 0  # Handle case where all values are NaN in the batch\n",
    "\n",
    "        # Apply reduction method\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(batch_errors)\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(batch_errors)\n",
    "        else:\n",
    "            return batch_errors  # No reduction, return individual batch errors\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_fourier_moments(signal, axis=-1):\n",
    "    # Perform the FFT\n",
    "    fft_coeffs = np.fft.fft(signal, axis=axis)\n",
    "\n",
    "    # Calculate the zero, first, and second Fourier moments\n",
    "    zero_moment = fft_coeffs[..., 0]\n",
    "    first_moment = fft_coeffs[..., 1]\n",
    "\n",
    "    # Calculate magnitude m0, m1, and m2\n",
    "    m0 = np.abs(zero_moment) / signal.shape[axis]  # Normalize m0 by the signal length\n",
    "    m1 = 2.0 * np.abs(first_moment) / signal.shape[axis]\n",
    "\n",
    "    # Calculate the phase of the signal\n",
    "    phases = np.angle(first_moment) % (2.0 * torch.pi)\n",
    "\n",
    "    return m0, m1, phases\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def compute_fourier_moments(signal, dim=-1):\n",
    "    # Perform the FFT\n",
    "    fft_coeffs = torch.fft.fft(signal, dim=dim)\n",
    "\n",
    "    # Calculate the zero, first, and second Fourier moments\n",
    "    zero_moment = fft_coeffs[..., 0]\n",
    "    first_moment = fft_coeffs[..., 1]\n",
    "    second_moment = fft_coeffs[..., 2]\n",
    "\n",
    "    # Calculate magnitude m0, m1, and m2\n",
    "    m0 = torch.abs(zero_moment) / signal.size(dim)  # Normalize m0 by the signal length\n",
    "    m1 = 2.0 * torch.abs(first_moment) / signal.size(dim)\n",
    "    m2 = 2.0 * torch.abs(second_moment) / signal.size(dim)\n",
    "\n",
    "    # Calculate the phase of the signal\n",
    "    phases = torch.angle(first_moment) % (2.0 * torch.pi)\n",
    "\n",
    "    return m0, m1, m2, phases\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AngularErrorLoss(nn.Module):\n",
    "    def __init__(self, rwd_idx=-1, zero_idx=0, stim_idx=0):\n",
    "        super(AngularErrorLoss, self).__init__()\n",
    "        self.loss = nn.SmoothL1Loss()\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.loss = NanMeanMSELoss()\n",
    "        self.rwd_idx = rwd_idx\n",
    "        self.zero_idx = zero_idx\n",
    "        self.stim_idx = stim_idx\n",
    "\n",
    "    def forward(self, readout, targets):\n",
    "        m0, m1, m2, phi = compute_fourier_moments(readout, dim=-1)\n",
    "\n",
    "        ones = torch.ones_like(m0[:, self.rwd_idx])\n",
    "        zeros = torch.zeros_like(m0[:, self.zero_idx])\n",
    "\n",
    "        # Compute the angular difference\n",
    "        # predicted_angles = phi[:, self.rwd_idx]\n",
    "        # angular_diff = torch.atan2(torch.sin(predicted_angles - targets), torch.cos(predicted_angles - targets))\n",
    "        # # Compute Smooth L1 Loss based on angular differences\n",
    "        # loss_angular = self.loss(angular_diff, torch.zeros_like(angular_diff))\n",
    "\n",
    "        predicted_sin = torch.sin(phi[:, self.rwd_idx])\n",
    "        predicted_cos = torch.cos(phi[:, self.rwd_idx])\n",
    "\n",
    "        target_sin = torch.sin(targets)\n",
    "        target_cos = torch.cos(targets)\n",
    "\n",
    "        loss_sin = self.loss(predicted_sin, target_sin)\n",
    "        loss_cos = self.loss(predicted_cos, target_cos)\n",
    "        loss_angular = (loss_sin + loss_cos) / 2\n",
    "\n",
    "        # Regularization losses\n",
    "        loss_zero = self.loss(m1[:, self.zero_idx], zeros)\n",
    "        regularization = F.relu(ones - m1[:, self.rwd_idx] / m0[:, self.rwd_idx]).mean()\n",
    "\n",
    "        # Combine losses\n",
    "        total_loss = loss_angular + loss_zero + regularization\n",
    "\n",
    "        return total_loss\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AngularErrorLoss2(nn.Module):\n",
    "    def __init__(self, rwd_idx=-1, zero_idx=0, stim_idx=0):\n",
    "        super(AngularErrorLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.loss = nn.SmoothL1Loss()\n",
    "\n",
    "        self.rwd_idx = rwd_idx\n",
    "        self.zero_idx = zero_idx\n",
    "        self.stim_idx = stim_idx\n",
    "\n",
    "    def forward(self, readout, targets):\n",
    "        # m0, m1 , phi = decode_bump_torch(readout)\n",
    "        m0, m1, m2, phi = compute_fourier_moments(readout, dim=-1)\n",
    "\n",
    "        ones = torch.ones_like(m0[:, self.rwd_idx])\n",
    "        zeros = torch.zeros_like(m0[:, self.zero_idx])\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        predicted_sin = torch.sin(phi[:, self.rwd_idx])\n",
    "        predicted_cos = torch.cos(phi[:, self.rwd_idx])\n",
    "\n",
    "        target_sin = torch.sin(targets)\n",
    "        target_cos = torch.cos(targets)\n",
    "\n",
    "        loss_sin = self.loss(predicted_sin, target_sin)\n",
    "        loss_cos = self.loss(predicted_cos, target_cos)\n",
    "        loss += (loss_sin + loss_cos) / 2\n",
    "\n",
    "        loss += self.loss(m1[:, self.zero_idx], zeros) * len(self.zero_idx)\n",
    "        # loss += self.loss(m1[:, self.rwd_idx] / m0[:, self.rwd_idx], ones) * len(self.rwd_idx)\n",
    "        loss += F.relu(ones - m1[:, self.rwd_idx] / m0[:, self.rwd_idx]).mean() * len(self.rwd_idx)\n",
    "        return loss\n",
    "```\n",
    "\n",
    "Other\n",
    "-----\n",
    "\n",
    "``` ipython\n",
    "def angle_AB(A, B):\n",
    "    A_norm = A / (np.linalg.norm(A) + 1e-5)\n",
    "    B_norm = B / (np.linalg.norm(B) + 1e-5)\n",
    "\n",
    "    return int(np.arccos(A_norm @ B_norm) * 180 / np.pi)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def convert_seconds(seconds):\n",
    "    h = seconds // 3600\n",
    "    m = (seconds % 3600) // 60\n",
    "    s = seconds % 60\n",
    "    return h, m, s\n",
    "```\n",
    "\n",
    "Model\n",
    "=====\n",
    "\n",
    "``` ipython\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "conf_name = \"train_odr_EI.yml\"\n",
    "DEVICE = 'cuda:0'\n",
    "seed = np.random.randint(0, 1e6)\n",
    "print(seed)\n",
    "N_BATCH = 32\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(model.random_shifts.shape)\n",
    "```\n",
    "\n",
    "Training\n",
    "========\n",
    "\n",
    "### Parameters\n",
    "\n",
    "``` ipython\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape)\n",
    "```\n",
    "\n",
    "Testing the network on steps from sample odor offset to test odor onset\n",
    "\n",
    "``` ipython\n",
    "stim_mask = torch.zeros((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)), device=DEVICE, dtype=torch.bool)\n",
    "print('stim_mask', stim_mask.shape)\n",
    "\n",
    "for j in range(model.N_BATCH):\n",
    "        # from ith stim onset to stim offset\n",
    "        mask = torch.arange((model.start_indices[0, j] - model.N_STEADY)/ model.N_WINDOW,\n",
    "                            (model.end_indices[0, j] - model.N_STEADY) / model.N_WINDOW).to(torch.int)\n",
    "        stim_mask[j, mask] = True\n",
    "\n",
    "idx = np.random.randint(32)\n",
    "print(torch.where(stim_mask[0]==1)[0])\n",
    "stim_mask = stim_mask.repeat(N_TARGETS, 1)\n",
    "print('stim_mask', stim_mask.shape)\n",
    "print(torch.where(stim_mask[32]==1)[0])\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rwd_mask = torch.zeros((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)), device=DEVICE, dtype=torch.bool)\n",
    "print('rwd_mask', rwd_mask.shape)\n",
    "\n",
    "for i in range(model.N_BATCH):\n",
    "    # from first stim onset to second stim onset\n",
    "    mask = torch.arange((model.start_indices[0, i] - model.N_STEADY)/ model.N_WINDOW,\n",
    "                        (model.start_indices[1, i] - model.N_STEADY) / model.N_WINDOW).to(torch.int)\n",
    "    # print(mask)\n",
    "    rwd_mask[i, mask] = True\n",
    "\n",
    "idx = np.random.randint(32)\n",
    "print(torch.where(rwd_mask[idx]==1)[0])\n",
    "# model.lr_eval_win = torch.max(torch.sum(rwd_mask==1, axis=-1))\n",
    "\n",
    "rwd_mask = rwd_mask.repeat(N_TARGETS, 1)\n",
    "print('rwd_mask', rwd_mask.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "zero_mask = torch.zeros((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)), device=DEVICE, dtype=torch.bool)\n",
    "print('zero_mask', zero_mask.shape)\n",
    "\n",
    "for i in range(model.N_BATCH):\n",
    "    mask = ~rwd_mask[i]\n",
    "    zero_mask[i, mask] = True\n",
    "\n",
    "idx = np.random.randint(32)\n",
    "print(torch.where(zero_mask[idx]==1)[0])\n",
    "\n",
    "zero_mask = zero_mask.repeat(N_TARGETS, 1)\n",
    "print('zero_mask', zero_mask.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)\n",
    "\n",
    "# mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))\n",
    "stim_mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STIM_OFF[0].cpu().numpy() - model.N_STEADY))\n",
    "\n",
    "stim_idx = np.where(stim_mask)[0]\n",
    "print('stim', stim_idx)\n",
    "\n",
    "mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STIM_ON[1].cpu().numpy() - model.N_STEADY))\n",
    "rwd_idx = np.where(mask)[0]\n",
    "print('rwd', rwd_idx)\n",
    "\n",
    "model.lr_eval_win = rwd_idx.shape[0]\n",
    "\n",
    "stim_mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STIM_ON[1].cpu().numpy() - model.N_STEADY))\n",
    "\n",
    "# stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY))\n",
    "\n",
    "zero_idx = np.where(~mask & ~stim_mask )[0]\n",
    "print('zero', zero_idx)\n",
    "```\n",
    "\n",
    "### Inputs and Labels\n",
    "\n",
    "``` ipython\n",
    "N_TARGETS = 8\n",
    "phase_list = np.linspace(0, 360, N_TARGETS+1)[:-1]\n",
    "print(phase_list)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(model.PHI0.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "ff_input = []\n",
    "labels = []\n",
    "\n",
    "model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)\n",
    "\n",
    "for i in range(len(phase_list)):\n",
    "    model.PHI0[:, 0] = phase_list[i]\n",
    "    labels.append(torch.ones((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)),\n",
    "                             device=DEVICE, dtype=torch.float) * phase_list[i] * torch.pi / 180.0)\n",
    "\n",
    "    ff_input.append(model.init_ff_input())\n",
    "\n",
    "labels = torch.vstack(labels)\n",
    "ff_input = torch.vstack(ff_input)\n",
    "print('ff_input', ff_input.shape, 'labels', labels.shape)\n",
    "```\n",
    "\n",
    "### Run\n",
    "\n",
    "``` ipython\n",
    "batch_size = 32\n",
    "train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "criterion = AngularErrorLoss(rwd_idx=rwd_idx, zero_idx=zero_idx, stim_idx=stim_idx)\n",
    "# SGD, Adam, Adam\n",
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "num_epochs = 15\n",
    "start = perf_counter()\n",
    "loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n",
    "end = perf_counter()\n",
    "print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "torch.save(model.state_dict(), 'models/odr.pth')\n",
    "```\n",
    "\n",
    "Testing\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "# model_state_dict = torch.load('models/odr.pth')\n",
    "# model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=4)\n",
    "# model.load_state_dict(model_state_dict)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(phase_list)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "  model.N_BATCH = 8\n",
    "\n",
    "  ff_input = []\n",
    "  labels = []\n",
    "\n",
    "  model.PHI0 = torch.ones((1, model.PHI0.shape[-1]), device=DEVICE, dtype=torch.float)\n",
    "\n",
    "  for i in range(len(phase_list)):\n",
    "      model.PHI0[0] = phase_list[i]\n",
    "      ff_input.append(model.init_ff_input())\n",
    "\n",
    "ff_input = torch.vstack(ff_input)\n",
    "print('ff_input', ff_input.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(model.PHI0)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rates = model.forward(ff_input=ff_input).cpu().detach().numpy()\n",
    "print('rates', rates.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(ff_input.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plot_rates_selec(rates=ff_input.cpu().detach().numpy(), idx=20, thresh=.5)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plot_m0_m1_phi(ff_input.cpu().numpy()[..., model.slices[0]], 10)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "m0, m1, phi = decode_bump(ff_input.cpu().numpy()[..., model.slices[0]], axis=-1)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plot_rates_selec(rates, idx=30, thresh=.2)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plot_m0_m1_phi(rates, 3)\n",
    "```"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
