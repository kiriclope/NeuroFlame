{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Settings\n",
    "=================\n",
    "\n",
    "``` ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%run ../../../notebooks/setup.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "```\n",
    "\n",
    "Imports\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pal = sns.color_palette(\"tab10\")\n",
    "DEVICE = 'cuda:1'\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "from notebooks.setup import *\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from time import perf_counter\n",
    "from scipy.stats import circmean\n",
    "\n",
    "from src.network import Network\n",
    "from src.plot_utils import plot_con\n",
    "from src.decode import decode_bump, circcvl\n",
    "from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor\n",
    "```\n",
    "\n",
    "Helpers\n",
    "=======\n",
    "\n",
    "Data Split\n",
    "----------\n",
    "\n",
    "``` ipython\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "def split_data(X, Y, train_perc=0.8, batch_size=32):\n",
    "\n",
    "    if Y.ndim==3:\n",
    "      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                          train_size=train_perc,\n",
    "                                                          stratify=Y[:, 0, 0].cpu().numpy(),\n",
    "                                                          shuffle=True)\n",
    "    else:\n",
    "      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                          train_size=train_perc,\n",
    "                                                          stratify=Y[:, 0].cpu().numpy(),\n",
    "                                                          shuffle=True)\n",
    "\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    print(Y_train.shape, Y_test.shape)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, Y_train)\n",
    "    val_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "```\n",
    "\n",
    "Optimization\n",
    "------------\n",
    "\n",
    "``` ipython\n",
    "def torch_angle_AB(U, V):\n",
    "      # Calculate the dot product\n",
    "      dot_product = torch.dot(U, V)\n",
    "\n",
    "      # Calculate the magnitudes of U and V\n",
    "      magnitude_U = torch.linalg.norm(U)\n",
    "      magnitude_V = torch.linalg.norm(V)\n",
    "\n",
    "      # Compute the cosine of the angle\n",
    "      cos_theta = dot_product / (magnitude_U * magnitude_V + .00001)\n",
    "\n",
    "      # Calculate the angle in radians, then convert to degrees\n",
    "      angle_radians = torch.acos(cos_theta)\n",
    "      return torch.round(torch.rad2deg(angle_radians))\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def skewness(tensor, dim=0):\n",
    "    mean = torch.mean(tensor, dim)\n",
    "    std_dev = torch.std(tensor, dim) + 1e-6\n",
    "    skew = torch.mean(((tensor - mean) / std_dev) ** 3, dim)\n",
    "    return skew\n",
    "\n",
    "def kurtosis(tensor, dim=0):\n",
    "    mean = torch.mean(tensor, dim)\n",
    "    std_dev = torch.std(tensor, dim) + 1e-6\n",
    "    kurt = torch.mean(((tensor - mean) / std_dev) ** 4, dim) - 3  # Excess kurtosis\n",
    "    return kurt\n",
    "\n",
    "def gaussianity_loss(parameters):\n",
    "    loss = 0.0\n",
    "    for param in parameters:\n",
    "        if param.numel()!=1:\n",
    "            skew = skewness(param)\n",
    "            kurt = kurtosis(param)\n",
    "            loss += (skew ** 2 + kurt ** 2)\n",
    "    return loss.mean()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1, clip_grad=0, zero_grad=None, IF_GAUSS=0):\n",
    "\n",
    "      model.train()\n",
    "      total_loss = 0.0\n",
    "      total_batches = len(dataloader)\n",
    "\n",
    "      for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(model.device), y.to(model.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            rates = model(X)\n",
    "            loss = loss_fn(model.readout, y)\n",
    "\n",
    "            if IF_GAUSS:\n",
    "                  loss += 0.1 * gaussianity_loss(model.parameters())\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if zero_grad is not None:\n",
    "                  try:\n",
    "                        if zero_grad == 'all':\n",
    "                              model.low_rank.U.grad[:, :] = 0\n",
    "                              model.low_rank.V.grad[:, :] = 0\n",
    "                        else:\n",
    "                              model.low_rank.U.grad[:, zero_grad] = 0\n",
    "                              model.low_rank.V.grad[:, zero_grad] = 0\n",
    "                  except:\n",
    "                        pass\n",
    "\n",
    "            if clip_grad:\n",
    "                  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "                  #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "      avg_loss = total_loss / total_batches\n",
    "      return avg_loss\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def validation_step(dataloader, model, loss_fn):\n",
    "      num_batches = len(dataloader)\n",
    "      model.eval()\n",
    "\n",
    "      val_loss = 0.0\n",
    "      with torch.no_grad():\n",
    "          for X, y in dataloader:\n",
    "              X, y = X.to(model.device), y.to(model.device)\n",
    "\n",
    "              rates = model(X)\n",
    "              loss = loss_fn(model.readout, y)\n",
    "              val_loss += loss.item()\n",
    "\n",
    "          val_loss /= num_batches\n",
    "\n",
    "      return val_loss\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def validation_step(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            rates = model(X)\n",
    "            batch_loss = loss_fn(model.readout, y)\n",
    "            val_loss += batch_loss.item() * X.size(0)\n",
    "\n",
    "    val_loss /= size\n",
    "    return val_loss\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def optimization(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=.005, zero_grad=None, IF_GAUSS=0):\n",
    "      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)\n",
    "      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "      device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')\n",
    "      model.to(device)\n",
    "\n",
    "      loss_list = []\n",
    "      val_loss_list = []\n",
    "      angle_list = []\n",
    "\n",
    "      for epoch in range(num_epochs):\n",
    "          loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, zero_grad=zero_grad, IF_GAUSS=IF_GAUSS)\n",
    "          val_loss = validation_step(val_loader, model, loss_fn)\n",
    "\n",
    "          scheduler.step(val_loss)\n",
    "          loss_list.append(loss)\n",
    "          val_loss_list.append(val_loss)\n",
    "\n",
    "          memory = model.low_rank.V[model.slices[0], 0]\n",
    "          readout = model.low_rank.V[model.slices[0], 1]\n",
    "\n",
    "          angle = torch_angle_AB(memory, readout).item()\n",
    "          angle_list.append(angle)\n",
    "\n",
    "          print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}, Angle(U, W) : {angle} 째')\n",
    "\n",
    "          if val_loss < thresh and loss < thresh:\n",
    "              print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')\n",
    "              break\n",
    "\n",
    "          if val_loss > 300:\n",
    "              print(f'Stopping training as loss is too high: {val_loss}')\n",
    "              break\n",
    "\n",
    "          if torch.isnan(torch.tensor(loss)):\n",
    "              print(f'Stopping training as loss is NaN.')\n",
    "              break\n",
    "\n",
    "      return loss_list, val_loss_list\n",
    "```\n",
    "\n",
    "Loss\n",
    "----\n",
    "\n",
    "``` ipython\n",
    "def imbalance_func(target, imbalance):\n",
    "    output = torch.zeros_like(target)\n",
    "\n",
    "    output[target == 0] = imbalance\n",
    "    output[target == 1] = 1\n",
    "\n",
    "    return output\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SignBCELoss(nn.Module):\n",
    "      def __init__(self, alpha=1.0, thresh=2.0, imbalance=0):\n",
    "            super(SignBCELoss, self).__init__()\n",
    "            self.alpha = alpha\n",
    "            self.thresh = thresh\n",
    "\n",
    "            self.imbalance = imbalance\n",
    "            self.bce_with_logits = nn.BCEWithLogitsLoss()\n",
    "\n",
    "      def forward(self, readout, targets):\n",
    "            if self.alpha != 1.0:\n",
    "                  bce_loss = self.bce_with_logits(readout, targets)\n",
    "            else:\n",
    "                  bce_loss = 0.0\n",
    "\n",
    "            # average readout over bins\n",
    "            mean_readout = readout.mean(dim=1).unsqueeze(-1)\n",
    "\n",
    "            # only penalizing not licking when pair\n",
    "            if self.imbalance == -1:\n",
    "                  # sign_overlap = torch.abs(torch.sign(2 * targets - 1)) * mean_readout\n",
    "                  sign_overlap = torch.sign(targets) * mean_readout\n",
    "                  self.imbalance = 0\n",
    "            else:\n",
    "                  sign_overlap = torch.sign(2 * targets - 1) * mean_readout\n",
    "\n",
    "            if self.imbalance > 1.0:\n",
    "                  sign_loss = F.relu(torch.sign(targets) * self.thresh - imbalance_func(targets, self.imbalance) * sign_overlap)\n",
    "            elif self.imbalance == 0:\n",
    "                  sign_loss = F.relu(imbalance_func(targets, self.imbalance) * self.thresh - sign_overlap)\n",
    "            else:\n",
    "                  sign_loss = F.relu(self.thresh - sign_overlap)\n",
    "\n",
    "            combined_loss = (1-self.alpha) * bce_loss + self.alpha * sign_loss\n",
    "\n",
    "            return combined_loss.mean()\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "class DualLoss(nn.Module):\n",
    "      def __init__(self, alpha=1.0, thresh=2.0, cue_idx=[], rwd_idx=-1, zero_idx=[], read_idx=[-1], imbalance=0):\n",
    "            super(DualLoss, self).__init__()\n",
    "            self.alpha = alpha\n",
    "            self.thresh = thresh\n",
    "            self.imbalance = imbalance\n",
    "\n",
    "            # BL idx\n",
    "            self.zero_idx = zero_idx\n",
    "            # rwd idx for DRT\n",
    "            self.cue_idx = torch.tensor(cue_idx, dtype=torch.int, device=DEVICE)\n",
    "            # rwd idx for DPA\n",
    "            self.rwd_idx = torch.tensor(rwd_idx, dtype=torch.int, device=DEVICE)\n",
    "\n",
    "            # readout idx\n",
    "            self.read_idx = read_idx\n",
    "\n",
    "            self.loss = SignBCELoss(self.alpha, self.thresh, self.imbalance)\n",
    "            self.l1loss = nn.SmoothL1Loss()\n",
    "            # self.l1loss = nn.MSELoss()\n",
    "\n",
    "      def forward(self, readout, targets):\n",
    "\n",
    "            zeros = torch.zeros_like(readout[:, self.zero_idx, 0])\n",
    "            # custom zeros for readout\n",
    "            BL_loss = self.l1loss(readout[:, self.zero_idx, self.read_idx[0]], zeros)\n",
    "            # zero memory only before stim\n",
    "            if len(self.read_idx)>1:\n",
    "                  BL_loss += self.l1loss(readout[:, :9, self.read_idx[1]], zeros[:, :9])\n",
    "\n",
    "            is_empty = (self.cue_idx.numel() == 0)\n",
    "\n",
    "            if is_empty:\n",
    "                  DPA_loss = self.loss(readout[:,  self.rwd_idx, self.read_idx[0]], targets)\n",
    "                  return DPA_loss + BL_loss\n",
    "            else:\n",
    "                  self.loss.imbalance = self.imbalance[0]\n",
    "                  DPA_loss = self.loss(readout[:,  self.rwd_idx, self.read_idx[0]], targets[:, 0, :self.rwd_idx.shape[0]])\n",
    "\n",
    "                  self.loss.imbalance = self.imbalance[1]\n",
    "                  DRT_loss = self.loss(readout[:, self.cue_idx, self.read_idx[1]], targets[:, 1, :self.cue_idx.shape[0]])\n",
    "\n",
    "                  return DPA_loss + DRT_loss + BL_loss\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Accuracy(nn.Module):\n",
    "      def __init__(self, thresh=4.0):\n",
    "            super(Accuracy, self).__init__()\n",
    "            self.thresh = thresh\n",
    "\n",
    "      def forward(self, readout, targets):\n",
    "            mean_readout = readout.mean(dim=1)\n",
    "            sign_loss = (mean_readout >= self.thresh)\n",
    "            return 1.0 * (sign_loss == targets[:, 0])\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "class DualPerf(nn.Module):\n",
    "      def __init__(self, alpha=1.0, thresh=2.0, cue_idx=[], rwd_idx=-1, zero_idx=[], read_idx=[-1], imbalance=0):\n",
    "            super(DualPerf, self).__init__()\n",
    "            self.alpha = alpha\n",
    "            self.thresh = thresh\n",
    "\n",
    "            self.imbalance = imbalance\n",
    "\n",
    "            # BL idx\n",
    "            self.zero_idx = zero_idx\n",
    "            # rwd idx for DRT\n",
    "            self.cue_idx = torch.tensor(cue_idx, dtype=torch.int, device=DEVICE)\n",
    "            # rwd idx for DPA\n",
    "            self.rwd_idx = torch.tensor(rwd_idx, dtype=torch.int, device=DEVICE)\n",
    "\n",
    "            # readout idx\n",
    "            self.read_idx = read_idx\n",
    "\n",
    "            self.loss = Accuracy(thresh=self.thresh)\n",
    "\n",
    "      def forward(self, readout, targets):\n",
    "            targets[targets==-1] = 0\n",
    "            is_empty = (self.cue_idx.numel() == 0)\n",
    "\n",
    "            if is_empty:\n",
    "                  DPA_loss = self.loss(readout[:,  self.rwd_idx, self.read_idx[0]], targets)\n",
    "                  return DPA_loss\n",
    "            else:\n",
    "                  self.loss.imbalance = self.imbalance[0]\n",
    "                  DPA_loss = self.loss(readout[:,  self.rwd_idx, self.read_idx[0]], targets[:, 0, :self.rwd_idx.shape[0]])\n",
    "\n",
    "                  self.loss.imbalance = self.imbalance[1]\n",
    "                  DRT_loss = self.loss(readout[:, self.cue_idx, self.read_idx[1]], targets[:, 1, :self.cue_idx.shape[0]])\n",
    "\n",
    "                  return DPA_loss, DRT_loss\n",
    "```\n",
    "\n",
    "Other\n",
    "-----\n",
    "\n",
    "``` ipython\n",
    "def angle_AB(A, B):\n",
    "      A_norm = A / (np.linalg.norm(A) + 1e-5)\n",
    "      B_norm = B / (np.linalg.norm(B) + 1e-5)\n",
    "\n",
    "      return int(np.arccos(A_norm @ B_norm) * 180 / np.pi)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_theta(a, b, GM=0, IF_NORM=0):\n",
    "\n",
    "      u, v = a, b\n",
    "\n",
    "      if GM:\n",
    "          v = b - np.dot(b, a) / np.dot(a, a) * a\n",
    "\n",
    "      if IF_NORM:\n",
    "          u = a / np.linalg.norm(a)\n",
    "          v = b / np.linalg.norm(b)\n",
    "\n",
    "      return np.arctan2(v, u) % (2.0 * np.pi)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_idx(model, rank=1):\n",
    "      # print(model.low_rank.U.shape)\n",
    "      # ksi = torch.vstack((model.low_rank.U[:,0], model.low_rank.U[:,1]))\n",
    "      ksi = torch.hstack((model.low_rank.V, model.low_rank.U)).T\n",
    "      ksi = ksi[:, :model.Na[0]]\n",
    "\n",
    "      try:\n",
    "            readout = model.low_rank.linear.weight.data\n",
    "            ksi = torch.vstack((ksi, readout))\n",
    "      except:\n",
    "            pass\n",
    "\n",
    "      print('ksi', ksi.shape)\n",
    "\n",
    "      ksi = ksi.cpu().detach().numpy()\n",
    "      theta = get_theta(ksi[0], ksi[rank])\n",
    "\n",
    "      return theta.argsort()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_overlap(model, rates):\n",
    "      ksi = model.odors.cpu().detach().numpy()\n",
    "      return rates @ ksi.T / rates.shape[-1]\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import scipy.stats as stats\n",
    "\n",
    "def plot_smooth(data, ax, color):\n",
    "      mean = data.mean(axis=0)\n",
    "      ci = smooth.std(axis=0, ddof=1) * 1.96\n",
    "\n",
    "      # Plot\n",
    "      ax.plot(mean, color=color)\n",
    "      ax.fill_between(range(data.shape[1]), mean - ci, mean + ci, alpha=0.25, color=color)\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def convert_seconds(seconds):\n",
    "      h = seconds // 3600\n",
    "      m = (seconds % 3600) // 60\n",
    "      s = seconds % 60\n",
    "      return h, m, s\n",
    "```\n",
    "\n",
    "plots\n",
    "-----\n",
    "\n",
    "``` ipython\n",
    "import pickle as pkl\n",
    "import os\n",
    "def pkl_save(obj, name, path=\".\"):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    destination = path + \"/\" + name + \".pkl\"\n",
    "    print(\"saving to\", destination)\n",
    "    pkl.dump(obj, open(destination, \"wb\"))\n",
    "\n",
    "\n",
    "def pkl_load(name, path=\".\"):\n",
    "    source = path + \"/\" + name + '.pkl'\n",
    "    # print('loading from', source)\n",
    "    return pkl.load(open( source, \"rb\"))\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def add_vlines(ax=None, mouse=\"\"):\n",
    "    t_BL = [0, 1]\n",
    "    t_STIM = [1 , 2]\n",
    "    t_ED = [2, 3]\n",
    "    t_DIST = [3 , 4]\n",
    "    t_MD = [4 , 5]\n",
    "    t_CUE = [5 , 5.5]\n",
    "    t_RWD = [5.5, 6.0]\n",
    "    t_LD = [6.0 , 7.0]\n",
    "    t_TEST = [7.0, 8.0]\n",
    "    t_RWD2 = [11 , 12]\n",
    "\n",
    "    # time_periods = [t_STIM, t_DIST, t_TEST, t_CUE, t_RWD, t_RWD2]\n",
    "    # colors = [\"b\", \"b\", \"b\", \"g\", \"y\", \"y\"]\n",
    "\n",
    "    time_periods = [t_STIM, t_DIST, t_TEST, t_CUE]\n",
    "    colors = [\"b\", \"b\", \"b\", \"g\"]\n",
    "\n",
    "    if ax is None:\n",
    "        for period, color in zip(time_periods, colors):\n",
    "            plt.axvspan(period[0], period[1], alpha=0.1, color=color)\n",
    "    else:\n",
    "        for period, color in zip(time_periods, colors):\n",
    "            ax.axvspan(period[0], period[1], alpha=0.1, color=color)\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def plot_rates_selec(rates, idx, thresh=0.5, figname='fig.svg'):\n",
    "        ordered = rates[..., idx]\n",
    "        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "        r_max = thresh * np.max(rates[0])\n",
    "\n",
    "        ax[0].imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)\n",
    "        ax[0].set_ylabel('Neuron #')\n",
    "        ax[0].set_xlabel('Step')\n",
    "\n",
    "        ax[1].imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)\n",
    "        ax[1].set_yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))\n",
    "        ax[1].set_ylabel('Pref. Location (째)')\n",
    "        ax[1].set_xlabel('Step')\n",
    "        plt.savefig(figname, dpi=300)\n",
    "        plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem, t\n",
    "\n",
    "def mean_ci(data):\n",
    "  # Calculate mean and SEM\n",
    "  mean = np.nanmean(data, axis=0)\n",
    "  serr = sem(data, axis=0, nan_policy='omit')\n",
    "\n",
    "  # Calculate the t critical value for 95% CI\n",
    "  n = np.sum(~np.isnan(data), axis=0)\n",
    "  t_val = t.ppf(0.975, df=n - 1)  # 0.975 for two-tailed 95% CI\n",
    "\n",
    "  # Calculate 95% confidence intervals\n",
    "  ci = t_val * serr\n",
    "\n",
    "  return mean, ci\n",
    "\n",
    "def plot_overlap_label(readout, y, axis=0, label=['pair', 'unpair'], figname='fig.svg', title='first'):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=[3*width, height], sharey=True)\n",
    "\n",
    "    time = np.linspace(0, 9, readout.shape[1])\n",
    "    trial = [0, 1, -1]\n",
    "    colors = ['r', 'b', 'g']\n",
    "    ls = ['--', '-']\n",
    "\n",
    "    for j in range(3):\n",
    "        for i in range(2):\n",
    "        # Get the data for each condition\n",
    "            if axis == 0:\n",
    "                sign_readout = 2*y[-1, :, np.newaxis, np.newaxis] * readout\n",
    "                data = sign_readout[(y[0]==i) & (y[1]==trial[j]), :, axis]\n",
    "            else:\n",
    "                data = readout[(y[0]==i) & (y[1]==trial[j]), :, axis]\n",
    "\n",
    "            mean, ci = mean_ci(data)\n",
    "            ax[j].plot(time, mean, ls=ls[i], label=label[i], color=colors[j])\n",
    "            ax[j].fill_between(time, mean - ci, mean + ci, color=colors[j], alpha=0.1)\n",
    "\n",
    "        add_vlines(ax[j])\n",
    "        ax[j].set_xlabel('Time (s)')\n",
    "\n",
    "        if axis==0:\n",
    "            ax[j].set_ylabel('A/B Overlap (Hz)')\n",
    "        elif axis==1:\n",
    "            ax[j].set_ylabel('GNG Overlap (Hz)')\n",
    "        else:\n",
    "            ax[j].set_ylabel('Readout (Hz)')\n",
    "\n",
    "            # ax[j].set_xlim([1, 10])\n",
    "        ax[j].axhline(0, color='k', ls='--')\n",
    "\n",
    "    plt.savefig('../figures/dual/%s' % figname, dpi=300)\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def plot_avg_overlap(readout, n_batch, labels=['A', 'B'], figname='fig.svg'):\n",
    "      fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "      time = np.linspace(0, 9, readout.shape[1])\n",
    "      size = readout.shape[0] // 2\n",
    "      print(readout.shape[0], size)\n",
    "\n",
    "      readout = readout.reshape((3, ))\n",
    "\n",
    "      for i in range(readout.shape[-1]):\n",
    "            if i==0:\n",
    "                  ax[i].plot(time, (readout[:size, :, i].T - readout[size:,:,i].T), ls='-', label=labels[0])\n",
    "            else:\n",
    "                  ax[i].plot(time, readout[size:, :, i].T, ls='--', label='Go')\n",
    "\n",
    "            add_vlines(ax[i])\n",
    "            ax[i].set_xlabel('Time (s)')\n",
    "\n",
    "      ax[0].set_ylabel('Sample Overlap (Hz)')\n",
    "      ax[1].set_ylabel('Go/NoGo Overlap (Hz)')\n",
    "      # ax[2].set_ylabel('Readout (Hz)')\n",
    "\n",
    "      # plt.legend(fontsize=10, frameon=False)\n",
    "      plt.savefig(figname, dpi=300)\n",
    "      plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def plot_m0_m1_phi(rates, idx, figname='fig.svg'):\n",
    "\n",
    "      m0, m1, phi = decode_bump(rates[..., idx], axis=-1)\n",
    "      fig, ax = plt.subplots(1, 3, figsize=[3*width, height])\n",
    "\n",
    "      time = np.linspace(0, 9, m0.T.shape[0])\n",
    "\n",
    "      ax[0].plot(time, m0[:2].T)\n",
    "      ax[0].plot(time, m0[2:].T, '--')\n",
    "      #ax[0].set_ylim([0, 360])\n",
    "      #ax[0].set_yticks([0, 90, 180, 270, 360])\n",
    "      ax[0].set_ylabel('$\\mathcal{F}_0$ (Hz)')\n",
    "      ax[0].set_ylabel('Activity (Hz)')\n",
    "      ax[0].set_xlabel('Time (s)')\n",
    "      add_vlines(ax[0])\n",
    "\n",
    "      ax[1].plot(time, m1[:2].T)\n",
    "      ax[1].plot(time, m1[2:].T, '--')\n",
    "      # ax[1].set_ylim([0, 360])\n",
    "      # ax[1].set_yticks([0, 90, 180, 270, 360])\n",
    "      ax[1].set_ylabel('$\\mathcal{F}_1$ (Hz)')\n",
    "      ax[1].set_ylabel('Bump Amplitude (Hz)')\n",
    "      ax[1].set_xlabel('Time (s)')\n",
    "      add_vlines(ax[1])\n",
    "\n",
    "      ax[2].plot(time, phi[:2].T * 180 / np.pi)\n",
    "      ax[2].plot(time, phi[2:].T * 180 / np.pi, '--')\n",
    "      ax[2].set_ylim([0, 360])\n",
    "      ax[2].set_yticks([0, 90, 180, 270, 360])\n",
    "      ax[2].set_ylabel('Bump Center (째)')\n",
    "      ax[2].set_xlabel('Time (s)')\n",
    "      add_vlines(ax[2])\n",
    "\n",
    "      plt.savefig(figname, dpi=300)\n",
    "      plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "def plot_fix_points(rates, ax, title='', color='k'):\n",
    "    m0, m1, phi = decode_bump(rates[:, -1], axis=-1)\n",
    "\n",
    "    x = np.cos(phi)\n",
    "    y = np.sin(phi)\n",
    "\n",
    "    xNoGo = np.cos(3*np.pi /2.)\n",
    "    yNoGo = np.sin(3*np.pi /2)\n",
    "\n",
    "    xGo = np.cos(np.pi /2.)\n",
    "    yGo = np.sin(np.pi /2)\n",
    "\n",
    "    # rad = np.max(np.sqrt(x**2+y**2))\n",
    "\n",
    "    ax.plot(x, y, 'o', ms=15, color=color)\n",
    "    ax.plot(xGo, yGo, 'o', ms=15, color='w', markeredgecolor='k')\n",
    "    ax.plot(xNoGo, yNoGo, 'o', ms=15, color='w', markeredgecolor='k')\n",
    "    circle = Circle((0., 0.), 1, fill=False, edgecolor='k')\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "    # Set the aspect of the plot to equal to make the circle circular\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "    # plt.savefig('fp_dpa.svg', dpi=300)\n",
    "    # plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Define custom colormap with red at the center\n",
    "cdict = {\n",
    "    'red':   [(0.0, 0.0, 0.0),\n",
    "              (0.5, 1.0, 1.0),\n",
    "              (1.0, 1.0, 1.0)],\n",
    "    'green': [(0.0, 0.0, 0.0),\n",
    "              (0.5, 0.0, 0.0),\n",
    "              (1.0, 1.0, 1.0)],\n",
    "    'blue':  [(0.0, 1.0, 1.0),\n",
    "              (0.5, 0.0, 0.0),\n",
    "              (1.0, 0.0, 0.0)]\n",
    "}\n",
    "\n",
    "custom_cmap = LinearSegmentedColormap('RedCenterMap', cdict)\n",
    "\n",
    "# Plot to visualize the colormap\n",
    "gradient = np.linspace(0, 1, 256)\n",
    "gradient = np.vstack((gradient, gradient))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 1))\n",
    "ax.imshow(gradient, aspect='auto', cmap=custom_cmap)\n",
    "ax.set_axis_off()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def plot_overlap(readout, labels=['pair', 'unpair'], figname='fig.svg'):\n",
    "      fig, ax = plt.subplots(1, readout.shape[-1], figsize=[readout.shape[-1]*width, height])\n",
    "\n",
    "      time = np.linspace(0, 9, readout.shape[1])\n",
    "      size = readout.shape[0] // 2\n",
    "\n",
    "      for i in range(readout.shape[-1]):\n",
    "            ax[i].plot(time, readout[:size, :, i].T, ls='-', label=labels[0])\n",
    "            if i==0:\n",
    "                  ax[i].plot(time, -readout[size:, :, i].T, ls='--', label=labels[1])\n",
    "            else:\n",
    "                  ax[i].plot(time, readout[size:, :, i].T, ls='--', label=labels[1])\n",
    "\n",
    "            add_vlines(ax[i])\n",
    "            ax[i].set_xlabel('Time (s)')\n",
    "\n",
    "      ax[0].set_ylabel('Sample Overlap (Hz)')\n",
    "      ax[1].set_ylabel('Go/NoGo Overlap (Hz)')\n",
    "      if readout.shape[-1] == 3:\n",
    "            ax[-1].set_ylabel('Readout (Hz)')\n",
    "\n",
    "      # ax[1].legend(fontsize=10, frameon=False)\n",
    "      plt.savefig(figname, dpi=300)\n",
    "      plt.show()\n",
    "```\n",
    "\n",
    "Model\n",
    "=====\n",
    "\n",
    "``` ipython\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "conf_name = \"train_dual.yml\"\n",
    "DEVICE = 'cuda:0'\n",
    "\n",
    "seed = np.random.randint(0, 1e6)\n",
    "\n",
    "seed = 971646 # good\n",
    "# seed = 295741 # not bad\n",
    "# seed= 404520\n",
    "# seed= 332246 # china\n",
    "\n",
    "seed = 0\n",
    "print(seed)\n",
    "\n",
    "A0 = 1.0 # sample/dist\n",
    "B0 = 1.0 # cue\n",
    "C0 = 0.0 # DRT rwd\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=1)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Sample Classification\n",
    "=====================\n",
    "\n",
    "Training\n",
    "--------\n",
    "\n",
    "### Parameters\n",
    "\n",
    "``` ipython\n",
    "model.J_STP.requires_grad = True\n",
    "# model.low_rank.lr_kappa.requires_grad = False\n",
    "\n",
    "if model.LR_READOUT:\n",
    "    for param in model.low_rank.linear.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.low_rank.linear.bias.requires_grad = False\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "with torch.no_grad():\n",
    "     model.low_rank.U[:, 1] = 0\n",
    "     model.low_rank.V[:, 1] = 0\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)\n",
    "\n",
    "mask = (steps >= (model.N_STIM_OFF[0].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))\n",
    "rwd_idx = np.where(mask)[0]\n",
    "print('rwd', rwd_idx)\n",
    "\n",
    "model.lr_eval_win = rwd_idx.shape[0]\n",
    "\n",
    "stim_mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0].cpu().numpy() - model.N_STEADY))\n",
    "\n",
    "zero_idx = np.where(~mask & ~stim_mask )[0]\n",
    "print('zero', zero_idx)\n",
    "```\n",
    "\n",
    "### Inputs and Labels\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = 512\n",
    "\n",
    "model.I0[0] = A0\n",
    "model.I0[1] = 0\n",
    "model.I0[2] = 0\n",
    "model.I0[3] = 0\n",
    "model.I0[4] = 0\n",
    "\n",
    "A = model.init_ff_input()\n",
    "\n",
    "model.I0[0] = -A0\n",
    "model.I0[1] = 0\n",
    "model.I0[2] = 0\n",
    "model.I0[3] = 0\n",
    "model.I0[4] = 0\n",
    "\n",
    "B = model.init_ff_input()\n",
    "\n",
    "ff_input = torch.cat((A, B))\n",
    "print(ff_input.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "labels_A = torch.ones((model.N_BATCH, rwd_idx.shape[0]))\n",
    "labels_B = torch.zeros((model.N_BATCH, rwd_idx.shape[0]))\n",
    "labels = torch.cat((labels_A, labels_B))\n",
    "\n",
    "print('labels', labels.shape)\n",
    "```\n",
    "\n",
    "### Run\n",
    "\n",
    "``` ipython\n",
    "batch_size = 32\n",
    "train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "criterion = DualLoss(alpha=1.0, thresh=4.0, rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=1, read_idx=[0])\n",
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print('Sample Classification')\n",
    "num_epochs = 15\n",
    "start = perf_counter()\n",
    "loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=1)\n",
    "end = perf_counter()\n",
    "print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "torch.save(model.state_dict(), '../models/dual/dpa_naive_%d.pth' % seed)\n",
    "```\n",
    "\n",
    "Testing\n",
    "-------\n",
    "\n",
    "``` ipython\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = 10\n",
    "\n",
    "model.I0[0] = 1\n",
    "model.I0[1] = 0\n",
    "model.I0[2] = 0\n",
    "\n",
    "A = model.init_ff_input()\n",
    "\n",
    "model.I0[0] = -1\n",
    "model.I0[1] = 0\n",
    "model.I0[2] = 0\n",
    "\n",
    "B = model.init_ff_input()\n",
    "\n",
    "ff_input = torch.cat((A, B))\n",
    "print('ff_input', ff_input.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rates = model.forward(ff_input=ff_input).cpu().detach().numpy()\n",
    "print('rates', rates.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "readout = model.readout.cpu().detach().numpy()\n",
    "print('readout', readout.shape)\n",
    "plot_overlap(readout, labels=['A', 'B'])\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "idx = get_idx(model, 1)\n",
    "plot_rates_selec(rates, idx)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "idx = get_idx(model, 1)\n",
    "plot_m0_m1_phi(rates, idx)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "U = model.low_rank.U.cpu().detach().numpy()\n",
    "V = model.low_rank.V.cpu().detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "# ax[0].hist(U[:, 0], histtype='step', bins='auto')\n",
    "# ax[0].hist(U[:, 1], histtype='step', bins='auto')\n",
    "ax[0].hist(V[:, 0], histtype='step', bins='auto')\n",
    "ax[1].hist(V[:, 1], histtype='step', bins='auto')\n",
    "ax[0].set_xlabel('$ n_{AB} $')\n",
    "ax[1].set_xlabel('$ n_{GNG} $')\n",
    "\n",
    "ax[0].set_ylabel('Count')\n",
    "ax[1].set_ylabel('Count')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plt.scatter(V[:, 0], V[:, 1])\n",
    "plt.xlabel('$ n_{AB} $')\n",
    "plt.ylabel('$ n_{GNG} $')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "DPA Task\n",
    "========\n",
    "\n",
    "``` ipython\n",
    "model_state_dict = torch.load('../models/dual/dpa_naive_%d.pth' % seed)\n",
    "model.load_state_dict(model_state_dict)\n",
    "```\n",
    "\n",
    "Training\n",
    "--------\n",
    "\n",
    "### Parameters\n",
    "\n",
    "``` ipython\n",
    "with torch.no_grad():\n",
    "    rand_vec = torch.randn((model.Na[0], ), device=model.device)\n",
    "    model.low_rank.U[:, 1] = rand_vec\n",
    "    model.low_rank.V[:, 1] = rand_vec\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.J_STP.requires_grad = False\n",
    "\n",
    "if model.LR_READOUT:\n",
    "    for param in model.low_rank.linear.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.low_rank.linear.bias.requires_grad = False\n",
    "\n",
    "if model.LR_KAPPA:\n",
    "    model.low_rank.lr_kappa.requires_grad = False\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)\n",
    "mask = (steps >= (model.N_STIM_ON[4].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))\n",
    "rwd_idx = np.where(mask)[0]\n",
    "print('rwd', rwd_idx)\n",
    "\n",
    "# mask for A/B memory from sample to test\n",
    "cue_mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps < (model.N_STIM_ON[-1].cpu().numpy() - model.N_STEADY))\n",
    "cue_idx = np.where(cue_mask)[0]\n",
    "cue_idx = []\n",
    "print('cue', cue_idx)\n",
    "\n",
    "if len(cue_idx) !=0:\n",
    "    model.lr_eval_win = np.max((rwd_idx.shape[0], cue_idx.shape[0]))\n",
    "else:\n",
    "    model.lr_eval_win = rwd_idx.shape[0]\n",
    "\n",
    "stim_mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0].cpu().numpy() - model.N_STEADY))\n",
    "\n",
    "mask_zero = ~mask  & ~stim_mask\n",
    "zero_idx = np.where(mask_zero)[0]\n",
    "print('zero', zero_idx)\n",
    "```\n",
    "\n",
    "### Inputs and Labels\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = 256\n",
    "\n",
    "model.I0[0] = A0 # sample\n",
    "model.I0[1] = 0 # distractor\n",
    "model.I0[2] = 0 # cue\n",
    "model.I0[3] = 0 # drt rwd\n",
    "model.I0[4] = A0 # test\n",
    "\n",
    "AC_pair = model.init_ff_input()\n",
    "\n",
    "model.I0[0] = A0\n",
    "model.I0[1] = 0\n",
    "model.I0[2] = 0\n",
    "model.I0[3] = 0\n",
    "model.I0[4] = -A0\n",
    "\n",
    "AD_pair = model.init_ff_input()\n",
    "\n",
    "model.I0[0] = -A0\n",
    "model.I0[1] = 0\n",
    "model.I0[2] = 0\n",
    "model.I0[3] = 0\n",
    "model.I0[4] = A0\n",
    "\n",
    "BC_pair = model.init_ff_input()\n",
    "\n",
    "model.I0[0] = -A0\n",
    "model.I0[1] = 0\n",
    "model.I0[2] = 0\n",
    "model.I0[3] = 0\n",
    "model.I0[4] = -A0\n",
    "\n",
    "BD_pair = model.init_ff_input()\n",
    "\n",
    "ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))\n",
    "print('ff_input', ff_input.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "labels_pair = torch.ones((2 * model.N_BATCH, model.lr_eval_win))\n",
    "labels_unpair = torch.zeros((2 * model.N_BATCH, model.lr_eval_win))\n",
    "\n",
    "labels = torch.cat((labels_pair, labels_unpair))\n",
    "\n",
    "if len(cue_idx)!=0:\n",
    "    labels =  labels.repeat((2, 1, 1))\n",
    "    labels = torch.transpose(labels, 0, 1)\n",
    "    model.J_STP.requires_grad = True\n",
    "\n",
    "print('labels', labels.shape)\n",
    "```\n",
    "\n",
    "### Run\n",
    "\n",
    "``` ipython\n",
    "batch_size = 32\n",
    "train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "if len(cue_idx) == 0:\n",
    "    criterion = DualLoss(alpha=1.0, thresh=4.0, rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=1, read_idx=[1])\n",
    "else:\n",
    "    criterion = DualLoss(alpha=1.0, thresh=4.0, rwd_idx=rwd_idx, zero_idx=zero_idx, cue_idx=cue_idx, imbalance=[0.0, 1.0], read_idx=[1, 0])\n",
    "\n",
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print('training DPA')\n",
    "num_epochs = 15\n",
    "start = perf_counter()\n",
    "if len(cue_idx) == 0:\n",
    "    loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=None)\n",
    "else:\n",
    "    loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=None)\n",
    "end = perf_counter()\n",
    "print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))\n",
    "torch.save(model.state_dict(), '../models/dual/dpa_%d.pth' % seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "torch.save(model.state_dict(), '../models/dual/dpa_%d.pth' % seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Testing\n",
    "-------\n",
    "\n",
    "``` ipython\n",
    "model_state_dict = torch.load('../models/dual/dpa_%d.pth' % seed)\n",
    "model.load_state_dict(model_state_dict)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = 1\n",
    "\n",
    "model.I0[0] = A0\n",
    "model.I0[1] = 0\n",
    "model.I0[2] = 0\n",
    "model.I0[3] = 0\n",
    "model.I0[4] = A0\n",
    "\n",
    "AC_pair = model.init_ff_input()\n",
    "\n",
    "model.I0[0] = A0\n",
    "model.I0[1] = 0\n",
    "model.I0[2] = 0\n",
    "model.I0[3] = 0\n",
    "model.I0[4] = -A0\n",
    "\n",
    "AD_pair = model.init_ff_input()\n",
    "\n",
    "model.I0[0] = -A0\n",
    "model.I0[1] = 0\n",
    "model.I0[2] = 0\n",
    "model.I0[3] = 0\n",
    "model.I0[4] = A0\n",
    "\n",
    "BC_pair = model.init_ff_input()\n",
    "\n",
    "model.I0[0] = -A0\n",
    "model.I0[1] = 0\n",
    "model.I0[2] = 0\n",
    "model.I0[3] = 0\n",
    "model.I0[4] = -A0\n",
    "\n",
    "BD_pair = model.init_ff_input()\n",
    "\n",
    "ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))\n",
    "print('ff_input', ff_input.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "labels_pair = torch.ones((2 * model.N_BATCH, 2))\n",
    "labels_unpair = torch.zeros((2 * model.N_BATCH, 2))\n",
    "\n",
    "labels = torch.cat((labels_pair, labels_unpair))\n",
    "print('labels', labels.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rates = model.forward(ff_input=ff_input).detach().cpu().numpy()\n",
    "rates_dpa = rates\n",
    "print(rates.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plot_overlap(model.readout.cpu().detach().numpy(), labels=['pair', 'unpair'], figname='../figures/dual/dpa_overlap_%d.svg' % seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "idx = get_idx(model, 1)\n",
    "plot_m0_m1_phi(rates, idx)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "U = model.low_rank.U.cpu().detach().numpy()\n",
    "V = model.low_rank.V.cpu().detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "# ax[0].hist(U[:, 0], histtype='step', bins='auto')\n",
    "# ax[0].hist(U[:, 1], histtype='step', bins='auto')\n",
    "ax[0].hist(V[:, 0], histtype='step', bins='auto')\n",
    "ax[1].hist(V[:, 1], histtype='step', bins='auto')\n",
    "ax[0].set_xlabel('$ n_{AB} $')\n",
    "ax[1].set_xlabel('$ n_{GNG} $')\n",
    "\n",
    "ax[0].set_ylabel('Count')\n",
    "ax[1].set_ylabel('Count')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]\n",
    "V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]\n",
    "\n",
    "odors = model.odors.cpu().numpy()\n",
    "\n",
    "m = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]\n",
    "n = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 1]\n",
    "\n",
    "vectors = [U, V, m, n]\n",
    "labels = ['$m_\\\\text{AB}$', '$n_\\\\text{AB}$', '$m_\\\\text{GnG}$', '$n_\\\\text{GnG}$']\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "num_vectors = len(vectors)\n",
    "cov_matrix = np.zeros((num_vectors, num_vectors))\n",
    "\n",
    "for i in range(num_vectors):\n",
    "    for j in range(num_vectors):\n",
    "        cov_matrix[i][j] = angle_AB(vectors[i], vectors[j])\n",
    "\n",
    "# Mask the upper triangle\n",
    "mask = np.triu(np.ones_like(cov_matrix, dtype=bool))\n",
    "masked_cov_matrix = np.ma.masked_array(cov_matrix, mask=mask)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the masked covariance matrix\n",
    "img = plt.imshow(masked_cov_matrix, cmap=custom_cmap, interpolation='nearest', vmin=30, vmax=150)\n",
    "cbar = plt.colorbar(label='Angle (째)')\n",
    "cbar.set_ticks([30, 90, 120])\n",
    "\n",
    "# Set axis labels on top and left\n",
    "# plt.gca().xaxis.tick_top()\n",
    "plt.xticks(ticks=np.arange(num_vectors), labels=labels)\n",
    "plt.yticks(ticks=np.arange(num_vectors), labels=labels)\n",
    "\n",
    "# Invert y-axis\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "for i in range(num_vectors):\n",
    "    for j in range(i + 1):\n",
    "        plt.text(j, i, f'{cov_matrix[i, j]:.0f}', ha='center', va='center', color='black')\n",
    "\n",
    "plt.savefig('../figures/dual/cov_dpa_%d.svg' % seed, dpi=300)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Go/NoGo Task\n",
    "============\n",
    "\n",
    "``` ipython\n",
    "model_state_dict = torch.load('../models/dual/dpa_%d.pth' % seed)\n",
    "model.load_state_dict(model_state_dict)\n",
    "```\n",
    "\n",
    "Training\n",
    "--------\n",
    "\n",
    "``` ipython\n",
    "model.J_STP.requires_grad = False\n",
    "model.low_rank.lr_kappa.requires_grad = False\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "for name, param in model.named_parameters():\n",
    "      if param.requires_grad:\n",
    "            print(name, param.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)\n",
    "\n",
    "# mask for lick/nolick  from cue to test\n",
    "rwd_mask = (steps >= (model.N_STIM_ON[2].cpu().numpy() - model.N_STEADY)) & (steps < (model.N_STIM_ON[4].cpu().numpy() - model.N_STEADY))\n",
    "rwd_idx = np.where(rwd_mask)[0]\n",
    "print('rwd', rwd_idx)\n",
    "\n",
    "# mask for Go/NoGo memory from dist to cue\n",
    "cue_mask = (steps >= (model.N_STIM_ON[1].cpu().numpy() - model.N_STEADY)) & (steps < (model.N_STIM_ON[2].cpu().numpy() - model.N_STEADY))\n",
    "cue_idx = np.where(cue_mask)[0]\n",
    "# cue_idx = []\n",
    "print('cue', cue_idx)\n",
    "\n",
    "mask_zero = (steps < (model.N_STIM_ON[1].cpu().numpy() - model.N_STEADY))\n",
    "zero_idx = np.where(mask_zero)[0]\n",
    "print('zero', zero_idx)\n",
    "\n",
    "if len(cue_idx)!=0:\n",
    "    model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))\n",
    "else:\n",
    "    model.lr_eval_win = rwd_idx.shape[0]\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = 512\n",
    "\n",
    "model.I0[0] = 0\n",
    "model.I0[1] = A0\n",
    "model.I0[2] = float(B0)\n",
    "model.I0[3] = 0\n",
    "model.I0[4] = 0\n",
    "\n",
    "Go = model.init_ff_input()\n",
    "\n",
    "model.I0[0] = 0\n",
    "model.I0[1] = -A0\n",
    "model.I0[2] = float(B0)\n",
    "model.I0[3] = 0\n",
    "model.I0[4] = 0\n",
    "\n",
    "NoGo = model.init_ff_input()\n",
    "\n",
    "ff_input = torch.cat((Go, NoGo))\n",
    "print(ff_input.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "labels_Go = torch.ones((model.N_BATCH, model.lr_eval_win))\n",
    "labels_NoGo = torch.zeros((model.N_BATCH, model.lr_eval_win))\n",
    "labels = torch.cat((labels_Go, labels_NoGo))\n",
    "print(labels.shape)\n",
    "# print(labels)\n",
    "if len(cue_idx)!=0:\n",
    "    labels =  labels.repeat((2, 1, 1))\n",
    "    labels = torch.transpose(labels, 0, 1)\n",
    "print('labels', labels.shape)\n",
    "```\n",
    "\n",
    "### Run\n",
    "\n",
    "``` ipython\n",
    "batch_size = 16\n",
    "train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "criterion = DualLoss(alpha=1.0, thresh=4.0, rwd_idx=rwd_idx, zero_idx=zero_idx, cue_idx=cue_idx, imbalance=[0.0, 1.0], read_idx=[1, 1])\n",
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print('training DRT')\n",
    "num_epochs = 15\n",
    "start = perf_counter()\n",
    "loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=0)\n",
    "end = perf_counter()\n",
    "print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "torch.save(model.state_dict(), '../models/dual/dual_naive_%d.pth' % seed)\n",
    "```\n",
    "\n",
    "Test\n",
    "----\n",
    "\n",
    "``` ipython\n",
    "model_state_dict = torch.load('../models/dual/dual_naive_%d.pth' % seed)\n",
    "model.load_state_dict(model_state_dict)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "``` example\n",
    "425f9e8b-fe47-46ff-87f6-8059ca5729d3\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = 1\n",
    "\n",
    "model.I0[0] = 0\n",
    "model.I0[1] = A0\n",
    "model.I0[2] = float(B0)\n",
    "model.I0[3] = 0.0\n",
    "model.I0[4] = 0.0\n",
    "\n",
    "A = model.init_ff_input()\n",
    "\n",
    "model.I0[0] = 0 # NoGo\n",
    "model.I0[1] = -A0 # cue\n",
    "model.I0[2] = float(B0) # rwd\n",
    "model.I0[3] = 0.0\n",
    "model.I0[4] = 0.0\n",
    "\n",
    "B = model.init_ff_input()\n",
    "\n",
    "ff_input = torch.cat((A, B))\n",
    "print('ff_input', ff_input.shape)\n",
    "```\n",
    "\n",
    "``` example\n",
    "fe8121ab-de4b-48cb-8045-3c4d954a3f3d\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rates = model.forward(ff_input=ff_input).cpu().detach().numpy()\n",
    "print(rates.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plot_overlap(model.readout.cpu().detach().numpy(), labels=['Go', 'NoGo'], figname='../figures/dual/GoNoGo_overlaps_%d.svg' % seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "U = model.low_rank.U.cpu().detach().numpy()\n",
    "V = model.low_rank.V.cpu().detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "# ax[0].hist(U[:, 0], histtype='step', bins='auto')\n",
    "# ax[0].hist(U[:, 1], histtype='step', bins='auto')\n",
    "ax[0].hist(V[:, 0], histtype='step', bins='auto')\n",
    "ax[1].hist(V[:, 1], histtype='step', bins='auto')\n",
    "ax[0].set_xlabel('$ n_{AB} $')\n",
    "ax[1].set_xlabel('$ n_{GNG} $')\n",
    "\n",
    "ax[0].set_ylabel('Count')\n",
    "ax[1].set_ylabel('Count')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]\n",
    "V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]\n",
    "\n",
    "odors = model.odors.cpu().numpy()\n",
    "\n",
    "m = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]\n",
    "n = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 1]\n",
    "\n",
    "vectors = [U, V, m, n]\n",
    "labels = ['$m_\\\\text{AB}$', '$n_\\\\text{AB}$', '$m_\\\\text{GnG}$', '$n_\\\\text{GnG}$']\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "num_vectors = len(vectors)\n",
    "cov_matrix = np.zeros((num_vectors, num_vectors))\n",
    "\n",
    "for i in range(num_vectors):\n",
    "    for j in range(num_vectors):\n",
    "        cov_matrix[i][j] = angle_AB(vectors[i], vectors[j])\n",
    "\n",
    "# Mask the upper triangle\n",
    "mask = np.triu(np.ones_like(cov_matrix, dtype=bool))\n",
    "masked_cov_matrix = np.ma.masked_array(cov_matrix, mask=mask)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the masked covariance matrix\n",
    "img = plt.imshow(masked_cov_matrix, cmap=custom_cmap, interpolation='nearest', vmin=30, vmax=150)\n",
    "cbar = plt.colorbar(label='Angle (째)')\n",
    "cbar.set_ticks([30, 90, 120])\n",
    "\n",
    "# Set axis labels on top and left\n",
    "# plt.gca().xaxis.tick_top()\n",
    "plt.xticks(ticks=np.arange(num_vectors), labels=labels)\n",
    "plt.yticks(ticks=np.arange(num_vectors), labels=labels)\n",
    "\n",
    "# Invert y-axis\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "for i in range(num_vectors):\n",
    "    for j in range(i + 1):\n",
    "        plt.text(j, i, f'{cov_matrix[i, j]:.0f}', ha='center', va='center', color='black')\n",
    "\n",
    "plt.savefig('../figures/dual/cov_drt_%d.svg' % seed, dpi=300)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Dual Task\n",
    "=========\n",
    "\n",
    "Testing\n",
    "-------\n",
    "\n",
    "``` ipython\n",
    "model_state_dict = torch.load('../models/dual/dual_naive_%d.pth' % seed)\n",
    "model.load_state_dict(model_state_dict)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)\n",
    "\n",
    "mask_rwd = (steps >= (model.N_STIM_ON[-1].cpu().numpy() - model.N_STEADY))\n",
    "rwd_idx = np.where(mask_rwd)[0]\n",
    "print('rwd', rwd_idx)\n",
    "\n",
    "mask_cue = (steps >= (model.N_STIM_ON[2].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STIM_OFF[3].cpu().numpy() - model.N_STEADY))\n",
    "cue_idx = np.where(mask_cue)[0]\n",
    "print('cue', cue_idx)\n",
    "\n",
    "mask_GnG = (steps >= (model.N_STIM_OFF[1].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STIM_ON[2].cpu().numpy() - model.N_STEADY))\n",
    "GnG_idx = np.where(mask_GnG)[0]\n",
    "print('GnG', GnG_idx)\n",
    "\n",
    "stim_mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY))\n",
    "\n",
    "mask_zero = ~mask_rwd & ~mask_cue & ~stim_mask\n",
    "zero_idx = np.where(mask_zero)[0]\n",
    "print('zero', zero_idx)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]\n",
    "V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]\n",
    "\n",
    "odors = model.odors.cpu().numpy()\n",
    "\n",
    "m = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]\n",
    "n = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 1]\n",
    "\n",
    "vectors = [U, V, m, n]\n",
    "labels = ['$m_\\\\text{AB}$', '$n_\\\\text{AB}$', '$m_\\\\text{GnG}$', '$n_\\\\text{GnG}$']\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "num_vectors = len(vectors)\n",
    "cov_matrix = np.zeros((num_vectors, num_vectors))\n",
    "\n",
    "for i in range(num_vectors):\n",
    "    for j in range(num_vectors):\n",
    "        cov_matrix[i][j] = angle_AB(vectors[i], vectors[j])\n",
    "\n",
    "# Mask the upper triangle\n",
    "mask = np.triu(np.ones_like(cov_matrix, dtype=bool))\n",
    "masked_cov_matrix = np.ma.masked_array(cov_matrix, mask=mask)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the masked covariance matrix\n",
    "img = plt.imshow(masked_cov_matrix, cmap=custom_cmap, interpolation='nearest', vmin=30, vmax=150)\n",
    "cbar = plt.colorbar(label='Angle (째)')\n",
    "cbar.set_ticks([30, 90, 120])\n",
    "\n",
    "# Set axis labels on top and left\n",
    "# plt.gca().xaxis.tick_top()\n",
    "plt.xticks(ticks=np.arange(num_vectors), labels=labels)\n",
    "plt.yticks(ticks=np.arange(num_vectors), labels=labels)\n",
    "\n",
    "# Invert y-axis\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "for i in range(num_vectors):\n",
    "    for j in range(i + 1):\n",
    "        plt.text(j, i, f'{cov_matrix[i, j]:.0f}', ha='center', va='center', color='black')\n",
    "\n",
    "plt.savefig('../figures/dual/cov_naive_%d.svg' % seed, dpi=300)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "N_BATCH = 32\n",
    "model.N_BATCH = N_BATCH\n",
    "\n",
    "model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))\n",
    "\n",
    "ff_input = []\n",
    "labels = np.zeros((3, 12, model.N_BATCH, model.lr_eval_win))\n",
    "\n",
    "l=0\n",
    "for j in [0, 1, -1]:\n",
    "    for i in [-1, 1]:\n",
    "        for k in [-1, 1]:\n",
    "\n",
    "            model.I0[0] = i # sample\n",
    "            labels[2, l] = i * np.ones((model.N_BATCH, model.lr_eval_win))\n",
    "\n",
    "            model.I0[1] = j # distractor\n",
    "            model.I0[4] = k # test\n",
    "\n",
    "            if i==k: # Pair Trials\n",
    "                labels[0, l] = np.ones((model.N_BATCH, model.lr_eval_win))\n",
    "\n",
    "            if j==1: # Go\n",
    "                model.I0[2] = float(B0) # cue\n",
    "                model.I0[3] = float(C0) * model.IF_RL # rwd\n",
    "                labels[1, l] = np.ones((model.N_BATCH, model.lr_eval_win))\n",
    "            elif j==-1: # NoGo\n",
    "                model.I0[2] = float(B0) # cue\n",
    "                model.I0[3] = 0.0 # rwd\n",
    "                labels[1, l] = -np.ones((model.N_BATCH, model.lr_eval_win))\n",
    "            else: # DPA\n",
    "                model.I0[2] = 0 # cue\n",
    "                model.I0[3] = 0 # rwd\n",
    "\n",
    "            l+=1\n",
    "\n",
    "            ff_input.append(model.init_ff_input())\n",
    "\n",
    "labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(3, 12 * model.N_BATCH, model.lr_eval_win).transpose(0,1)\n",
    "# labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(3, -1, model.lr_eval_win).transpose(0, 1)\n",
    "ff_input = torch.vstack(ff_input)\n",
    "print('ff_input', ff_input.shape, 'labels', labels.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rates = model.forward(ff_input=ff_input).detach()\n",
    "rates = rates.cpu().detach().numpy()\n",
    "print(rates.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def calculate_mean_accuracy_and_sem(accuracies):\n",
    "    mean_accuracy = accuracies.mean()\n",
    "    std_dev = accuracies.std(unbiased=True).item()\n",
    "    sem = std_dev / np.sqrt(len(accuracies))\n",
    "    return mean_accuracy, sem\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "readout = model.readout.cpu().detach().numpy()\n",
    "print(readout.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "y = labels[..., -1].T.cpu().numpy().copy()\n",
    "plot_overlap_label(model.readout.cpu().detach().numpy(), y=y, axis=0, figname='sample_overlaps_naive.svg')\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "y = labels[..., -1].T.cpu().numpy().copy()\n",
    "plot_overlap_label(model.readout.cpu().detach().numpy(), y=y, axis=1, figname='gng_overlaps_naive.svg')\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "y = labels[..., -1].T.cpu().numpy().copy()\n",
    "plot_overlap_label(model.readout.cpu().detach().numpy(), y=y, axis=-1)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "criterion = DualPerf(alpha=1.0, thresh=1.0, cue_idx=cue_idx, rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=[0.0, 0.0], read_idx=[-1, 1])\n",
    "dpa_perf, drt_perf = criterion(model.readout, labels.clone())\n",
    "\n",
    "dpa_mean, dpa_sem = calculate_mean_accuracy_and_sem(dpa_perf)\n",
    "drt_mean, drt_sem = calculate_mean_accuracy_and_sem(drt_perf)\n",
    "print('perf', dpa_mean, drt_mean)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height], sharex=True)\n",
    "\n",
    "ax[0].errorbar(0, dpa_mean.item(), yerr=dpa_sem.item(), fmt='o', label='Naive',\n",
    "             color='k', ecolor='k', elinewidth=3, capsize=5)\n",
    "# ax[0].errorbar(1, dpa_mean2.item(), yerr=dpa_sem2.item(), fmt='o', label='Expert',\n",
    "#              color='k', ecolor='k', elinewidth=3, capsize=5)\n",
    "\n",
    "ax[0].set_xlim(-1, 2)\n",
    "ax[0].set_ylim(0.4, 1.1)\n",
    "\n",
    "ax[0].set_ylabel('DPA Accuracy')\n",
    "ax[0].set_xticks([0, 1], ['Naive', 'Expert'])\n",
    "ax[0].axhline(y=0.5, color='k', linestyle='--')\n",
    "\n",
    "ax[1].errorbar(0, drt_mean.item(), yerr=drt_sem.item(), fmt='o', label='Naive',\n",
    "             color='k', ecolor='k', elinewidth=3, capsize=5)\n",
    "# ax[1].errorbar(1, drt_mean2.item(), yerr=drt_sem2.item(), fmt='o', label='Expert',\n",
    "#              color='k', ecolor='k', elinewidth=3, capsize=5)\n",
    "\n",
    "ax[1].set_xlim(-1, 2)\n",
    "ax[1].set_ylim(0.4, 1.1)\n",
    "\n",
    "ax[1].set_ylabel('Go/NoGo Accuracy')\n",
    "ax[1].set_xticks([0, 1], ['Naive', 'Expert'])\n",
    "ax[1].axhline(y=0.5, color='k', linestyle='--')\n",
    "\n",
    "plt.savefig('../figures/dual/dual_perf_%d.svg' % seed, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Training\n",
    "--------\n",
    "\n",
    "``` ipython\n",
    "model.J_STP.requires_grad = False\n",
    "model.low_rank.lr_kappa.requires_grad = False\n",
    "```\n",
    "\n",
    "``` example\n",
    "76aa6557-dd20-4b91-881f-81bcf4537720\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.N_BATCH = 64\n",
    "\n",
    "model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))\n",
    "\n",
    "ff_input = []\n",
    "labels = np.zeros((2, 12, model.N_BATCH, model.lr_eval_win))\n",
    "\n",
    "l=0\n",
    "for i in [-1, 1]:\n",
    "    for j in [-1, 0, 1]:\n",
    "        for k in [-1, 1]:\n",
    "\n",
    "            model.I0[0] = i # sample\n",
    "            model.I0[1] = j # distractor\n",
    "            model.I0[4] = k # test\n",
    "\n",
    "            if i==k: # Pair Trials\n",
    "                labels[0, l] = np.ones((model.N_BATCH, model.lr_eval_win))\n",
    "\n",
    "            if j==1: # Go\n",
    "                model.I0[2] = float(B0) # cue\n",
    "                model.I0[3] = float(C0) * model.IF_RL # rwd\n",
    "\n",
    "                labels[1, l] = np.ones((model.N_BATCH, model.lr_eval_win))\n",
    "            elif j==-1: # NoGo\n",
    "                model.I0[2] = float(B0) # cue\n",
    "                model.I0[3] = 0.0 # rwd\n",
    "                labels[1, l] = -np.ones((model.N_BATCH, model.lr_eval_win))\n",
    "            else: # DPA\n",
    "                model.I0[2] = 0 # cue\n",
    "                model.I0[3] = 0 # rwd\n",
    "\n",
    "            l+=1\n",
    "\n",
    "            ff_input.append(model.init_ff_input())\n",
    "\n",
    "labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(2, -1, model.lr_eval_win).transpose(0, 1)\n",
    "# labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(3, -1, model.lr_eval_win).transpose(0, 1)\n",
    "ff_input = torch.vstack(ff_input)\n",
    "print('ff_input', ff_input.shape, 'labels', labels.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "batch_size = 16\n",
    "train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "criterion = DualLoss(alpha=1.0, thresh=4.0, cue_idx=cue_idx, rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=[1.0, 0.0], read_idx=[-1, 1])\n",
    "learning_rate = 0.1\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print('training Dual')\n",
    "num_epochs = 15\n",
    "start = perf_counter()\n",
    "\n",
    "loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=None)\n",
    "end = perf_counter()\n",
    "print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "torch.save(model.state_dict(), '../models/dual/dual_train_%d.pth' % seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Re-Testing\n",
    "----------\n",
    "\n",
    "``` ipython\n",
    "model_state_dict = torch.load('../models/dual/dual_train_%d.pth' % seed)\n",
    "model.load_state_dict(model_state_dict)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)\n",
    "\n",
    "mask_rwd = (steps >= (model.N_STIM_ON[-1].cpu().numpy() - model.N_STEADY))\n",
    "rwd_idx = np.where(mask_rwd)[0]\n",
    "print('rwd', rwd_idx)\n",
    "\n",
    "mask_cue = (steps >= (model.N_STIM_ON[2].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STIM_OFF[3].cpu().numpy() - model.N_STEADY))\n",
    "cue_idx = np.where(mask_cue)[0]\n",
    "print('cue', cue_idx)\n",
    "\n",
    "mask_GnG = (steps >= (model.N_STIM_OFF[1].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STIM_ON[2].cpu().numpy() - model.N_STEADY))\n",
    "GnG_idx = np.where(mask_GnG)[0]\n",
    "print('GnG', GnG_idx)\n",
    "\n",
    "stim_mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY))\n",
    "\n",
    "mask_zero = ~mask_rwd & ~mask_cue & ~stim_mask\n",
    "zero_idx = np.where(mask_zero)[0]\n",
    "print('zero', zero_idx)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]\n",
    "V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]\n",
    "\n",
    "odors = model.odors.cpu().numpy()\n",
    "\n",
    "m = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]\n",
    "n = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 1]\n",
    "\n",
    "vectors = [U, V, m, n]\n",
    "labels = ['$m_\\\\text{AB}$', '$n_\\\\text{AB}$', '$m_\\\\text{GnG}$', '$n_\\\\text{GnG}$']\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "num_vectors = len(vectors)\n",
    "cov_matrix = np.zeros((num_vectors, num_vectors))\n",
    "\n",
    "for i in range(num_vectors):\n",
    "    for j in range(num_vectors):\n",
    "        cov_matrix[i][j] = angle_AB(vectors[i], vectors[j])\n",
    "\n",
    "# Mask the upper triangle\n",
    "mask = np.triu(np.ones_like(cov_matrix, dtype=bool))\n",
    "masked_cov_matrix = np.ma.masked_array(cov_matrix, mask=mask)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the masked covariance matrix\n",
    "img = plt.imshow(masked_cov_matrix, cmap=custom_cmap, interpolation='nearest', vmin=30, vmax=150)\n",
    "cbar = plt.colorbar(label='Angle (째)')\n",
    "cbar.set_ticks([30, 90, 120])\n",
    "\n",
    "# Set axis labels on top and left\n",
    "# plt.gca().xaxis.tick_top()\n",
    "plt.xticks(ticks=np.arange(num_vectors), labels=labels)\n",
    "plt.yticks(ticks=np.arange(num_vectors), labels=labels)\n",
    "\n",
    "# Invert y-axis\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "for i in range(num_vectors):\n",
    "    for j in range(i + 1):\n",
    "        plt.text(j, i, f'{cov_matrix[i, j]:.0f}', ha='center', va='center', color='black')\n",
    "plt.savefig('../figures/dual/cov_train_%d.svg' % seed, dpi=300)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "N_BATCH = 32\n",
    "model.N_BATCH = N_BATCH\n",
    "\n",
    "model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))\n",
    "\n",
    "ff_input = []\n",
    "labels = np.zeros((3, 12, model.N_BATCH, model.lr_eval_win))\n",
    "\n",
    "l=0\n",
    "for j in [0, 1, -1]:\n",
    "    for i in [-1, 1]:\n",
    "        for k in [-1, 1]:\n",
    "\n",
    "            model.I0[0] = i # sample\n",
    "            labels[2, l] = i * np.ones((model.N_BATCH, model.lr_eval_win))\n",
    "\n",
    "            model.I0[1] = j # distractor\n",
    "            model.I0[4] = k # test\n",
    "\n",
    "            if i==k: # Pair Trials\n",
    "                labels[0, l] = np.ones((model.N_BATCH, model.lr_eval_win))\n",
    "\n",
    "            if j==1: # Go\n",
    "                model.I0[2] = float(B0) # cue\n",
    "                model.I0[3] = float(C0) * model.IF_RL # rwd\n",
    "\n",
    "                labels[1, l] = np.ones((model.N_BATCH, model.lr_eval_win))\n",
    "            elif j==-1: # NoGo\n",
    "                model.I0[2] = float(B0) # cue\n",
    "                model.I0[3] = 0.0 # rwd\n",
    "                labels[1, l] = -np.ones((model.N_BATCH, model.lr_eval_win))\n",
    "            else: # DPA\n",
    "                model.I0[2] = 0 # cue\n",
    "                model.I0[3] = 0 # rwd\n",
    "\n",
    "            l+=1\n",
    "\n",
    "            ff_input.append(model.init_ff_input())\n",
    "\n",
    "labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(3, -1, model.lr_eval_win).transpose(0, 1)\n",
    "\n",
    "ff_input = torch.vstack(ff_input)\n",
    "print('ff_input', ff_input.shape, 'labels', labels.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rates = model.forward(ff_input=ff_input).detach()\n",
    "rates = rates.cpu().detach().numpy()\n",
    "print(rates.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(labels.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "criterion = DualPerf(alpha=1.0, thresh=1.0, cue_idx=cue_idx, rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=[0.0, 0.0], read_idx=[-1, -1])\n",
    "dpa_perf2, drt_perf2 = criterion(model.readout, labels.clone())\n",
    "dpa_mean2, dpa_sem2 = calculate_mean_accuracy_and_sem(dpa_perf2)\n",
    "drt_mean2, drt_sem2 = calculate_mean_accuracy_and_sem(drt_perf2)\n",
    "print('perf', dpa_mean2, drt_mean2)\n",
    "```\n",
    "\n",
    "``` example\n",
    "---------------------------------------------------------------------------\n",
    "RuntimeError                              Traceback (most recent call last)\n",
    "Cell In[117], line 2\n",
    "      1 B0=\"1.0\"\n",
    "----> 2 y = labels[..., -1].T.cpu().numpy().copy()\n",
    "      3 plot_overlap_label(model.readout.cpu().detach().numpy(), y=y, axis=0, figname='sample_overlap_trained.svg')\n",
    "\n",
    "RuntimeError: CUDA error: device-side assert triggered\n",
    "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
    "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
    "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "y = labels[..., -1].T.cpu().numpy().copy()\n",
    "plot_overlap_label(model.readout.cpu().detach().numpy(), y=y, axis=0, figname='sample_overlap_trained.svg')\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "y = labels[..., -1].T.cpu().numpy().copy()\n",
    "plot_overlap_label(model.readout.cpu().detach().numpy(), y=y, axis=1, figname='gng_overlap_trained.svg')\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height], sharex=True)\n",
    "\n",
    "ax[0].errorbar(0, dpa_mean.item(), yerr=dpa_sem.item(), fmt='o', label='Naive',\n",
    "             color='k', ecolor='k', elinewidth=3, capsize=5)\n",
    "ax[0].errorbar(1, dpa_mean2.item(), yerr=dpa_sem2.item(), fmt='o', label='Expert',\n",
    "             color='k', ecolor='k', elinewidth=3, capsize=5)\n",
    "\n",
    "ax[0].set_xlim(-1, 2)\n",
    "ax[0].set_ylim(0.4, 1.1)\n",
    "\n",
    "ax[0].set_ylabel('DPA Accuracy')\n",
    "ax[0].set_xticks([0, 1], ['Naive', 'Expert'])\n",
    "ax[0].axhline(y=0.5, color='k', linestyle='--')\n",
    "\n",
    "ax[1].errorbar(0, drt_mean.item(), yerr=drt_sem.item(), fmt='o', label='Naive',\n",
    "             color='k', ecolor='k', elinewidth=3, capsize=5)\n",
    "ax[1].errorbar(1, drt_mean2.item(), yerr=drt_sem2.item(), fmt='o', label='Expert',\n",
    "             color='k', ecolor='k', elinewidth=3, capsize=5)\n",
    "\n",
    "ax[1].set_xlim(-1, 2)\n",
    "ax[1].set_ylim(0.4, 1.1)\n",
    "\n",
    "ax[1].set_ylabel('Go/NoGo Accuracy')\n",
    "ax[1].set_xticks([0, 1], ['Naive', 'Expert'])\n",
    "ax[1].axhline(y=0.5, color='k', linestyle='--')\n",
    "\n",
    "plt.savefig('../figures/dual/dual_perf_%d.svg' % seed, dpi=300)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "U = model.low_rank.U.cpu().detach().numpy()\n",
    "V = model.low_rank.V.cpu().detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "# ax[0].hist(U[:, 0], histtype='step', bins='auto')\n",
    "# ax[0].hist(U[:, 1], histtype='step', bins='auto')\n",
    "ax[0].hist(V[:, 0], histtype='step', bins='auto')\n",
    "ax[1].hist(V[:, 1], histtype='step', bins='auto')\n",
    "ax[0].set_xlabel('$ n_{AB} $')\n",
    "ax[1].set_xlabel('$ n_{GNG} $')\n",
    "\n",
    "ax[0].set_ylabel('Count')\n",
    "ax[1].set_ylabel('Count')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "plt.scatter(V[:, 0], V[:, 1])\n",
    "plt.xlabel('$ n_{AB} $')\n",
    "plt.ylabel('$ n_{GNG} $')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Fix\n",
    "===\n",
    "\n",
    "``` ipython\n",
    "def get_fix_points(model, task, seed, test=0):\n",
    "    model_state_dict = torch.load('../models/dual/%s_%d.pth' % (task, seed))\n",
    "    model.load_state_dict(model_state_dict)\n",
    "\n",
    "    ff_input = get_input(model, test)\n",
    "    rates = model.forward(ff_input=ff_input).cpu().detach().numpy()\n",
    "    print(rates.shape)\n",
    "    idx = get_idx(model, rank=1)\n",
    "    return rates[..., idx]\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_input(model, test=0):\n",
    "    model.N_BATCH = 10\n",
    "\n",
    "    model.I0[0] = 1\n",
    "    model.I0[1] = 0\n",
    "    model.I0[2] = 0\n",
    "    model.I0[3] = 0\n",
    "    model.I0[4] = test\n",
    "\n",
    "    A_pair = model.init_ff_input()\n",
    "\n",
    "    model.I0[0] = -1\n",
    "    model.I0[1] = 0\n",
    "    model.I0[2] = 0\n",
    "    model.I0[3] = 0\n",
    "    model.I0[4] = test\n",
    "\n",
    "    B_pair = model.init_ff_input()\n",
    "\n",
    "    ff_input = torch.cat((A_pair, B_pair))\n",
    "\n",
    "    return ff_input\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "dpa = get_fix_points(model, 'dpa', seed)\n",
    "dual_naive = get_fix_points(model, 'dual_naive', seed)\n",
    "dual_train = get_fix_points(model, 'dual_train', seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "dpa_C = get_fix_points(model, 'dpa', seed, test=1)\n",
    "dual_naive_C = get_fix_points(model, 'dual_naive', seed, test=1)\n",
    "dual_train_C = get_fix_points(model, 'dual_train', seed, test=1)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "dpa_D = get_fix_points(model, 'dpa', seed, test=-1)\n",
    "dual_naive_D = get_fix_points(model, 'dual_naive', seed, test=-1)\n",
    "dual_train_D = get_fix_points(model, 'dual_train', seed, test=-1)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 3, figsize=[3*height, height])\n",
    "plot_fix_points(dpa, ax[0], 'DPA')\n",
    "plot_fix_points(dual_naive, ax[1], 'Dual Naive')\n",
    "plot_fix_points(dual_train, ax[-1], 'Dual Expert')\n",
    "\n",
    "plot_fix_points(dpa_C, ax[0], 'DPA', color='b')\n",
    "plot_fix_points(dual_naive_C, ax[1], 'Dual Naive', color='b')\n",
    "plot_fix_points(dual_train_C, ax[-1], 'Dual Expert', color='b')\n",
    "\n",
    "plot_fix_points(dpa_D, ax[0], 'DPA', color='g')\n",
    "plot_fix_points(dual_naive_D, ax[1], 'Dual Naive', color='g')\n",
    "plot_fix_points(dual_train_D, ax[-1], 'Dual Expert', color='g')\n",
    "\n",
    "plt.savefig('../figures/dual/fixed_points_%d.svg' % seed, dpi=300)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rates = np.stack((dpa, dual_naive, dual_train))\n",
    "pkl_save(rates, './models/dual/rates_%d' % seed)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.DURATION = 8\n",
    "model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
