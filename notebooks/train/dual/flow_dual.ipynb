{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import gc\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pal = sns.color_palette(\"tab10\")\n",
    "DEVICE = 'cuda:1'\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "from notebooks.setup import *\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from time import perf_counter\n",
    "from scipy.stats import circmean\n",
    "\n",
    "from src.network import Network\n",
    "from src.plot_utils import plot_con\n",
    "from src.decode import decode_bump, circcvl\n",
    "from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import pickle as pkl\n",
    "\n",
    "def pkl_save(obj, name, path=\".\"):\n",
    "      pkl.dump(obj, open(path + \"/\" + name + \".pkl\", \"wb\"))\n",
    "\n",
    "\n",
    "def pkl_load(name, path=\".\"):\n",
    "      return pkl.load(open(path + \"/\" + name + '.pkl', \"rb\"))\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def add_vlines(model, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        for i in range(len(model.T_STIM_ON)):\n",
    "            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)\n",
    "    else:\n",
    "        for i in range(len(model.T_STIM_ON)):\n",
    "            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)\n",
    "\n",
    "```\n",
    "\n",
    "Notebook Settings\n",
    "=================\n",
    "\n",
    "``` ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%run ../../../notebooks/setup.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "```\n",
    "\n",
    "``` example\n",
    "The autoreload extension is already loaded. To reload it, use:\n",
    "  %reload_ext autoreload\n",
    "Python exe\n",
    "/home/leon/mambaforge/envs/torch/bin/python\n",
    "```\n",
    "\n",
    "Utils\n",
    "=====\n",
    "\n",
    "``` ipython\n",
    "def init_model(task, seed, **kwargs):\n",
    "    model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=1, **kwargs)\n",
    "    path = model.SAVE_PATH\n",
    "    model_state_dict = torch.load('%s/%s_%d.pth' % (path, task, seed))\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    # print('task', task, 'seed', seed)\n",
    "\n",
    "    return model\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def del_tensor(tensor):\n",
    "    DEVICE = tensor.device\n",
    "    del tensor\n",
    "    gc.collect()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.device(DEVICE)\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.reset_accumulated_memory_stats(DEVICE)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def run_grid(GRID_RANGE, seed, task, **kwargs):\n",
    "\n",
    "    GRID_LIST = [[-GRID_RANGE, 0], [0, GRID_RANGE]]\n",
    "\n",
    "    rates_grid = []\n",
    "    with torch.no_grad():\n",
    "        for GRID_X_RANGE in GRID_LIST:\n",
    "            for GRID_Y_RANGE in GRID_LIST:\n",
    "                model = init_model(task, seed, **kwargs)\n",
    "\n",
    "                model.GRID_X_RANGE = GRID_X_RANGE\n",
    "                model.GRID_Y_RANGE = GRID_Y_RANGE\n",
    "\n",
    "                model.N_BATCH = int(model.GRID_SIZE * model.GRID_SIZE)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    ff_input = model.init_ff_input()\n",
    "                    # print(ff_input.shape, model.N_BATCH)\n",
    "\n",
    "                    rates = model(ff_input, RET_REC=0).cpu().detach().numpy()\n",
    "                    # print('rates', rates.shape)\n",
    "                rates_grid.append(rates)\n",
    "\n",
    "                del_tensor(ff_input)\n",
    "                del_tensor(model)\n",
    "\n",
    "    return np.vstack(rates_grid)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_low_rank(rates, model, IF_REC=0):\n",
    "    if IF_REC==0:\n",
    "        vec1 = model.low_rank.V.T[0]\n",
    "        vec2 = model.low_rank.V.T[1]\n",
    "\n",
    "        vec2 = vec2 - (vec2 @ vec1) * vec1 / (vec1 @ vec1)\n",
    "\n",
    "        # vec1 = vec1 / torch.linalg.norm(vec1)\n",
    "        # vec2 = vec2 / torch.linalg.norm(vec2)\n",
    "\n",
    "        vec = torch.stack((vec1, vec2))\n",
    "        overlaps = rates @ vec.T / model.Na[0]\n",
    "    else:\n",
    "        vec1 = model.low_rank.U.T[0]\n",
    "        vec2 = model.low_rank.U.T[1]\n",
    "        # vec2 = vec2 - (vec2 @ vec1) * vec1 / (vec1 @ vec1)\n",
    "        vec1 = vec1 / torch.linalg.norm(vec1)**2\n",
    "        vec2 = vec2 / torch.linalg.norm(vec2)**2\n",
    "\n",
    "        vec = torch.stack((vec1, vec2))\n",
    "        overlaps = model.rec_input[0, :, :] @ vec.T\n",
    "\n",
    "    return overlaps.cpu().detach().numpy(), vec.cpu().detach().numpy()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import numpy as np\n",
    "\n",
    "def get_bissec(point1, point2, length=100):\n",
    "    # Calculate the directional vector of the original line\n",
    "    direction = point2 - point1\n",
    "    print(direction.shape)\n",
    "    # Midpoint of the line segment\n",
    "    midpoint = (point1 + point2) / 2\n",
    "\n",
    "    # Direction of the orthogonal line (perpendicular vector)\n",
    "    orthogonal_direction = np.array([-direction[1], direction[0]])\n",
    "\n",
    "    # Normalize the orthogonal direction\n",
    "    orthogonal_direction = orthogonal_direction / np.linalg.norm(orthogonal_direction)\n",
    "\n",
    "    # Calculate the endpoints of the orthogonal line segment\n",
    "    endpoint1 = midpoint - (length / 2) * orthogonal_direction\n",
    "    endpoint2 = midpoint + (length / 2) * orthogonal_direction\n",
    "\n",
    "    return np.array([endpoint1, endpoint2])\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "def create_mesh(x, y, size=100):\n",
    "    x_min, x_max = np.min((x, y)) - 1, np.max((x, y)) + 1\n",
    "    y_min, y_max = np.min((x, y)) - 1, np.max((x, y)) + 1\n",
    "\n",
    "    dx = np.gradient(x, axis=1)\n",
    "    dy = np.gradient(y, axis=1)\n",
    "\n",
    "    # Create a dense grid\n",
    "    xi, yi = np.meshgrid(np.linspace(x_min, x_max, size),\n",
    "                         np.linspace(y_min, y_max, size))\n",
    "\n",
    "    # Flatten your dx and dy along with x and y for interpolation\n",
    "    points = np.vstack((x.flatten(), y.flatten())).T\n",
    "    dx_flat = dx.flatten()\n",
    "    dy_flat = dy.flatten()\n",
    "\n",
    "\n",
    "    # Interpolating on the grid\n",
    "    ui = griddata(points, dx_flat, (xi, yi), method='linear', fill_value=np.nan)\n",
    "    vi = griddata(points, dy_flat, (xi, yi), method='linear', fill_value=np.nan)\n",
    "\n",
    "    return xi, yi, ui, vi\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def create_mesh(x, y, size=100, sigma=0, interp_method='nearest', mask_radius=10):\n",
    "    \"\"\"\n",
    "    x, y: arrays of shape (n_traj, n_points)\n",
    "    size: grid size along each axis\n",
    "    sigma: Gaussian smoothing for velocities (0=none)\n",
    "    interp_method: 'linear', 'cubic', or 'nearest'\n",
    "    mask_radius: mask out grid points farther than this multiple of median point spacing\n",
    "\n",
    "    Returns: xi, yi, ui, vi (masked arrays)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    # Flatten for easier handling\n",
    "    x_flat = x.flatten()\n",
    "    y_flat = y.flatten()\n",
    "\n",
    "    # Compute dense grid\n",
    "    x_min, x_max = np.min(x_flat)-1, np.max(x_flat)+1\n",
    "    y_min, y_max = np.min(y_flat)-1, np.max(y_flat)+1\n",
    "\n",
    "    xi, yi = np.meshgrid(np.linspace(x_min, x_max, size),\n",
    "                         np.linspace(y_min, y_max, size))\n",
    "\n",
    "    # Compute velocities (finite differences along time axis)\n",
    "    dx = np.gradient(x, axis=1)\n",
    "    dy = np.gradient(y, axis=1)\n",
    "\n",
    "    # Optional smoothing of velocities\n",
    "    if sigma > 0:\n",
    "        dx = gaussian_filter(dx, sigma=sigma)\n",
    "        dy = gaussian_filter(dy, sigma=sigma)\n",
    "\n",
    "    dx_flat = dx.flatten()\n",
    "    dy_flat = dy.flatten()\n",
    "\n",
    "    # Prepare for griddata interpolation\n",
    "    points = np.vstack((x_flat, y_flat)).T\n",
    "\n",
    "    # Interpolate velocity components onto grid\n",
    "    ui = griddata(points, dx_flat, (xi, yi), method=interp_method, fill_value=np.nan)\n",
    "    vi = griddata(points, dy_flat, (xi, yi), method=interp_method, fill_value=np.nan)\n",
    "\n",
    "    # Find where it failed\n",
    "    mask = np.isnan(ui)\n",
    "\n",
    "    # Interpolate only those points with 'nearest'\n",
    "    if np.any(mask):\n",
    "        ui_nearest = griddata(points, dx_flat, (xi, yi), method='nearest')\n",
    "        vi_nearest = griddata(points, dy_flat, (xi, yi), method='nearest')\n",
    "        ui[mask] = ui_nearest[mask]\n",
    "        vi[mask] = vi_nearest[mask]\n",
    "\n",
    "    # # Mask far-from-data regions (optional)\n",
    "    # tree = cKDTree(points)\n",
    "    # dists, _ = tree.query(np.column_stack([xi.flatten(), yi.flatten()]), k=1)\n",
    "    # dists = dists.reshape(xi.shape)\n",
    "    # median_spacing = np.median(np.sqrt(np.diff(x_flat)**2 + np.diff(y_flat)**2))\n",
    "    # mask = dists > (mask_radius * median_spacing)\n",
    "    # ui = np.ma.masked_where(mask, ui)\n",
    "    # vi = np.ma.masked_where(mask, vi)\n",
    "\n",
    "    return xi, yi, ui, vi\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import matplotlib as mpl\n",
    "\n",
    "def plot_field(overlaps, ax, window, IF_FP=0, task=0, GRID_TEST=0, IF_CBAR=0):\n",
    "    x = overlaps[:, window:, 0]\n",
    "    y = overlaps[:, window:, 1]\n",
    "\n",
    "    xi, yi, ui, vi = create_mesh(x, y, size=300)\n",
    "    speed = np.sqrt(ui**2+vi**2)\n",
    "    speed = (speed - np.mean(speed)) / (np.std(speed) + 1e-6)\n",
    "\n",
    "    center, center_ = get_fp(overlaps, window, task, GRID_TEST=GRID_TEST)\n",
    "\n",
    "    vmin, vmax = np.nanpercentile(speed, [5, 95])\n",
    "    norm = mpl.colors.Normalize(vmin, vmax)\n",
    "\n",
    "    heatmap = ax.streamplot(xi, yi, ui, vi, density=0.5, arrowsize=1.25, norm=norm, color=('w', 0.5))\n",
    "    heatmap = ax.pcolormesh(xi, yi, speed, cmap='coolwarm', shading='gouraud', norm=norm)\n",
    "    # heatmap = ax.imshow(speed, extent=(yi.min(), yi.max(), yi.min(), yi.max()), cmap='jet', norm=norm, origin='lower', aspect='auto')\n",
    "\n",
    "    ax.plot(center.T[0], center.T[1], 'o', color='w', ms=18)\n",
    "    # if GRID_TEST is not None:\n",
    "    #     ax.plot(center_.T[0], center_.T[1], 'o', color='w', ms=18)\n",
    "\n",
    "    # ax.set_aspect('equal')\n",
    "    # ax.set_xlim([yi.min(), yi.max()])\n",
    "    # ax.set_ylim([yi.min(), yi.max()])\n",
    "    ax.set_yticks([-10, 0, 10])\n",
    "    heatmap.set_clim(-1.5, 1.5)\n",
    "\n",
    "    if IF_CBAR:\n",
    "        cbar = plt.colorbar(heatmap, ax=ax)\n",
    "        cbar.set_label('Norm. Speed')\n",
    "        # cbar.set_clim(-1.5, 1.5)\n",
    "\n",
    "    ax.set_xlabel('A/B Overlap')\n",
    "    ax.set_ylabel('Choice Overlap')\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def save_fig(figname, GRID_TEST, format='png'):\n",
    "\n",
    "    if GRID_TEST==4:\n",
    "        plt.savefig('../figures/flow/%s_test_C_%d.%s' % (figname, seed, format), dpi=300)\n",
    "    elif GRID_TEST==9:\n",
    "        plt.savefig('../figures/flow/%s_test_D_%d.%s' % (figname, seed, format), dpi=300)\n",
    "    elif GRID_TEST==1:\n",
    "        plt.savefig('../figures/flow/%s_go_%d.%s' % (figname, seed, format), dpi=300)\n",
    "    elif GRID_TEST==6:\n",
    "        plt.savefig('../figures/flow/%s_nogo_%d.%s' % (figname, seed, format), dpi=300)\n",
    "    elif GRID_TEST==0:\n",
    "        plt.savefig('../figures/flow/%s_sample_A_%d.%s' % (figname, seed, format), dpi=300)\n",
    "    elif GRID_TEST==5:\n",
    "        plt.savefig('../figures/flow/%s_sample_B_%d.%s' % (figname, seed, format), dpi=300)\n",
    "    else:\n",
    "        plt.savefig('../figures/flow/%s_%d.%s' % (figname, seed, format), dpi=300)\n",
    "\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "def integrate_to_attractor(xi, yi, ui, vi, attractors, n_steps=500, dt=0.05, tol=1e-2):\n",
    "    \"\"\"\n",
    "    For each mesh point, integrate its trajectory and assign the attractor (index) it converges to.\n",
    "    Returns: basin_map (shape of xi), index to attractor for each gridpoint.\n",
    "    \"\"\"\n",
    "    shape = xi.shape\n",
    "    positions = np.stack([xi.flatten(), yi.flatten()], axis=1)\n",
    "    basin_idx = np.full(positions.shape[0], -1, dtype=int)\n",
    "\n",
    "    # Make interpolators for u,v\n",
    "    def interp_field(pos, field):\n",
    "        # input pos: Nx2, field: mesh\n",
    "        coords = [\n",
    "            (pos[:,1] - yi[0,0]) / (yi[0,-1] - yi[0,0]) * (yi.shape[1]-1),\n",
    "            (pos[:,0] - xi[0,0]) / (xi[-1,0] - xi[0,0]) * (xi.shape[0]-1)\n",
    "        ]\n",
    "        # Reversed axes, order is (y, x)\n",
    "        return map_coordinates(field.T, coords, order=1, mode='nearest')\n",
    "\n",
    "    # For each gridpoint, integrate until close to attractor or steps end\n",
    "    curr = positions.copy()\n",
    "    for step in range(n_steps):\n",
    "        if np.all(basin_idx >= 0):\n",
    "            break\n",
    "        not_assigned = (basin_idx < 0)\n",
    "        u_ = interp_field(curr[not_assigned], ui)\n",
    "        v_ = interp_field(curr[not_assigned], vi)\n",
    "        curr[not_assigned,0] += dt * u_\n",
    "        curr[not_assigned,1] += dt * v_\n",
    "\n",
    "        # Check for proximity to attractors\n",
    "        for i, fp in enumerate(attractors):\n",
    "            dists = np.linalg.norm(curr[not_assigned] - fp, axis=1)\n",
    "            close = dists < tol\n",
    "            basin_idx[not_assigned.nonzero()[0][close]] = i\n",
    "\n",
    "    basin_map = basin_idx.reshape(shape)\n",
    "    return basin_map\n",
    "```\n",
    "\n",
    "Model\n",
    "=====\n",
    "\n",
    "``` ipython\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame\"\n",
    "conf_name = \"train_dual.yml\"\n",
    "DEVICE = 'cuda:1'\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "kwargs = {\n",
    "    'DURATION': 40.0,\n",
    "    'TASK': 'dual_flow',\n",
    "    'T_STIM_ON': [1.0, 2.0],\n",
    "    'T_STIM_OFF': [2.0, 300.0],\n",
    "    'I0': [1.0, 1.0],\n",
    "    'GRID_SIZE': 10,\n",
    "    'GRID_TEST': 0, # here\n",
    "    'GRID_INPUT': 0,\n",
    "    'IF_OPTO': 0\n",
    "}\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "tasks = ['dpa']\n",
    "tasks = ['dpa', 'dual_naive', 'dual_train']\n",
    "seed = np.random.randint(100)\n",
    "seed = 3\n",
    "print(seed)\n",
    "GRID_RANGE = 0.4\n",
    "```\n",
    "\n",
    "Flow\n",
    "====\n",
    "\n",
    "``` ipython\n",
    "rates = []\n",
    "for task in tasks:\n",
    "        rates.append(run_grid(GRID_RANGE, seed, task, **kwargs))\n",
    "rates = np.array(rates)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rates_tensor = torch.tensor(rates).to(DEVICE)\n",
    "print(rates_tensor.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model = init_model(task, seed, **kwargs)\n",
    "overlaps, vec = get_low_rank(rates_tensor, model, IF_REC=0)\n",
    "print(overlaps.shape)\n",
    "\n",
    "window = int((model.N_STIM_OFF[0] - model.N_STEADY) / model.N_WINDOW) + 1\n",
    "\n",
    "# ff_overlaps = ff_input[..., model.N_STEADY: , model.slices[0]] @ vec.T\n",
    "# ff_overlaps = ff_overlaps[:, ::10]\n",
    "# print(overlaps.shape, ff_overlaps.shape)\n",
    "```\n",
    "\n",
    "Field\n",
    "=====\n",
    "\n",
    "``` ipython\n",
    "from sklearn.cluster import KMeans\n",
    "def get_fp(overlaps, window, task, GRID_TEST=None, x=None, y=None):\n",
    "    kmeans = KMeans(n_clusters=5, random_state=None)\n",
    "\n",
    "    if x is None:\n",
    "        x = overlaps[:, window:, 0]\n",
    "        y = overlaps[:, window:, 1]\n",
    "\n",
    "    x_fp = x[:, -1]\n",
    "    y_fp = y[:, -1]\n",
    "    fp = np.stack((x_fp, y_fp)).T\n",
    "\n",
    "    # print(fp.shape)\n",
    "    kmeans.fit(fp)\n",
    "    center = np.array(kmeans.cluster_centers_)\n",
    "\n",
    "    if task==2:\n",
    "        center = center[:3]\n",
    "\n",
    "    center_ = []\n",
    "\n",
    "    if GRID_TEST is None:\n",
    "        pkl_save(center, 'center_%s' % task, path=\"/home/leon/\")\n",
    "    else:\n",
    "        center_ = pkl_load('center_%s' % task, path=\"/home/leon/\")\n",
    "\n",
    "    return center, center_\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "# fig, ax = plt.subplots(1, 1, figsize=[width, width])\n",
    "# aplot_field(overlaps[0], ax, window, IF_FP=1, task=0, GRID_TEST=model.GRID_TEST, IF_CBAR=1);\n",
    "# save_fig('flow_field_cbar_seed_%d' % (seed), GRID_TEST=model.GRID_TEST)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "for i in range(len(tasks)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[width, width])\n",
    "    if i==3:\n",
    "        plot_field(overlaps[0], ax, window, IF_FP=1, task=0, GRID_TEST=model.GRID_TEST, IF_CBAR=1)\n",
    "        save_fig('flow_field_cbar_seed_%d' % (seed), GRID_TEST=model.GRID_TEST)\n",
    "    else:\n",
    "        plot_field(overlaps[i], ax, window, IF_FP=1, task=i, GRID_TEST=model.GRID_TEST, IF_CBAR=0);\n",
    "        save_fig('flow_field_task_%s_seed_%d' % (tasks[i], seed), GRID_TEST=model.GRID_TEST)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, len(tasks), figsize=[len(tasks) * width, width])\n",
    "\n",
    "for i in range(len(tasks)):\n",
    "    plot_field(overlaps[i], ax[i], window, IF_FP=1, task=i, GRID_TEST=model.GRID_TEST)\n",
    "\n",
    "save_fig('flow_field_seed_%d' % seed, GRID_TEST=model.GRID_TEST)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
