{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Settings\n",
    "\n",
    "``` ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "%run ../../notebooks/setup.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "```\n",
    "\n",
    "# Imports\n",
    "\n",
    "``` ipython\n",
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "\n",
    "from src.network import Network\n",
    "from src.decode import decode_bump\n",
    "from src.utils import clear_cache\n",
    "```\n",
    "\n",
    "# Helpers\n",
    "\n",
    "``` ipython\n",
    "def convert_seconds(seconds):\n",
    "    h = seconds // 3600\n",
    "    m = (seconds % 3600) // 60\n",
    "    s = seconds % 60\n",
    "    return h, m, s\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "import numpy as np\n",
    "def get_theta(a, b, GM=0, IF_NORM=0):\n",
    "\n",
    "    u, v = a, b\n",
    "\n",
    "    if GM:\n",
    "        v = b - np.dot(b, a) / np.dot(a, a) * a\n",
    "\n",
    "    if IF_NORM:\n",
    "        u = a / np.linalg.norm(a)\n",
    "        v = b / np.linalg.norm(b)\n",
    "\n",
    "    return np.arctan2(v, u)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_idx(model):\n",
    "    ksi = model.PHI0.cpu().detach().numpy()\n",
    "    print(ksi.shape)\n",
    "\n",
    "    theta = get_theta(ksi[0], ksi[2], GM=0, IF_NORM=0)\n",
    "    return theta.argsort()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "def get_overlap(model, rates):\n",
    "    ksi = model.PHI0.cpu().detach().numpy()\n",
    "    return rates @ ksi.T / rates.shape[-1]\n",
    "\n",
    "```\n",
    "\n",
    "# Parameters\n",
    "\n",
    "``` ipython\n",
    "REPO_ROOT = '/home/leon/models/NeuroTorch/'\n",
    "conf_name = 'config_EI.yml'\n",
    "```\n",
    "\n",
    "# Exploring Parameter Space\n",
    "\n",
    "To find parameters for which we have a multistable ring attractor, we\n",
    "use torch **batching** capabilities to run parallel simulations across\n",
    "the parameter space. The idea is that we will create \"batches\" of\n",
    "parameters and pass them to the model.\n",
    "\n",
    "## Batching a single parameter\n",
    "\n",
    "``` ipython\n",
    "model = Network(conf_name, REPO_ROOT, IF_STP=1, DT=0.001, VERBOSE=0, LIVE_FF_UPDATE=1, I0=[1, 0])\n",
    "```\n",
    "\n",
    "With torch we can easily pass lists of parameters or batches to the\n",
    "model. Here, let's batch the recurrent strenght $J_{EE}$.\n",
    "\n",
    "``` ipython\n",
    "N_BATCH = 20\n",
    "# Here we pass a list of parameters to J_STP which is JEE for the model with stp\n",
    "model.J_STP = torch.linspace(0, 10, N_BATCH, dtype=torch.float32, device='cuda')\n",
    "\n",
    "# For consistency we need to add a dummy extra dimension\n",
    "# This is so that the models performs dot products correctly\n",
    "# In the model J_STP is multiplied by rates of size (N_BATCH * N_NEURON)\n",
    "# (N_BATCH * 1) * (N_BATCH * N_NEURON) = (N_BATCH * N_NEURON)\n",
    "\n",
    "model.J_STP = model.J_STP.unsqueeze(-1)\n",
    "# we need to scale J_STP correctly 1/sqrt(K)\n",
    "model.J_STP = model.J_STP * model.Jab[0, 0]  \n",
    "print('Jee', model.J_STP.shape)\n",
    "\n",
    "# We set the number of batches\n",
    "model.N_BATCH = N_BATCH\n",
    "# and run the model\n",
    "\n",
    "start = perf_counter()\n",
    "rates_Jee = model().cpu().detach().numpy()\n",
    "end = perf_counter()\n",
    "print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))\n",
    "print('rates', rates_Jee.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "idx = get_idx(model)\n",
    "rates_ordered = rates_Jee[..., idx]\n",
    "\n",
    "m0, m1, phi = decode_bump(rates_ordered, axis=-1)\n",
    "print(m0.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].plot(model.J_STP.cpu(), m0[:, -1], '-o')\n",
    "ax[0].set_xlabel('$J_{EE}$')\n",
    "ax[0].set_ylabel('$<Rates>_i$')\n",
    "\n",
    "ax[1].plot(rates_Jee.mean(-1).T)\n",
    "ax[1].set_xlabel('$J_{EE}$')\n",
    "ax[1].set_ylabel('Rates')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(model.J_STP.shape, m1.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].plot(model.J_STP.cpu(), m1[:, -1])\n",
    "ax[0].set_xlabel('$J_{EE}$')\n",
    "ax[0].set_ylabel('$\\mathcal{F}_1$')\n",
    "\n",
    "ax[1].plot(m1.T)\n",
    "ax[1].set_xlabel('$Step$')\n",
    "ax[1].set_ylabel('$\\mathcal{F}_1$')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Here, for example, with J<sub>STP</sub>=10 we have a ring attractor!\n",
    "\n",
    "``` ipython\n",
    "\n",
    "```\n",
    "\n",
    "## Batching multiple parameters\n",
    "\n",
    "### Simuls\n",
    "\n",
    "Sometimes we won't be so lucky and need to search harder over multiple\n",
    "parameters. In order to **batch** over multiple parameters, we need to\n",
    "carefully create each parameter batch. Here, let's batch the recurrent\n",
    "strenght $J_{EE}$ and the feedforward strength $J_{E0}$.\n",
    "\n",
    "``` ipython\n",
    "model = Network(conf_name, REPO_ROOT, IF_STP=1, VERBOSE=0, LIVE_FF_UPDATE=1, N_BATCH=1, I0=[.2, 0])\n",
    "```\n",
    "\n",
    "First we create the lists of parameters to sweep\n",
    "\n",
    "``` ipython\n",
    "N_JEE = 20\n",
    "N_JE0 = 20\n",
    "\n",
    "JEE_list = np.linspace(0, 20, N_JEE).astype(np.float32)\n",
    "print('Jee list', JEE_list)\n",
    "\n",
    "JE0_list = np.linspace(1, 3, N_JE0).astype(np.float32)\n",
    "print('Je0 list', JE0_list)\n",
    "\n",
    "JEE = torch.from_numpy(JEE_list).to('cuda')\n",
    "JE0 = torch.from_numpy(JE0_list).to('cuda')\n",
    "```\n",
    "\n",
    "Now we need to expand these lists into tensors with the correct shapes.\n",
    "To do so we create a two new tensors J<sub>EE</sub> and J<sub>E0</sub>\n",
    "of size (N<sub>JEE</sub>, N<sub>JE0</sub>) where each row of\n",
    "J<sub>EE</sub> is a repetition of Jee list and each column of Je0 is a\n",
    "copy of Je0 list. In that way, all the values of J<sub>EE</sub> are\n",
    "associated once with a value of Je0.\n",
    "\n",
    "``` ipython\n",
    "JEE = JEE.unsqueeze(0).expand(N_JE0, N_JEE)\n",
    "print('JEE first col', JEE[0])\n",
    "\n",
    "JE0 = JE0.unsqueeze(1).expand(N_JE0, N_JEE)\n",
    "print('JE0 first row', JE0[:, 0])\n",
    "```\n",
    "\n",
    "Torch models need a single batch dimension so we concatenate the two\n",
    "dimensions into tensors of size\n",
    "(N<sub>BATCH</sub>=N<sub>JEE</sub>\\*N<sub>JE0</sub>, 1) We need the\n",
    "extra dummy dimension so that in the model dot products are done\n",
    "properly.\n",
    "\n",
    "``` ipython\n",
    "JEE = JEE.reshape((-1, 1)) \n",
    "print('JEE', JEE.shape)\n",
    "\n",
    "JE0 = JE0.reshape((-1, 1)) \n",
    "print('JE0', JE0.shape)\n",
    "```\n",
    "\n",
    "Now we need to set the number of batches and copy our tensors to the\n",
    "model\n",
    "\n",
    "``` ipython\n",
    "N_BATCH = N_JE0 * N_JEE\n",
    "# Here we need to do some work on Ja0 first,\n",
    "# since it has two dimensions for E and I and we need to repeat the I values\n",
    "Ja0 = model.Ja0.repeat((N_BATCH, 1, 1))\n",
    "print('Ja0', Ja0.shape)\n",
    "\n",
    "# now we can pass JE0 to Ja0\n",
    "# we need to scale JaE properly\n",
    "Ja0[:,0] = JE0 * model.M0 * torch.sqrt(model.Ka[0])\n",
    "\n",
    "# and pass N_BATCH, Ja0 and Jee to the model\n",
    "model.N_BATCH = N_BATCH\n",
    "# copy Ja0\n",
    "model.Ja0 = Ja0 \n",
    "# in the model with stp, JEE is J_STP\n",
    "model.J_STP = JEE # * model.Jab[0, 0]\n",
    "```\n",
    "\n",
    "Let's run the simulations\n",
    "\n",
    "``` ipython\n",
    "start = perf_counter()\n",
    "rates = model().cpu().detach().numpy()\n",
    "end = perf_counter()\n",
    "print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))\n",
    "print('rates', rates.shape)\n",
    "```\n",
    "\n",
    "Let's compute the fourier moments of the population activity and reshape\n",
    "them\n",
    "\n",
    "``` ipython\n",
    "idx = get_idx(model)\n",
    "rates_ordered = rates[..., idx]\n",
    "\n",
    "m0, m1, phi = decode_bump(rates_ordered, axis=-1)\n",
    "print(m0.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "m0 = m0.reshape(N_JE0, N_JEE, -1)\n",
    "m1 = m1.reshape(N_JE0, N_JEE, -1)  \n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].imshow(m0[..., -5:].mean(-1),\n",
    "             cmap='jet', origin='lower', vmin=0, vmax=20, aspect='auto',\n",
    "             extent=[JEE_list[0], JEE_list[-1], JE0_list[0], JE0_list[-1]])\n",
    "\n",
    "ax[0].set_xlabel('$J_{EE}$')\n",
    "ax[0].set_ylabel('$J_{E0}$')\n",
    "\n",
    "ax[1].imshow((m1[...,-5:].mean(-1) - m1[..., :model.N_STIM_ON[0]].mean(-1))\n",
    "             / m0[...,-5:].mean(-1),\n",
    "             cmap='jet', origin='lower', vmin=0, vmax=1, aspect='auto',\n",
    "             extent=[JEE_list[0], JEE_list[-1], JE0_list[0], JE0_list[-1]])\n",
    "\n",
    "ax[1].set_xlabel('$J_{EE}$')\n",
    "ax[1].set_ylabel('$J_{E0}$')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "idx = 6\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].plot(m1[idx].T, alpha=.3)\n",
    "ax[0].set_ylabel('$\\mathcal{F}_1$')\n",
    "ax[0].set_xlabel('step')\n",
    "ax[0].set_title('Varying $J_{EE}$')\n",
    "\n",
    "ax[1].plot(m1[:, idx].T)\n",
    "ax[1].set_ylabel('$\\mathcal{F}_1$')\n",
    "ax[1].set_xlabel('step')\n",
    "ax[1].set_title('Varying $J_{E0}$')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "The parameters corresponding to (row 3, col -1) work!\n",
    "\n",
    "We can get their values from their matrix form\n",
    "\n",
    "``` ipython\n",
    "JEE = JEE.reshape((N_JE0, N_JEE))\n",
    "JE0 = JE0.reshape((N_JE0, N_JEE))  \n",
    "\n",
    "print('JE0', JE0[3, -1].item())\n",
    "print('JEE', JEE[3, -1].item())\n",
    "```\n",
    "\n",
    "or directly from the original lists\n",
    "\n",
    "``` ipython\n",
    "print('JE0', JE0_list[-1])\n",
    "print('JEE', JEE_list[-1])\n",
    "```\n",
    "\n",
    "### Test\n",
    "\n",
    "Let's test them.\n",
    "\n",
    "``` ipython\n",
    "idx = [3, 10]\n",
    "\n",
    "model = Network(conf_name, REPO_ROOT, TASK='dual_rand',\n",
    "                VERBOSE=0, DEVICE='cuda', seed=0, N_BATCH=1, LIVE_FF_UPDATE=1)\n",
    "\n",
    "# model.Ja0[:, 0] = JE0[idx[0], idx[1]] * model.M0 * torch.sqrt(model.Ka[0])\n",
    "# model.J_STP = JEE[idx[0], idx[1]]\n",
    "\n",
    "print(JE0[idx[0], idx[1]].item(), JEE[idx[0], idx[1]].item())\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "rates_test = model().cpu().numpy()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "idx = get_idx(model)\n",
    "rates_ordered = rates_test[..., idx]\n",
    "\n",
    "m0, m1, phi = decode_bump(rates_ordered, axis=-1)\n",
    "print(m0.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "m0, m1, phi = decode_bump(rates_test, axis=-1)\n",
    "print('m0', m0.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=(2*width, height))\n",
    "\n",
    "r_max = 10\n",
    "\n",
    "ax[0].imshow(rates_ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max, origin='lower')\n",
    "ax[0].set_ylabel('Neuron #')\n",
    "ax[0].set_xlabel('Step')\n",
    "\n",
    "ax[1].plot(m1.T)\n",
    "ax[1].set_ylabel('$\\mathcal{F}_1$')\n",
    "ax[1].set_xlabel('Step')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "\n",
    "```"
   ],
   "id": "c291fa50-5b31-4e61-82e7-213f362f0fe1"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
