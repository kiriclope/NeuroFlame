{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Settings\n",
    "=================\n",
    "\n",
    "``` ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "%run ../../notebooks/setup.py\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "```\n",
    "\n",
    "Imports\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "import sys\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "\n",
    "from src.network import Network\n",
    "from src.plot_utils import plot_con\n",
    "from src.decode import decode_bump\n",
    "from src.utils import clear_cache\n",
    "```\n",
    "\n",
    "Helpers\n",
    "=======\n",
    "\n",
    "``` ipython\n",
    "def convert_seconds(seconds):\n",
    "    h = seconds // 3600\n",
    "    m = (seconds % 3600) // 60\n",
    "    s = seconds % 60\n",
    "    return h, m, s\n",
    "```\n",
    "\n",
    "RNN with torch\n",
    "==============\n",
    "\n",
    "Single Trial\n",
    "------------\n",
    "\n",
    "Here we will run a single simulation with the parameters provided in\n",
    "**/conf/config<sub>2pop</sub>.yml**.\n",
    "\n",
    "``` ipython\n",
    "start = perf_counter()\n",
    "\n",
    "# We need to define the project root\n",
    "REPO_ROOT = \"/home/leon/models/NeuroFlame/\"\n",
    "\n",
    "# First we create a network with\n",
    "model = Network('config_2pop.yml', REPO_ROOT)\n",
    "\n",
    "# then we run the simulation with\n",
    "output = model()\n",
    "\n",
    "print('output', output.shape)\n",
    "# model outputs a tensor of rates of size (N_BATCH, N_STEPS, N_NEURON), so we need to convert it to numpy\n",
    "\n",
    "rates = output[0].cpu().numpy()\n",
    "print('rates', rates.shape)\n",
    "\n",
    "end = perf_counter()\n",
    "print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))\n",
    "\n",
    "Ne = model.Na[0].detach().cpu().numpy()\n",
    "N = model.N_NEURON\n",
    "```\n",
    "\n",
    "We can delete the model with\n",
    "\n",
    "``` ipython\n",
    "print('gpu memory before del:', torch.cuda.memory_allocated()/100000)\n",
    "del model\n",
    "clear_cache()\n",
    "print('gpu memory after del:', torch.cuda.memory_allocated()/100000)\n",
    "```\n",
    "\n",
    "Let's look at the activities of the neurons\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 3, figsize=(2*width, height))\n",
    "\n",
    "r_max = 10\n",
    "\n",
    "ax[0].imshow(rates.T, aspect='auto', cmap='jet', vmin=0, vmax=r_max, origin='lower')\n",
    "ax[0].set_ylabel('Neuron #')\n",
    "ax[0].set_xlabel('Step')\n",
    "\n",
    "ax[1].plot(rates.mean(-1))\n",
    "for i in range(10):\n",
    "    ax[1].plot(rates[..., i], alpha=0.2)\n",
    "\n",
    "ax[1].set_ylabel('$<Rates>_i$')\n",
    "ax[1].set_xlabel('Step')\n",
    "ax[1].set_ylim([0, r_max])\n",
    "\n",
    "ax[2].hist(rates[-1], density=True, bins='auto')\n",
    "ax[2].set_xlabel('Density')\n",
    "ax[2].set_ylabel('Rates')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "```\n",
    "\n",
    "Multiple Trials\n",
    "---------------\n",
    "\n",
    "### Multiple Initial Conditions\n",
    "\n",
    "We can run multiple initializations of the network changing\n",
    "N<sub>BATCH</sub> to the number of initializations that we want.\n",
    "\n",
    "``` ipython\n",
    "model = Network('config_2pop.yml', REPO_ROOT, GAIN=5)\n",
    "\n",
    "model.N_BATCH = 10\n",
    "rates = model().cpu().numpy()\n",
    "print('rates', rates.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=(2*width, height))\n",
    "\n",
    "for i in range(rates.shape[0]):\n",
    "    ax[0].hist(rates.mean(1)[i], bins=20, density=True)\n",
    "ax[0].set_ylabel('$<Rates>_i$')\n",
    "ax[0].set_xlabel('Initialization')\n",
    "\n",
    "ax[1].plot(rates.mean(-1).T)\n",
    "ax[1].set_ylabel('$<Rates>_i$')\n",
    "ax[1].set_xlabel('Step')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(torch.cuda.memory_allocated()/100000)\n",
    "del model\n",
    "clear_cache()\n",
    "print(torch.cuda.memory_allocated()/100000)\n",
    "```\n",
    "\n",
    "### Batching Feedforward Inputs\n",
    "\n",
    "To run some parameter searches, we can easily batch over a different set\n",
    "of ff inputs Let's see an example where we change the ff inputs to the\n",
    "excitatory population\n",
    "\n",
    "1.  The easy way (but memory consuming)\n",
    "\n",
    "    We create a batch of inputs of size (N<sub>BATCH</sub>,\n",
    "    N<sub>STEPS</sub>, N<sub>NEURON</sub>)\n",
    "\n",
    "    ``` ipython\n",
    "    model = Network('config_2pop.yml', REPO_ROOT)\n",
    "\n",
    "    ff_list = np.linspace(0, 10, 10)\n",
    "    ff_inputs = []\n",
    "    for i in ff_list:\n",
    "        model.Ja0[:, 0] = i  # here we set the ff input to E to value i in 0 .. 10\n",
    "        ff_inputs.append(model.init_ff_input())\n",
    "\n",
    "    ff_inputs = torch.vstack(ff_inputs)\n",
    "    print('ff_inputs', ff_inputs.shape)\n",
    "    ```\n",
    "\n",
    "    Then we pass these inputs to the model\n",
    "\n",
    "    ``` ipython\n",
    "    rates = model(ff_inputs).cpu().numpy()\n",
    "    print(rates.shape)\n",
    "    ```\n",
    "\n",
    "    ``` ipython\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(2*width, height))\n",
    "\n",
    "    ax[0].plot(rates.mean((1,-1)), '-o')\n",
    "    ax[0].set_ylabel('$<Rates>_i$')\n",
    "    ax[0].set_xlabel('FF inputs')\n",
    "\n",
    "    ax[1].plot(rates.mean(-1).T)  \n",
    "    ax[1].set_ylabel('$<Rates>_i$')\n",
    "    ax[1].set_xlabel('Step')\n",
    "    ax[1].set_ylim([0, 30])\n",
    "    plt.show()\n",
    "    ```\n",
    "\n",
    "    ``` ipython\n",
    "    print(torch.cuda.memory_allocated()/100000)\n",
    "    del model\n",
    "    clear_cache()\n",
    "    print(torch.cuda.memory_allocated()/100000)\n",
    "    ```\n",
    "\n",
    "2.  The hard way (slow but more memory friendly)\n",
    "\n",
    "    We create a batch of ff inputs that are updated at each time step\n",
    "\n",
    "    ``` ipython\n",
    "    model = Network('config_2pop.yml', REPO_ROOT, LIVE_FF_UPDATE=1)\n",
    "\n",
    "    N_BATCH = 10\n",
    "    print('original ff_input', model.Ja0.shape)\n",
    "\n",
    "    new_Ja0 = model.Ja0.repeat((N_BATCH, 1, 1)) \n",
    "    print('new ff_input', new_Ja0.shape)\n",
    "\n",
    "    new_Ja0[:, 0] = torch.linspace(0, 10, N_BATCH, device='cuda').unsqueeze(-1) * model.M0 * torch.sqrt(model.Ka[0])\n",
    "    print('batched ff_input', new_Ja0[:, 0].squeeze(-1))\n",
    "    ```\n",
    "\n",
    "    ``` ipython\n",
    "    model.N_BATCH = N_BATCH\n",
    "    model.Ja0 = new_Ja0\n",
    "    model.LIVE_FF_UPDATE = 1\n",
    "\n",
    "    start = perf_counter()\n",
    "    rates = model().cpu().numpy()\n",
    "    end = perf_counter()\n",
    "    print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))\n",
    "\n",
    "    print('rates', rates.shape)\n",
    "    ```\n",
    "\n",
    "    ``` ipython\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(2*width, height))\n",
    "\n",
    "    ax[0].plot(rates.mean((1,-1)), '-o')\n",
    "    ax[0].set_ylabel('$<Rates>_i$')\n",
    "    ax[0].set_xlabel('FF inputs')\n",
    "\n",
    "    ax[1].plot(rates.mean(-1).T)  \n",
    "    ax[1].set_ylabel('$<Rates>_i$')\n",
    "    ax[1].set_xlabel('Step')\n",
    "    ax[1].set_ylim([0, 30])\n",
    "    plt.show()\n",
    "    ```\n",
    "\n",
    "    ``` ipython\n",
    "    print(torch.cuda.memory_allocated()/100000)\n",
    "    del model\n",
    "    clear_cache()\n",
    "    print(torch.cuda.memory_allocated()/100000)\n",
    "    ```\n",
    "\n",
    "### Batching Reccurent Weights Jab\n",
    "\n",
    "``` ipython\n",
    "model = Network('config_2pop.yml', REPO_ROOT, IF_STP=0, DT=0.001, GAIN=0.5, VERBOSE=0, LIVE_FF_UPDATE=1)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.IF_BATCH_J = 1\n",
    "\n",
    "Jee_list = torch.linspace(0.0, 1.5, 10, device='cuda')  \n",
    "model.Jab_batch = Jee_list.unsqueeze(-1) * model.Jab[0, 0]\n",
    "print(model.Jab_batch[:, 0])\n",
    "\n",
    "model.N_BATCH = model.Jab_batch.shape[0]\n",
    "model.VERBOSE = 0\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "start = perf_counter()\n",
    "rates_Jee = model().cpu().detach().numpy()\n",
    "end = perf_counter()\n",
    "print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))\n",
    "\n",
    "print('rates', rates.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "mean_rates = rates_Jee[:,-1].mean(-1)\n",
    "\n",
    "ax[0].plot(Jee_list.cpu().numpy(), mean_rates)\n",
    "ax[0].set_xlabel('$J_{EE}$')\n",
    "ax[0].set_ylabel('$<Rates>_i$')\n",
    "# ax[0].set_ylim([0, 60])\n",
    "\n",
    "ax[1].plot(rates_Jee.mean(-1).T)\n",
    "ax[1].set_xlabel('$J_{EE}$')\n",
    "ax[1].set_ylabel('Rates')\n",
    "# ax[1].set_ylim([0, 60])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(torch.cuda.memory_allocated()/100000)\n",
    "del model\n",
    "clear_cache()\n",
    "print(torch.cuda.memory_allocated()/100000)\n",
    "```\n",
    "\n",
    "### Batching Feedforward Inputs and Weights\n",
    "\n",
    "``` ipython\n",
    "model = Network('config_2pop.yml', REPO_ROOT, IF_STP=0, DT=0.001, GAIN=0.5, LIVE_FF_UPDATE=1)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "N_BATCH = 10\n",
    "\n",
    "JEE = torch.linspace(0.0, 5.0, N_BATCH, device='cuda')\n",
    "JE0 = torch.linspace(0.0, 5.0, N_BATCH, device='cuda')\n",
    "\n",
    "JEE = JEE.unsqueeze(1).expand(N_BATCH, N_BATCH) \n",
    "JEE = JEE.reshape((-1, 1)) * model.Jab[0, 0]\n",
    "print('Jee', JEE.shape)\n",
    "\n",
    "JE0 = JE0.unsqueeze(0).expand(N_BATCH, N_BATCH)\n",
    "JE0 = JE0.reshape((-1, 1))\n",
    "print('Je0', JE0.shape)\n",
    "\n",
    "new_Ja0 = model.Ja0.repeat((N_BATCH*N_BATCH, 1, 1)) \n",
    "\n",
    "print('Ja0', new_Ja0.shape)\n",
    "new_Ja0[:,0] = JE0 * torch.sqrt(model.Ka[0]) * model.M0\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(JEE[:, 0].reshape(N_BATCH, N_BATCH)[0])\n",
    "print(JEE[:, 0].reshape(N_BATCH, N_BATCH)[:, 0])\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(new_Ja0[..., 0, 0].reshape(N_BATCH, N_BATCH)[0])\n",
    "print(new_Ja0[..., 0, 0].reshape(N_BATCH, N_BATCH)[:, 0])\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "model.IF_BATCH_J = 1\n",
    "model.Jab_batch = JEE * model.Jab[0, 0]\n",
    "\n",
    "model.Ja0 = new_Ja0\n",
    "\n",
    "model.N_BATCH = model.Jab_batch.shape[0]\n",
    "model.VERBOSE = 0\n",
    "\n",
    "start = perf_counter()\n",
    "rates = model().cpu().detach().numpy()\n",
    "end = perf_counter()\n",
    "print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))\n",
    "\n",
    "print('rates', rates.shape)\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "mean_rates = rates.mean(-1).reshape(N_BATCH, N_BATCH, -1)\n",
    "print(mean_rates[0, :, -1])\n",
    "print(mean_rates[:, 0, -1])\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n",
    "\n",
    "ax[0].imshow(mean_rates[..., -1].T, cmap='jet', origin='lower', aspect='auto')\n",
    "ax[0].set_xlabel('$J_{EE}$')\n",
    "ax[0].set_ylabel('$J_{E0}$')\n",
    "\n",
    "ax[1].plot(mean_rates[-1, :, -1]) # over inputs\n",
    "ax[1].plot(mean_rates[:, -1, -1]) # over Js\n",
    "\n",
    "ax[1].set_xlabel('$J_{EE}$')\n",
    "ax[1].set_ylabel('$J_{E0}$')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "``` ipython\n",
    "print(torch.cuda.memory_allocated()/100000)\n",
    "del model\n",
    "clear_cache()\n",
    "print(torch.cuda.memory_allocated()/100000)\n",
    "```"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
