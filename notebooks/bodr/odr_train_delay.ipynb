{"cells":[{"cell_type":"markdown","id":"5dbd5701-423d-420d-a145-909dc3ff6896","metadata":{},"source":"Training RNNs on ODR\n====================\n\n"},{"cell_type":"markdown","id":"806d08b5-a3ef-4a03-8dda-6d8b691c1262","metadata":{},"source":["## Notebook Settings\n\n"]},{"cell_type":"code","execution_count":1,"id":"5d474f5d-fe57-49e2-b14a-b2293f30ebe8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nPython exe\n/home/leon/mambaforge/envs/torch/bin/python"}],"source":["%load_ext autoreload\n%autoreload 2\n%reload_ext autoreload\n\n%run ../../../notebooks/setup.py\n%matplotlib inline\n%config InlineBackend.figure_format = 'png'\n\nREPO_ROOT = \"/home/leon/models/NeuroFlame\"\npal = sns.color_palette(\"tab10\")"]},{"cell_type":"markdown","id":"850fb505-dd71-4783-9fec-60a23993a3b7","metadata":{},"source":["## Imports\n\n"]},{"cell_type":"code","execution_count":1,"id":"ed00bc26-dc7f-41bc-bc49-00b732a05643","metadata":{},"outputs":[],"source":["import torch\n  import torch.nn as nn\n  import torch.optim as optim\n  # import torchmetrics\n  import torch.nn.functional as F\n  from torch.utils.data import Dataset, TensorDataset, DataLoader"]},{"cell_type":"code","execution_count":1,"id":"d59690fe-8abf-4859-867b-8475ced09be2","metadata":{},"outputs":[],"source":["import sys\n  sys.path.insert(0, '../../../')\n\n  import pandas as pd\n  import torch.nn as nn\n  from time import perf_counter\n  from scipy.stats import circmean\n\n  from src.network import Network\n  from src.plot_utils import plot_con\n  from src.decode import decode_bump, circcvl, decode_bump_torch\n  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor"]},{"cell_type":"markdown","id":"29971fea-11c4-4fe6-9783-fe8a98c0a5a7","metadata":{},"source":["## Helpers\n\n"]},{"cell_type":"markdown","id":"21f8518b-4b19-4f78-bcac-142140eb07e2","metadata":{},"source":["### plots\n\n"]},{"cell_type":"code","execution_count":1,"id":"ed0f9446-e0b8-4729-9a34-45171024979a","metadata":{},"outputs":[],"source":["def add_vlines(model, ax=None):\n\n    if ax is None:\n        for i in range(len(model.T_STIM_ON)):\n            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)\n    else:\n        for i in range(len(model.T_STIM_ON)):\n            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)"]},{"cell_type":"code","execution_count":1,"id":"c812d0b7-2b9b-4a15-9255-b06d01d3cbba","metadata":{},"outputs":[],"source":["def plot_rates_selec(rates, idx=0, thresh=0.5, figname='fig.svg'):\n        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n        r_max = thresh * np.max(rates[idx])\n\n        idx = np.random.randint(0, 96)\n        vmin, vmax = np.percentile(rates[idx].reshape(-1), [5, 95])\n\n        ax[0].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=vmin, vmax=vmax)\n        ax[0].set_ylabel('Neuron #')\n        ax[0].set_xlabel('Step')\n\n        idx = np.random.randint(0, 96)\n        vmin, vmax = np.percentile(rates[idx].reshape(-1), [5, 95])\n        ax[1].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=vmin, vmax=vmax)\n        ax[1].set_ylabel('Neuron #')\n        ax[1].set_xlabel('Step')\n        # ax[1].set_ylim([745, 755])\n        # plt.savefig(figname, dpi=300)\n        plt.show()"]},{"cell_type":"code","execution_count":1,"id":"82fe44c9-e60d-436e-8d8d-9c0acd304cac","metadata":{},"outputs":[],"source":["def plot_m0_m1_phi(model, rates, idx, figname='fig.svg'):\n\n      m0, m1, phi = decode_bump_torch(rates, axis=-1, RET_TENSOR=0)\n      print(m0.shape, m1.shape, phi.shape)\n\n      fig, ax = plt.subplots(1, 3, figsize=[2*width, height])\n\n      xtime = np.linspace(0, model.DURATION, m0.shape[-1])\n      idx = np.random.randint(0, 96, 16)\n\n      ax[0].plot(xtime, m0[idx].T)\n      #ax[0].set_ylim([0, 360])\n      #ax[0].set_yticks([0, 90, 180, 270, 360])\n      ax[0].set_ylabel('$\\mathcal{F}_0$ (Hz)')\n      ax[0].set_xlabel('Time (s)')\n      add_vlines(model, ax[0])\n\n      ax[1].plot(xtime, m1[idx].T)\n      # ax[1].set_ylim([0, 360])\n      # ax[1].set_yticks([0, 90, 180, 270, 360])\n      ax[1].set_ylabel('$\\mathcal{F}_1$ (Hz)')\n      ax[1].set_xlabel('Time (s)')\n      add_vlines(model, ax[1])\n\n      ax[2].plot(xtime, phi[idx].T * 180 / np.pi, alpha=.5)\n      ax[2].set_ylim([0, 360])\n      ax[2].set_yticks([0, 90, 180, 270, 360])\n      ax[2].set_ylabel('Phase (°)')\n      ax[2].set_xlabel('Time (s)')\n      add_vlines(model, ax[2])\n\n      plt.savefig(figname, dpi=300)\n      plt.show()"]},{"cell_type":"markdown","id":"8bd7161f-7728-4eff-b796-61efb955a87d","metadata":{},"source":["### Data Split\n\n"]},{"cell_type":"code","execution_count":1,"id":"d570403b-79b2-4ae3-a767-d8652ac381be","metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n\n  def split_data(X, Y, train_perc=0.8, batch_size=32, shuffle=True):\n\n      # if shuffle:\n      #     X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n      #                                                         train_size=train_perc,\n      #                                                         stratify=Y[:, 0].cpu().numpy(),\n      #                                                         shuffle=True)\n      # else:\n      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n                                                          train_size=train_perc,\n                                                          stratify=None,\n                                                          shuffle=False)\n\n      plt.hist(Y_train[Y_train!=-999].cpu() * 180 / np.pi, bins=15, label='train')\n      plt.hist(Y_test[Y_test!=-999].cpu() * 180 / np.pi, bins=15, label='test')\n      plt.xlabel('Target Loc. (°)')\n      plt.ylabel('Count')\n      plt.show()\n\n      print(X_train.shape, X_test.shape)\n      print(Y_train.shape, Y_test.shape)\n\n      train_dataset = TensorDataset(X_train, Y_train)\n      val_dataset = TensorDataset(X_test, Y_test)\n\n      # Create data loaders\n      train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=shuffle)\n      val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n\n      return train_loader, val_loader"]},{"cell_type":"markdown","id":"7d8cb7a4-1b1d-46f9-9166-9618219f4f51","metadata":{},"source":["### Optimization\n\n"]},{"cell_type":"code","execution_count":1,"id":"124e8d8b-8809-4b0d-9077-3e4d294476e4","metadata":{},"outputs":[],"source":["def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=0.001, clip_grad=0, zero_grad=0):\n    device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n\n    model.train()\n    total_loss = 0.0\n    total_batches = len(dataloader)\n\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        optimizer.zero_grad()\n\n        rates = model(X)\n        loss = loss_fn(rates, y)\n\n        # Initialize reg_loss as a scalar tensor\n        reg_loss = torch.tensor(0.0, device=device)\n\n        # Only apply the penalty once per step\n        if penalty is not None:\n            for param in model.parameters():\n                if penalty == 'l1':\n                    reg_loss += torch.sum(torch.abs(param))\n                elif penalty == 'l2':\n                    reg_loss += torch.sum(param ** 2)  # Better to use param ** 2\n\n        loss = loss + lbd * reg_loss\n\n        # Backpropagation\n        loss.backward()\n\n        # Clip gradients\n        if clip_grad:\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n            #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    avg_loss = total_loss / total_batches\n    return avg_loss"]},{"cell_type":"code","execution_count":1,"id":"819b37c5-05ab-4aed-b1fc-05def216feba","metadata":{},"outputs":[],"source":["def validation_step(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n\n    model.eval()\n    val_loss = 0.0\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n\n            rates = model(X)\n            batch_loss = loss_fn(rates, y)\n            val_loss += batch_loss.item() * X.size(0)\n\n    val_loss /= size\n    return val_loss"]},{"cell_type":"code","execution_count":1,"id":"66a57998-45a9-405e-bfc4-cdbb214574a5","metadata":{},"outputs":[],"source":["def optimization(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=0.005, zero_grad=0, gamma=0.9):\n\n    # Choose one scheduler\n    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n    # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)\n    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n\n    device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n\n    loss_list = []\n    val_loss_list = []\n\n    for epoch in range(num_epochs):\n        loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, zero_grad=zero_grad)\n        val_loss = validation_step(val_loader, model, loss_fn)\n\n        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n            scheduler.step(val_loss)\n        else:\n            scheduler.step()\n\n        loss_list.append(loss)\n        val_loss_list.append(val_loss)\n\n        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}')\n\n        if val_loss < thresh and loss < thresh:\n            print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')\n            break\n\n        if val_loss > 300:\n            print(f'Stopping training as loss is too high: {val_loss}')\n            break\n\n        if torch.isnan(torch.tensor(loss)):\n            print(f'Stopping training as loss is NaN.')\n            break\n\n    return loss_list, val_loss_list"]},{"cell_type":"markdown","id":"aa88b576-efd6-498d-aa29-1743b30d7eed","metadata":{},"source":["### Loss\n\n"]},{"cell_type":"code","execution_count":1,"id":"dc3e34ce-da15-40cd-9329-6319bc1526b2","metadata":{},"outputs":[],"source":["import torch\n\ndef skewed_gaussian_loss(theta_batch, y_pred, theta_bias, sigma=30, alpha=1.0):\n    \"\"\"\n    Asymmetric likelihood loss with skew controlled by alpha.\n    - theta_batch: True stimulus angles (batch_size)\n    - y_pred: Network predictions (batch_size)\n    - sigma: Base noise level (degrees)\n    - alpha: Skew magnitude/direction (alpha > 0: skew away from theta_bias)\n    \"\"\"\n    # Compute angular difference (handling circularity)\n    # delta = torch.remainder(theta_batch - theta_bias + torch.pi, 2.0 * torch.pi) - torch.pi\n    delta = theta_batch - theta_bias\n    delta = (delta + torch.pi) % (2 * torch.pi) - torch.pi\n\n    # Determine skew direction: alpha should be positive if stimulus > theta_bias\n    sign = torch.where(delta > 0, 1.0, -1.0)  # 1 if stimulus is clockwise from bias\n    alpha_scaled = alpha * sign  # Skew direction depends on stimulus location\n\n    # Skewed Gaussian likelihood\n    delta = theta_batch - y_pred\n    delta = (delta + torch.pi) % (2 * torch.pi) - torch.pi\n    z = delta / sigma\n    likelihood = torch.exp(-0.5 * z**2) * (1 + torch.erf(alpha_scaled * z / torch.sqrt(torch.tensor(2.0).to(y_pred.device))))\n\n    # Negative log-likelihood loss\n    loss = -torch.log(likelihood + 1e-6)\n    return loss"]},{"cell_type":"code","execution_count":1,"id":"7f10b0ee-fa06-4ae2-a5ec-02cebeea93d2","metadata":{},"outputs":[],"source":["def gaussian_loss(theta_batch, y_pred, sigma=30):\n        delta = y_pred - theta_batch\n        delta = (delta + torch.pi) % (2 * torch.pi) - torch.pi\n\n        likelihood = torch.exp(-0.5 * (delta / sigma)**2)\n\n        return -torch.log(likelihood + 1e-6)"]},{"cell_type":"code","execution_count":1,"id":"d754b631-6665-4608-8103-ad210a975ecc","metadata":{},"outputs":[],"source":["def polar_loss(theta_batch, y_pred):\n        loss = nn.MSELoss(reduction='none')\n        predicted_sin = torch.sin(y_pred)\n        predicted_cos = torch.cos(y_pred)\n\n        target_sin = torch.sin(theta_batch)\n        target_cos = torch.cos(theta_batch)\n\n        loss_sin = loss(predicted_sin, target_sin)\n        loss_cos = loss(predicted_cos, target_cos)\n\n        loss_angular = (loss_sin + loss_cos)\n\n        return loss_angular"]},{"cell_type":"code","execution_count":1,"id":"a126e60d-5371-4e05-b868-38c13bad0673","metadata":{},"outputs":[],"source":["import torch\nimport torch.nn as nn\n\nclass CircularAngleLoss(nn.Module):\n    def __init__(self, mode='angular', reduction='mean'):\n        super().__init__()\n        self.mode = mode\n        self.reduction = reduction\n        self.mse = nn.MSELoss(reduction=reduction)\n\n    def forward(self, pred_angle, target_angle):\n        if self.mode == 'polar':\n            pred_sin, pred_cos = torch.sin(pred_angle), torch.cos(pred_angle)\n            target_sin, target_cos = torch.sin(target_angle), torch.cos(target_angle)\n            loss_sin = self.mse(pred_sin, target_sin)\n            loss_cos = self.mse(pred_cos, target_cos)\n            return (loss_sin + loss_cos) / 2\n\n        elif self.mode == 'angular':\n            error = 1 - torch.cos(pred_angle - target_angle)\n            if self.reduction == 'mean':\n                return error.mean()\n            elif self.reduction == 'sum':\n                return error.sum()\n            else:\n                return error\n        else:\n            raise ValueError(f\"Unknown loss mode: {self.mode}\")"]},{"cell_type":"code","execution_count":1,"id":"fd9ef0f0-8a29-49d0-a31e-dd3e60ac7165","metadata":{},"outputs":[],"source":["import torch\nimport torch.nn as nn\nimport torch.distributions\n\nclass VonMisesNLLLoss(nn.Module):\n    def __init__(self, kappa=4.0, reduction='none'):\n        super().__init__()\n        self.kappa = kappa\n        self.reduction = reduction\n\n    def forward(self, pred_angle, target_angle):\n        # pred_angle and target_angle in radians, same shape\n        vm = torch.distributions.VonMises(pred_angle, self.kappa)\n        nll = -vm.log_prob(target_angle)\n        if self.reduction == 'mean':\n            return nll.mean()\n        elif self.reduction == 'sum':\n            return nll.sum()\n        else:\n            return nll  # (no reduction)"]},{"cell_type":"code","execution_count":1,"id":"11773538-908c-44f6-9ced-95178285feb3","metadata":{},"outputs":[],"source":["import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass AngularErrorLoss(nn.Module):\n    def __init__(self, thresh=1, reg_tuning=0.1, sigma_stimulus=30):\n        super(AngularErrorLoss, self).__init__()\n\n        self.loss = nn.MSELoss(reduction='none')\n        # self.loss = nn.SmoothL1Loss(reduction='none')\n\n        # self.polar_loss = VonMisesNLLLoss(reduction='none')\n        self.polar_loss = CircularAngleLoss(reduction='none')\n\n        self.thresh = thresh\n        self.reg_tuning = reg_tuning\n        self.sigma_stimulus = sigma_stimulus * torch.pi / 180.0\n\n    def forward(self, readout, theta_batch):\n        m0, m1, y_pred = decode_bump_torch(readout, axis=-1, device=readout.device)\n\n        valid_mask = theta_batch != -999\n        invalid_mask = ~valid_mask\n        total_loss = 0\n\n        # angular loss (Dcos, Dsin)\n        loss_polar = self.polar_loss(theta_batch, y_pred) * valid_mask\n        loss_angular = loss_polar.sum()\n\n        # loss_gaussian = gaussian_loss(theta_batch, y_pred, sigma=self.sigma_stimulus) * valid_mask\n        # loss_angular = loss_gaussian.sum()\n\n        total_loss += loss_angular\n\n        # imposing tuning strength\n        regularization = F.relu(self.thresh * m0 - m1) * valid_mask\n        total_loss += self.reg_tuning * regularization.sum()\n\n        # normalize over batch and time points\n        total_loss /= valid_mask.sum()\n\n        # imposing zero tuning in invalid mask\n        loss_zero = self.loss(m1, 0.0 * m1) * invalid_mask\n        total_loss += loss_zero.sum() / invalid_mask.sum()\n\n        return total_loss"]},{"cell_type":"markdown","id":"9ab35331-e990-4b7d-b8a6-190939f77d7a","metadata":{},"source":["### Other\n\n"]},{"cell_type":"code","execution_count":1,"id":"66543682-a553-44e0-bcf1-32df44250f42","metadata":{},"outputs":[],"source":["import pickle as pkl\n\n  def pkl_save(obj, name, path=\".\"):\n      pkl.dump(obj, open(path + \"/\" + name + \".pkl\", \"wb\"))\n\n\n  def pkl_load(name, path=\".\"):\n      return pkl.load(open(path + \"/\" + name + '.pkl', \"rb\"))"]},{"cell_type":"code","execution_count":1,"id":"f12970aa-604a-4b70-85a6-302bf953ab25","metadata":{},"outputs":[],"source":["def convert_seconds(seconds):\n      h = seconds // 3600\n      m = (seconds % 3600) // 60\n      s = seconds % 60\n      return h, m, s"]},{"cell_type":"markdown","id":"667c5a5a-b0d7-4df8-87fd-5db1a5c57b2a","metadata":{},"source":["## Model\n\n"]},{"cell_type":"code","execution_count":1,"id":"19ff75be-bc75-4b9e-a517-304288eacb74","metadata":{},"outputs":[],"source":["kwargs = {\n    'GAIN': 1.0,\n    'DURATION': 10.0,\n    'T_STEADY': 4,\n\n    'T_STIM_ON': [4.0, 6.0],\n    'T_STIM_OFF': [5.0, 7.0],\n\n    'Jab': [1.0, -1.3, 1, -1],\n    'I0': [0.5, -2.0],\n    'PHI0': [180.0, 180],\n    'SIGMA0': [2.0, 0.0],\n    'M0': 1,\n\n    'RANDOM_DELAY': 1,\n    'MIN_DELAY': 0,\n    'MAX_DELAY': 3,\n\n    'IF_FF_STP': 0,\n    'FF_USE': 0.5,\n    'TAU_FF_FAC': 0.0,\n    'TAU_FF_REC': 0.5,\n\n    'IS_STP': [1, 0, 0, 0],\n    'USE': [0.05, 0.03, 0.03, 0.1],\n    'TAU_FAC': [2.0, 2.0, 2.0, 0.0],\n    'TAU_REC': [0.2, 0.2, 0.2, 0.1],\n    'W_STP': [1.0, 3.0, 4.0, 1.0],\n\n    'IF_NMDA': 0,\n    'R_NMDA': 1.0,\n    'TAU_NMDA': [2.0, 2.0],\n\n    'IF_FF_ADAPT': 0,\n    'A_FF_ADAPT': 1.0,\n    'TAU_FF_ADAPT': 100.0,\n\n    'IF_ADAPT': 1,\n    'A_ADAPT': 1.0,\n    'TAU_ADAPT': 100.0,\n}"]},{"cell_type":"code","execution_count":1,"id":"862cddeb-e286-40e5-8aa4-b85acc5dd371","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"N_BATCH 1024 batch_size 128\nseed 0"}],"source":["REPO_ROOT = \"/home/leon/models/NeuroFlame\"\nconf_name = \"train_odr_EI.yml\"\nDEVICE = 'cuda'\n\ntotal_batches = 128 * 8\nbatch_size = 128\nratio = total_batches // batch_size\n\nN_BATCH = int(batch_size * ratio)\nprint('N_BATCH', N_BATCH, 'batch_size', batch_size)\n\nseed = np.random.randint(0, 1e6)\nseed = 0\nprint('seed', seed)"]},{"cell_type":"code","execution_count":1,"id":"9e9fd44a-b30d-477c-90e6-3244c7b3b9ad","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"EE post 0 pre 0 Jab tensor(0.0632, device='cuda:0') torch.Size([750, 750])"}],"source":["model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH, **kwargs)"]},{"cell_type":"markdown","id":"ff4480f5-ac93-4a28-afe9-5419e150dcaa","metadata":{},"source":["## Training\n\n"]},{"cell_type":"code","execution_count":1,"id":"801e1af9-8da4-48df-b690-49a03f938538","metadata":{},"outputs":[],"source":["model.J_STP.requires_grad = True"]},{"cell_type":"markdown","id":"5122023a-eb95-4c7e-8e28-1c95e17e29f6","metadata":{},"source":["#### Parameters\n\n"]},{"cell_type":"code","execution_count":1,"id":"b00fdcf1-15fa-45d8-aba8-b29e72f4dc16","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Wab_train torch.Size([750, 750])\nJ_STP torch.Size([])"}],"source":["for name, param in model.named_parameters():\n      if param.requires_grad:\n          print(name, param.shape)"]},{"cell_type":"code","execution_count":1,"id":"fed5b944-ab13-4f21-8c28-46eadb95cc7b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"rwd_mask torch.Size([1024, 131])\ntensor([40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n        58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75],\n       device='cuda:0')"}],"source":["model.N_BATCH = N_BATCH\nrwd_mask = torch.zeros((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)), device=DEVICE, dtype=torch.bool)\nprint('rwd_mask', rwd_mask.shape)\n\nfor i in range(model.N_BATCH):\n    # from first stim onset to second stim onset\n    mask = torch.arange((model.start_indices[0, i] - model.N_STEADY)/ model.N_WINDOW,\n                        (model.start_indices[1, i] - model.N_STEADY) / model.N_WINDOW).to(torch.int)\n    # print(mask)\n    rwd_mask[i, mask] = True\n\nidx = np.random.randint(N_BATCH)\nprint(torch.where(rwd_mask[idx]==1)[0])"]},{"cell_type":"code","execution_count":1,"id":"ce1f79bc-9002-4ff0-8b10-8e58736ad51e","metadata":{},"outputs":[],"source":[""]},{"cell_type":"markdown","id":"11e1b2b2-71b4-4992-9959-81e428ac5519","metadata":{},"source":["#### Inputs and Labels\n\n"]},{"cell_type":"code","execution_count":1,"id":"eab022e7-c2f0-406d-937e-8d3cb32cdae0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"total_batches 8\ntorch.Size([1024, 1])"}],"source":["total_batches = N_BATCH // batch_size\n\nprint('total_batches', N_BATCH // batch_size)\n\nlabels = []\nfor _ in range(total_batches):\n    batch_labels = torch.randint(0, 360, (batch_size, 1)).to(DEVICE)\n    labels.append(batch_labels)\n\nlabels = torch.cat(labels, dim=0)\nprint(labels.shape)"]},{"cell_type":"code","execution_count":1,"id":"b05eab5b-ef9c-4543-823f-0f6c3c6065df","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"torch.Size([1024, 2, 1]) torch.Size([1024, 855, 1000]) torch.Size([1024, 131])"}],"source":["model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)\nmodel.PHI0[:, 0] = labels * np.pi / 180.0\n\nwindow_size = int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)\nlabels = labels.repeat(1, window_size) * np.pi / 180.0\nlabels[~rwd_mask] = -999\n\nff_input = model.init_ff_input()\nprint(model.PHI0.shape, ff_input.shape, labels.shape)"]},{"cell_type":"code","execution_count":1,"id":"80d2c87f-f4e6-420a-8ddb-5b473e1c4bb5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"torch.Size([98378])\ntorch.Size([35766])\n"},{"data":{"image/png":"","text/plain":"<matplotlib.figure.Figure>"},"metadata":{},"output_type":"display_data"}],"source":["print(labels[labels==-999].shape)\nprint(labels[labels!=-999].shape)\nplt.hist(labels[labels!=-999].cpu() * 180 / np.pi, bins=15)\nplt.xlabel('Target Loc. (°)')\nplt.show()"]},{"cell_type":"markdown","id":"61b996a5-22a7-4084-b927-1b5608d05e13","metadata":{},"source":["#### Run\n\n"]},{"cell_type":"code","execution_count":1,"id":"0dd5748c-6026-464a-83bf-d25e19759ff1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"\ntorch.Size([819, 855, 1000]) torch.Size([205, 855, 1000])\ntorch.Size([819, 131]) torch.Size([205, 131])"},{"data":{"image/png":"","text/plain":"<matplotlib.figure.Figure>"},"metadata":{},"output_type":"display_data"}],"source":["train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":1,"id":"dd139110-3f44-4198-ac26-53a69ece60b7","metadata":{},"outputs":[],"source":["criterion = AngularErrorLoss(thresh=0.75, sigma_stimulus=30)\nlearning_rate = 0.1\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":1,"id":"1d79490a-4204-44db-b3e2-502695d51c5d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/5, Training Loss: 0.4708, Validation Loss: 0.3339\nEpoch 2/5, Training Loss: 0.1862, Validation Loss: 0.0784\nEpoch 3/5, Training Loss: 0.0815, Validation Loss: 0.0697\nEpoch 4/5, Training Loss: 0.0691, Validation Loss: 0.0781\nEpoch 5/5, Training Loss: 0.0678, Validation Loss: 0.0684\nElapsed (with compilation) = 0h 1m 9s"}],"source":["num_epochs = 5\n  start = perf_counter()\n  loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, thresh=.005)\n  end = perf_counter()\n  print(\"Elapsed (with compilation) = %dh %dm %ds\" % convert_seconds(end - start))"]},{"cell_type":"code","execution_count":1,"id":"115de812-57b8-4597-aaf9-8de1abab41f7","metadata":{},"outputs":[],"source":["torch.save(model.state_dict(), '../models/odr_%d.pth' % seed)"]},{"cell_type":"markdown","id":"9fa51b02-ee26-4af9-9ff3-eb3bc58d4765","metadata":{},"source":["## Testing\n\n"]},{"cell_type":"code","execution_count":1,"id":"0eb271e0-831b-4e5f-971f-e49ba045a6a7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Parameter containing:\ntensor(2.1821, device='cuda:0', requires_grad=True)"}],"source":["model_state_dict = torch.load('../models/odr/odr_%d.pth' % seed);\nmodel.load_state_dict(model_state_dict);\nmodel.eval();\n\nprint(model.J_STP)"]},{"cell_type":"code","execution_count":1,"id":"daed475f-9bd4-4b13-901b-3dbbf35d0a09","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"torch.Size([1024, 2, 1]) torch.Size([1024, 855, 1000]) torch.Size([1024, 1])"}],"source":["with torch.no_grad():\n    model.N_BATCH = N_BATCH\n\n    labels = torch.randint(0, 360, (N_BATCH, 1)).to(DEVICE) * torch.pi / 180.0\n    model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)\n    model.PHI0[:, 0] = labels\n\n\n    ff_input = model.init_ff_input()\n    print(model.PHI0.shape, ff_input.shape, labels.shape)"]},{"cell_type":"code","execution_count":1,"id":"56bfbfb2-a76c-419f-9d27-a2bbaec6d1af","metadata":{},"outputs":[{"data":{"image/png":"","text/plain":"<matplotlib.figure.Figure>"},"metadata":{},"output_type":"display_data"}],"source":["plt.hist(labels[:, 0].cpu() * 180 / np.pi, bins='auto', density=True)\nplt.xlabel('Target Loc. (°)')\nplt.ylabel('Density')\nplt.xticks(np.linspace(0, 360, 5))\n# plt.savefig('./figs/memhist/targets.svg', dpi=300)\nplt.show()"]},{"cell_type":"code","execution_count":1,"id":"e50f1fdf-3964-4ac6-81ca-4e79d856f49f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"rates (1024, 131, 750)"}],"source":["with torch.no_grad():\n    rates = model.forward(ff_input=ff_input).cpu().detach().numpy()\nprint('rates', rates.shape)"]},{"cell_type":"code","execution_count":1,"id":"805a9f14-6332-402c-b1d1-6c14be93fac7","metadata":{},"outputs":[{"data":{"image/png":"","text/plain":"<matplotlib.figure.Figure>"},"metadata":{},"output_type":"display_data"}],"source":["plot_rates_selec(rates=ff_input.cpu().detach().numpy(), idx=20, thresh=.5)"]},{"cell_type":"code","execution_count":1,"id":"ab184bea-769a-4569-9c28-e48c6eb0a1ef","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(1024, 855) (1024, 855) (1024, 855)\n"},{"data":{"image/png":"","text/plain":"<matplotlib.figure.Figure>"},"metadata":{},"output_type":"display_data"}],"source":["plot_m0_m1_phi(model, ff_input.cpu().numpy()[..., model.slices[0]], 10)"]},{"cell_type":"code","execution_count":1,"id":"02e87d45-d151-4418-9b4a-401933fffe92","metadata":{},"outputs":[{"data":{"image/png":"","text/plain":"<matplotlib.figure.Figure>"},"metadata":{},"output_type":"display_data"}],"source":["plot_rates_selec(rates=rates, idx=20, thresh=.5)"]},{"cell_type":"code","execution_count":1,"id":"bc7758bd-5353-4bfb-8825-495ceb9a3521","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(1024, 131) (1024, 131) (1024, 131)\n"},{"data":{"image/png":"","text/plain":"<matplotlib.figure.Figure>"},"metadata":{},"output_type":"display_data"}],"source":["plot_m0_m1_phi(model, rates, 4)"]},{"cell_type":"code","execution_count":1,"id":"c738ee56-43e9-4968-a0ed-1028d3674a49","metadata":{},"outputs":[],"source":["# targets = (target_loc + np.pi) % (2 * np.pi) - np.pi\n\n# fig, ax = plt.subplots(1, 2, figsize=[2*width, height])\n# # ax[0].hist(targets[:, 0] * 180 / np.pi , bins=32 , histtype='step')\n# ax[0].hist(errors2, bins=32, histtype='step')\n# ax[0].set_xlabel('Encoding Errors (°)')\n\n# ax[1].hist(errors, bins=32)\n# ax[1].set_xlabel('Memory Errors (°)')\n# # ax[1].set_xlim([-45, 45])\n# plt.show()"]},{"cell_type":"markdown","id":"a6cbcd2b-5392-4df8-9c97-cb48bff31869","metadata":{},"source":["## Connectivity\n\n"]},{"cell_type":"code","execution_count":1,"id":"609c42a7-093c-47a3-8f9f-80825d122f7f","metadata":{},"outputs":[],"source":["model_state_dict = torch.load('../models/odr/odr_%d.pth' % seed);\nmodel.load_state_dict(model_state_dict);\nmodel.eval();"]},{"cell_type":"code","execution_count":1,"id":"41468078-3554-43c4-ba19-2e9e63e378ec","metadata":{},"outputs":[],"source":["from src.lr_utils import LowRankWeights, clamp_tensor\nCij = model.GAIN * ( model.W_stp_T[0]  + model.Wab_train[model.slices[0], model.slices[0]])\n# Cij = model.Wab_train / model.Na[0] * model.J_STP\n# Cij[Cij>0]= 1\nCij = clamp_tensor(Cij, 0, model.slices).cpu().detach().numpy()\n\nCij0 = pkl_load('matrix', path=\".\")\nKj0 = pkl_load( 'Kj', path=\".\")\nKi0 = pkl_load( 'Ki', path=\".\")"]},{"cell_type":"code","execution_count":1,"id":"e2a471ce-ac8a-42f7-8c3c-6add4c6ef11e","metadata":{},"outputs":[{"data":{"image/png":"","text/plain":"<matplotlib.figure.Figure>"},"metadata":{},"output_type":"display_data"}],"source":["plt.figure(figsize=(2.5*width, 1.5*height))  # Set the figure size (width, height) in inches\n\n  ax1 = plt.subplot2grid((2, 3), (0, 0), rowspan=2)\n  im = ax1.imshow(Cij, cmap='jet', aspect=1, vmin=0)\n  ax1.set_xlabel(\"Presynaptic\")\n  ax1.set_ylabel(\"Postsynaptic\")\n\n  # Second column, first row\n  ax2 = plt.subplot2grid((2, 3), (0, 1))\n  Kj = np.sum(Cij, axis=0)  # sum over pres\n  ax2.plot(circcvl(Kj-Kj0, windowSize=75))\n  # ax2.set_xticklabels([])\n  ax2.set_ylabel(\"$K_j$\")\n\n  # # Second column, second row\n  ax3 = plt.subplot2grid((2, 3), (1, 1))\n  Ki = np.sum(Cij, axis=1)  # sum over pres\n  ax3.plot(circcvl(Ki-Ki0, windowSize=75))\n  ax3.set_ylabel(\"$K_i$\")\n\n  ax4 = plt.subplot2grid((2, 3), (0, 2), rowspan=2)\n  diags = []\n  for i in range(int(Cij.shape[0] / 2)):\n      diags.append(np.trace(Cij, offset=i) / Cij.shape[0])\n  diags = np.array(diags)\n  ax4.plot(diags)\n  ax4.set_xlabel(\"Neuron #\")\n  ax4.set_ylabel(\"$P_{ij}$\")\n\n  plt.tight_layout()\n  plt.show()"]},{"cell_type":"code","execution_count":1,"id":"051eef8c-d399-494e-af42-8adaee3530f8","metadata":{},"outputs":[{"data":{"image/png":"","text/plain":"<matplotlib.figure.Figure>"},"metadata":{},"output_type":"display_data"}],"source":["fig, ax = plt.subplots(1, 2, figsize=[2*width, height], sharey=1)\n\n  Dij = Cij.flatten()\n  np.random.shuffle(Dij)\n  Dij = Dij.reshape(Cij.shape)\n\n  im = ax[0].imshow(Dij, cmap='jet', aspect=1, vmin=0)\n  ax[0].set_xlabel(\"Presynaptic\")\n  ax[0].set_ylabel(\"Postsynaptic\")\n  ax[0].set_title('Naive')\n  # ax[0].set_xticks(np.linspace(0, 750, 4))\n  # ax[0].set_yticks(np.linspace(0, 750, 4))\n\n  im = ax[1].imshow(Cij, cmap='jet', aspect=1, vmin=0)\n  ax[1].set_xlabel(\"Presynaptic\")\n  ax[1].set_ylabel(\"Postsynaptic\")\n  ax[1].set_title('Trained')\n  # ax[1].set_xticks(np.linspace(0, 750, 4))\n  # ax[1].set_yticks(np.linspace(0, 750, 4))\n  plt.tight_layout()\n  plt.show()"]},{"cell_type":"code","execution_count":1,"id":"da8acb38-bce3-4e1e-8a49-f756eb453c1e","metadata":{},"outputs":[],"source":[""]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":5}