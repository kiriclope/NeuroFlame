#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/html-theme-readtheorg.setup
#+TITLE: NeuroFlame: Fast Learning And Modeling Engine
#+FILETAGS: RNN Torch

#+ATTR_HTML: :width 400px
[[./neuroflame.jpeg]]

Copyright © 2024 by Melanie Tschiersch. All rights reserved.

* Introduction

This package provides an implementation of a recurrent neural network trainer and simulator with Pytorch.
Networks can have multiple neural populations with different connectivity types (all-to-all, sparse) and structures (feature selective, spatially tuned, low rank).

Networks models can be trained in a unsupervised or supervised manner just as vanilla RNNs in Pytorch.

* Installation

#+begin_src sh
  pip install -r requirements.txt
#+end_src

or alternatively using conda (I recommend using mamba's [[https://github.com/conda-forge/miniforge][miniforge]], a c++ conda implementation)

#+begin_src sh
  mamba install --file conda_requirements.txt
#+end_src

* Project Structure
#+begin_src sh
  .
  ├── conf  # contains configuration files in yaml format.
  │   ├── *.yml
  ├── notebooks  # contains ipython notebooks.
  │   ├── setup.py
  │   └── *.ipynb
  ├── org  # contains org notebooks.
  │   ├── /doc/*.org
  │   └── *.org
  ├── src  # contains source code.
  │   ├── activation.py  # contains custom activation functions.
  │   ├── connectivity.py  # contains custom connectivity profiles.
  │   ├── decode.py
  │   ├── lif_network.py  # implementation of a LIF network.
  │   ├── lif_neuron.py
  │   ├── lr_utils.py  # utils for low rank networks.
  │   ├── network.py  # core of the project.
  │   ├── plasticity.py  # contains STP.
  │   ├── plot_utils.py
  │   ├── sparse.py  # utils for large sparse matrices.
  │   ├── stimuli.py  # contains custom stimuli for behavioral tasks.
  │   ├── train.py  # utils to train networks.
  └── └── utils.py
#+end_src

* [[file:/org/doc/dynamics.org][Network Dynamics]]
*** Dynamics
**** Currents

Neuron $i$ in population $A$ has a reccurent input $h^A_i$,

$$  \tau_{syn} \frac{dh_i}{dt}(t) = - h_i(t) + \sum_j J_{ij} h_j(t) $$

or not

$$ h^A_i(t) = \sum_{jB} J^{AB}_{ij} h_j(t) $$

**** Rates

The models can have rate dynamics (setting *RATE_DYN* to 1 in the configuration file):

$$ \tau_A \frac{d r^A_i}{dt}(t) = - r^A_i(t) + \Phi( \sum_{jB} J^{AB}_{ij} h^{AB}_j(t) + h^A_{ext}(t)) $$

Here, $r_i$ is the rate of unit $i$ in population $A$

otherwise rates will be instantaneous:

$$ r^A_i(t) = \Phi(\sum_{jB} J^{AB}_{ij} h_j(t) + h^A_{ext}(t)) $$

Here $\Phi$ is the transfer function defined in *src/activation.py* and can be set to a threshold linear, a sigmoid or a non linear function (Brunel et al., 2003).

*** Connectivity
The connectivities available in NeuroFlame are described [[file:/org/tests/connectivity.org][here]].

Probability of connection from population B to A:

**** Sparse Nets
by default it is a sparse net

$$ P_{ij}^{AB} = \frac{K_B}{N_B} $$

otherwise
it can be cosine

$$ P_{ij}^{AB} = ( 1.0 + \Kappa_B \cos(\theta_i^A - \theta_j^B) ) $$

and also low rank

$$ J_{ij}^{AB} = \frac{J_{AB}}{\sqrt{K_B}} with proba. P_{ij}^{AB} * \frac{K_B}{N_B} $$
$$ 0 otherwise $$

**** All to all

$$ J_{ij}^{AB} =  \frac{J_{AB}}{N_B} P_{ij}^{AB} $$

where Pij can be as above.

* Network Simulations
** Basic Usage

Here is how to run a simulation

#+begin_src ipython
  # import the network class
  from src.network import Network

  # Define repository root
  repo_root = '/'

  # Choose a config file
  conf_file = './conf/conf_EI.yml'

  # Other parameters can be overwriten with kwargs
  # kwargs can be any of the args in the config file

  # initialize model
  model = Network(conf_file, repo_root, **kwargs)

  # run a forward pass
  rates = model()
#+end_src

** [[file:/org/doc/neurotorch.org][Parallel Network Simulations]]

I describe in detail how to run a network simulation and use NeuroFlame to effectively run parallel simulations for different parameters [[file:/org/doc/neurotorch.org][here]].

* [[file:/org/train.org][Network Training]]
[[file:/org/train.org][Here]], I show how to train networks.
* Tutorials
** [[file:/org/tests/balance.org][Balanced Networks]]
[[file:/org/tests/balance.org][Here]], a tutorial on balanced networks.
** [[file:/org/search/multi_stable.org][Multistability]]

**** Fully connected
[[file:/org/search/ring_attractor.org][Here]], a notebook that shows how to use NeuroFlame to locate ring attractors in parameter space.
**** Sparse
[[file:/org/search/multi_stable.org][Here]], a notebook that shows how to use NeuroFlame to locate multistable balance states in parameter space.

** [[file:/org/tests/stp.org][Short Term Plasticity]]
[[file:/org/tests/stp.org][Here]], a tutorial on STP with NeuroFlame.
** [[file:/org/tests/stimuli.org][Behavioral Tasks]]
 [[file:/org/tests/stimuli.org][Here]], a tutorial on how to use different stimuli to get the model to perform different behavioral tasks.
** [[file:/org/serial_bias.org][Serial Bias]]
[[file:/org/serial_bias.org][Here]], a tutorial on how to get serial bias in a balanced network model.

* Contributing
Feel free to contribute.

#+begin_example
MIT License
Copyright (c) [2023] [A. Mahrach]
#+end_example
