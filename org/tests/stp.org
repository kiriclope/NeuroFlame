#+STARTUP: fold
#+TITLE: Short term plasticity
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session test :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import sys
  sys.path.insert(0, '../../')

  import torch
  import gc
  from time import perf_counter

  from src.network import Network
  from src.plasticity import Plasticity
  from src.decode import decode_bump
  from src.utils import clear_cache

  REPO_ROOT = '/home/leon/models/NeuroTorch/'
#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

* Testing STP implementation
** From the Plasticity class in src/plasticity.py

First, I we will plot the dynamics of the stp variables for a neuron with a given rate and Gaussian temporal noise.

#+begin_src ipython
  tau_list = torch.tensor([0.5, 0.25])
  N_BATCH = 2

  stp = Plasticity(USE=0.03, TAU_FAC=tau_list, TAU_REC=0.2, DT=0.01, size=(2, 10))

  N_STEPS = 500

  A_ux = []
  u_stp = []
  x_stp = []
  
  for _ in range(N_STEPS):
      rate = 10 + 10 * torch.randn((2, 10), device='cuda')

      A_ux.append(stp(rate))
      u_stp.append(stp.u_stp)
      x_stp.append(stp.x_stp)

  A_ux = torch.stack(A_ux, dim=1).cpu().numpy()
  u_stp = torch.stack(u_stp, dim=1).cpu().numpy()
  x_stp = torch.stack(x_stp, dim=1).cpu().numpy()
  print(A_ux.shape, u_stp.shape, x_stp.shape)
#+end_src

#+RESULTS:
: (2, 500, 10) (2, 500, 10) (2, 500, 10)

#+begin_src ipython
  fig, ax = plt.subplots(1, 3, figsize=(3*width, height))

  ax[0].plot(A_ux[0, :], 'k', label='Aux', alpha=0.25)
  ax[1].plot(u_stp[0, :], 'r', label='u', alpha=0.25)
  ax[2].plot(x_stp[0, :], 'b', label='x', alpha=0.25)

  ax[0].set_xlabel('Step')
  ax[0].set_ylabel('$A_{ux}$')

  ax[1].set_xlabel('Step')
  ax[1].set_ylabel('$u$')

  ax[2].set_xlabel('Step')
  ax[2].set_ylabel('$x$')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/5753aded24c89d3f8aeb90277d486185dc26d404.png]]

Then I will look at the evolution of the steady state value of A_ux with the rate for different values of tau_fac

#+begin_src ipython
  tau_list = torch.tensor([1.0, .75, .5, .25])
  N_BATCH = tau_list.shape[0]
  
  stp = Plasticity(USE=0.03, TAU_FAC=tau_list, TAU_REC=0.2, DT=0.01, size=(N_BATCH, 10))
#+end_src

#+RESULTS:

#+begin_src ipython
  A_ux = []
  x = []
  u = []

  N_RATES = 100
  N_STEPS = 300

  for i in range(N_RATES): # firing rate
      rates = i + np.sqrt(i) * torch.randn((N_BATCH, N_STEPS, 10), device='cuda')
      for j in range(N_STEPS): # steps before convergence
          A_u_x = stp(rates[:, j])
      A_ux.append(A_u_x)
      u.append(stp.u_stp)
      x.append(stp.x_stp)

  A_ux = torch.stack(A_ux, dim=1).cpu().numpy()
  u = torch.stack(u, dim=1).cpu().numpy()
  x = torch.stack(x, dim=1).cpu().numpy()
  print(A_ux.shape, u.shape, x.shape)

#+end_src

#+RESULTS:
: (4, 100, 10) (4, 100, 10) (4, 100, 10)

#+begin_src ipython
  fig, ax = plt.subplots(1, 3, figsize=[3*width, height])
  
  ax[0].plot(A_ux.mean(-1).T, label=tau_list.cpu().numpy())
  ax[0].set_xlabel('Rate (Hz)')
  ax[0].set_ylabel('$A_{ux}$')

  ax[1].plot(u.mean(-1).T, label=tau_list.cpu().numpy())
  ax[1].set_xlabel('Rate (Hz)')
  ax[1].set_ylabel('$u$')
  ax[1].set_ylim([0, 1])

  ax[2].plot(x.mean(-1).T, label=tau_list.cpu().numpy())
  ax[2].set_xlabel('Rate (Hz)')
  ax[2].set_ylabel('$x$')
  ax[2].set_ylim([0, 1])
  ax[2].legend(frameon=False, loc="right", fontsize=14, title='$\\tau_{fac}$')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/94d85f0cdf9555535252e14b9cb7a16adcf81725.png]]

This is what we expect!

** From the Network class in src/network.py
*** Single Trial

#+begin_src ipython
  model = Network('config_2pop.yml', 'None', REPO_ROOT, IF_STP=1, DT=0.001, GAIN=1.0, VERBOSE=0, TASK='odr')
  rates = model(RET_STP=1).cpu().detach().numpy()
#+end_src

#+RESULTS:

#+begin_src ipython
  u_list = model.u_list.cpu().numpy()
  x_list = model.x_list.cpu().numpy()
  Aux = u_list * x_list
  print(u_list.shape, x_list.shape)
#+end_src

#+RESULTS:
: (1, 101, 8000) (1, 101, 8000)

#+begin_src ipython
  fig, ax = plt.subplots(1, 3, figsize=[3*width, height])

  ax[0].plot(rates.mean(-1).T, 'k')
  ax[0].plot(rates[0, :, :10], alpha=.25)
  ax[0].set_xlabel('$Step$')
  ax[0].set_ylabel('Rates')

  ax[1].plot(u_list.mean(-1).T, 'k')
  ax[1].plot(u_list[0, :, :10], alpha=.25)
  ax[1].set_xlabel('Step')
  ax[1].set_ylabel('$u$')

  ax[2].plot(x_list.mean(-1).T, 'k')
  ax[2].plot(x_list[0, :, :10], alpha=.25)
  ax[2].set_xlabel('Step')
  ax[2].set_ylabel('$x$')
  
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/3ad394da0e7aceb1779608b558fded7f499b8292.png]]

#+begin_src ipython
  m0, m1, phi = decode_bump(rates, axis=-1)
  print(phi.shape)
#+end_src

#+RESULTS:
: (1, 101)

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])

  ax[0].imshow(rates.T, aspect='auto', cmap='jet', vmin=0, vmax=10, origin='lower')
  ax[0].set_ylabel('Pref. Location (°)')
  ax[0].set_yticks(np.linspace(0, model.Na[0].cpu(), 5), np.linspace(0, 360, 5).astype(int))
  ax[0].set_xlabel('Step')

  ax[1].plot(phi[0] * 180 / np.pi)
  ax[1].set_yticks(np.linspace(0, 360, 5).astype(int), np.linspace(0, 360, 5).astype(int))
  ax[1].set_ylabel('Pref. Location (°)')
  ax[1].set_xlabel('Step')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/133b895932e14796ee139b8a6172cdcd74cdedf9.png]]

#+begin_src ipython
#  plt.plot(rates[-1], Aux[-1], 'o')
#+end_src

#+begin_src ipython
  print(torch.cuda.memory_allocated()/100000)
  del model
  clear_cache()
  print(torch.cuda.memory_allocated()/100000)
#+end_src

#+RESULTS:
: 48552.22272
: 44485.23776

#+begin_src ipython

#+end_src

#+RESULTS:

*** Rates vs Ie

#+begin_src ipython
  model = Network('config_2pop.yml', 'None', REPO_ROOT, IF_STP=1, DT=0.001, GAIN=0.5, VERBOSE=0)
#+end_src

#+RESULTS:

#+begin_src ipython
  Je0_list = np.linspace(0, 10, 10)
  print(Je0_list)
  
  ff_inputs = []
  for i in Je0_list:
      model.Ja0[:, 0] = i  # here we set the ff input to E to value i in 0 .. 10      
      ff_inputs.append(model.init_ff_input())

  ff_inputs = torch.vstack(ff_inputs)  
#+end_src

#+RESULTS:
: [ 0.          1.11111111  2.22222222  3.33333333  4.44444444  5.55555556
:   6.66666667  7.77777778  8.88888889 10.        ]

#+begin_src ipython
  rates_Je0 = model(ff_inputs, RET_STP=1).cpu().detach().numpy()
#+end_src

#+RESULTS:

#+begin_src ipython
  u_list = model.u_list.cpu().numpy()
  x_list = model.x_list.cpu().numpy()
  print(u_list.shape, x_list.shape)
#+end_src

#+RESULTS:
: (10, 101, 8000) (10, 101, 8000)

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])

  mean_rates = rates_Je0[:,-1].mean(-1)

  ax[0].plot(Je0_list, mean_rates)
  ax[0].set_xlabel('$J_{E0}$')
  ax[0].set_ylabel('$<Rates>_i$')
  # ax[0].set_ylim([0, 60])

  ax[1].plot(rates_Je0.mean(-1).T)
  ax[1].set_xlabel('Step')
  ax[1].set_ylabel('Rates')
  # ax[1].set_ylim([0, 60])
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/71fe07544041ac44d3c8594ca456649e9a4c3711.png]]

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])

  mean_rates = u_list[:,-1].mean(-1) * x_list[:,-1].mean(-1)

  ax[0].plot(Je0_list, mean_rates)
  ax[0].set_xlabel('$J_{E0}$')
  ax[0].set_ylabel('$A_{ux}$')

  ax[1].plot(u_list.mean(-1).T * x_list.mean(-1).T)
  ax[1].set_xlabel('Step')
  ax[1].set_ylabel('$A_{ux}$')

  plt.show()

#+end_src

#+RESULTS:
[[file:./.ob-jupyter/364019780eb44381d02197e9fdc3bf9bdfa035c2.png]]

#+begin_src ipython
  print(torch.cuda.memory_allocated()/100000)
  del model
  clear_cache()
  print(torch.cuda.memory_allocated()/100000)
#+end_src

#+RESULTS:
: 49145.2928
: 44485.23776

*** Rates vs Jee

#+begin_src ipython
  model = Network('config_2pop.yml', 'None', REPO_ROOT, IF_STP=1, DT=0.001, GAIN=0.5, VERBOSE=0)
#+end_src

#+RESULTS:

#+begin_src ipython
  model.IF_BATCH_J = 1

  Jee_list = torch.linspace(0.5, 3, 10, device='cuda')
  model.Jab_batch = Jee_list.unsqueeze(-1) * model.Jab[0, 0]

  model.IF_STP = 1
  model.N_BATCH = model.Jab_batch.shape[0]
  model.VERBOSE = 0
  
  rates_Jee = model(RET_STP=1).cpu().detach().numpy()
#+end_src

#+RESULTS:

#+begin_src ipython
  u_list = model.u_list.cpu().numpy()
  x_list = model.x_list.cpu().numpy()
  print(u_list.shape, x_list.shape)
#+end_src

#+RESULTS:
: (10, 101, 8000) (10, 101, 8000)

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
  
  mean_rates = rates_Jee[:,-1].mean(-1)

  ax[0].plot(Jee_list.cpu().numpy(), mean_rates)
  ax[0].set_xlabel('$J_{EE}$')
  ax[0].set_ylabel('$<Rates>_i$')
  # ax[0].set_ylim([0, 60])

  ax[1].plot(rates_Jee.mean(-1).T)
  ax[1].set_xlabel('$J_{EE}$')
  ax[1].set_ylabel('Rates')
  # ax[1].set_ylim([0, 60])
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/f7c34f7ba68fdffe51c1d98b5454946b816ea362.png]]

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])

  mean_rates = u_list[:,-1].mean(-1) * x_list[:,-1].mean(-1)

  ax[0].plot(Jee_list.cpu(), mean_rates)
  ax[0].set_xlabel('$J_{EE}$')
  ax[0].set_ylabel('$A_{ux}$')

  ax[1].plot(u_list.mean(-1).T * x_list.mean(-1).T)
  ax[1].set_xlabel('Step')
  ax[1].set_ylabel('$A_{ux}$')

  plt.show()

#+end_src

#+RESULTS:
[[file:./.ob-jupyter/983116f4c5a05858db64b0da95e8669fc9186747.png]]

#+begin_src ipython
  print(torch.cuda.memory_allocated()/100000)
  del model
  clear_cache()
  print(torch.cuda.memory_allocated()/100000)
#+end_src

#+RESULTS:
: 51705.29792
: 44485.23776

*** Rates vs Use

#+begin_src ipython
  model = Network('config_2pop.yml', 'None', REPO_ROOT, IF_STP=1, DT=0.001, GAIN=0.5, VERBOSE=0)
#+end_src

#+RESULTS:

#+begin_src ipython  
  model.USE = torch.linspace(0.01, 0.1, 10, device='cuda')
  model.N_BATCH = model.USE.shape[0]
  
  rates_use = model(RET_STP=1).cpu().detach().numpy()
  print(rates_use.shape)
#+end_src

#+RESULTS:
: (10, 101, 8000)

#+begin_src ipython
  u_list = model.u_list.cpu().numpy()
  x_list = model.x_list.cpu().numpy()
  print(u_list.shape, x_list.shape)
#+end_src

#+RESULTS:
: (10, 101, 8000) (10, 101, 8000)

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
  
  mean_rates = rates_use[:,-1].mean(-1)

  ax[0].plot(model.USE.cpu().numpy(), mean_rates)
  ax[0].set_xlabel('Use')
  ax[0].set_ylabel('$<Rates>_i$')
  # ax[0].set_ylim([0, 60])

  ax[1].plot(rates_use.mean(-1).T)
  ax[1].set_xlabel('Step')
  ax[1].set_ylabel('Rates')
  # ax[1].set_ylim([0, 60])
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/bc15f6b76a0bfc42a002c7407105f892cb61e639.png]]

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])

  Aux = u_list * x_list

  ax[0].plot(model.USE.cpu(), Aux[:, -1].mean(-1))
  ax[0].set_xlabel('$Use$')
  ax[0].set_ylabel('$A_{ux}$')

  ax[1].plot(Aux.mean(-1).T)
  ax[1].set_xlabel('Step')
  ax[1].set_ylabel('$A_{ux}$')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/c0c2935b60ba38d3241e43ea055b58a7b02c588e.png]]

#+begin_src ipython
  print(torch.cuda.memory_allocated()/100000)
  del model
  clear_cache()
  print(torch.cuda.memory_allocated()/100000)
#+end_src

#+RESULTS:
: 49145.29792
: 44485.23776

#+begin_src ipython

#+end_src

#+RESULTS:

*** Rates vs Tau fac

#+begin_src ipython
  model = Network('config_2pop.yml', 'None', REPO_ROOT, IF_STP=1, DT=0.001, GAIN=0.5, VERBOSE=0, DURATION=10)
#+end_src

#+RESULTS:

#+begin_src ipython
  model.TAU_FAC = torch.linspace(0.25, 1.0, 10, device='cuda')
  model.N_BATCH = model.TAU_FAC.shape[0]

  rates_fac = model(RET_STP=1).cpu().detach().numpy()
  print(rates_fac.shape)
#+end_src

#+RESULTS:
: (10, 101, 8000)

#+begin_src ipython
  u_list = model.u_list.cpu().numpy()
  x_list = model.x_list.cpu().numpy()
  print(u_list.shape, x_list.shape)
#+end_src

#+RESULTS:
: (10, 101, 8000) (10, 101, 8000)

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])

  mean_rates = rates_fac[:,-1].mean(-1)

  ax[0].plot(model.TAU_FAC.cpu().numpy()*1000, mean_rates, 'k')
  ax[0].plot(model.TAU_FAC.cpu().numpy()*1000, rates_fac[:, -1, :10], alpha=.25)
  ax[0].set_xlabel('$\\tau_{fac}$')
  ax[0].set_ylabel('$<Rates>_i$')
  
  ax[1].plot(rates_fac.mean(-1).T)
  ax[1].set_xlabel('Step')
  ax[1].set_ylabel('Rates')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/d4ed076f62eddf6d09745b1dfd7b73917842cadc.png]]

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])

  mean_Aux = u_list[:,-1].mean(-1) * x_list[:,-1].mean(-1)

  ax[0].plot(model.TAU_FAC.cpu().numpy() * 1000, mean_Aux)
  ax[0].set_xlabel('$\\tau_{fac}$')
  ax[0].set_ylabel('$A_{ux}$')

  ax[1].plot(u_list.mean(-1).T * x_list.mean(-1).T)
  ax[1].set_xlabel('Step')
  ax[1].set_ylabel('$A_{ux}$')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/0c87ed08fc486ef7330a42f7fe64f726bc9d2e74.png]]

#+begin_src ipython
  print(torch.cuda.memory_allocated()/100000)
  del model
  clear_cache()
  print(torch.cuda.memory_allocated()/100000)
#+end_src

#+RESULTS:
: 49145.29792
: 44485.23776

#+begin_src ipython

#+end_src

#+RESULTS:
