#+STARTUP: fold
#+TITLE: Training Low Rank RNNs
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session light :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import lightning as L
  import torch
  import torch.nn as nn
  import torch.nn.functional as F
  import torch.optim as optim
  from torch.utils.data import Dataset, TensorDataset, DataLoader

  DEVICE = 'cuda:1'
#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.lrnet import LRNet

  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

* Helpers
** Data Split

#+begin_src ipython
  from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

  def split_data(X, Y, train_perc=0.8, batch_size=32):

    if Y.ndim==3:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0, 0].cpu().numpy(),
                                                          shuffle=True)
    else:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0].cpu().numpy(),
                                                          shuffle=True)
    print(X_train.shape, X_test.shape)
    print(Y_train.shape, Y_test.shape)

    train_dataset = TensorDataset(X_train, Y_train)
    val_dataset = TensorDataset(X_test, Y_test)

    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader
#+end_src

#+RESULTS:

* Configuration
#+begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroFlame"
  conf_name = "config_train.yml"
  DEVICE = 'cuda:1'
  seed = np.random.randint(0, 1e6)
  print(seed)
  #seed = 760946
#+end_src

#+RESULTS:
: 796932

* Model
#+begin_src ipython
  model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=16)
#+end_src

#+RESULTS:

* Dataset

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: low_rank.U torch.Size([1000, 1])
: low_rank.V torch.Size([1000, 1])
: low_rank.lr_kappa torch.Size([1])
: low_rank.linear.weight torch.Size([1, 500])
: low_rank.linear.bias torch.Size([1])

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT=1
#+end_src

#+RESULTS:

Testing the network on steps from sample odor offset to test odor onset

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

  mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  rwd_idx = np.where(mask)[0]
  print('rwd', rwd_idx)

  model.lr_eval_win = rwd_idx.shape[0]

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))

  zero_idx = np.where(~mask & ~stim_mask )[0]
  print('zero', zero_idx)
#+end_src

#+RESULTS:
: rwd [ 20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37
:   38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55
:   56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73
:   74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91
:   92  93  94  95  96  97  98  99 100]
: zero [0 1 2 3 4 5 6 7 8 9]

*** Inputs and Labels

#+begin_src ipython
  model.N_BATCH = 128

  model.I0[0] = 2.0
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = -2.0
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([256, 1110, 1000])

#+begin_src ipython
  labels_A = torch.ones((model.N_BATCH, 1))
  labels_B = torch.zeros((model.N_BATCH, 1))
  labels = torch.cat((labels_A, labels_B))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([256, 1])

#+begin_src ipython
  batch_size = 32
  train_loader, val_loader = split_data(ff_input.to(DEVICE), labels.to(DEVICE), train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([204, 1110, 1000]) torch.Size([52, 1110, 1000])
: torch.Size([204, 1]) torch.Size([52, 1])

* Run

#+begin_src ipython
  autoencoder = LRNet(model)
#+end_src

#+RESULTS:

#+begin_src ipython
  trainer = L.Trainer(devices=[1])
  trainer.fit(model=autoencoder, train_dataloaders=train_loader)
#+end_src

#+RESULTS:
#+begin_src ipython
  trainer.log
#+end_src

#+RESULTS:
: 2a6785f5-83fa-4008-81b1-5e0053e39a6f

#+begin_src ipython

#+end_src
