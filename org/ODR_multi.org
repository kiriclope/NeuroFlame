#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session odr_multi :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroTorch"
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Helpers
** Data
#+begin_src ipython
  def get_rates_ini_phi(name, ini_list, phi_list):
    rates_list = []
    for ini in ini_list:
      for phi in phi_list:
        rates = np.load(REPO_ROOT + '/data/simul/%s_ini_%d_phi_%d.npy' % (name, ini, phi))
        rates_list.append(rates)
        
    rates_list = np.array(rates_list).reshape(len(ini_list), len(phi_list), rates.shape[0], rates.shape[1])
    print(rates_list.shape)
    return rates_list  
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_df_ini_phi(rates):
      n_trials, n_phi, n_times, n_neurons = rates.shape

      # Create indices
      trials_ind, phi_ind, times_ind, neurons_ind = np.indices((n_trials, n_phi, n_times, n_neurons))

      # Construct DataFrame
      df = pd.DataFrame({
          'trial': trials_ind.flatten(),
          'phi': phi_ind.flatten(),
          'neuron': neurons_ind.flatten(),
          'time': times_ind.flatten(),
          'rates': rates.flatten()
      })

      return df

#+end_src

#+RESULTS:

#+begin_src ipython
  def load_data_ini_phi(name, ini_list, phi_list):
      rates = get_rates_ini_phi(name, ini_list, phi_list)
      df = get_df_ini_phi(rates)
      return df
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_code_ini_phi(df):
      df_code = df.groupby(['time', 'trial', 'phi'] )['rates'].apply(decode_bump).reset_index()
      df_code[['m0', 'm1', 'phase']] = pd.DataFrame(df_code['rates'].tolist(), index=df_code.index)
      df_code = df_code.drop(columns=['rates'])
      
      end_point = df_code[df_code.time==df_code.time.iloc[-1]]
      end_point = end_point.drop(columns=['time'])
      print(end_point.head())  
      return df_code, end_point  
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_precision(x):

      cmean =  (x - circmean(x, low=-np.pi, high=np.pi)) % (2* np.pi) - np.pi

      cmean[cmean > np.pi/2] -= np.pi
      cmean[cmean < -np.pi/2] += np.pi
      
      return cmean
#+end_src

#+RESULTS:

** Simul

#+begin_src ipython
  import torch.nn as nn
  def run_ini_phi(conf, name, ini_list, phi_list, **kwargs):
      start = perf_counter()

      for ini in ini_list:
          for phi in phi_list:
              model = Network('%s' % conf, '%s_ini_%d_phi_%d' % (name, ini, phi),
                              REPO_ROOT, PHI0=phi, **kwargs)

              model = nn.DataParallel(model)
              model.module.run()

      end = perf_counter()
      print("Elapsed (with compilation) = {}s".format((end - start)))
#+end_src

#+RESULTS:

#+begin_src ipython
  from joblib import Parallel, delayed
  import torch
  import os
  import warnings
  warnings.filterwarnings("ignore")

  def run_simulation(conf, name, ini, phi, device, **kwargs):
      warnings.filterwarnings("ignore")

      # torch.cuda.set_device(device)

      # REPO_ROOT = "/home/leon/models/NeuroTorch"
      model = Network('%s' % conf, '%s_ini_%d_phi_%d' % (name, ini, phi),
                      REPO_ROOT, PHI0=phi, DEVICE=device, **kwargs)

      model.run()
      # del model
      # Optionally clear this process's GPU memory
      # torch.cuda.empty_cache()
      
  def run_ini_phi_parallel(batch_size, conf, name, ini_list, phi_list, available_gpu_memory=0, device='cuda:0', **kwargs):

      print('batch size', batch_size)
      start = perf_counter()

      # Run the simulations in parallel with optimal n_jobs
      Parallel(n_jobs=batch_size)(
          delayed(run_simulation)(conf, name, ini, phi, device=device, **kwargs)
          for ini, phi in [(ini, phi) for ini in ini_list for phi in phi_list]
      )

      torch.cuda.empty_cache()
      end = perf_counter()
      print("Elapsed (with compilation) = {}s".format((end - start)))

      print("Done")
#+end_src

#+RESULTS:

#+begin_src python
  import torch.multiprocessing as mp
  from time import perf_counter
  import torch

  # Assuming Network is defined somewhere
  # from your_project import Network
  mp.set_start_method('spawn')

  def run_simulation(conf, name, ini, phi, device, gpu_queue, **kwargs):
      # Get the device ID from the queue for this process
      device_id = gpu_queue.get()
      device = 'cuda:{}'.format(device_id)

      torch.cuda.set_device(device)

      # Initialize the model with the given configuration
      model = Network('%s' % conf, '%s_ini_%d_phi_%d' % (name, ini, phi),
                      PHI0=phi, DEVICE=device, **kwargs)

      model.run()

      # Clear the process's GPU memory
      torch.cuda.empty_cache()

      # Put the device ID back into the queue for other processes to reuse
      gpu_queue.put(device_id)

  def run_ini_phi_parallel(batch_size, conf, name, ini_list, phi_list, **kwargs):
      start = perf_counter()

      # Set start method to spawn to create new CUDA contexts for each process
      mp.set_start_method('spawn', force=True)

      # Create a queue with device IDs
      gpu_queue = mp.Queue()
      for i in range(torch.cuda.device_count()):
          gpu_queue.put(i)

      # Create all combinations of ini and phi
      combinations = [(ini, phi) for ini in ini_list for phi in phi_list]

      # Create a pool of workers equal to the number of available GPUs
      pool = mp.Pool(processes=batch_size)
      
      # Start the processes
      jobs = []     
      for ini, phi in combinations:
          job = pool.apply_async(run_simulation, (conf, name, ini, phi, 'cuda', gpu_queue), kwargs)
          jobs.append(job)

      # Wait for all jobs to complete
      for job in jobs:
          job.get()

      pool.close()
      pool.join()

      end = perf_counter()
      print("Elapsed (with compilation) = {}s".format((end - start)))
      print("Done")

  # Usage example with hypothetical values:
  # run_ini_phi_parallel(batch_size=4, conf='config1', name='experiment', ini_list=[1, 2, 3], phi_list=[0.1, 0.2, 0.3])
#+end_src

#+RESULTS:
: None

#+begin_src ipython
  torch.cuda.empty_cache()
#+end_src

#+RESULTS:

* Imports

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl
#+end_src

#+RESULTS:

* Multiple Trials
** Parameters

#+begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroTorch"
  conf_name = "config_bump.yml"

  ini_list = np.arange(0, 10)
  phi_list = np.linspace(0, 315, 8)
  phi_tensor = torch.tensor(phi_list).repeat_interleave(len(ini_list))
  phi= phi_tensor.unsqueeze(1).repeat(1, 5)
  phi = phi.unsqueeze(0).repeat(1, 1, 1)
  # phi = phi.view(1, len(phi_list), len(ini_list), 2)
  print(phi.size())
  print(phi[0, :, :5])
  # phi_list = [180]
#+end_src

#+RESULTS:
#+begin_example
  torch.Size([1, 80, 5])
  tensor([[  0.,   0.,   0.,   0.,   0.],
          [  0.,   0.,   0.,   0.,   0.],
          [  0.,   0.,   0.,   0.,   0.],
          [  0.,   0.,   0.,   0.,   0.],
          [  0.,   0.,   0.,   0.,   0.],
          [  0.,   0.,   0.,   0.,   0.],
          [  0.,   0.,   0.,   0.,   0.],
          [  0.,   0.,   0.,   0.,   0.],
          [  0.,   0.,   0.,   0.,   0.],
          [  0.,   0.,   0.,   0.,   0.],
          [ 45.,  45.,  45.,  45.,  45.],
          [ 45.,  45.,  45.,  45.,  45.],
          [ 45.,  45.,  45.,  45.,  45.],
          [ 45.,  45.,  45.,  45.,  45.],
          [ 45.,  45.,  45.,  45.,  45.],
          [ 45.,  45.,  45.,  45.,  45.],
          [ 45.,  45.,  45.,  45.,  45.],
          [ 45.,  45.,  45.,  45.,  45.],
          [ 45.,  45.,  45.,  45.,  45.],
          [ 45.,  45.,  45.,  45.,  45.],
          [ 90.,  90.,  90.,  90.,  90.],
          [ 90.,  90.,  90.,  90.,  90.],
          [ 90.,  90.,  90.,  90.,  90.],
          [ 90.,  90.,  90.,  90.,  90.],
          [ 90.,  90.,  90.,  90.,  90.],
          [ 90.,  90.,  90.,  90.,  90.],
          [ 90.,  90.,  90.,  90.,  90.],
          [ 90.,  90.,  90.,  90.,  90.],
          [ 90.,  90.,  90.,  90.,  90.],
          [ 90.,  90.,  90.,  90.,  90.],
          [135., 135., 135., 135., 135.],
          [135., 135., 135., 135., 135.],
          [135., 135., 135., 135., 135.],
          [135., 135., 135., 135., 135.],
          [135., 135., 135., 135., 135.],
          [135., 135., 135., 135., 135.],
          [135., 135., 135., 135., 135.],
          [135., 135., 135., 135., 135.],
          [135., 135., 135., 135., 135.],
          [135., 135., 135., 135., 135.],
          [180., 180., 180., 180., 180.],
          [180., 180., 180., 180., 180.],
          [180., 180., 180., 180., 180.],
          [180., 180., 180., 180., 180.],
          [180., 180., 180., 180., 180.],
          [180., 180., 180., 180., 180.],
          [180., 180., 180., 180., 180.],
          [180., 180., 180., 180., 180.],
          [180., 180., 180., 180., 180.],
          [180., 180., 180., 180., 180.],
          [225., 225., 225., 225., 225.],
          [225., 225., 225., 225., 225.],
          [225., 225., 225., 225., 225.],
          [225., 225., 225., 225., 225.],
          [225., 225., 225., 225., 225.],
          [225., 225., 225., 225., 225.],
          [225., 225., 225., 225., 225.],
          [225., 225., 225., 225., 225.],
          [225., 225., 225., 225., 225.],
          [225., 225., 225., 225., 225.],
          [270., 270., 270., 270., 270.],
          [270., 270., 270., 270., 270.],
          [270., 270., 270., 270., 270.],
          [270., 270., 270., 270., 270.],
          [270., 270., 270., 270., 270.],
          [270., 270., 270., 270., 270.],
          [270., 270., 270., 270., 270.],
          [270., 270., 270., 270., 270.],
          [270., 270., 270., 270., 270.],
          [270., 270., 270., 270., 270.],
          [315., 315., 315., 315., 315.],
          [315., 315., 315., 315., 315.],
          [315., 315., 315., 315., 315.],
          [315., 315., 315., 315., 315.],
          [315., 315., 315., 315., 315.],
          [315., 315., 315., 315., 315.],
          [315., 315., 315., 315., 315.],
          [315., 315., 315., 315., 315.],
          [315., 315., 315., 315., 315.],
          [315., 315., 315., 315., 315.]], dtype=torch.float64)
#+end_example

#+begin_src ipython 
  n_sim = len(ini_list) * len(phi_list) 
  total_seconds = n_sim * 1.93
  hours = total_seconds // 3600  # number of hours
  total_seconds %= 3600  # remaining seconds after hours are accounted for

  minutes = total_seconds // 60  # number of minutes
  seconds = total_seconds % 60  # remaining seconds after minutes are accounted for
  print('n_sim', n_sim, 'Expected runtime', f"{hours}h {minutes}m {seconds}s")
#+end_src

#+RESULTS:
: n_sim 80 Expected runtime 0.0h 2.0m 34.400000000000006s

** Simulation

#+begin_src ipython
  name = 'odr_off'
  run_ini_phi(conf_name, name, ini_list, phi_list)
  # n_jobs = 1
  # run_ini_phi_parallel(n_jobs, conf_name, name, ini_list, phi_list, device='cuda:1', REC_LAST_ONLY=1)
#+end_src

#+RESULTS:
: Elapsed (with compilation) = 38.801885939901695s

#+begin_src ipython
  n_jobs = 10
  run_ini_phi_parallel(n_jobs, conf_name, name, ini_list, phi_list, device='cuda:1', REC_LAST_ONLY=0)
#+end_src

#+RESULTS:
: batch size 10
: Elapsed (with compilation) = 62.229770260863006s
: Done

#+begin_src ipython 
  name = 'odr_on'
  n_jobs = 32
  # run_ini_phi(conf_name, name, ini_list, phi_list, Ja0=[24])
  run_ini_phi_parallel(n_jobs, conf_name, name, ini_list, phi_list, device='cuda:1', Ja0=[24], Jab=[-2.5], REC_LAST_ONLY=1)
#+end_src

#+RESULTS:
: batch size 32
: Done

** Load data

#+begin_src ipython
  name = 'odr_off'
  df = load_data_ini_phi(name, ini_list, phi_list)
  df_code, end_point = get_code_ini_phi(df)
#+end_src

#+RESULTS:
: (40, 8, 1, 1000)
:    trial  phi        m0        m1     phase
: 0      0    0  5.898682  5.414098  0.151582
: 1      0    1  5.898918  5.329563 -0.764372
: 2      0    2  5.876810  5.355007 -1.728505
: 3      0    3  5.898257  5.471752 -2.309134
: 4      0    4  5.912850  5.516602  3.018613

#+begin_src ipython
  name = 'odr_on'
  df_on = load_data_ini_phi(name, ini_list, phi_list)
  df_code_on, end_point_on = get_code_ini_phi(df_on)
#+end_src

#+RESULTS:
: (40, 8, 1, 1000)
:    trial  phi        m0        m1     phase
: 0      0    0  9.056557  4.124823  0.057107
: 1      0    1  9.036468  4.217732 -1.042520
: 2      0    2  9.069246  4.382596 -1.614233
: 3      0    3  9.063930  4.311031 -2.261653
: 4      0    4  9.057012  4.266793 -3.095974

#+begin_src ipython
  fig, ax = plt.subplots(1, 3, figsize=[2.5*width, height])

  # sns.lineplot(end_point, x='Ie', y='m0', ax=ax[0], legend=False, marker='o')
  for phi in df_code.phi.unique():
      sns.lineplot(df_code, x='time', y=df_code[df_code.phi==phi]['phase']*180/np.pi, ax=ax[0], legend=False, hue='trial', lw=2, alpha=0.2)

  ax[0].set_xlabel('Time (s)')
  ax[0].set_ylabel('Phase (°)')

  for phi in df_code.phi.unique():
      sns.histplot(data=end_point, x=end_point[end_point.phi==phi]['phase']*180/np.pi, kde=False, bins='auto', stat='density', ax=ax[1])
  ax[1].set_xlabel('Time (s)')
  ax[1].set_ylabel('Phase (°)')

  # sns.histplot(data=end_point, x=end_point['phase']*180/np.pi,kde=False, bins=10, stat='density', color='b')
  # print(end_point.head())
  theta = [np.cos(end_point['phase']-np.pi/2), np.sin(end_point['phase']-np.pi/2)]
  ax[2].plot(theta[0], theta[1], 'o')
  ax[2].set_xlim([-1.5, 1.5])
  ax[2].set_ylim([-1.5, 1.5])

  ax[2].set_xlabel('$ \\xi_S$')
  ax[2].set_ylabel('$ \\xi_D$')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/dbd0cacefb9025fc62c77c548466ee0487622966.png]]

#+begin_src ipython
  end_point['accuracy'] = (end_point.phase - end_point['phi'] * np.pi / 180) % (2 * np.pi)
  end_point['precision'] = end_point.groupby(['phi'], group_keys=False)['phase'].apply(get_precision)

  end_point_on['accuracy'] = (end_point_on.phase - end_point_on['phi'] * np.pi / 180) % (2 * np.pi)
  end_point_on['precision'] = end_point_on.groupby(['phi'], group_keys=False)['phase'].apply(get_precision)
  
  print(end_point.head())
#+end_src

#+RESULTS:
:    trial  phi        m0        m1     phase  accuracy  precision
: 0      0    0  5.898682  5.414098  0.151582  0.151582   0.144388
: 1      0    1  5.898918  5.329563 -0.764372  5.501360  -0.031763
: 2      0    2  5.876810  5.355007 -1.728505  4.519773  -0.170998
: 3      0    3  5.898257  5.471752 -2.309134  3.921692   0.037029
: 4      0    4  5.912850  5.516602  3.018613  2.948800  -0.070538

#+begin_src ipython
  fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

  bins = 160
  sns.histplot(data=end_point, x=end_point['phase']*180/np.pi, legend=False, lw=2, ax=ax[0], kde=False, bins=bins, stat='density', color='b')
  sns.histplot(data=end_point_on, x=end_point_on['phase']*180/np.pi, legend=False, lw=2, ax=ax[0], kde=False, bins=bins, stat='density', color='r')
  ax[0].set_xlabel('$\phi$(°)')
  ax[0].set_ylabel('Density')
  ax[0].set_xticks([-180, -90 ,0, 90, 180], [0, 90, 180, 270, 360])

  sns.histplot(data=end_point, x=end_point['accuracy']*180/np.pi, legend=False, lw=2, ax=ax[1], kde=False, bins=bins, stat='density', color='b')
  sns.histplot(data=end_point_on, x=end_point_on['accuracy']*180/np.pi, legend=False, lw=2, ax=ax[1], kde=False, bins=bins, stat='density', color='r')
  ax[1].set_xlabel('$\phi - \phi_{stim}$ (°)')
  ax[1].set_ylabel('Density')
  ax[1].set_xticks([0, 90, 180, 270, 360])

  bins = 8
  sns.histplot(data=end_point, x=end_point['precision']*180/np.pi, legend=False, ax=ax[2], bins=bins, kde=True, stat='density', element='step', alpha=0,color = 'b')
  sns.histplot(data=end_point_on, x=end_point_on['precision']*180/np.pi, legend=False, ax=ax[2], bins=bins, kde=True, stat='density', element='step', alpha=0., color='r')
  ax[2].set_xlabel('$\phi - <\phi>_{trials}$ (°)')
  ax[2].set_ylabel('Density')
  ax[2].set_xlim([-30, 30])

  plt.show()  
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/56bde2144d435b4dbd988a112d99dba946cbbd36.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

