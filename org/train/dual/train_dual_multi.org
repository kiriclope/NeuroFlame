#+Startup: fold
#+TITLE: Training Low Rank RNNs
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session train_dual_multi :kernel torch :exports results :output-dir ./figures/multi :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython :tangle no
%load_ext autoreload
%autoreload 2
%reload_ext autoreload
%run ../../../notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython :tangle ./run_dual_multi.py
import torch
import torch.nn as nn
import torch.optim as optim

from torch.utils.data import Dataset, TensorDataset, DataLoader

REPO_ROOT = "/home/leon/models/NeuroFlame"

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

pal = sns.color_palette("tab10")
DEVICE = 'cuda:0'
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ./run_dual_multi.py
import sys
sys.path.insert(0, '../../../')

from notebooks.setup import *

import pandas as pd
import torch.nn as nn
from time import perf_counter
from scipy.stats import circmean

from src.network import Network
from src.plot_utils import plot_con
from src.decode import decode_bump, circcvl
from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

* Train

#+begin_src ipython :tangle ./run_dual_multi.py
sys.path.insert(0, '../../../src')
# import src.train
from src.train.dual.train_dpa import train_dpa
from src.train.dual.train_gng import train_gng
from src.train.dual.train_dual import train_dual
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ./run_dual_multi.py
REPO_ROOT = "/home/leon/models/NeuroFlame"
conf_name = "train_dual.yml"
DEVICE = 'cuda:0'

# seed = np.random.randint(0, 1e6)
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ./run_dual_multi.py

#+end_src

#+RESULTS:

#+begin_src ipython :tangle ./run_dual_multi.py
for ite in range(0, 10):
    seed = ite
    print('model', seed)
    train_dpa(REPO_ROOT, conf_name, seed, DEVICE)
    train_gng(REPO_ROOT, conf_name, seed, DEVICE)
    train_dual(REPO_ROOT, conf_name, seed, DEVICE)
#+end_src

#+RESULTS:
#+begin_example
model 0
750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 2, 60])
training DPA
 10% 1/10 [00:49<07:23, 49.28s/it]Epoch 1/10, Training Loss: 1.2149, Validation Loss: 0.7676
 20% 2/10 [01:37<06:28, 48.61s/it]Epoch 2/10, Training Loss: 0.2983, Validation Loss: 0.1868
 30% 3/10 [02:24<05:36, 48.03s/it]Epoch 3/10, Training Loss: 0.1671, Validation Loss: 0.1459
 30% 3/10 [03:12<07:28, 64.01s/it]Epoch 4/10, Training Loss: 0.1348, Validation Loss: 0.1370
Stopping training as loss has fallen below the threshold: 0.13482191155736262, 0.13704338691583492
Elapsed (with compilation) = 0h 3m 12s

750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 20])
labels torch.Size([1024, 2, 20])
training DRT
 10% 1/10 [00:47<07:05, 47.27s/it]Epoch 1/10, Training Loss: 0.3876, Validation Loss: 0.1022
 10% 1/10 [01:34<14:11, 94.61s/it]Epoch 2/10, Training Loss: 0.0978, Validation Loss: 0.0939
Stopping training as loss has fallen below the threshold: 0.0977920564607932, 0.09385358745731959
Elapsed (with compilation) = 0h 1m 34s

750
250
training Dual
 10% 1/10 [00:36<05:24, 36.00s/it]Epoch 1/10, Training Loss: 1.7498, Validation Loss: 1.2679
 20% 2/10 [01:11<04:45, 35.72s/it]Epoch 2/10, Training Loss: 1.1970, Validation Loss: 1.0450
 30% 3/10 [01:47<04:09, 35.63s/it]Epoch 3/10, Training Loss: 0.9755, Validation Loss: 0.9333
 40% 4/10 [02:22<03:33, 35.55s/it]Epoch 4/10, Training Loss: 0.9136, Validation Loss: 0.9198
 50% 5/10 [02:58<02:57, 35.54s/it]Epoch 5/10, Training Loss: 0.9055, Validation Loss: 0.8873
 60% 6/10 [03:33<02:21, 35.50s/it]Epoch 6/10, Training Loss: 0.9182, Validation Loss: 0.9209
 70% 7/10 [04:09<01:46, 35.56s/it]Epoch 7/10, Training Loss: 0.8757, Validation Loss: 0.8569
 80% 8/10 [04:44<01:11, 35.60s/it]Epoch 8/10, Training Loss: 0.8562, Validation Loss: 0.8394
 90% 9/10 [05:23<00:36, 36.46s/it]Epoch 9/10, Training Loss: 0.8404, Validation Loss: 0.8356
100% 10/10 [05:58<00:00, 35.90s/it]Epoch 10/10, Training Loss: 0.8345, Validation Loss: 0.8291
Elapsed (with compilation) = 0h 5m 58s

model 1
750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 2, 60])
training DPA
 10% 1/10 [00:47<07:06, 47.39s/it]Epoch 1/10, Training Loss: 1.2871, Validation Loss: 0.9757
 20% 2/10 [01:34<06:16, 47.01s/it]Epoch 2/10, Training Loss: 0.3891, Validation Loss: 0.2157
 30% 3/10 [02:21<05:28, 46.96s/it]Epoch 3/10, Training Loss: 0.1848, Validation Loss: 0.1628
 40% 4/10 [03:08<04:41, 46.97s/it]Epoch 4/10, Training Loss: 0.1553, Validation Loss: 0.1477
 40% 4/10 [03:55<05:52, 58.82s/it]Epoch 5/10, Training Loss: 0.1365, Validation Loss: 0.1449
Stopping training as loss has fallen below the threshold: 0.13645836825554186, 0.14494136092139454
Elapsed (with compilation) = 0h 3m 55s

750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 20])
labels torch.Size([1024, 2, 20])
training DRT
 10% 1/10 [00:54<08:12, 54.68s/it]Epoch 1/10, Training Loss: 0.4562, Validation Loss: 0.1117
 10% 1/10 [01:42<15:20, 102.29s/it]Epoch 2/10, Training Loss: 0.1039, Validation Loss: 0.0975
Stopping training as loss has fallen below the threshold: 0.10392370805717431, 0.09751853652116729
Elapsed (with compilation) = 0h 1m 42s

750
250
training Dual
 10% 1/10 [00:36<05:26, 36.32s/it]Epoch 1/10, Training Loss: 2.0228, Validation Loss: 1.2305
 20% 2/10 [01:11<04:47, 35.89s/it]Epoch 2/10, Training Loss: 1.0897, Validation Loss: 1.0080
 30% 3/10 [01:48<04:14, 36.33s/it]Epoch 3/10, Training Loss: 0.9647, Validation Loss: 0.9527
 40% 4/10 [02:24<03:37, 36.20s/it]Epoch 4/10, Training Loss: 0.9349, Validation Loss: 0.9164
 50% 5/10 [03:00<03:00, 36.03s/it]Epoch 5/10, Training Loss: 0.9069, Validation Loss: 0.8941
 60% 6/10 [03:38<02:26, 36.66s/it]Epoch 6/10, Training Loss: 0.8871, Validation Loss: 0.9250
 70% 7/10 [04:18<01:53, 37.76s/it]Epoch 7/10, Training Loss: 0.8775, Validation Loss: 0.8920
 80% 8/10 [04:56<01:15, 37.86s/it]Epoch 8/10, Training Loss: 0.8705, Validation Loss: 0.8896
 90% 9/10 [05:37<00:38, 38.87s/it]Epoch 9/10, Training Loss: 0.8475, Validation Loss: 0.8342
100% 10/10 [06:17<00:00, 37.79s/it]Epoch 10/10, Training Loss: 0.7550, Validation Loss: 0.6986
Elapsed (with compilation) = 0h 6m 17s

model 2
750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 2, 60])
training DPA
 10% 1/10 [00:54<08:08, 54.25s/it]Epoch 1/10, Training Loss: 1.1786, Validation Loss: 0.6825
 20% 2/10 [01:42<06:47, 50.98s/it]Epoch 2/10, Training Loss: 0.2945, Validation Loss: 0.2023
 30% 3/10 [02:30<05:46, 49.52s/it]Epoch 3/10, Training Loss: 0.1780, Validation Loss: 0.1724
 30% 3/10 [03:19<07:44, 66.35s/it]Epoch 4/10, Training Loss: 0.1497, Validation Loss: 0.1365
Stopping training as loss has fallen below the threshold: 0.14965989154118758, 0.13651449694866089
Elapsed (with compilation) = 0h 3m 19s

750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 20])
labels torch.Size([1024, 2, 20])
training DRT
 10% 1/10 [00:50<07:35, 50.58s/it]Epoch 1/10, Training Loss: 0.2724, Validation Loss: 0.1003
 10% 1/10 [01:40<15:08, 100.94s/it]Epoch 2/10, Training Loss: 0.0954, Validation Loss: 0.0920
Stopping training as loss has fallen below the threshold: 0.09535798946252236, 0.09199056501795606
Elapsed (with compilation) = 0h 1m 40s

750
250
training Dual
 10% 1/10 [00:40<06:01, 40.20s/it]Epoch 1/10, Training Loss: 1.8175, Validation Loss: 1.1347
 20% 2/10 [01:18<05:13, 39.15s/it]Epoch 2/10, Training Loss: 1.0326, Validation Loss: 0.9572
 30% 3/10 [01:56<04:30, 38.58s/it]Epoch 3/10, Training Loss: 0.9379, Validation Loss: 0.9209
 40% 4/10 [02:32<03:45, 37.58s/it]Epoch 4/10, Training Loss: 0.9266, Validation Loss: 0.9105
 50% 5/10 [03:08<03:04, 36.97s/it]Epoch 5/10, Training Loss: 0.8808, Validation Loss: 0.8704
 60% 6/10 [03:44<02:25, 36.50s/it]Epoch 6/10, Training Loss: 0.8627, Validation Loss: 0.8607
 70% 7/10 [04:21<01:50, 36.97s/it]Epoch 7/10, Training Loss: 0.8269, Validation Loss: 0.8047
 80% 8/10 [05:00<01:14, 37.35s/it]Epoch 8/10, Training Loss: 0.7102, Validation Loss: 0.6389
 90% 9/10 [05:42<00:38, 38.81s/it]Epoch 9/10, Training Loss: 0.5303, Validation Loss: 0.4965
100% 10/10 [06:22<00:00, 38.24s/it]Epoch 10/10, Training Loss: 0.4749, Validation Loss: 0.3478
Elapsed (with compilation) = 0h 6m 22s

model 3
750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 2, 60])
training DPA
 10% 1/10 [00:50<07:37, 50.80s/it]Epoch 1/10, Training Loss: 1.1958, Validation Loss: 0.6345
 20% 2/10 [01:43<06:57, 52.20s/it]Epoch 2/10, Training Loss: 0.2942, Validation Loss: 0.2037
 30% 3/10 [02:35<06:04, 52.02s/it]Epoch 3/10, Training Loss: 0.1795, Validation Loss: 0.1707
 40% 4/10 [03:23<05:00, 50.16s/it]Epoch 4/10, Training Loss: 0.1493, Validation Loss: 0.1529
 40% 4/10 [04:10<06:15, 62.65s/it]Epoch 5/10, Training Loss: 0.1382, Validation Loss: 0.1270
Stopping training as loss has fallen below the threshold: 0.13815650343894958, 0.12697128973356106
Elapsed (with compilation) = 0h 4m 10s

750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 20])
labels torch.Size([1024, 2, 20])
training DRT
 10% 1/10 [00:48<07:15, 48.40s/it]Epoch 1/10, Training Loss: 0.4315, Validation Loss: 0.1053
 10% 1/10 [01:35<14:22, 95.82s/it]Epoch 2/10, Training Loss: 0.1000, Validation Loss: 0.0957
Stopping training as loss has fallen below the threshold: 0.0999724273211681, 0.09573739018382096
Elapsed (with compilation) = 0h 1m 35s

750
250
training Dual
 10% 1/10 [00:36<05:26, 36.32s/it]Epoch 1/10, Training Loss: 2.1534, Validation Loss: 1.3482
 20% 2/10 [01:11<04:46, 35.79s/it]Epoch 2/10, Training Loss: 1.1934, Validation Loss: 1.0927
 30% 3/10 [01:47<04:09, 35.61s/it]Epoch 3/10, Training Loss: 1.0315, Validation Loss: 0.9877
 40% 4/10 [02:22<03:33, 35.56s/it]Epoch 4/10, Training Loss: 0.9234, Validation Loss: 0.9024
 50% 5/10 [02:59<02:59, 35.93s/it]Epoch 5/10, Training Loss: 0.9064, Validation Loss: 0.9193
 60% 6/10 [03:34<02:23, 35.83s/it]Epoch 6/10, Training Loss: 0.8821, Validation Loss: 0.8707
 70% 7/10 [04:10<01:47, 35.87s/it]Epoch 7/10, Training Loss: 0.8385, Validation Loss: 0.7960
 80% 8/10 [04:46<01:11, 35.83s/it]Epoch 8/10, Training Loss: 0.7412, Validation Loss: 0.6998
 90% 9/10 [05:22<00:35, 35.78s/it]Epoch 9/10, Training Loss: 0.6473, Validation Loss: 0.6327
100% 10/10 [05:59<00:00, 35.94s/it]Epoch 10/10, Training Loss: 0.5249, Validation Loss: 0.3856
Elapsed (with compilation) = 0h 5m 59s

model 4
750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 2, 60])
training DPA
 10% 1/10 [00:51<07:40, 51.18s/it]Epoch 1/10, Training Loss: 1.1917, Validation Loss: 0.6394
 20% 2/10 [01:38<06:32, 49.11s/it]Epoch 2/10, Training Loss: 0.3268, Validation Loss: 0.2204
 30% 3/10 [02:27<05:40, 48.70s/it]Epoch 3/10, Training Loss: 0.1944, Validation Loss: 0.1780
 40% 4/10 [03:17<04:55, 49.30s/it]Epoch 4/10, Training Loss: 0.1594, Validation Loss: 0.1454
 40% 4/10 [04:05<06:08, 61.34s/it]Epoch 5/10, Training Loss: 0.1398, Validation Loss: 0.1368
Stopping training as loss has fallen below the threshold: 0.13980543642089918, 0.13675006424508443
Elapsed (with compilation) = 0h 4m 5s

750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 20])
labels torch.Size([1024, 2, 20])
training DRT
 10% 1/10 [00:47<07:09, 47.68s/it]Epoch 1/10, Training Loss: 0.4034, Validation Loss: 0.1077
 10% 1/10 [01:37<14:41, 97.97s/it]Epoch 2/10, Training Loss: 0.1010, Validation Loss: 0.0956
Stopping training as loss has fallen below the threshold: 0.10103613424759644, 0.0956191748380661
Elapsed (with compilation) = 0h 1m 37s

750
250
training Dual
 10% 1/10 [00:38<05:43, 38.18s/it]Epoch 1/10, Training Loss: 1.8617, Validation Loss: 1.3629
 20% 2/10 [01:14<04:57, 37.19s/it]Epoch 2/10, Training Loss: 1.2001, Validation Loss: 1.1122
 30% 3/10 [01:49<04:14, 36.32s/it]Epoch 3/10, Training Loss: 0.9963, Validation Loss: 0.9452
 40% 4/10 [02:25<03:35, 35.98s/it]Epoch 4/10, Training Loss: 0.9263, Validation Loss: 0.9177
 50% 5/10 [03:01<02:59, 35.91s/it]Epoch 5/10, Training Loss: 0.9087, Validation Loss: 0.9265
 60% 6/10 [03:42<02:30, 37.60s/it]Epoch 6/10, Training Loss: 0.8881, Validation Loss: 0.8798
 70% 7/10 [04:23<01:56, 38.72s/it]Epoch 7/10, Training Loss: 0.8578, Validation Loss: 0.8631
 80% 8/10 [05:02<01:17, 38.98s/it]Epoch 8/10, Training Loss: 0.7892, Validation Loss: 0.7272
 90% 9/10 [05:38<00:38, 38.12s/it]Epoch 9/10, Training Loss: 0.8466, Validation Loss: 0.7870
100% 10/10 [06:18<00:00, 37.84s/it]Epoch 10/10, Training Loss: 0.7084, Validation Loss: 0.6024
Elapsed (with compilation) = 0h 6m 18s

model 5
750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 2, 60])
training DPA
 10% 1/10 [00:51<07:41, 51.30s/it]Epoch 1/10, Training Loss: 1.1715, Validation Loss: 0.5543
 20% 2/10 [01:39<06:36, 49.61s/it]Epoch 2/10, Training Loss: 0.2813, Validation Loss: 0.1997
 30% 3/10 [02:35<06:06, 52.32s/it]Epoch 3/10, Training Loss: 0.1788, Validation Loss: 0.1813
 40% 4/10 [03:23<05:04, 50.70s/it]Epoch 4/10, Training Loss: 0.1563, Validation Loss: 0.1428
 40% 4/10 [04:12<06:18, 63.16s/it]Epoch 5/10, Training Loss: 0.1417, Validation Loss: 0.1422
Stopping training as loss has fallen below the threshold: 0.14171351306140423, 0.14220506796022742
Elapsed (with compilation) = 0h 4m 12s

750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 20])
labels torch.Size([1024, 2, 20])
training DRT
 10% 1/10 [00:47<07:07, 47.46s/it]Epoch 1/10, Training Loss: 0.4511, Validation Loss: 0.1066
 10% 1/10 [01:34<14:10, 94.54s/it]Epoch 2/10, Training Loss: 0.0999, Validation Loss: 0.0962
Stopping training as loss has fallen below the threshold: 0.09986740336395226, 0.09620939762127109
Elapsed (with compilation) = 0h 1m 34s

750
250
training Dual
 10% 1/10 [00:35<05:21, 35.76s/it]Epoch 1/10, Training Loss: 1.8540, Validation Loss: 1.2233
 20% 2/10 [01:11<04:43, 35.46s/it]Epoch 2/10, Training Loss: 1.0671, Validation Loss: 1.0657
 30% 3/10 [01:46<04:08, 35.45s/it]Epoch 3/10, Training Loss: 0.9733, Validation Loss: 0.9216
 40% 4/10 [02:21<03:32, 35.46s/it]Epoch 4/10, Training Loss: 0.9082, Validation Loss: 0.9084
 50% 5/10 [02:57<02:57, 35.41s/it]Epoch 5/10, Training Loss: 0.8805, Validation Loss: 0.8652
 60% 6/10 [03:32<02:21, 35.33s/it]Epoch 6/10, Training Loss: 0.8580, Validation Loss: 0.8549
 70% 7/10 [04:07<01:46, 35.38s/it]Epoch 7/10, Training Loss: 0.8332, Validation Loss: 0.7876
 80% 8/10 [04:43<01:10, 35.45s/it]Epoch 8/10, Training Loss: 0.7156, Validation Loss: 0.7253
 90% 9/10 [05:19<00:35, 35.46s/it]Epoch 9/10, Training Loss: 0.5756, Validation Loss: 0.5131
100% 10/10 [05:55<00:00, 35.58s/it]Epoch 10/10, Training Loss: 0.4115, Validation Loss: 0.4566
Elapsed (with compilation) = 0h 5m 55s

model 6
750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 2, 60])
training DPA
 10% 1/10 [00:50<07:36, 50.67s/it]Epoch 1/10, Training Loss: 1.1835, Validation Loss: 0.6280
 20% 2/10 [01:40<06:39, 49.92s/it]Epoch 2/10, Training Loss: 0.3228, Validation Loss: 0.2042
 30% 3/10 [02:26<05:39, 48.48s/it]Epoch 3/10, Training Loss: 0.1767, Validation Loss: 0.1551
 30% 3/10 [03:17<07:41, 65.92s/it]Epoch 4/10, Training Loss: 0.1447, Validation Loss: 0.1355
Stopping training as loss has fallen below the threshold: 0.14468593379625908, 0.13553179495218323
Elapsed (with compilation) = 0h 3m 17s

750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 20])
labels torch.Size([1024, 2, 20])
training DRT
 10% 1/10 [00:53<07:58, 53.12s/it]Epoch 1/10, Training Loss: 0.3555, Validation Loss: 0.1089
 10% 1/10 [01:43<15:29, 103.26s/it]Epoch 2/10, Training Loss: 0.1000, Validation Loss: 0.0952
Stopping training as loss has fallen below the threshold: 0.10004913477370372, 0.09519333763093484
Elapsed (with compilation) = 0h 1m 43s

750
250
training Dual
 10% 1/10 [00:36<05:28, 36.47s/it]Epoch 1/10, Training Loss: 1.9150, Validation Loss: 1.2956
 20% 2/10 [01:18<05:17, 39.71s/it]Epoch 2/10, Training Loss: 1.0987, Validation Loss: 0.9697
 30% 3/10 [01:56<04:34, 39.18s/it]Epoch 3/10, Training Loss: 0.9679, Validation Loss: 0.9255
 40% 4/10 [02:35<03:54, 39.05s/it]Epoch 4/10, Training Loss: 0.9029, Validation Loss: 0.8840
 50% 5/10 [03:14<03:14, 38.95s/it]Epoch 5/10, Training Loss: 0.8847, Validation Loss: 0.8695
 60% 6/10 [03:53<02:35, 38.96s/it]Epoch 6/10, Training Loss: 0.8690, Validation Loss: 0.8597
 70% 7/10 [04:33<01:57, 39.26s/it]Epoch 7/10, Training Loss: 0.8575, Validation Loss: 0.8524
 80% 8/10 [05:14<01:19, 39.94s/it]Epoch 8/10, Training Loss: 0.8540, Validation Loss: 0.8372
 90% 9/10 [05:53<00:39, 39.64s/it]Epoch 9/10, Training Loss: 0.8267, Validation Loss: 0.8138
100% 10/10 [06:29<00:00, 38.99s/it]Epoch 10/10, Training Loss: 0.7222, Validation Loss: 0.5840
Elapsed (with compilation) = 0h 6m 29s

model 7
750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 2, 60])
training DPA
 10% 1/10 [00:47<07:08, 47.63s/it]Epoch 1/10, Training Loss: 1.2297, Validation Loss: 0.6578
 20% 2/10 [01:35<06:20, 47.56s/it]Epoch 2/10, Training Loss: 0.3158, Validation Loss: 0.2041
 30% 3/10 [02:25<05:41, 48.76s/it]Epoch 3/10, Training Loss: 0.1720, Validation Loss: 0.1586
 40% 4/10 [03:14<04:53, 48.98s/it]Epoch 4/10, Training Loss: 0.1430, Validation Loss: 0.1651
 40% 4/10 [04:02<06:04, 60.75s/it]Epoch 5/10, Training Loss: 0.1491, Validation Loss: 0.1263
Stopping training as loss has fallen below the threshold: 0.14913649398546952, 0.12625535675665228
Elapsed (with compilation) = 0h 4m 3s

750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 20])
labels torch.Size([1024, 2, 20])
training DRT
 10% 1/10 [00:48<07:18, 48.69s/it]Epoch 1/10, Training Loss: 0.4487, Validation Loss: 0.1104
 10% 1/10 [01:37<14:34, 97.14s/it]Epoch 2/10, Training Loss: 0.1000, Validation Loss: 0.0944
Stopping training as loss has fallen below the threshold: 0.1000178838865115, 0.09436115607982729
Elapsed (with compilation) = 0h 1m 37s

750
250
training Dual
 10% 1/10 [00:36<05:30, 36.72s/it]Epoch 1/10, Training Loss: 1.8430, Validation Loss: 1.3720
 20% 2/10 [01:12<04:51, 36.43s/it]Epoch 2/10, Training Loss: 1.1941, Validation Loss: 1.0365
 30% 3/10 [01:49<04:15, 36.54s/it]Epoch 3/10, Training Loss: 0.9792, Validation Loss: 0.9468
 40% 4/10 [02:26<03:39, 36.66s/it]Epoch 4/10, Training Loss: 0.9384, Validation Loss: 0.9159
 50% 5/10 [03:02<03:02, 36.42s/it]Epoch 5/10, Training Loss: 0.9038, Validation Loss: 0.9113
 60% 6/10 [03:38<02:24, 36.21s/it]Epoch 6/10, Training Loss: 0.9016, Validation Loss: 0.8994
 70% 7/10 [04:14<01:48, 36.07s/it]Epoch 7/10, Training Loss: 0.8870, Validation Loss: 0.8703
 80% 8/10 [04:49<01:11, 35.97s/it]Epoch 8/10, Training Loss: 0.8786, Validation Loss: 0.9054
 90% 9/10 [05:25<00:35, 35.95s/it]Epoch 9/10, Training Loss: 0.8791, Validation Loss: 0.8525
100% 10/10 [06:01<00:00, 36.14s/it]Epoch 10/10, Training Loss: 0.8541, Validation Loss: 0.8372
Elapsed (with compilation) = 0h 6m 1s

model 8
750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 2, 60])
training DPA
 10% 1/10 [00:47<07:09, 47.67s/it]Epoch 1/10, Training Loss: 1.2169, Validation Loss: 0.8452
 20% 2/10 [01:35<06:19, 47.49s/it]Epoch 2/10, Training Loss: 0.3414, Validation Loss: 0.2056
 30% 3/10 [02:22<05:32, 47.48s/it]Epoch 3/10, Training Loss: 0.1796, Validation Loss: 0.1563
 30% 3/10 [03:10<07:24, 63.49s/it]Epoch 4/10, Training Loss: 0.1460, Validation Loss: 0.1467
Stopping training as loss has fallen below the threshold: 0.14600354633652246, 0.14665831109372582
Elapsed (with compilation) = 0h 3m 10s

750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 20])
labels torch.Size([1024, 2, 20])
training DRT
 10% 1/10 [00:48<07:16, 48.53s/it]Epoch 1/10, Training Loss: 0.4403, Validation Loss: 0.1073
 10% 1/10 [01:36<14:31, 96.82s/it]Epoch 2/10, Training Loss: 0.0995, Validation Loss: 0.0948
Stopping training as loss has fallen below the threshold: 0.09952933126344131, 0.09479650993172715
Elapsed (with compilation) = 0h 1m 36s

750
250
training Dual
 10% 1/10 [00:35<05:21, 35.69s/it]Epoch 1/10, Training Loss: 1.8628, Validation Loss: 1.2114
 20% 2/10 [01:12<04:50, 36.37s/it]Epoch 2/10, Training Loss: 1.1476, Validation Loss: 1.0365
 30% 3/10 [01:48<04:13, 36.24s/it]Epoch 3/10, Training Loss: 0.9858, Validation Loss: 0.9342
 40% 4/10 [02:24<03:36, 36.15s/it]Epoch 4/10, Training Loss: 0.9461, Validation Loss: 0.9179
 50% 5/10 [03:00<02:59, 35.97s/it]Epoch 5/10, Training Loss: 0.9180, Validation Loss: 0.8885
 60% 6/10 [03:35<02:23, 35.82s/it]Epoch 6/10, Training Loss: 0.8925, Validation Loss: 0.9267
 70% 7/10 [04:11<01:47, 35.78s/it]Epoch 7/10, Training Loss: 0.9293, Validation Loss: 0.8608
 80% 8/10 [04:47<01:11, 35.71s/it]Epoch 8/10, Training Loss: 0.8713, Validation Loss: 0.8781
 90% 9/10 [05:22<00:35, 35.69s/it]Epoch 9/10, Training Loss: 0.8410, Validation Loss: 0.8166
100% 10/10 [05:58<00:00, 35.84s/it]Epoch 10/10, Training Loss: 0.8044, Validation Loss: 0.8224
Elapsed (with compilation) = 0h 5m 58s

model 9
750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 2, 60])
training DPA
 10% 1/10 [00:47<07:05, 47.24s/it]Epoch 1/10, Training Loss: 1.2206, Validation Loss: 0.6573
 20% 2/10 [01:34<06:17, 47.23s/it]Epoch 2/10, Training Loss: 0.3236, Validation Loss: 0.2086
 30% 3/10 [02:21<05:31, 47.34s/it]Epoch 3/10, Training Loss: 0.1790, Validation Loss: 0.1713
 30% 3/10 [03:09<07:21, 63.09s/it]Epoch 4/10, Training Loss: 0.1496, Validation Loss: 0.1359
Stopping training as loss has fallen below the threshold: 0.14963005253901848, 0.13587489745965817
Elapsed (with compilation) = 0h 3m 9s

750
250
../models/dual/last
ff_input torch.Size([1024, 605, 1000]) labels torch.Size([1024, 20])
labels torch.Size([1024, 2, 20])
training DRT
 10% 1/10 [00:47<07:06, 47.37s/it]Epoch 1/10, Training Loss: 0.4691, Validation Loss: 0.1290
 10% 1/10 [01:34<14:12, 94.70s/it]Epoch 2/10, Training Loss: 0.1114, Validation Loss: 0.1014
Stopping training as loss has fallen below the threshold: 0.11144900350616528, 0.1013538030589499
Elapsed (with compilation) = 0h 1m 34s

750
250
training Dual
 10% 1/10 [00:35<05:22, 35.78s/it]Epoch 1/10, Training Loss: 1.4183, Validation Loss: 1.0875
 20% 2/10 [01:11<04:45, 35.73s/it]Epoch 2/10, Training Loss: 0.9901, Validation Loss: 0.9522
 30% 3/10 [01:47<04:10, 35.73s/it]Epoch 3/10, Training Loss: 0.9409, Validation Loss: 0.9234
 40% 4/10 [02:22<03:34, 35.74s/it]Epoch 4/10, Training Loss: 0.8893, Validation Loss: 0.8541
 50% 5/10 [02:58<02:58, 35.72s/it]Epoch 5/10, Training Loss: 0.8067, Validation Loss: 0.7779
 60% 6/10 [03:34<02:22, 35.71s/it]Epoch 6/10, Training Loss: 0.6752, Validation Loss: 0.5888
 70% 7/10 [04:10<01:47, 35.75s/it]Epoch 7/10, Training Loss: 0.4760, Validation Loss: 0.4266
 80% 8/10 [04:45<01:11, 35.73s/it]Epoch 8/10, Training Loss: 0.3306, Validation Loss: 0.3959
 90% 9/10 [05:21<00:35, 35.73s/it]Epoch 9/10, Training Loss: 0.2958, Validation Loss: 0.2748
100% 10/10 [05:57<00:00, 35.74s/it]Epoch 10/10, Training Loss: 0.2589, Validation Loss: 0.3470
Elapsed (with compilation) = 0h 5m 57s

#+end_example

#+begin_src ipython :tangle ./run_dual_multi.py

#+end_src

#+RESULTS:
