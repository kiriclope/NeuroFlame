#+Startup: fold
#+TITLE: Training Low Rank RNNs
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session test_dual_multi :kernel torch :exports results :output-dir ./figures/multi :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython :tangle no
%load_ext autoreload
%autoreload 2
%reload_ext autoreload
%run ../../../notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
import torch
import torch.nn as nn
import torch.optim as optim
import torchmetrics
from torch.utils.data import Dataset, TensorDataset, DataLoader

REPO_ROOT = "/home/leon/models/NeuroFlame"

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

pal = sns.color_palette("tab10")
DEVICE = 'cuda:1'
#+end_src

#+RESULTS:

#+begin_src ipython
import sys
sys.path.insert(0, '../../../')

from notebooks.setup import *

import pandas as pd
import torch.nn as nn
from time import perf_counter
from scipy.stats import circmean

from src.network import Network
from src.plot_utils import plot_con
from src.decode import decode_bump, circcvl
from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

* Utils

#+begin_src ipython :tangle ../src/torch/utils.py
import pickle as pkl

def pkl_save(obj, name, path="."):
      pkl.dump(obj, open(path + "/" + name + ".pkl", "wb"))


def pkl_load(name, path="."):
      return pkl.load(open(path + "/" + name + '.pkl', "rb"))

#+end_src

#+RESULTS:

#+begin_src ipython
def add_vlines(ax=None, mouse=""):
    t_BL = [0, 1]
    t_STIM = [1 , 2]
    t_ED = [2, 3]
    t_DIST = [3 , 4]
    t_MD = [4 , 5]
    t_CUE = [5 , 5.5]
    t_RWD = [5.5, 6.0]
    t_LD = [6.0 , 7.0]
    t_TEST = [7.0, 8.0]
    t_RWD2 = [11 , 12]

    # time_periods = [t_STIM, t_DIST, t_TEST, t_CUE, t_RWD, t_RWD2]
    # colors = ["b", "b", "b", "g", "y", "y"]

    time_periods = [t_STIM, t_DIST, t_TEST, t_CUE]
    colors = ["b", "b", "b", "g"]

    if ax is None:
        for period, color in zip(time_periods, colors):
            plt.axvspan(period[0], period[1], alpha=0.1, color=color)
    else:
        for period, color in zip(time_periods, colors):
            ax.axvspan(period[0], period[1], alpha=0.1, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import sem, t

def mean_ci(data):
  # Calculate mean and SEM
  mean = np.nanmean(data, axis=0)
  serr = sem(data, axis=0, nan_policy='omit')

  # Calculate the t critical value for 95% CI
  n = np.sum(~np.isnan(data), axis=0)
  t_val = t.ppf(0.975, df=n - 1)  # 0.975 for two-tailed 95% CI

  # Calculate 95% confidence intervals
  ci = t_val * serr

  return mean, ci
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_overlap_label(readout, y, task=0, label=['pair', 'unpair'], figname='fig.svg', title='first'):
    '''
    y[0] is pairs, y[1] is samples, y[2] is task if not None
    '''

    size = y.shape[0]
    if size ==2:
        ones_slice = np.zeros(y.shape)
        y_ = np.vstack((y.copy(), ones_slice))
        task = 0
    else:
        y_ = y.copy()
        tasks = [0, 1, -1]


    fig, ax = plt.subplots(1, 3, figsize=[3*width, height], sharey=True)

    time = np.linspace(0, 10, readout.shape[1])
    colors = ['r', 'b', 'g']
    ls = ['--', '-', '-.', ':']
    label = ['AD', 'AC', 'BD', 'BC']
    mean_overlaps = []
    for k in range(2): # readout
        for j in range(2): # sample
            for i in range(2): # pair
                data = readout[(y_[0]==i) & (y_[1]==j) & (y_[2]==task), :, k]
                mean, ci = mean_ci(data)
                mean_overlaps.append(mean)
                ax[k].plot(time, mean, ls=ls[i+2*j], label=label[i+2*j], color=colors[task], alpha=1-j/4)
                ax[k].fill_between(time, mean - ci, mean + ci, color=colors[task], alpha=0.1)

        add_vlines(ax[k])
        ax[k].set_xlabel('Time (s)')

        if k==0:
            ax[k].set_ylabel('A/B Overlap (Hz)')
        elif k==1:
            ax[k].set_ylabel('GNG Overlap (Hz)')
        else:
            ax[k].set_ylabel('Readout (Hz)')

        ax[k].axhline(0, color='k', ls='--')

    mean_overlaps = np.array(mean_overlaps).reshape((2, 2, 2, -1))

    for j in range(2): # sample
        for i in range(2): # pair
            ax[-1].plot(mean_overlaps[0, j, i], mean_overlaps[1, j, i], color=colors[task], ls=ls[i+2*j], label=label[i+2*j])

    ax[-1].set_xlabel('A/B Overlap (Hz)')
    ax[-1].set_ylabel('Choice Overlap (Hz)')

    plt.legend(fontsize=10)
    plt.savefig('../figures/dual/%s' % figname, dpi=300)
    plt.show()
#+end_src

#+RESULTS:

* Simulations

#+begin_src ipython
REPO_ROOT = "/home/leon/models/NeuroFlame"
conf_name = "train_dual.yml"
DEVICE = 'cuda:1'
thresh= 5
seed = 1
#+end_src

#+RESULTS:

#+begin_src ipython
sys.path.insert(0, '../../../src')
from src.train.dual.train_dual import test_dual
#+end_src

#+RESULTS:

#+begin_src ipython
accuracies = []
readouts = []
covariances = []
labels = []

for seed in range(0, 15):
    acc_ = []
    cov_ = []
    readout_ = []
    labels_ = []
    for state in ['dpa', 'naive', 'train']:
        print(seed, state)
        with torch.no_grad():
            readout, y_labels, cov, accuracy = test_dual(REPO_ROOT, conf_name, seed, state, thresh, DEVICE)
        acc_.append(accuracy)
        cov_.append(cov)
        readout_.append(readout)
        labels_.append(y_labels)

    accuracies.append(acc_)
    readouts.append(readout_)
    covariances.append(cov_)
    labels.append(labels_)
#+end_src

#+RESULTS:
#+begin_example
0 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9374234  0.9387983  0.93698573] GoNoGo: 0.5203149318695068
0 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.7441343  0.74565476 0.7438055 ] GoNoGo: 0.5260804891586304
0 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.99260724 0.9936874  0.99277693] GoNoGo: 0.9065818190574646
1 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.8851261  0.88638014 0.8864182 ] GoNoGo: 0.5241410136222839
1 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.5000027  0.5000037  0.50000197] GoNoGo: 0.5001195669174194
1 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.99500597 0.9953146  0.9951806 ] GoNoGo: 0.8299541473388672
2 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9341389  0.93525934 0.93493557] GoNoGo: 0.461418479681015
2 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.49999958 0.4999996  0.49999967] GoNoGo: 0.500032901763916
2 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9987503 0.9987581 0.9987652] GoNoGo: 0.9056651592254639
3 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.92898786 0.9295932  0.92905825] GoNoGo: 0.49923908710479736
3 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.50001276 0.5000082  0.50001097] GoNoGo: 0.4998852610588074
3 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9821962  0.9896213  0.98281527] GoNoGo: 0.880948543548584
4 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.8815615  0.8822409  0.88133514] GoNoGo: 0.5038430690765381
4 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.5000174 0.500019  0.5000193] GoNoGo: 0.5002617835998535
4 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9958547  0.9962647  0.99600327] GoNoGo: 0.8705693483352661
5 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.87041116 0.87162    0.87019336] GoNoGo: 0.5224609375
5 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.49959582 0.5        0.49940032] GoNoGo: 0.6688634753227234
5 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9894491  0.99056995 0.989682  ] GoNoGo: 0.8456357717514038
6 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.87820786 0.8708385  0.86858034] GoNoGo: 0.5022470951080322
6 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9964605 0.5       0.9961324] GoNoGo: 0.743078887462616
6 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.98000544 0.98468184 0.9833989 ] GoNoGo: 0.8162459135055542
7 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.91047585 0.91114616 0.9101745 ] GoNoGo: 0.524433970451355
7 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.7496981  0.7497128  0.49999994] GoNoGo: 0.6549185514450073
7 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.99600935 0.997283   0.9962002 ] GoNoGo: 0.8543474078178406
8 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.92242205 0.9222703  0.9230915 ] GoNoGo: 0.5349599719047546
8 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.49999997 0.5        0.5       ] GoNoGo: 0.5000001788139343
8 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.99766636 0.9978787  0.99780166] GoNoGo: 0.8693098425865173
9 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.88314533 0.74367344 0.88650286] GoNoGo: 0.485834538936615
9 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.5077594  0.587832   0.55745864] GoNoGo: 0.5958970785140991
9 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9931414  0.99381423 0.99332416] GoNoGo: 0.8473647832870483
10 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.89172465 0.8917425  0.8921676 ] GoNoGo: 0.5341320633888245
10 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.78182817 0.5385435  0.7953768 ] GoNoGo: 0.8003989458084106
10 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9663223  0.9702254  0.96721035] GoNoGo: 0.7862358093261719
11 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.86531574 0.86705804 0.8670883 ] GoNoGo: 0.47162926197052
11 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.5002153 0.5015017 0.5002917] GoNoGo: 0.5054609775543213
11 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9944409  0.99499226 0.99444324] GoNoGo: 0.8547484874725342
12 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9015209  0.9013777  0.90180993] GoNoGo: 0.47798681259155273
12 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.99877363 0.998842   0.49999997] GoNoGo: 0.8101247549057007
12 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9984559  0.99865425 0.9985456 ] GoNoGo: 0.9635874629020691
13 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9245071 0.8937826 0.8757101] GoNoGo: 0.47274407744407654
13 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.50000966 0.50000536 0.5000418 ] GoNoGo: 0.49656105041503906
13 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9964615 0.9963932 0.9964726] GoNoGo: 0.9626781940460205
14 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9408324 0.9417577 0.9415026] GoNoGo: 0.49856624007225037
14 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.50257987 0.50200903 0.50212127] GoNoGo: 0.500018835067749
14 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9973185 0.9974394 0.9973748] GoNoGo: 0.9245874285697937
#+end_example

#+begin_src ipython
print(np.array(accuracies).shape)
acc = np.moveaxis(np.array(accuracies), 0, -1)
print(acc.shape)
#+end_src

#+RESULTS:
: (15, 3, 2, 4)
: (3, 2, 4, 15)

#+begin_src ipython
pkl_save(acc, 'acc', path="/home/leon")
#+end_src

#+RESULTS:

#+begin_src ipython
acc = pkl_load( 'acc', path="/home/leon")[..., 1:]
print(acc.shape)
#+end_src

#+RESULTS:
: (3, 2, 4, 14)

#+begin_src ipython

#+end_src


#+RESULTS:

* Performance

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height])

rd = np.random.normal(size=(acc.shape[-1])) / 10

pal = ['r', 'b', 'g']
for j in range(3):
    for i in range(3):
        acc_mean = np.mean(acc[j][0][i], -1)
        acc_sem = np.std(acc[j][0][i], axis=-1, ddof=1) / np.sqrt(len(acc[j][0][i]))

        ax[0].errorbar(i+4*j, acc_mean, yerr=acc_sem, fmt='o', color=pal[i], ecolor=pal[i], elinewidth=3, capsize=5)
        ax[0].plot(i+rd + 4*j, acc[j][0][i], 'o', alpha=0.1, color=pal[i])

# ax[0].set_xlim(-1, 4)
# ax[0].set_ylim(0.4, 1.1)

ax[0].set_ylabel('DPA Performance')
ax[0].set_xticks([1, 5, 9], ['DPA', 'Naive', 'Expert'])
ax[0].axhline(y=0.5, color='k', linestyle='--')

# ax[1].errorbar(rd, acc[0][-1], yerr=acc[1][-1], fmt='o', label='Naive',
#              color='k', ecolor='k', elinewidth=3, capsize=5)

for i in range(3):
    acc_mean = np.mean(acc[i][0][-1], -1)
    acc_sem = np.std(acc[i][0][-1], axis=-1, ddof=1) / np.sqrt(len(acc[0][-1]))

    ax[1].errorbar(i+i*0.5, acc_mean, yerr=acc_sem, fmt='o', color='k', ecolor='k', elinewidth=3, capsize=5)
    ax[1].plot(rd+i+i*0.5, acc[i][0][-1], 'ko', alpha=.1)

ax[1].set_xlim(-1, 3.5)
ax[1].set_ylim(0.4, 1.1)

ax[1].set_ylabel('GoNoGo Performance')
ax[1].set_xticks([0, 1.5, 3], ['DPA', 'Naive', 'Expert'])
ax[1].axhline(y=0.5, color='k', linestyle='--')

plt.savefig('../figures/dual/dual_perf_%d.svg' % seed, dpi=300)

plt.show()
#+end_src

#+RESULTS:
[[./figures/multi/figure_14.png]]

* Performance vs fixed points

 #+begin_src ipython
centers = pkl_load('fp_multi_auto', path="/home/leon/")# [:45]
print(centers.shape)
#+end_src

#+RESULTS:
: (10, 3, 2, 5)

#+begin_src ipython
fp = np.moveaxis(centers, 0, -1)
print(fp.shape)

theta = np.arctan2(fp[:, 1], fp[:, 0])
radius = np.sqrt(fp[:, 0]**2+ fp[:, 1]**2)
idx = np.where(np.abs(fp[:, 0])<2)
theta[idx] = np.nan
# plt.hist(theta[0, 3])
# plt.show()
print(theta.shape, radius.shape)

fp = np.stack((np.cos(theta), np.sin(theta)), axis=1)
print(fp.shape)
fp = np.nanmean(fp, -2)
#+end_src

#+RESULTS:
: (3, 2, 5, 10)
: (3, 5, 10) (3, 5, 10)
: (3, 2, 5, 10)

#+begin_src ipython
np.cos(3*np.pi/4)
#+end_src

#+RESULTS:
: -0.7071067811865475

#+begin_src ipython
def bin_loc(x, y, nbins=8):
    # Define number of bins (adjust nbins as needed)
    bins = np.linspace(np.min(x), np.max(x), nbins + 1)
    # Get bin centers for plotting:
    bin_centers = (bins[:-1] + bins[1:]) / 2

    # Digitize the x values into bins
    bin_indices = np.digitize(x, bins, right=True)

    # Compute the mean accuracy for each bin:
    mean_acc_bins = np.array([np.nanmean(y[bin_indices == i]) if np.any(bin_indices == i) else np.nan
                              for i in range(1, nbins + 1)])

    # Optionally remove bins with no data:
    valid = ~np.isnan(mean_acc_bins)

    return bin_centers[valid], mean_acc_bins[valid]
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np
import matplotlib.pyplot as plt

nbins = 3
task = 1
print(fp.shape, acc.shape)

x = np.hstack((fp[task, 1], fp[task, 1], fp[task, 1]))
y = np.hstack(acc[task, 0])[:x.shape[0]]
#idx = np.where(np.abs(fp[task, 0])>=1)

x = fp[task, 1]
y = acc[task, 0, 0]

print(x.shape, y.shape)

bin_centers, mean_acc_bins = bin_loc(x, y, nbins)

fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height])
ax[0].plot(bin_centers, mean_acc_bins, marker='o', linestyle='-')
ax[0].scatter(x, y)
ax[0].set_xlabel('y loc')
ax[0].set_ylabel('DPA Performance')

#ax[0].set_xlim([-1, 1])
ax[0].set_ylim([0.5, 1])

x = fp[task, 1]
y = acc[task, 0, -1]
bin_centers, mean_acc_bins = bin_loc(x, y, nbins)
ax[1].scatter(x, y)
ax[1].plot(bin_centers, mean_acc_bins, marker='o', linestyle='-')
ax[1].set_xlabel('y loc')
ax[1].set_ylabel('GoNoGo Performance')

# ax[1].set_xlim([-1, 1])
ax[1].set_ylim([0.5, 1])

plt.savefig('perf_yloc.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (3, 2, 10) (3, 2, 4, 9)
: (10,) (9,)
# [goto error]
#+begin_example
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
Cell In[39], line 17
     13 y = acc[task, 0, 0]
     15 print(x.shape, y.shape)
---> 17 bin_centers, mean_acc_bins = bin_loc(x, y, nbins)
     19 fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height])
     20 ax[0].plot(bin_centers, mean_acc_bins, marker='o', linestyle='-')

Cell In[38], line 11, in bin_loc(x, y, nbins)
      8 bin_indices = np.digitize(x, bins, right=True)
     10 # Compute the mean accuracy for each bin:
---> 11 mean_acc_bins = np.array([np.nanmean(y[bin_indices == i]) if np.any(bin_indices == i) else np.nan
     12                           for i in range(1, nbins + 1)])
     14 # Optionally remove bins with no data:
     15 valid = ~np.isnan(mean_acc_bins)

Cell In[38], line 11, in <listcomp>(.0)
      8 bin_indices = np.digitize(x, bins, right=True)
     10 # Compute the mean accuracy for each bin:
---> 11 mean_acc_bins = np.array([np.nanmean(y[bin_indices == i]) if np.any(bin_indices == i) else np.nan
     12                           for i in range(1, nbins + 1)])
     14 # Optionally remove bins with no data:
     15 valid = ~np.isnan(mean_acc_bins)

IndexError: boolean index did not match indexed array along dimension 0; dimension is 9 but corresponding boolean dimension is 10
#+end_example
:END:

#+begin_src ipython
from scipy.stats import pearsonr

fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height])

corr, p_value = pearsonr(fp[1, 1], acc[1, 0, 0])
ax[0].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))
ax[0].scatter(fp[1, 1], acc[1, 0, 0])
ax[0].set_ylim([0.5, 1])

corr, p_value = pearsonr(fp[1, 1], acc[1, 0, -1])
ax[1].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))
ax[1].scatter(fp[1, 1], acc[1, 0, -1])
ax[1].set_ylim([0.5, 1])

ax[0].set_xlabel('y loc')
ax[0].set_ylabel('DPA Performance')

ax[1].set_xlabel('y loc')
ax[1].set_ylabel('GoNoGo Performance')

plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/tmp/ipykernel_673301/1093610093.py in ?()
      1 from scipy.stats import pearsonr
      2
      3 fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height])
      4
----> 5 corr, p_value = pearsonr(fp[1, 1], acc[1, 0, 0])
      6 ax[0].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))
      7 ax[0].scatter(fp[1, 1], acc[1, 0, 0])
      8 ax[0].set_ylim([0.5, 1])

~/mambaforge/envs/torch/lib/python3.10/site-packages/scipy/stats/_stats_py.py in ?(x, y, alternative, method)
   4761
   4762     """
   4763     n = len(x)
   4764     if n != len(y):
-> 4765         raise ValueError('x and y must have the same length.')
   4766
   4767     if n < 2:
   4768         raise ValueError('x and y must have length at least 2.')

ValueError: x and y must have the same length.
#+end_example
[[./figures/multi/figure_20.png]]
:END:

#+begin_src ipython
from scipy.stats import pearsonr

fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height])

corr, p_value = pearsonr(fp[2, 1], np.nanmean(acc[-1, 0, :3], -2))
ax[0].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))
ax[0].scatter(fp[2, 1], np.nanmean(acc[2, 0, :3], -2))

corr, p_value = pearsonr(fp[2, 1], acc[2, 0, -1])
ax[1].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))
ax[1].scatter(fp[2, 1], acc[2, 0, -1])

ax[0].set_xlabel('y loc')
ax[0].set_ylabel('DPA Performance')

ax[1].set_xlabel('y loc')
ax[1].set_ylabel('GoNoGo Performance')

plt.show()
#+end_src

#+RESULTS:
[[./figures/multi/figure_21.png]]

* Overlaps

#+begin_src ipython
print(readout.shape, y_labels.shape)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[1], line 1
: ----> 1 print(readout.shape, y_labels.shape)
:
: NameError: name 'readout' is not defined
:END:

#+begin_src ipython
plot_overlap_label(readout, y_labels, task=0, figname='overlaps_naive_dpa.svg')
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[2], line 1
: ----> 1 plot_overlap_label(readout, y_labels, task=0, figname='overlaps_naive_dpa.svg')
:
: NameError: name 'plot_overlap_label' is not defined
:END:

#+begin_src ipython
plot_overlap_label(readout, y_labels, task=1, figname='overlaps_naive_go.svg')
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[3], line 1
: ----> 1 plot_overlap_label(readout, y_labels, task=1, figname='overlaps_naive_go.svg')
:
: NameError: name 'plot_overlap_label' is not defined
:END:

#+begin_src ipython
plot_overlap_label(readout, y_labels, task=-1, figname='overlaps_naive_nogo.svg')
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[4], line 1
: ----> 1 plot_overlap_label(readout, y_labels, task=-1, figname='overlaps_naive_nogo.svg')
:
: NameError: name 'plot_overlap_label' is not defined
:END:


#+begin_src ipython

#+end_src

#+RESULTS:

* Covariance

#+begin_src ipython
def plot_cov(cov_matrix, order=0, ax=None):

    if order==3:
        labels = ['$n_\\text{AB}$', '$n_\\text{Choice}$', 'Go', 'No Go']
    elif order==2:
        labels = ['$m_\\text{AB}$ $m_\\text{Choice}$', '$n_\\text{AB}$ $n_\\text{Choice}$', 'odor C', 'odor D']
    elif order==1:
        labels = ['$n_\\text{AB}$', '$n_\\text{Choice}$', 'A', 'B']
    elif order==0:
        labels = ['$m_\\text{AB}$', '$n_\\text{AB}$', '$m_\\text{Choice}$', '$n_\\text{Choice}$']

    num_vectors = cov_matrix.shape[0]
    mask = np.triu(np.ones_like(cov_matrix, dtype=bool))
    mask = np.ma.masked_array(cov_matrix, mask=mask)

    if ax is None:
        fig, ax = plt.subplots(figsize=(8, 6))

    # Plot the masked covariance matrix
    img = ax.imshow(mask, cmap='coolwarm', interpolation=None)
    # cbar = plt.colorbar(label='Angle (°)')
    # cbar.set_ticks([30, 90, 120])

    # Set axis labels on top and left
    ax.set_xticks(ticks=np.arange(num_vectors), labels=labels, fontsize=18)
    ax.set_yticks(ticks=np.arange(num_vectors), labels=labels, fontsize=18)

    # Invert y-axis
    ax.xaxis.set_ticks_position('top')
    ax.xaxis.set_label_position('top')

    # ax.yaxis.set_ticks_position('right')
    # ax.yaxis.set_label_position('right')
    ax.invert_yaxis()

    for i in range(num_vectors):
        for j in range(i + 1):
            ax.text(j, i, f'{cov_matrix[i, j]:.0f}', ha='center', va='center', color='black')
#+end_src

#+RESULTS:

#+begin_src ipython
cov = np.moveaxis(np.array(covariances), 0, -1)
print(cov.shape)
#+end_src

#+RESULTS:
: (3, 4, 4, 4, 10)

#+begin_src ipython
fig, ax = plt.subplots(1, 4, figsize=(4*8, 6))
plot_cov(cov[0][0].mean(-1), order=0, ax=ax[3])
plot_cov(cov[0][3].mean(-1), order=3, ax=ax[1])
plot_cov(cov[0][1].mean(-1), order=1, ax=ax[0])
plot_cov(cov[0][2].mean(-1), order=2, ax=ax[2])
plt.savefig('figures/covariances/cov_dpa.svg')
#+end_src

#+RESULTS:
[[./figures/multi/figure_29.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 4, figsize=(4*8, 6))
plot_cov(cov[1][0].mean(-1), order=0, ax=ax[3])
plot_cov(cov[1][3].mean(-1), order=3, ax=ax[1])
plot_cov(cov[1][1].mean(-1), order=1, ax=ax[0])
plot_cov(cov[1][2].mean(-1), order=2, ax=ax[2])
plt.savefig('figures/covariances/cov_dual_naive.svg')
#+end_src

#+RESULTS:
[[./figures/multi/figure_30.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 4, figsize=(4*8, 6))
plot_cov(cov[2][0].mean(-1), order=0, ax=ax[3])
plot_cov(cov[2][3].mean(-1), order=3, ax=ax[1])
plot_cov(cov[2][1].mean(-1), order=1, ax=ax[0])
plot_cov(cov[2][2].mean(-1), order=2, ax=ax[2])
plt.savefig('figures/covariances/cov_dual_train.svg')
#+end_src

#+RESULTS:
[[./figures/multi/figure_31.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=(3*8, 6))
plot_cov(cov[1][3].mean(-1), order=3, ax=ax[0])
plot_cov(cov[1][1].mean(-1), order=1, ax=ax[1])
plot_cov(cov[1][2].mean(-1), order=2, ax=ax[2])
#+end_src

#+RESULTS:
[[./figures/multi/figure_32.png]]

#+begin_src ipython
print(cov.shape)
cov_mean = np.mean(cov, -1)
cov_sem = np.std(cov, -1, ddof=1) / np.sqrt(cov.shape[-1])
print(cov_mean.shape)
#+end_src

#+RESULTS:
: (3, 4, 4, 4, 10)
: (3, 4, 4, 4)

#+begin_src ipython
confidence = 0.95
alpha = 1 - confidence
t_score = t.ppf(1 - alpha/2, df=cov.shape[-1]-1)

# Calculate confidence interval margin
cov_ci = t_score * cov_sem
#print(cov_mean[0])
#+end_src

#+RESULTS:

#+begin_src ipython
for i in [2, 3]:
    plt.errorbar(i, np.mean(cov[0][2][0][i]), yerr=cov_ci[0][2][0][i], color='k', elinewidth=3, capsize=5, fmt='o')
    plt.errorbar(i+.5, np.mean(cov[0][2][1][i]), yerr=cov_ci[0][2][1][i], color='k', elinewidth=3, capsize=5, fmt='o')

plt.ylabel('Angle (°)')
labels = ['C vs $m_\\text{AB}$ $m_\\text{Choice}$', 'C vs $n_\\text{AB}$ $n_\\text{Choice}$',
          'D vs $m_\\text{AB}$ $m_\\text{Choice}$', 'D vs $n_\\text{AB}$ $n_\\text{Choice}$']

plt.plot([2, 2.5], [75, 75], 'k--')
plt.plot([3, 3.5], [104.5, 104.5], 'k--')
plt.xticks([2, 2.5, 3, 3.5], labels, fontsize=14, rotation=45)
plt.show()
#+end_src

#+RESULTS:
[[./figures/multi/figure_35.png]]

#+begin_src ipython
x = np.linspace(-np.pi, np.pi, 100)
mc = np.cos(x)
ms = np.sin(x)
print(np.cov(ms, ms * ms))
#+end_src

#+RESULTS:
: [[5.00000000e-01 3.93283762e-19]
:  [3.93283762e-19 1.27500000e-01]]
