#+Startup: fold
#+TITLE: Training Low Rank RNNs
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session test_dual_multi :kernel torch :exports results :output-dir ./figures/multi :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython :tangle no
%load_ext autoreload
%autoreload 2
%reload_ext autoreload
%run ../../../notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
import torch
import torch.nn as nn
import torch.optim as optim
import torchmetrics
from torch.utils.data import Dataset, TensorDataset, DataLoader

REPO_ROOT = "/home/leon/models/NeuroFlame"

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

pal = sns.color_palette("tab10")
DEVICE = 'cuda:1'
#+end_src

#+RESULTS:

#+begin_src ipython
import sys
sys.path.insert(0, '../../../')

from notebooks.setup import *

import pandas as pd
import torch.nn as nn
from time import perf_counter
from scipy.stats import circmean

from src.network import Network
from src.plot_utils import plot_con
from src.decode import decode_bump, circcvl
from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Utils

#+begin_src ipython :tangle ../src/torch/utils.py
import pickle as pkl

def pkl_save(obj, name, path="."):
      pkl.dump(obj, open(path + "/" + name + ".pkl", "wb"))


def pkl_load(name, path="."):
      return pkl.load(open(path + "/" + name + '.pkl', "rb"))

#+end_src

#+RESULTS:

#+begin_src ipython
def add_vlines(ax=None, mouse=""):
    t_BL = [0, 1]
    t_STIM = [1 , 2]
    t_ED = [2, 3]
    t_DIST = [3 , 4]
    t_MD = [4 , 5]
    t_CUE = [5 , 5.5]
    t_RWD = [5.5, 6.0]
    t_LD = [6.0 , 7.0]
    t_TEST = [7.0, 8.0]
    t_RWD2 = [11 , 12]

    # time_periods = [t_STIM, t_DIST, t_TEST, t_CUE, t_RWD, t_RWD2]
    # colors = ["b", "b", "b", "g", "y", "y"]

    time_periods = [t_STIM, t_DIST, t_TEST, t_CUE]
    colors = ["b", "b", "b", "g"]

    if ax is None:
        for period, color in zip(time_periods, colors):
            plt.axvspan(period[0], period[1], alpha=0.1, color=color)
    else:
        for period, color in zip(time_periods, colors):
            ax.axvspan(period[0], period[1], alpha=0.1, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import sem, t

def mean_ci(data):
  # Calculate mean and SEM
  mean = np.nanmean(data, axis=0)
  serr = sem(data, axis=0, nan_policy='omit')

  # Calculate the t critical value for 95% CI
  n = np.sum(~np.isnan(data), axis=0)
  t_val = t.ppf(0.975, df=n - 1)  # 0.975 for two-tailed 95% CI

  # Calculate 95% confidence intervals
  ci = t_val * serr

  return mean, ci
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_overlap_label(readout, y, task=0, label=['pair', 'unpair'], figname='fig.svg', title='first'):
    '''
    y[0] is pairs, y[1] is samples, y[2] is task if not None
    '''

    size = y.shape[0]
    if size ==2:
        ones_slice = np.zeros(y.shape)
        y_ = np.vstack((y.copy(), ones_slice))
        task = 0
    else:
        y_ = y.copy()
        tasks = [0, 1, -1]


    fig, ax = plt.subplots(1, 3, figsize=[3*width, height], sharey=True)

    time = np.linspace(0, 10, readout.shape[1])
    colors = ['r', 'b', 'g']
    ls = ['--', '-', '-.', ':']
    label = ['AD', 'AC', 'BD', 'BC']
    mean_overlaps = []
    for k in range(2): # readout
        for j in range(2): # sample
            for i in range(2): # pair
                data = readout[(y_[0]==i) & (y_[1]==j) & (y_[2]==task), :, k]
                mean, ci = mean_ci(data)
                mean_overlaps.append(mean)
                ax[k].plot(time, mean, ls=ls[i+2*j], label=label[i+2*j], color=colors[task], alpha=1-j/4)
                ax[k].fill_between(time, mean - ci, mean + ci, color=colors[task], alpha=0.1)

        add_vlines(ax[k])
        ax[k].set_xlabel('Time (s)')

        if k==0:
            ax[k].set_ylabel('A/B Overlap (Hz)')
        elif k==1:
            ax[k].set_ylabel('GNG Overlap (Hz)')
        else:
            ax[k].set_ylabel('Readout (Hz)')

        ax[k].axhline(0, color='k', ls='--')

    mean_overlaps = np.array(mean_overlaps).reshape((2, 2, 2, -1))

    for j in range(2): # sample
        for i in range(2): # pair
            ax[-1].plot(mean_overlaps[0, j, i], mean_overlaps[1, j, i], color=colors[task], ls=ls[i+2*j], label=label[i+2*j])

    ax[-1].set_xlabel('A/B Overlap (Hz)')
    ax[-1].set_ylabel('Choice Overlap (Hz)')

    plt.legend(fontsize=10)
    plt.savefig('../figures/dual/%s' % figname, dpi=300)
    plt.show()
#+end_src

#+RESULTS:

* Simulations

#+begin_src ipython
kwargs = {'VAR_FF': [.25, .25]}
#+end_src

#+RESULTS:

#+begin_src ipython
REPO_ROOT = "/home/leon/models/NeuroFlame"
conf_name = "train_dual.yml"
DEVICE = 'cuda:1'
thresh= 5
seed = 1
#+end_src

#+RESULTS:

#+begin_src ipython
sys.path.insert(0, '../../../src')
from src.train.dual.train_dual import test_dual
#+end_src

#+RESULTS:


#+begin_src ipython
accuracies = []
readouts = []
covariances = []
labels = []

for seed in range(30):
    acc_ = []
    cov_ = []
    readout_ = []
    labels_ = []
    for state in ['dpa', 'naive', 'train']:
        print(seed, state)
        with torch.no_grad():
            readout, y_labels, cov, accuracy = test_dual(REPO_ROOT, conf_name, seed, state, DEVICE, **kwargs)
        acc_.append(accuracy)
        cov_.append(cov)
        readout_.append(readout)
        labels_.append(y_labels)

    accuracies.append(acc_)
    readouts.append(readout_)
    covariances.append(cov_)
    labels.append(labels_)
#+end_src

#+RESULTS:
#+begin_example
0 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9720199 0.8523503 0.8981968] GoNoGo: 0.45269766449928284
0 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.7231733 0.5003025 0.7228412] GoNoGo: 0.6658311486244202
0 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97451144 0.9724641  0.81671005] GoNoGo: 0.6942513585090637
1 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9651914  0.9333944  0.96436477] GoNoGo: 0.4114170968532562
1 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.837301   0.37197462 0.82775533] GoNoGo: 0.6020299196243286
1 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96770215 0.97395635 0.7657508 ] GoNoGo: 0.7280504703521729
2 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9695239  0.75780594 0.93319255] GoNoGo: 0.5628544688224792
2 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9598958  0.49860469 0.910549  ] GoNoGo: 0.7079517245292664
2 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9737793  0.97666717 0.93222153] GoNoGo: 0.7640541195869446
3 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9608588  0.83623236 0.5673589 ] GoNoGo: 0.5834091305732727
3 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.91404563 0.5832544  0.56715274] GoNoGo: 0.6639478802680969
3 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9754983  0.96692395 0.77296406] GoNoGo: 0.7316307425498962
4 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9681132 0.8594754 0.9660088] GoNoGo: 0.4390503466129303
4 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.94821954 0.52451485 0.9452677 ] GoNoGo: 0.6616805195808411
4 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9728066 0.9640066 0.6066355] GoNoGo: 0.7193593978881836
5 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.93064046 0.92507553 0.9281436 ] GoNoGo: 0.5559876561164856
5 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.90026593 0.8740857  0.8998764 ] GoNoGo: 0.6331362724304199
5 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96832323 0.97407556 0.9717124 ] GoNoGo: 0.6480440497398376
6 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96656746 0.74939156 0.91281205] GoNoGo: 0.6426889896392822
6 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9491816  0.64966583 0.87693465] GoNoGo: 0.7439175248146057
6 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96704197 0.9761006  0.96194273] GoNoGo: 0.7786898016929626
7 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97033775 0.9536253  0.73428005] GoNoGo: 0.635977029800415
7 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9541961 0.6911115 0.9483363] GoNoGo: 0.6346116065979004
7 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9763625 0.9634572 0.8363488] GoNoGo: 0.7103897929191589
8 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9688142  0.75904566 0.7767735 ] GoNoGo: 0.5953772664070129
8 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9535276  0.64033544 0.8387917 ] GoNoGo: 0.7064731121063232
8 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.972633   0.96448034 0.7140371 ] GoNoGo: 0.7318043112754822
9 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96820015 0.6610368  0.6743368 ] GoNoGo: 0.2937496602535248
9 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.95671946 0.5        0.7065267 ] GoNoGo: 0.7276277542114258
9 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9728643  0.9648803  0.69854385] GoNoGo: 0.7211206555366516
10 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9653436  0.60152626 0.6574524 ] GoNoGo: 0.5088169574737549
10 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9581166  0.50068474 0.7224375 ] GoNoGo: 0.7594243884086609
10 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.927635   0.9620659  0.74996364] GoNoGo: 0.5935690999031067
11 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9688061  0.9686038  0.95508295] GoNoGo: 0.47278037667274475
11 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.84733766 0.73383594 0.79915744] GoNoGo: 0.6422269940376282
11 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97428703 0.9719484  0.9438797 ] GoNoGo: 0.6959367990493774
12 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96303135 0.96211684 0.9627834 ] GoNoGo: 0.6173374652862549
12 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.94469976 0.8887952  0.88864535] GoNoGo: 0.6770827174186707
12 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97616565 0.9639733  0.64298916] GoNoGo: 0.6637209057807922
13 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97025895 0.9706286  0.9701667 ] GoNoGo: 0.5800203084945679
13 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9686458  0.75087863 0.9679312 ] GoNoGo: 0.7024478912353516
13 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9739323  0.97279763 0.9680961 ] GoNoGo: 0.7260840535163879
14 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96920705 0.96764416 0.7366842 ] GoNoGo: 0.5746060609817505
14 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.866496  0.7461038 0.8528014] GoNoGo: 0.6547021865844727
14 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97160953 0.9712706  0.8992572 ] GoNoGo: 0.7387393116950989
15 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9656446  0.5952016  0.62732846] GoNoGo: 0.38382089138031006
15 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.71867776 0.5        0.4858447 ] GoNoGo: 0.6858966946601868
15 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96501577 0.9684069  0.859861  ] GoNoGo: 0.7938629388809204
16 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9672979  0.55702126 0.6123964 ] GoNoGo: 0.609102725982666
16 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.94517195 0.50002414 0.6207735 ] GoNoGo: 0.7191570401191711
16 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97324425 0.9709638  0.78706914] GoNoGo: 0.7772181034088135
17 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96339047 0.9323894  0.9332494 ] GoNoGo: 0.4989718496799469
17 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.93452555 0.5750625  0.8414941 ] GoNoGo: 0.6954391598701477
17 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96810395 0.9630574  0.65934914] GoNoGo: 0.7426929473876953
18 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97069263 0.9360101  0.95175   ] GoNoGo: 0.5535123348236084
18 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.927203  0.5000094 0.9005867] GoNoGo: 0.6891828179359436
18 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97263396 0.9696073  0.93969285] GoNoGo: 0.6805928349494934
19 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9692198 0.9546955 0.7777456] GoNoGo: 0.4691721498966217
19 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.95702296 0.5006658  0.88593346] GoNoGo: 0.6991552710533142
19 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97357917 0.96613854 0.7180715 ] GoNoGo: 0.7126514911651611
20 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.966948   0.93552727 0.9387503 ] GoNoGo: 0.6076880693435669
20 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.727115  0.5147919 0.6983388] GoNoGo: 0.7132598161697388
20 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96792376 0.9704752  0.932002  ] GoNoGo: 0.7267165780067444
21 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97027415 0.7799478  0.97052014] GoNoGo: 0.5906422138214111
21 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9536483  0.6794575  0.94803864] GoNoGo: 0.6696606874465942
21 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9727596 0.964589  0.8591974] GoNoGo: 0.7104523181915283
22 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96678185 0.5753232  0.6843081 ] GoNoGo: 0.5026178359985352
22 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.92162967 0.48832008 0.5559291 ] GoNoGo: 0.7239274382591248
22 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9701105 0.9759695 0.8820984] GoNoGo: 0.718550980091095
23 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97120124 0.97065824 0.9683241 ] GoNoGo: 0.5681753158569336
23 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.72466093 0.72677845 0.7250652 ] GoNoGo: 0.6598532795906067
23 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97193503 0.97422194 0.75492334] GoNoGo: 0.7133038640022278
24 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9701255  0.96765137 0.942598  ] GoNoGo: 0.5671401619911194
24 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.96214396 0.9632802  0.9437959 ] GoNoGo: 0.6250223517417908
24 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97123915 0.96065223 0.6347788 ] GoNoGo: 0.7088860273361206
25 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9680703 0.5675136 0.9311797] GoNoGo: 0.48727846145629883
25 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.93388015 0.5827375  0.9054969 ] GoNoGo: 0.6883659362792969
25 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.972329   0.9672784  0.70246494] GoNoGo: 0.7049396634101868
26 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9681361 0.9680174 0.9671512] GoNoGo: 0.4840525984764099
26 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.87476045 0.500215   0.8403599 ] GoNoGo: 0.6584271192550659
26 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9729219  0.974324   0.76405656] GoNoGo: 0.727149248123169
27 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97049606 0.94350845 0.9698321 ] GoNoGo: 0.4641452431678772
27 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9412894 0.7190796 0.9224919] GoNoGo: 0.5558111667633057
27 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97187334 0.97208583 0.7983347 ] GoNoGo: 0.6979700922966003
28 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9678731 0.9561358 0.9558547] GoNoGo: 0.5049555897712708
28 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9080899  0.7236483  0.64685893] GoNoGo: 0.7056488394737244
28 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9731681  0.9687398  0.68692434] GoNoGo: 0.7500553131103516
29 dpa
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.97012967 0.9687951  0.9579433 ] GoNoGo: 0.5173481702804565
29 naive
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.960452   0.7266695  0.95265836] GoNoGo: 0.7417410016059875
29 train
Testing Dual
Elapsed (with compilation) = 0h 0m 0s
Dual accuracy: [0.9660574  0.9675936  0.64862955] GoNoGo: 0.7413902282714844
#+end_example

#+RESULTS:

#+begin_src ipython
print(np.array(accuracies).shape)
acc = np.moveaxis(np.array(accuracies), 0, -1)
print(acc.shape)
#+end_src

#+RESULTS:
: (30, 3, 2, 4)
: (3, 2, 4, 30)

#+begin_src ipython
pkl_save(acc, 'acc', path="/home/leon")
#+end_src

#+RESULTS:

#+begin_src ipython
acc = pkl_load( 'acc', path="/home/leon")[..., 1:]
print(acc.shape)
#+end_src

#+RESULTS:
: (3, 2, 4, 29)

#+begin_src ipython

#+end_src


#+RESULTS:

* Performance

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height])

rd = np.random.normal(size=(acc.shape[-1])) / 10

pal = ['r', 'b', 'g']
for j in range(3):
    for i in range(3):
        acc_mean = np.mean(acc[j][0][i], -1)
        acc_sem = np.std(acc[j][0][i], axis=-1, ddof=1) / np.sqrt(len(acc[j][0][i]))

        ax[0].errorbar(i+4*j, acc_mean, yerr=acc_sem, fmt='o', color=pal[i], ecolor=pal[i], elinewidth=3, capsize=5)
        ax[0].plot(i+rd + 4*j, acc[j][0][i], 'o', alpha=0.1, color=pal[i])

# ax[0].set_xlim(-1, 4)
# ax[0].set_ylim(0.4, 1.1)

ax[0].set_ylabel('DPA Performance')
ax[0].set_xticks([1, 5, 9], ['DPA', 'Naive', 'Expert'])
ax[0].axhline(y=0.5, color='k', linestyle='--')

# ax[1].errorbar(rd, acc[0][-1], yerr=acc[1][-1], fmt='o', label='Naive',
#              color='k', ecolor='k', elinewidth=3, capsize=5)

for i in range(3):
    acc_mean = np.mean(acc[i][0][-1], -1)
    acc_sem = np.std(acc[i][0][-1], axis=-1, ddof=1) / np.sqrt(len(acc[0][-1]))

    ax[1].errorbar(i+i*0.5, acc_mean, yerr=acc_sem, fmt='o', color='k', ecolor='k', elinewidth=3, capsize=5)
    ax[1].plot(rd+i+i*0.5, acc[i][0][-1], 'ko', alpha=.1)

ax[1].set_xlim(-1, 3.5)
ax[1].set_ylim(0.4, 1.1)

ax[1].set_ylabel('GoNoGo Performance')
ax[1].set_xticks([0, 1.5, 3], ['DPA', 'Naive', 'Expert'])
ax[1].axhline(y=0.5, color='k', linestyle='--')

plt.savefig('../figures/dual/dual_perf_%d.svg' % seed, dpi=300)

plt.show()
#+end_src

#+RESULTS:
[[./figures/multi/figure_15.png]]

* Performance vs fixed points

 #+begin_src ipython
centers = pkl_load('fp_multi_auto', path="/home/leon/")[:-1]
print(centers.shape)
#+end_src

#+RESULTS:
: (29, 3, 2, 5)

#+begin_src ipython
fp = np.moveaxis(centers, 0, -1)
print(fp.shape)

theta = np.arctan2(fp[:, 1], fp[:, 0])
radius = np.sqrt(fp[:, 0]**2+ fp[:, 1]**2)
idx = np.where(np.abs(fp[:, 0])<2)
theta[idx] = np.nan
# plt.hist(theta[0, 3])
# plt.show()
print(theta.shape, radius.shape)

fp = np.stack((np.cos(theta), np.sin(theta)), axis=1)
print(fp.shape)
fp = np.nanmean(fp, -2)
#+end_src

#+RESULTS:
: (3, 2, 5, 29)
: (3, 5, 29) (3, 5, 29)
: (3, 2, 5, 29)

#+begin_src ipython
np.cos(3*np.pi/4)
#+end_src

#+RESULTS:
: -0.7071067811865475

#+begin_src ipython
def bin_loc(x, y, nbins=8):
    # Define number of bins (adjust nbins as needed)
    bins = np.linspace(np.min(x), np.max(x), nbins+1)
    # Get bin centers for plotting:
    bin_centers = (bins[:-1] + bins[1:]) / 2

    # Digitize the x values into bins
    bin_indices = np.digitize(x, bins, right=True)
    print(bin_indices.shape)
    # Compute the mean accuracy for each bin:
    mean_acc_bins = np.array([np.nanmean(y[bin_indices == i]) if np.any(bin_indices == i) else np.nan
                              for i in range(1, nbins + 1)])

    # Optionally remove bins with no data:
    valid = ~np.isnan(mean_acc_bins)

    return bin_centers[valid], mean_acc_bins[valid]
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np

def bin_loc(x, y, nbins=8):
    bins = np.linspace(np.min(x), np.max(x), nbins + 1)
    bin_centers = (bins[:-1] + bins[1:]) / 2

    # Digitize; 0 means left of bins[0], 1..nbins are the bins
    bin_indices = np.digitize(x, bins, right=True)

    mean_acc_bins = [
        np.nanmean(y[bin_indices == i]) if np.any(bin_indices == i) else np.nan
        for i in range(1, nbins + 1)
    ]
    mean_acc_bins = np.array(mean_acc_bins)

    valid = ~np.isnan(mean_acc_bins)
    return bin_centers[valid], mean_acc_bins[valid]
#+end_src

#+RESULTS:

#+begin_src ipython
x = np.linspace(0, 1, 11)  # 0, 0.1, ..., 1.0
y = x**2
centers, means = bin_loc(x, y, nbins=5)
print(centers, means)
#+end_src

#+RESULTS:
: [0.1 0.3 0.5 0.7 0.9] [0.025 0.125 0.305 0.565 0.905]

#+begin_src ipython
def bin_loc(x, y, nbins=8):
    bins = np.linspace(np.min(x), np.max(x), nbins + 1)
    bin_centers = (bins[:-1] + bins[1:]) / 2  # length: nbins
    bin_indices = np.digitize(x, bins, right=True)  # values: 1..nbins

    # Aggregate means for each bin (1-based bin indices)
    mean_acc_bins = np.full(nbins, np.nan)
    for i in range(1, nbins + 1):
        in_bin = bin_indices == i
        if np.any(in_bin):
            mean_acc_bins[i-1] = np.nanmean(y[in_bin])

    # mask bin_centers/mean_acc_bins together
    valid = ~np.isnan(mean_acc_bins)
    return bin_centers[valid], mean_acc_bins[valid]
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np
import matplotlib.pyplot as plt

nbins = 3
task = 1
print(fp.shape, acc.shape)

x = np.hstack((fp[task, 1], fp[task, 1], fp[task, 1]))
y = np.hstack(acc[task, 0])[:x.shape[0]]
#idx = np.where(np.abs(fp[task, 0])>=1)

x = fp[task, 1]
y = acc[task, 0, 0]

print(x.shape, y.shape)

bin_centers, mean_acc_bins = bin_loc(x, y, nbins)

fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height])
ax[0].plot(bin_centers, mean_acc_bins, marker='o', linestyle='-')
ax[0].scatter(x, y)
ax[0].set_xlabel('y loc')
ax[0].set_ylabel('DPA Performance')

#ax[0].set_xlim([-1, 1])
ax[0].set_ylim([0.5, 1])

x = fp[task, 1]
y = acc[task, 0, -1]
bin_centers, mean_acc_bins = bin_loc(x, y, nbins)
ax[1].scatter(x, y)
ax[1].plot(bin_centers, mean_acc_bins, marker='o', linestyle='-')
ax[1].set_xlabel('y loc')
ax[1].set_ylabel('GoNoGo Performance')

# ax[1].set_xlim([-1, 1])
ax[1].set_ylim([0.5, 1])

plt.savefig('perf_yloc.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (3, 2, 29) (3, 2, 4, 29)
: (29,) (29,)
[[./figures/multi/figure_23.png]]
:END:

#+begin_src ipython
from scipy.stats import pearsonr

fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height])

corr, p_value = pearsonr(fp[1, 1], acc[1, 0, 0])
ax[0].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))
ax[0].scatter(fp[1, 1], acc[1, 0, 0])
ax[0].set_ylim([0.5, 1])

corr, p_value = pearsonr(fp[1, 1], acc[1, 0, -1])
ax[1].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))
ax[1].scatter(fp[1, 1], acc[1, 0, -1])
ax[1].set_ylim([0.5, 1])

ax[0].set_xlabel('y loc')
ax[0].set_ylabel('DPA Performance')

ax[1].set_xlabel('y loc')
ax[1].set_ylabel('GoNoGo Performance')

plt.show()
#+end_src

#+RESULTS:
[[./figures/multi/figure_24.png]]

#+begin_src ipython
from scipy.stats import pearsonr

fig, ax = plt.subplots(1, 2, figsize=[1.5*width, height])

corr, p_value = pearsonr(fp[2, 1], np.nanmean(acc[-1, 0, :3], -2))
ax[0].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))
ax[0].scatter(fp[2, 1], np.nanmean(acc[2, 0, :3], -2))

corr, p_value = pearsonr(fp[2, 1], acc[2, 0, -1])
ax[1].set_title("Corr: %.2f, p-value: %.3f" % (corr, p_value))
ax[1].scatter(fp[2, 1], acc[2, 0, -1])

ax[0].set_xlabel('y loc')
ax[0].set_ylabel('DPA Performance')

ax[1].set_xlabel('y loc')
ax[1].set_ylabel('GoNoGo Performance')

plt.show()
#+end_src

#+RESULTS:
[[./figures/multi/figure_25.png]]

* Overlaps

#+begin_src ipython
print(readout.shape, y_labels.shape)
#+end_src

#+RESULTS:
: (768, 101, 2) (3, 768)

#+begin_src ipython
plot_overlap_label(readout, y_labels, task=0, figname='overlaps_naive_dpa.svg')
#+end_src

#+RESULTS:
:RESULTS:
:END:

#+begin_src ipython
plot_overlap_label(readout, y_labels, task=1, figname='overlaps_naive_go.svg')
#+end_src

#+RESULTS:

#+begin_src ipython
plot_overlap_label(readout, y_labels, task=-1, figname='overlaps_naive_nogo.svg')
#+end_src

#+RESULTS:


#+begin_src ipython

#+end_src

#+RESULTS:

* Covariance

#+begin_src ipython
def plot_cov(cov_matrix, order=0, ax=None):

    if order==3:
        labels = ['$n_\\text{AB}$', '$n_\\text{Choice}$', 'Go', 'No Go']
    elif order==2:
        labels = ['$m_\\text{AB}$ $m_\\text{Choice}$', '$n_\\text{AB}$ $n_\\text{Choice}$', 'odor C', 'odor D']
    elif order==1:
        labels = ['$n_\\text{AB}$', '$n_\\text{Choice}$', 'A', 'B']
    elif order==0:
        labels = ['$m_\\text{AB}$', '$n_\\text{AB}$', '$m_\\text{Choice}$', '$n_\\text{Choice}$']

    num_vectors = cov_matrix.shape[0]
    mask = np.triu(np.ones_like(cov_matrix, dtype=bool))
    mask = np.ma.masked_array(cov_matrix, mask=mask)

    if ax is None:
        fig, ax = plt.subplots(figsize=(8, 6))

    # Plot the masked covariance matrix
    img = ax.imshow(mask, cmap='coolwarm', interpolation=None)
    # cbar = plt.colorbar(label='Angle (°)')
    # cbar.set_ticks([30, 90, 120])

    # Set axis labels on top and left
    ax.set_xticks(ticks=np.arange(num_vectors), labels=labels, fontsize=18)
    ax.set_yticks(ticks=np.arange(num_vectors), labels=labels, fontsize=18)

    # Invert y-axis
    ax.xaxis.set_ticks_position('top')
    ax.xaxis.set_label_position('top')

    # ax.yaxis.set_ticks_position('right')
    # ax.yaxis.set_label_position('right')
    ax.invert_yaxis()

    for i in range(num_vectors):
        for j in range(i + 1):
            ax.text(j, i, f'{cov_matrix[i, j]:.0f}', ha='center', va='center', color='black')
#+end_src

#+RESULTS:

#+begin_src ipython
cov = np.moveaxis(np.array(covariances), 0, -1)
print(cov.shape)
#+end_src

#+RESULTS:
: (3, 4, 4, 4, 20)

#+begin_src ipython
fig, ax = plt.subplots(1, 4, figsize=(4*8, 6))
plot_cov(cov[0][0].mean(-1), order=0, ax=ax[3])
plot_cov(cov[0][3].mean(-1), order=3, ax=ax[1])
plot_cov(cov[0][1].mean(-1), order=1, ax=ax[0])
plot_cov(cov[0][2].mean(-1), order=2, ax=ax[2])
plt.savefig('figures/covariances/cov_dpa.svg')
#+end_src

#+RESULTS:
[[./figures/multi/figure_29.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 4, figsize=(4*8, 6))
plot_cov(cov[1][0].mean(-1), order=0, ax=ax[3])
plot_cov(cov[1][3].mean(-1), order=3, ax=ax[1])
plot_cov(cov[1][1].mean(-1), order=1, ax=ax[0])
plot_cov(cov[1][2].mean(-1), order=2, ax=ax[2])
plt.savefig('figures/covariances/cov_dual_naive.svg')
#+end_src

#+RESULTS:
[[./figures/multi/figure_30.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 4, figsize=(4*8, 6))
plot_cov(cov[2][0].mean(-1), order=0, ax=ax[3])
plot_cov(cov[2][3].mean(-1), order=3, ax=ax[1])
plot_cov(cov[2][1].mean(-1), order=1, ax=ax[0])
plot_cov(cov[2][2].mean(-1), order=2, ax=ax[2])
plt.savefig('figures/covariances/cov_dual_train.svg')
#+end_src

#+RESULTS:
[[./figures/multi/figure_31.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=(3*8, 6))
plot_cov(cov[1][3].mean(-1), order=3, ax=ax[0])
plot_cov(cov[1][1].mean(-1), order=1, ax=ax[1])
plot_cov(cov[1][2].mean(-1), order=2, ax=ax[2])
#+end_src

#+RESULTS:
[[./figures/multi/figure_32.png]]

#+begin_src ipython
print(cov.shape)
cov_mean = np.mean(cov, -1)
cov_sem = np.std(cov, -1, ddof=1) / np.sqrt(cov.shape[-1])
print(cov_mean.shape)
#+end_src

#+RESULTS:
: (3, 4, 4, 4, 10)
: (3, 4, 4, 4)

#+begin_src ipython
confidence = 0.95
alpha = 1 - confidence
t_score = t.ppf(1 - alpha/2, df=cov.shape[-1]-1)

# Calculate confidence interval margin
cov_ci = t_score * cov_sem
#print(cov_mean[0])
#+end_src

#+RESULTS:

#+begin_src ipython
for i in [2, 3]:
    plt.errorbar(i, np.mean(cov[0][2][0][i]), yerr=cov_ci[0][2][0][i], color='k', elinewidth=3, capsize=5, fmt='o')
    plt.errorbar(i+.5, np.mean(cov[0][2][1][i]), yerr=cov_ci[0][2][1][i], color='k', elinewidth=3, capsize=5, fmt='o')

plt.ylabel('Angle (°)')
labels = ['C vs $m_\\text{AB}$ $m_\\text{Choice}$', 'C vs $n_\\text{AB}$ $n_\\text{Choice}$',
          'D vs $m_\\text{AB}$ $m_\\text{Choice}$', 'D vs $n_\\text{AB}$ $n_\\text{Choice}$']

plt.plot([2, 2.5], [75, 75], 'k--')
plt.plot([3, 3.5], [104.5, 104.5], 'k--')
plt.xticks([2, 2.5, 3, 3.5], labels, fontsize=14, rotation=45)
plt.show()
#+end_src

#+RESULTS:
[[./figures/multi/figure_35.png]]

#+begin_src ipython
x = np.linspace(-np.pi, np.pi, 100)
mc = np.cos(x)
ms = np.sin(x)
print(np.cov(ms, ms * ms))
#+end_src

#+RESULTS:
: [[5.00000000e-01 3.93283762e-19]
:  [3.93283762e-19 1.27500000e-01]]
