:PROPERTIES:
:GPTEL_MODEL: gpt-4o
:GPTEL_BACKEND: ChatGPT
:GPTEL_SYSTEM: You are a large language model living in Emacs and a helpful assistant. Respond concisely.
:GPTEL_BOUNDS: nil
:END:
#+STARTUP: fold
#+TITLE: ODR Serial Bias and Reference Bias
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session odr_sb :kernel torch :exports results :output-dir ./figures/odr_sb :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  from scipy.stats import binned_statistic
#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl
  import os

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

* Results
** Pref loc

#+begin_src ipython
start_idx = int((model.N_STIM_ON[2] - model.N_STEADY) / model.N_WINDOW)
end_idx = int((model.N_STIM_OFF[2] -model.N_STEADY) / model.N_WINDOW)

mean_rates = rates_tensor[:, start_idx:end_idx].mean(dim=1).cpu().detach().numpy()
angles = model.PHI0[:, 2, 0].cpu().numpy()
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np

nbins = 96

# Create linearly spaced bin edges from 0 to 360
bins = np.linspace(0, 2*np.pi, nbins + 1)

# Use numpy.histogram to get the bin counts
counts, _ = np.histogram(angles, bins=bins)
print(len(counts))
# Find the bin index for each angle
bin_indices = np.digitize(angles, bins) - 1
#+end_src

#+RESULTS:
: 96

#+begin_src ipython
from astropy.stats.circstats import circmean
#+end_src

#+RESULTS:

#+begin_src ipython
pref_locs = []

for i in range(mean_rates.shape[1]):
    normalized_rates = np.zeros_like(mean_rates[:,i], dtype=float)

    for j, rate in enumerate(mean_rates[:, i]):
        bin_index = bin_indices[j]
        if 0 <= bin_index < nbins:  # Ensure index is within valid range
            normalized_rates[j] = rate / counts[bin_index] if counts[bin_index] > 0 else 0

    pref_locs.append(circmean(angles, weights=normalized_rates, axis=0))
pref_locs = np.array(pref_locs)
print(pref_locs.shape)
#+end_src

#+RESULTS:
: (750,)

#+begin_src ipython
normalized_rates = np.zeros_like(mean_rates, dtype=float)

for i in range(mean_rates.shape[0]):
        bin_index = bin_indices[i]
        if 0 <= bin_index < nbins:  # Ensure index is within valid range
                normalized_rates[i] = mean_rates[i] / counts[bin_index] if counts[bin_index] > 0 else 0

pref_locs = []
for i in range(mean_rates.shape[1]):
        pref_locs.append(circmean(angles, weights=normalized_rates[:, i], axis=0))

pref_locs = np.array(pref_locs)
print(pref_locs.shape, normalized_rates.shape)
#+end_src

#+RESULTS:
: (750,) (832, 750)

#+begin_src ipython
print(normalized_rates.shape)
#+end_src

#+RESULTS:
: (832, 750)

#+begin_src ipython
pref_locs[pref_locs<0] += 2* np.pi
# pref_locs[pref_locs<0] += 360
plt.hist(pref_locs )
plt.xlabel('Pref Loc (°)')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_29.png]]

 #+begin_src ipython
theta = torch.linspace(
    0,
    2.0 * torch.pi,
    pref_locs.shape[-1] + 1,
    device=DEVICE,
)[:-1].cpu().numpy()

plt.scatter(theta * 180 / np.pi, pref_locs * 180 / np.pi)
plt.xlabel('Ground Truth (°)')
plt.ylabel('Pref Loc (°)')
#+end_src

#+RESULTS:
:RESULTS:
: Text(0, 0.5, 'Pref Loc (°)')
[[./figures/odr_sb/figure_30.png]]
:END:

#+begin_src ipython
idx_pref = np.argsort(pref_locs)
m0, m1, phi = decode_bump(rates[..., idx_pref], axis=-1)
#+end_src

#+RESULTS:

** Tuning
#+begin_src ipython
mean_rates = rates_tensor[:, start_idx:end_idx, idx_pref].mean(dim=1)
angles = model.PHI0[:, 2, 0]
#+end_src

#+RESULTS:

#+begin_src ipython
import torch

def calculate_osi_and_circular_variance(rates, angles):

    # Step 2: Compute the preferred angle and responses
    unique_angles = torch.unique(angles)
    angle_responses = torch.stack([mean_rates[angles == angle].mean(dim=0) for angle in unique_angles])

    R_pref, pref_indices = angle_responses.max(dim=0)
    pref_angles = unique_angles[pref_indices]

    # Step 3: Calculate the orthogonal angle
    orth_angles = (pref_angles + torch.pi / 2) % (2 * torch.pi)

    # Find closest angles in unique_angles for each orth_angle
    orth_indices = torch.argmin(torch.abs(unique_angles.unsqueeze(1) - orth_angles), dim=0)
    R_orth = angle_responses.gather(0, orth_indices.unsqueeze(0)).squeeze(0)

    # Calculate OSI
    osi = (R_pref - R_orth) / (R_pref + R_orth).clamp(min=1e-6)

    # Step 4: Calculate Circular Variance
    complex_sum = torch.sum(angle_responses * torch.exp(1j * unique_angles.unsqueeze(1)), dim=0)
    cv = 1 - torch.abs(complex_sum) / angle_responses.sum(dim=0).clamp(min=1e-6)

    return osi, cv, pref_angles

osi, circvar, pref = calculate_osi_and_circular_variance(torch.tensor(mean_rates), torch.tensor(angles))
#+end_src

#+RESULTS:

#+begin_src ipython
if IF_BIAS:
        pkl_save(osi, 'osi_bias', path="/home/leon/")
        pkl_save(circvar, 'circvar_bias', path="/home/leon/")
        pkl_save(pref, 'pref_bias', path="/home/leon/")

        osi_ = pkl_load('osi', path="/home/leon/")
        circvar_ = pkl_load('circvar', path="/home/leon/")
        pref_ = pkl_load('pref', path="/home/leon/")
else:
        pkl_save(osi, 'osi', path="/home/leon/")
        pkl_save(circvar, 'circvar', path="/home/leon/")
        pkl_save(pref, 'pref', path="/home/leon/")
#+end_src

#+RESULTS:
: saving to /home/leon//osi.pkl
: saving to /home/leon//circvar.pkl
: saving to /home/leon//pref.pkl

#+begin_src ipython
theta = torch.linspace(
    0,
    2.0 * torch.pi,
    pref.shape[-1] + 1,
    device=DEVICE,
)[:-1]

plt.plot(theta.cpu().numpy() * 180 / np.pi, circcvl(pref.cpu().numpy()- theta.cpu().numpy()) * 180 / np.pi)
if IF_BIAS:
    plt.plot(theta.cpu().numpy() * 180 / np.pi, circcvl(pref_.cpu().numpy()- theta.cpu().numpy()) * 180 / np.pi)
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_35.png]]

#+begin_src ipython
pref, indices = torch.sort(pref, descending=False)
plt.plot(pref.cpu().detach() * 180 / np.pi, circcvl(circvar[indices].cpu().detach(), windowSize=100))

if IF_BIAS:
    pref_, indices_ = torch.sort(pref_, descending=False)
    plt.plot(pref_.cpu().detach()* 180 / np.pi, circcvl(circvar_[indices_].cpu().detach(), windowSize=100))

plt.xlabel('Pref Loc (°)')
plt.ylabel('Circvar')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_36.png]]

#+begin_src ipython
if IF_BIAS:
    plt.plot(pref.cpu().numpy()-pref_.cpu().numpy())
    plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
if IF_BIAS:
    plt.scatter(pref_.cpu().numpy(), pref.cpu().numpy())
    plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])

ax[0].hist(osi.cpu().detach(), bins='auto', density=True, histtype='step')
ax[0].set_xlabel('OSI')
ax[0].set_ylabel('Density')

ax[1].hist(circvar.cpu().detach(), bins='auto', density=True, histtype='step', label='biased')
ax[1].set_xlabel('Circular Var.')
ax[1].set_ylabel('Density')

if IF_BIAS:
    ax[0].hist(osi_.cpu().detach(), bins='auto', density=True, histtype='step')
    ax[1].hist(circvar_.cpu().detach(), bins='auto', density=True, histtype='step', label='unbiased')

plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_39.png]]

 #+begin_src ipython
if IF_BIAS:
    fig, ax = plt.subplots(1, 2, figsize=[2*height, height])

    ax[0].scatter(osi_.cpu().detach(), osi.cpu().detach())
    ax[0].set_xlabel('Unbiased OSI')
    ax[0].set_ylabel('Biased OSI')

    ax[1].scatter(circvar_.cpu().detach(), circvar.cpu().detach())
    ax[1].set_xlabel('Unbiased circvar')
    ax[1].set_ylabel('Biased circvar')

    plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_neuron_tuning_curves(mean_rates, angles, neuron_indices, device='cpu'):
    # Normalize angles to [-pi, pi)
    angles = (angles ) % (2 * torch.pi) - torch.pi
    angles, indices = torch.sort(angles, descending=False)

    # Reorder the mean_rates tensor using the sorted indices
    mean_rates = mean_rates[indices]

    # Get unique angles and their inverse indices
    unique_angles, inverse_indices = torch.unique(angles, return_inverse=True)
    n_neurons = mean_rates.size(1)

    # Calculate responses per angle
    summed_responses = torch.zeros(len(unique_angles), n_neurons, device=device)
    for i, angle_idx in enumerate(inverse_indices):
        summed_responses[angle_idx] += mean_rates[i]

    # Average the responses
    angle_counts = torch.bincount(inverse_indices, minlength=len(unique_angles))
    averaged_responses = summed_responses / angle_counts.unsqueeze(1).float()

    print(unique_angles[:10])
    # Align responses to each neuron's preferred location
    aligned_responses = torch.empty_like(averaged_responses)

    for neuron_idx in range(n_neurons):
        responses = averaged_responses[:, neuron_idx]
        preferred_idx = responses.argmax()
        aligned_responses[:, neuron_idx] = torch.roll(responses, shifts=-preferred_idx.item(), dims=0)

    mean_aligned_responses = aligned_responses

    # Adjust unique angle values for consistent plotting
    unique_angles[unique_angles < 0] += 2 * torch.pi
    mean_aligned_responses[0] = mean_aligned_responses[-1]

    unique_angles, indices = torch.sort(unique_angles, descending=False)
    mean_aligned_responses = mean_aligned_responses[indices]

    return unique_angles, mean_aligned_responses

neuron_indices = np.arange(0, 10)  # example indices, not needed for average
aligned_angles, population_tuning_curve  = plot_neuron_tuning_curves(mean_rates, angles, neuron_indices, device='cuda:1')
#+end_src

#+RESULTS:
: tensor([-3.1241, -3.1067, -3.0543, -3.0369, -3.0194, -3.0020, -2.9845, -2.9671,
:         -2.9496, -2.9322], device='cuda:1')

#+begin_src ipython
plt.plot(normalized_rates[:, 5])
#+end_src

#+RESULTS:
:RESULTS:
| <matplotlib.lines.Line2D | at | 0x7f8c9ff40820> |
[[./figures/odr_sb/figure_42.png]]
:END:

#+begin_src ipython
if IF_BIAS:
        pkl_save(aligned_angles, 'aligned_angles_bias', path="/home/leon/")
        pkl_save(population_tuning_curve, 'population_tuning_curve_bias', path="/home/leon/")

        aligned_angles_ = pkl_load('aligned_angles', path="/home/leon/")
        population_tuning_curve_ = pkl_load('population_tuning_curve', path="/home/leon/")
else:
        pkl_save(aligned_angles, 'aligned_angles', path="/home/leon/")
        pkl_save(population_tuning_curve, 'population_tuning_curve', path="/home/leon/")
#+end_src

#+RESULTS:
: saving to /home/leon//aligned_angles.pkl
: saving to /home/leon//population_tuning_curve.pkl

 #+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
for i in range(10):
    i = np.random.randint(750)
    ax[0].plot(aligned_angles.cpu().numpy() * 180 / np.pi, population_tuning_curve[:, i].cpu().detach().numpy(), '-')
    if IF_BIAS:
        ax[1].plot(aligned_angles_.cpu().numpy() * 180 / np.pi, population_tuning_curve_[:, i].cpu().detach().numpy(), '-')

ax[0].set_xlabel('Preferred Location (°)')
ax[0].set_ylabel('Rate (Hz)')

ax[1].set_xlabel('Preferred Location (°)')
ax[1].set_ylabel('Rate (Hz)')

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_44.png]]

#+begin_src ipython
    plt.plot(aligned_angles.cpu().numpy() * 180 / np.pi, population_tuning_curve.mean(dim=1).cpu().detach().numpy(), '-', label='Biased')
    if IF_BIAS:
        plt.plot(aligned_angles_.cpu().numpy() * 180 / np.pi, population_tuning_curve_.mean(dim=1).cpu().detach().numpy(), '-', label='Unbiased')

    plt.xlabel('Preferred Location (°)')
    plt.ylabel('Rate (Hz)')
    plt.legend()
    plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_45.png]]

#+begin_src ipython
import torch
import numpy as np
from scipy.stats import skew

def calculate_width_and_skewness(mean_rates, angles):

    # Step 2: Unique angles and aggregate responses
    unique_angles, inverse_indices = torch.unique(angles, return_inverse=True)
    angle_responses = torch.zeros(len(unique_angles), mean_rates.size(1)).to(DEVICE)

    for i, angle_idx in enumerate(inverse_indices):
        angle_responses[angle_idx] += mean_rates[i]

    # Normalize by the count of each angle presentation
    angle_counts = torch.bincount(inverse_indices, minlength=len(unique_angles))
    angle_responses /= angle_counts.unsqueeze(1).float()

    # Initialize arrays for width and skewness
    width_estimates = torch.zeros(mean_rates.size(1)).to(DEVICE)
    skewness_estimates = torch.zeros(mean_rates.size(1)).to(DEVICE)

    # Calculate width and skewness for each neuron
    for neuron in range(mean_rates.size(1)):
        # Get responses
        responses = angle_responses[:, neuron]
        pref_idx = responses.argmax()
        pref = unique_angles[pref_idx]

        # Width estimate using FWHM
        peak_rate = torch.max(responses)
        half_max = peak_rate / 2

        # Find indices where response is greater than half max
        high_inds = torch.where(responses > half_max)[0]
        if len(high_inds) > 1:
            width_estimates[neuron] = unique_angles[high_inds[-1]] - unique_angles[high_inds[0]]

        # Skewness
        skewness_estimates[neuron] = skew(responses.cpu().detach().numpy())

    return width_estimates * 180 / torch.pi, skewness_estimates

tuning_width, skewness = calculate_width_and_skewness(mean_rates, angles)
#+end_src

#+RESULTS:

#+begin_src ipython
import numpy as np

def compute_angular_skewness(mean_rates, angles):
    """
    Compute the skewness of tuning curves for given mean firing rates and angles.

    Parameters:
    - mean_rates: a list or array of mean firing rates for each angle.
    - angles: a list or array of angles in radians.

    Returns:
    - skewness: the computed skewness of the tuning curve.
    """
    # Convert angles to complex representation on the unit circle
    z = np.exp(1j * angles)

    # Compute the weighted mean direction
    R_total = np.sum(mean_rates)
    z_bar = np.sum(mean_rates * z) / R_total

    # Compute angular deviations
    delta_theta = np.angle(z * np.conj(z_bar))

    # Calculate weighted skewness
    numerator = np.sum(mean_rates * delta_theta**3)
    denominator = (R_total * (np.sum(mean_rates * delta_theta**2)))**1.5

    skewness = numerator / denominator if denominator != 0 else np.nan

    return skewness

# Example usage
# skewness = compute_angular_skewness(mean_rates.cpu().detach().numpy(), angles.cpu().detach().numpy())

#+end_src

#+RESULTS:

#+begin_src ipython
import ineqpy
#+end_src

#+RESULTS:

#+begin_src ipython
import torch
import numpy as np
from scipy.optimize import curve_fit

def gaussian(x, mu, sigma, amplitude):
    return amplitude * np.exp(-0.5 * ((x - mu) / sigma) ** 2)

def fit_gaussian_and_estimate_params(mean_rates, angles):
    # Rates is (N_BATCH, N_NEURONS, N_TIME)
    unique_angles, inverse_indices = np.unique(angles, return_inverse=True)
    angle_responses = np.zeros((len(unique_angles), mean_rates.shape[1]))

    for i, angle_idx in enumerate(inverse_indices):
        angle_responses[angle_idx] += mean_rates[i]

    # angle_counts = np.bincount(inverse_indices)
    # angle_responses /= angle_counts[:, None]

    width_estimates = np.zeros(mean_rates.shape[1])
    skewness_estimates = np.zeros(mean_rates.shape[1])

    # Fit Gaussian and calculate properties
    for neuron in range(mean_rates.shape[1]):
        responses = angle_responses[:, neuron]
        pref_idx = responses.argmax()
        pref = unique_angles[pref_idx]

        # Initial guess for Gaussian parameters
        initial_guess = [unique_angles[np.argmax(responses)], 1.0, responses.max()]

        # Fit Gaussian
        try:
            popt, _ = curve_fit(gaussian, unique_angles, responses, p0=initial_guess)
            mu, sigma, amplitude = popt

            # Save the width and inferred skewness
            width_estimates[neuron] = sigma

            # Skewness estimate can be derived from response distribution but Gaussian itself doesn't model skewness
            residuals = responses - gaussian(unique_angles, *popt)
            # skewness_estimates[neuron] = skew(residuals)
            # skewness_estimates[neuron] = skew(responses)
            # skewness_estimates[neuron] = compute_angular_skewness(responses, angles)
            ang = unique_angles - pref
            ang[ang>np.pi] -= 2 * np.pi
            ang[ang<-np.pi] += 2 * np.pi
            skewness_estimates[neuron] = ineqpy.statistics.skew(ang, responses)

        except RuntimeError:
            # Handle case where fit fails
            width_estimates[neuron] = np.nan
            skewness_estimates[neuron] = np.nan

    return width_estimates * 180 / np.pi, skewness_estimates

# Example usage

# tuning_width, skewness = fit_gaussian_and_estimate_params(mean_rates.cpu().detach().numpy(), angles.cpu().numpy())
tuning_width, skewness = fit_gaussian_and_estimate_params(normalized_rates, angles.cpu().numpy())
#+end_src

#+RESULTS:

#+begin_src ipython

#+end_src

#+RESULTS:

#+begin_src ipython
if IF_BIAS:
        pkl_save(tuning_width, 'tuning_width_bias', path="/home/leon/")
        pkl_save(skewness, 'skewness_bias', path="/home/leon/")

        tuning_width_ = pkl_load('tuning_width', path="/home/leon/")
        skewness_ = pkl_load('skewness', path="/home/leon/")
else:
        pkl_save(tuning_width, 'tuning_width', path="/home/leon/")
        pkl_save(skewness, 'skewness', path="/home/leon/")
#+end_src

#+RESULTS:
: saving to /home/leon//tuning_width.pkl
: saving to /home/leon//skewness.pkl

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])

ax[0].hist(tuning_width, bins='auto', density=True, histtype='step')
ax[0].set_xlabel('Tuning Width')
ax[0].set_ylabel('Density')

ax[1].hist(skewness, bins='auto', density=True, histtype='step', label='biased')
ax[1].set_xlabel('Skewness')
ax[1].set_ylabel('Density')

if IF_BIAS:
    ax[0].hist(tuning_width_, bins='auto', density=True, histtype='step')
    ax[1].hist(skewness_, bins='auto', density=True, histtype='step', label='unbiased')

plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_52.png]]

#+begin_src ipython
pref, indices = torch.sort(pref, descending=False)
plt.plot(pref.cpu().detach() * 180 / np.pi, skewness[indices.cpu().numpy()])
# plt.plot(pref.cpu().detach()* 180 / np.pi, circcvl(skewness[indices.cpu().numpy()], windowSize=10))


if IF_BIAS:
    pref_, indices_ = torch.sort(pref_, descending=False)
    plt.plot(pref_.cpu().detach() * 180 / np.pi, skewness_[indices.cpu().numpy()])
    # plt.plot(pref_.cpu().detach()* 180 / np.pi, circcvl(skewness_[indices_.cpu().numpy()], windowSize=10))

plt.xlabel('Pref Loc (°)')
plt.ylabel('Skewness')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_53.png]]

 #+begin_src ipython
if IF_BIAS:
    fig, ax = plt.subplots(1, 2, figsize=[2*height, height])

    ax[0].scatter(tuning_width_, tuning_width)
    ax[0].set_xlabel('Unbiased Tuning Width')
    ax[0].set_ylabel('Biased Tuning Width')

    ax[1].scatter(skewness_, skewness)
    ax[1].set_xlabel('Unbiased Skew')
    ax[1].set_ylabel('Biased Skew')

    plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython

#+end_src

#+RESULTS:

#+begin_src ipython
if IF_BIAS:
        pkl_save(aligned_angles, 'aligned_angles_bias', path="/home/leon/")
        pkl_save(population_tuning_curve, 'population_tuning_curve_bias', path="/home/leon/")

        aligned_angles_ = pkl_load('aligned_angles', path="/home/leon/")
        population_tuning_curve_ = pkl_load('population_tuning_curve', path="/home/leon/")
else:
        pkl_save(aligned_angles, 'aligned_angles', path="/home/leon/")
        pkl_save(population_tuning_curve, 'population_tuning_curve', path="/home/leon/")
#+end_src

#+RESULTS:
: saving to /home/leon//aligned_angles.pkl
: saving to /home/leon//population_tuning_curve.pkl

** errors

#+begin_src ipython
# reference = 180 - reference
target_loc = PHI0[:, -1]

rel_loc = (PHI0[:, 0] - target_loc) * np.pi / 180.0
rel_loc = (rel_loc + np.pi) % (2 * np.pi) - np.pi
rel_loc *= 180 / np.pi

ref_loc = (reference - PHI0[:, -1]) * np.pi / 180.0
ref_loc = (ref_loc + np.pi) % (2 * np.pi) - np.pi
ref_loc *= 180 / np.pi

window_size = int((model.N_STIM_OFF[-1]-model.N_STEADY) / model.N_WINDOW)
# errors = phi - phi[:, window_size][:, np.newaxis]
errors = (phi - target_loc * np.pi / 180.0)
errors = (errors + np.pi) % (2 * np.pi) - np.pi
errors *= 180 / np.pi

window_size = int((model.N_STIM_OFF[0]-model.N_STEADY) / model.N_WINDOW)
errors2 = ((phi - PHI0[:, 0] * np.pi / 180.0))
# errors2 = phi - phi[:, window_size][:, np.newaxis]
errors2 = (errors2 + np.pi) % (2 * np.pi) - np.pi
errors2 *= 180 / np.pi

print(errors.shape, target_loc.shape, rel_loc.shape, ref_loc.shape)
#+end_src

#+RESULTS:
: (832, 226) (832, 1) (832, 1) (832, 1)

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].plot(np.linspace(0, model.DURATION, errors.shape[-1]), errors2[:32].T)
add_vlines(model, ax[0])
# ax[0].set_xlim([2.5, 4.5])
ax[0].set_xlabel('t')
ax[0].set_ylabel('prev. error (°)')

ax[1].plot(np.linspace(0, model.DURATION, errors.shape[-1]), errors[:32].T)
add_vlines(model, ax[1])
ax[1].set_xlabel('t')
ax[1].set_ylabel('curr. error (°)')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_58.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.75*width, height])
ax[0].hist(rel_loc[:, 0], bins='auto')
ax[0].set_xlabel('Rel. Location (°)')

ax[1].hist(errors2[:, int((model.N_STIM_ON[1]-model.N_STEADY)/model.N_WINDOW)], bins='auto')
ax[1].set_xlabel('Prev. Errors (°)')

ax[2].hist(errors[:, -1], bins=64)
ax[2].set_xlabel('Curr. Errors (°)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_59.png]]

#+begin_src ipython
mask = np.abs(errors) <= 25
print(mask.shape)

errors = np.where(mask, errors, np.nan)[:, -1]
print(errors.shape)
rel_loc = rel_loc[~np.isnan(errors)]
ref_loc = ref_loc[~np.isnan(errors)]
target_loc = target_loc[:, -1][~np.isnan(errors), np.newaxis]
errors = errors[~np.isnan(errors), np.newaxis]
# errors = errors[mask]
print(errors.shape, target_loc.shape, rel_loc.shape, ref_loc.shape)
#+end_src

#+RESULTS:
: (832, 226)
: (832,)
: (832, 1) (832, 1) (832, 1) (832, 1)

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.75*width, height])
ax[0].hist(rel_loc[:, 0], bins='auto')
ax[0].set_xlabel('Rel. Location (°)')

ax[1].hist(errors2[:, int((model.N_STIM_ON[1]-model.N_STEADY)/model.N_WINDOW)], bins='auto')
ax[1].set_xlabel('Prev. Errors (°)')

ax[2].hist(errors[:, -1], bins='auto')
ax[2].set_xlabel('Curr. Errors (°)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_61.png]]

** biases

#+begin_src ipython
data = pd.DataFrame({'target_loc': target_loc[:, -1], 'rel_loc': rel_loc[:, -1], 'errors': errors[:, -1], 'ref_loc': ref_loc[:, -1]})

if IF_BIAS:
    df_naive = pkl_load('df_naive_%d' % seed, path="./figures/odr")
else:
    df_naive = data
#+end_src

#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[3*width, height])

n_bins=16
ax[0].plot(df_naive['target_loc'], df_naive['errors'], 'o', alpha=.1)
ax[0].set_xlabel('Target Loc. (°)')
ax[0].set_ylabel('Error (°)')

stt = binned_statistic(df_naive['target_loc'], df_naive['errors'], statistic='mean', bins=n_bins, range=[0, 360])
dstt = np.mean(np.diff(stt.bin_edges))
ax[0].plot(stt.bin_edges[:-1]+dstt/2,stt.statistic,'r')

ax[0].axhline(color='k', linestyle=":")

ax[1].plot(rel_loc[:, 0], errors[:,-1], 'bo', alpha=.1)
ax[1].set_xlabel('Rel. Loc. (°)')
ax[1].set_ylabel('Error (°)')

stt = binned_statistic(rel_loc[:, 0], errors[:, -1], statistic='mean', bins=n_bins, range=[-180, 180])
dstt = np.mean(np.diff(stt.bin_edges))
ax[1].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')

ax[2].plot(ref_loc[:, 0], errors[:,-1], 'bo', alpha=.1)
ax[2].set_xlabel('Ref. Loc. (°)')
ax[2].set_ylabel('Error (°)')

stt = binned_statistic(ref_loc[:, 0], errors[:, -1], statistic='mean', bins=n_bins, range=[-180, 180])
dstt = np.mean(np.diff(stt.bin_edges))
ax[2].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_63.png]]

#+begin_src ipython
n_bins = 16
angle_min = 0
angle_max = 360

bin_edges = np.linspace(angle_min, angle_max, n_bins + 1)
data['bin_target'] = pd.cut(data['target_loc'], bins=bin_edges, include_lowest=True)

mean_errors_per_bin = data.groupby('bin_target')['errors'].mean()
data['adjusted_errors'] = data.apply(
    lambda row: row['errors'] - mean_errors_per_bin.loc[row['bin_target']],
    axis=1
)

if IF_BIAS:
   df_naive['bin_target'] = pd.cut(df_naive['target_loc'], bins=bin_edges, include_lowest=True)
   mean_errors_per_bin = df_naive.groupby('bin_target')['errors'].mean()

   data['errors_naive'] = data.apply(
      lambda row: row['errors'] - mean_errors_per_bin.loc[row['bin_target']],
      axis=1
   )


bin_target = data.groupby('bin_target')['adjusted_errors'].agg(['mean', 'sem']).reset_index()
edges = bin_target['bin_target'].cat.categories
target_centers = (edges.left + edges.right) / 2

data['bin_rel'] = pd.cut(data['rel_loc'], bins=n_bins)
bin_rel = data.groupby('bin_rel')['adjusted_errors'].agg(['mean', 'sem']).reset_index()

edges = bin_rel['bin_rel'].cat.categories
centers = (edges.left + edges.right) / 2

data['bin_ref'] = pd.cut(data['ref_loc'], bins=n_bins)

if IF_BIAS:
   bin_ref = data.groupby('bin_ref')['errors_naive'].agg(['mean', 'sem']).reset_index()
else:
   bin_ref = data.groupby('bin_ref')['adjusted_errors'].agg(['mean', 'sem']).reset_index()

ref_edges = bin_ref['bin_ref'].cat.categories
ref_centers = (ref_edges.left + ref_edges.right) / 2
#+end_src

#+RESULTS:

 #+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[3*width, height])
ax[0].plot(centers, bin_target['mean'], 'b')
ax[0].fill_between(centers,
                   bin_target['mean'] - bin_target['sem'],
                   bin_target['mean'] + bin_target['sem'],
                   color='b', alpha=0.2)

ax[0].axhline(color='k', linestyle=":")
ax[0].set_xlabel('Target Loc. (°)')
ax[0].set_ylabel('Corrected Error (°)')

ax[1].plot(centers, bin_rel['mean'], 'b')
ax[1].fill_between(centers,
                bin_rel['mean'] - bin_rel['sem'],
                bin_rel['mean'] + bin_rel['sem'],
                color='b', alpha=0.2)

ax[1].axhline(color='k', linestyle=":")
ax[1].set_xlabel('Rel. Loc. (°)')
ax[1].set_ylabel('Corrected Error (°)')

ax[2].plot(ref_centers, bin_ref['mean'], 'b')
ax[2].fill_between(ref_centers,
                bin_ref['mean'] - bin_ref['sem'],
                bin_ref['mean'] + bin_ref['sem'],
                color='b', alpha=0.2)

ax[2].axhline(color='k', linestyle=":")
ax[2].set_xlabel('Ref. Loc. (°)')
ax[2].set_ylabel('Corrected Error (°)')

if IF_BIAS:
    plt.savefig('./figures/odr/odr_biases_train.svg', dpi=300)
else:
    plt.savefig('./figures/odr/odr_biases_naive.svg', dpi=300)

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_65.png]]

#+begin_src ipython
if IF_BIAS==0:
   pkl_save(data, 'df_naive_%d' %seed, path="./figures/odr")
#+end_src

#+RESULTS:
: saving to ./figures/odr/df_naive_2.pkl

#+begin_src ipython

#+end_src

#+RESULTS:

** Landscape

#+begin_src ipython
sys.path.insert(0, '/home/leon/dual_task/dual_data/')
from src.attractor.landscape import EnergyLandscape
#+end_src

#+RESULTS:

#+begin_src ipython
energy = EnergyLandscape()
print(phi.shape)
#+end_src

#+RESULTS:
: (832, 226)

#+begin_src ipython
num_bins = 250
bins = np.linspace(0, 2 * np.pi, num_bins, endpoint=False)
landscape = energy.fit(phi, bins)
print(landscape.shape)
#+end_src

#+RESULTS:
: (250,)

#+begin_src ipython
plt.plot(np.linspace(0, 360, landscape.shape[0]), landscape)
plt.xlabel('Pref Loc (°)')
plt.ylabel('Energy')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_71.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
