#+STARTUP: fold
#+TITLE: Training RNNs on ODR
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session odr :kernel torch  :exports results :output-dir ./figures/odr :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run ../../../notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'

REPO_ROOT = "/home/leon/models/NeuroFlame"
pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  # import torchmetrics
  import torch.nn.functional as F
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../../../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl, decode_bump_torch
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

* Helpers
** plots

#+begin_src ipython
def add_vlines(model, ax=None):

    if ax is None:
        for i in range(len(model.T_STIM_ON)):
            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)
    else:
        for i in range(len(model.T_STIM_ON)):
            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)

#+end_src

#+RESULTS:

#+begin_src ipython
def plot_rates_selec(rates, idx=0, thresh=0.5, figname='fig.svg'):
        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
        r_max = thresh * np.max(rates[idx])

        idx = np.random.randint(0, 96)
        ax[0].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[0].set_ylabel('Neuron #')
        ax[0].set_xlabel('Step')

        idx = np.random.randint(0, 96)
        ax[1].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[1].set_ylabel('Neuron #')
        ax[1].set_xlabel('Step')
        # ax[1].set_ylim([745, 755])
        # plt.savefig(figname, dpi=300)
        plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_m0_m1_phi(model, rates, idx, figname='fig.svg'):

      m0, m1, phi = decode_bump(rates, axis=-1)
      # m0, m1, phi = get_fourier_moments(rates, axis=-1)
      fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

      xtime = np.linspace(0, model.DURATION, m0.shape[-1])
      idx = np.random.randint(0, 96, 16)

      ax[0].plot(xtime, m0[idx].T)
      #ax[0].set_ylim([0, 360])
      #ax[0].set_yticks([0, 90, 180, 270, 360])
      ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
      ax[0].set_xlabel('Time (s)')
      add_vlines(model, ax[0])

      ax[1].plot(xtime, m1[idx].T)
      # ax[1].set_ylim([0, 360])
      # ax[1].set_yticks([0, 90, 180, 270, 360])
      ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
      ax[1].set_xlabel('Time (s)')
      add_vlines(model, ax[1])

      ax[2].plot(xtime, phi[idx].T * 180 / np.pi, alpha=.5)
      ax[2].set_ylim([0, 360])
      ax[2].set_yticks([0, 90, 180, 270, 360])
      ax[2].set_ylabel('Phase (°)')
      ax[2].set_xlabel('Time (s)')
      add_vlines(model, ax[2])

      plt.savefig(figname, dpi=300)
      plt.show()
    #+end_src

#+RESULTS:

** Data Split

#+begin_src ipython
  from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

  def split_data(X, Y, train_perc=0.8, batch_size=32, shuffle=True):

      # if shuffle:
      #     X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
      #                                                         train_size=train_perc,
      #                                                         stratify=Y[:, 0].cpu().numpy(),
      #                                                         shuffle=True)
      # else:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=None,
                                                          shuffle=False)

      plt.hist(Y_train[Y_train!=-999].cpu() * 180 / np.pi, bins=15, label='train')
      plt.hist(Y_test[Y_test!=-999].cpu() * 180 / np.pi, bins=15, label='test')
      plt.xlabel('Target Loc. (°)')
      plt.ylabel('Count')
      plt.show()

      print(X_train.shape, X_test.shape)
      print(Y_train.shape, Y_test.shape)

      train_dataset = TensorDataset(X_train, Y_train)
      val_dataset = TensorDataset(X_test, Y_test)

      # Create data loaders
      train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=shuffle)
      val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

      return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=0.001, clip_grad=0, zero_grad=0):
    device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

    model.train()
    total_loss = 0.0
    total_batches = len(dataloader)

    for batch, (X, y) in enumerate(dataloader):
        X, y = X.to(device), y.to(device)

        optimizer.zero_grad()

        rates = model(X)
        loss = loss_fn(rates, y)

        # Initialize reg_loss as a scalar tensor
        reg_loss = torch.tensor(0.0, device=device)

        # Only apply the penalty once per step
        if penalty is not None:
            for param in model.parameters():
                if penalty == 'l1':
                    reg_loss += torch.sum(torch.abs(param))
                elif penalty == 'l2':
                    reg_loss += torch.sum(param ** 2)  # Better to use param ** 2

        loss = loss + lbd * reg_loss

        # Backpropagation
        loss.backward()

        # Clip gradients
        if clip_grad:
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
            #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)

        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / total_batches
    return avg_loss
#+end_src

#+RESULTS:

#+begin_src ipython
def validation_step(dataloader, model, loss_fn):
    size = len(dataloader.dataset)
    device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

    model.eval()
    val_loss = 0.0

    with torch.no_grad():
        for X, y in dataloader:
            X, y = X.to(device), y.to(device)

            rates = model(X)
            batch_loss = loss_fn(rates, y)
            val_loss += batch_loss.item() * X.size(0)

    val_loss /= size
    return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
def optimization(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=0.005, zero_grad=0, gamma=0.9):

    # Choose one scheduler
    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)
    # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

    device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')
    model.to(device)

    loss_list = []
    val_loss_list = []

    for epoch in range(num_epochs):
        loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, zero_grad=zero_grad)
        val_loss = validation_step(val_loader, model, loss_fn)

        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
            scheduler.step(val_loss)
        else:
            scheduler.step()

        loss_list.append(loss)
        val_loss_list.append(val_loss)

        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss:.4f}, Validation Loss: {val_loss:.4f}')

        if val_loss < thresh and loss < thresh:
            print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')
            break

        if val_loss > 300:
            print(f'Stopping training as loss is too high: {val_loss}')
            break

        if torch.isnan(torch.tensor(loss)):
            print(f'Stopping training as loss is NaN.')
            break

    return loss_list, val_loss_list
#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
import torch

def skewed_gaussian_loss(theta_batch, y_pred, theta_bias, sigma=30, alpha=1.0):
    """
    Asymmetric likelihood loss with skew controlled by alpha.
    - theta_batch: True stimulus angles (batch_size)
    - y_pred: Network predictions (batch_size)
    - sigma: Base noise level (degrees)
    - alpha: Skew magnitude/direction (alpha > 0: skew away from theta_bias)
    """
    # Compute angular difference (handling circularity)
    # delta = torch.remainder(theta_batch - theta_bias + torch.pi, 2.0 * torch.pi) - torch.pi
    delta = theta_batch - theta_bias
    delta = (delta + torch.pi) % (2 * torch.pi) - torch.pi

    # Determine skew direction: alpha should be positive if stimulus > theta_bias
    sign = torch.where(delta > 0, 1.0, -1.0)  # 1 if stimulus is clockwise from bias
    alpha_scaled = alpha * sign  # Skew direction depends on stimulus location

    # Skewed Gaussian likelihood
    delta = theta_batch - y_pred
    delta = (delta + torch.pi) % (2 * torch.pi) - torch.pi
    z = delta / sigma
    likelihood = torch.exp(-0.5 * z**2) * (1 + torch.erf(alpha_scaled * z / torch.sqrt(torch.tensor(2.0).to(y_pred.device))))

    # Negative log-likelihood loss
    loss = -torch.log(likelihood + 1e-6)
    return loss
#+end_src

#+RESULTS:

#+begin_src ipython
    def gaussian_loss(theta_batch, y_pred, sigma=30):
        delta = y_pred - theta_batch
        delta = (delta + torch.pi) % (2 * torch.pi) - torch.pi

        likelihood = torch.exp(-0.5 * (delta / sigma)**2)

        return -torch.log(likelihood + 1e-6)
#+end_src

#+RESULTS:

#+begin_src ipython
def polar_loss(theta_batch, y_pred):
        loss = nn.MSELoss(reduction='none')
        predicted_sin = torch.sin(y_pred)
        predicted_cos = torch.cos(y_pred)

        target_sin = torch.sin(theta_batch)
        target_cos = torch.cos(theta_batch)

        loss_sin = loss(predicted_sin, target_sin)
        loss_cos = loss(predicted_cos, target_cos)

        loss_angular = (loss_sin + loss_cos)

        return loss_angular
#+end_src

#+RESULTS:

#+begin_src ipython
import torch
import torch.nn as nn
import torch.nn.functional as F

class AngularErrorLoss(nn.Module):
    def __init__(self, thresh=1, reg_tuning=0.1, sigma_stimulus=30):
        super(AngularErrorLoss, self).__init__()
        self.loss = nn.MSELoss(reduction='none')
        # self.loss = nn.SmoothL1Loss(reduction='none')

        self.thresh = thresh
        self.reg_tuning = reg_tuning
        self.sigma_stimulus = sigma_stimulus * torch.pi / 180.0

    def forward(self, readout, theta_batch):
        m0, m1, y_pred = decode_bump_torch(readout, axis=-1)

        valid_mask = theta_batch != -999
        invalid_mask = ~valid_mask
        total_loss = 0

        # angular loss (Dcos, Dsin)
        loss_polar = polar_loss(theta_batch, y_pred) * valid_mask
        loss_angular = loss_polar.sum()

        # loss_gaussian = gaussian_loss(theta_batch, y_pred, sigma=self.sigma_stimulus) * valid_mask
        # loss_angular = loss_gaussian.sum()

        total_loss += loss_angular

        # imposing tuning strength
        regularization = F.relu(self.thresh * m0 - m1) * valid_mask
        total_loss += self.reg_tuning * regularization.sum()

        # normalize over batch and time points
        total_loss /= valid_mask.sum()

        # imposing zero tuning in invalid mask
        loss_zero = self.loss(m1, 0.0 * m1) * invalid_mask
        total_loss += self.reg_tuning * (loss_zero.sum() / invalid_mask.sum())

        return total_loss
#+end_src

#+RESULTS:

** Other

#+begin_src ipython
import torch
import numpy as np
import matplotlib.pyplot as plt

def continuous_bimodal_phases(N_BATCH, preferred_angle, sigma):
    # Sample half from preferred_angle and half from preferred_angle + 180
    half_batch = N_BATCH // 2

    # Sample from preferred_angle
    samples_1 = torch.normal(mean=preferred_angle, std=sigma, size=(half_batch, 1))

    # Sample from preferred_angle + 180
    samples_2 = torch.normal(mean=(preferred_angle + 180) % 360, std=sigma, size=(N_BATCH - half_batch, 1))

    # Combine samples and wrap around 360
    phase_samples = torch.cat((samples_1, samples_2), dim=0) % 360

    return phase_samples

# Example usage
# N_BATCH = 500
# preferred_angle = 45
# sigma = 45

# samples = continuous_bimodal_phases(N_BATCH, preferred_angle, sigma)

# plt.hist(samples.numpy(), bins='auto', density=True)
# plt.xlabel('Phase (degrees)')
# plt.ylabel('Probability Density')
# plt.title('Bimodal Distribution of Phases')
# plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
import torch
import numpy as np
import matplotlib.pyplot as plt

def continuous_biased_phases(N_BATCH, preferred_angle, sigma):
    phase_samples = torch.normal(mean=preferred_angle, std=sigma, size=(N_BATCH, 1))
    phase_samples = phase_samples % 360

    return phase_samples
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl

  def pkl_save(obj, name, path="."):
      pkl.dump(obj, open(path + "/" + name + ".pkl", "wb"))


  def pkl_load(name, path="."):
      return pkl.load(open(path + "/" + name + '.pkl', "rb"))

#+end_src

#+RESULTS:

#+begin_src ipython
import torch
import numpy as np

def generate_weighted_phase_samples(N_BATCH, angles, preferred_angle, sigma):
    # Convert angles list to a tensor
    angles_tensor = torch.tensor(angles)

    # Calculate Gaussian probability distribution centered at preferred_angle
    probs = np.exp(-0.5 * ((angles - preferred_angle) / sigma) ** 2)
    probs /= probs.sum()  # Normalize to get probabilities

    # Create a categorical distribution from the computed probabilities
    distribution = torch.distributions.Categorical(torch.tensor(probs))

    # Sample from the distribution
    indices = distribution.sample((N_BATCH,))

    # Map indices to angles and reshape to (N_BATCH, 1)
    phase_samples = angles_tensor[indices].reshape(N_BATCH, 1)

    return phase_samples
#+end_src

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

* Model

#+begin_src ipython
REPO_ROOT = "/home/leon/models/NeuroFlame"
conf_name = "train_odr_EI.yml"
DEVICE = 'cuda'

total_batches = 128 * 6
batch_size = 128
ratio = total_batches // batch_size

N_BATCH = int(batch_size * ratio)
print('N_BATCH', N_BATCH, 'batch_size', batch_size)

seed = np.random.randint(0, 1e6)
seed = 1
print('seed', seed)
#+end_src

#+RESULTS:
: N_BATCH 768 batch_size 128
: seed 1


#+begin_src ipython
model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH)
#+end_src

#+RESULTS:

#+begin_src ipython
print(model.random_shifts.shape)
plt.hist(model.random_shifts.cpu().numpy() * model.DT)
plt.xlabel('Delay (s)')
plt.ylabel('Count')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: torch.Size([768])
[[./figures/odr/figure_21.png]]
:END:

* Training

#+begin_src ipython
model.J_STP.requires_grad = True
    #+end_src

#+RESULTS:

*** Parameters

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: Wab_train torch.Size([750, 750])
: J_STP torch.Size([])

#+begin_src ipython
model.N_BATCH = N_BATCH
rwd_mask = torch.zeros((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)), device=DEVICE, dtype=torch.bool)
print('rwd_mask', rwd_mask.shape)

for i in range(model.N_BATCH):
    # from first stim onset to second stim onset
    mask = torch.arange((model.start_indices[0, i] - model.N_STEADY)/ model.N_WINDOW,
                        (model.start_indices[1, i] - model.N_STEADY) / model.N_WINDOW).to(torch.int)
    # print(mask)
    rwd_mask[i, mask] = True

idx = np.random.randint(N_BATCH)
print(torch.where(rwd_mask[idx]==1)[0])
#+end_src

#+RESULTS:
: rwd_mask torch.Size([768, 161])
: tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,
:         28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,
:         46, 47, 48, 49, 50, 51, 52, 53, 54], device='cuda:0')

#+begin_src ipython

#+end_src

#+RESULTS:

*** Inputs and Labels

#+begin_src ipython
total_batches = N_BATCH // batch_size

print('total_batches', N_BATCH // batch_size)

labels = []
for _ in range(total_batches):
    batch_labels = torch.randint(0, 360, (batch_size, 1)).to(DEVICE)
    labels.append(batch_labels)

labels = torch.cat(labels, dim=0)
print(labels.shape)
#+end_src

#+RESULTS:
: total_batches 6
: torch.Size([768, 1])


#+begin_src ipython
model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)
model.PHI0[:, 0] = labels * np.pi / 180.0

window_size = int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)
labels = labels.repeat(1, window_size) * np.pi / 180.0
labels[~rwd_mask] = -999

ff_input = model.init_ff_input()
print(model.PHI0.shape, ff_input.shape, labels.shape)
#+end_src
#+RESULTS:
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([768, 2, 1]) torch.Size([768, 905, 1000]) torch.Size([768, 161])


#+begin_src ipython
print(labels[labels!=-999].shape)
plt.hist(labels[labels!=-999].cpu() * 180 / np.pi, bins=15)
plt.xlabel('Target Loc. (°)')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: torch.Size([44932])
[[./figures/odr/figure_28.png]]
:END:
#+RESULTS:

*** Run

#+begin_src ipython
train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size, shuffle=False)
#+end_src

#+RESULTS:
:RESULTS:
[[./figures/odr/figure_29.png]]
: torch.Size([614, 905, 1000]) torch.Size([154, 905, 1000])
: torch.Size([614, 161]) torch.Size([154, 161])
:END:

#+begin_src ipython
criterion = AngularErrorLoss(thresh=0.75, sigma_stimulus=30)
learning_rate = 0.1
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

       #+begin_src ipython
  num_epochs = 20
  start = perf_counter()
  loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, thresh=.005)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
#+begin_example
Epoch 1/20, Training Loss: 1.6500, Validation Loss: 1.6293
Epoch 2/20, Training Loss: 1.6050, Validation Loss: 1.5847
Epoch 3/20, Training Loss: 1.5305, Validation Loss: 1.5222
Epoch 4/20, Training Loss: 1.4428, Validation Loss: 1.4492
Epoch 5/20, Training Loss: 1.3405, Validation Loss: 1.3404
Epoch 6/20, Training Loss: 1.2006, Validation Loss: 1.1318
Epoch 7/20, Training Loss: 0.7008, Validation Loss: 0.0876
Epoch 8/20, Training Loss: 0.0809, Validation Loss: 0.0664
Epoch 9/20, Training Loss: 0.0678, Validation Loss: 0.0667
Epoch 10/20, Training Loss: 0.0603, Validation Loss: 0.0606
Epoch 11/20, Training Loss: 0.0590, Validation Loss: 0.0598
Epoch 12/20, Training Loss: 0.0529, Validation Loss: 0.0517
Epoch 13/20, Training Loss: 0.0486, Validation Loss: 0.0488
Epoch 14/20, Training Loss: 0.0451, Validation Loss: 0.0450
Epoch 15/20, Training Loss: 0.0418, Validation Loss: 0.0421
Epoch 16/20, Training Loss: 0.0391, Validation Loss: 0.0397
Epoch 17/20, Training Loss: 0.0369, Validation Loss: 0.0375
Epoch 18/20, Training Loss: 0.0353, Validation Loss: 0.0359
Epoch 19/20, Training Loss: 0.0338, Validation Loss: 0.0348
Epoch 20/20, Training Loss: 0.0326, Validation Loss: 0.0336
Elapsed (with compilation) = 0h 3m 34s
#+end_example

#+begin_src ipython
torch.save(model.state_dict(), '../models/odr/odr_%d.pth' % seed)
#+end_src

#+RESULTS:

* Testing

 #+begin_src ipython
model_state_dict = torch.load('../models/odr/odr_%d.pth' % seed);

model.load_state_dict(model_state_dict);
model.eval();
print(model.J_STP)
#+end_src

#+RESULTS:
: Parameter containing:
: tensor(3.8064, device='cuda:0', requires_grad=True)

#+begin_src ipython
    model.N_BATCH = N_BATCH

    labels = torch.randint(0, 360, (N_BATCH, 1)).to(DEVICE) * torch.pi / 180.0
    model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)
    model.PHI0[:, 0] = labels

    ff_input = model.init_ff_input()
    print(model.PHI0.shape, ff_input.shape, labels.shape)
#+end_src

#+RESULTS:
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([768, 2, 1]) torch.Size([768, 905, 1000]) torch.Size([768, 1])


#+begin_src ipython
plt.hist(labels[:, 0].cpu() * 180 / np.pi, bins='auto', density=True)
plt.xlabel('Target Loc. (°)')
plt.ylabel('Density')
plt.xticks(np.linspace(0, 360, 5))
# plt.savefig('./figs/memhist/targets.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_35.png]]

#+begin_src ipython
rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
print('ff_input', ff_input.shape)
print('rates', rates.shape)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
OutOfMemoryError                          Traceback (most recent call last)
Cell In[36], line 1
----> 1 rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
      2 print('ff_input', ff_input.shape)
      3 print('rates', rates.shape)

File ~/models/NeuroFlame/org/train/odr/../../../src/network.py:401, in Network.forward(self, ff_input, REC_LAST_ONLY, RET_FF, RET_STP, RET_REC)
    398 # returns full sequence
    399 if REC_LAST_ONLY == 0:
    400     # Stack list on 1st dim so that output is (N_BATCH, N_STEPS, N_NEURON)
--> 401     rates = torch.stack(rates_list, dim=1)
    402     # del rates_list
    404     if RET_REC:

OutOfMemoryError: CUDA out of memory. Tried to allocate 354.00 MiB. GPU 0 has a total capacity of 23.60 GiB of which 144.69 MiB is free. Including non-PyTorch memory, this process has 23.44 GiB memory in use. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
#+end_example
:END:

 #+begin_src ipython
plot_rates_selec(rates=ff_input.cpu().detach().numpy(), idx=20, thresh=.5)
#+end_src

#+RESULTS:
[[./figures/odr/figure_37.png]]

 #+begin_src ipython
plot_m0_m1_phi(model, ff_input.cpu().numpy()[..., model.slices[0]], 10)
#+end_src

#+RESULTS:
[[./figures/odr/figure_38.png]]

 #+begin_src ipython
plot_rates_selec(rates, idx=20, thresh=.5)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[39], line 1
: ----> 1 plot_rates_selec(rates, idx=20, thresh=.5)
:
: NameError: name 'rates' is not defined
:END:


   #+begin_src ipython
plot_m0_m1_phi(model, rates, 4)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[40], line 1
: ----> 1 plot_m0_m1_phi(model, rates, 4)
:
: NameError: name 'rates' is not defined
:END:


#+begin_src ipython
m0, m1, phi = decode_bump(rates, axis=-1)
print(phi.shape, labels.shape)

target_loc = labels.cpu().numpy()
# print(target_loc.shape)

errors = (phi - target_loc)
errors = (errors + np.pi) % (2 * np.pi) - np.pi
errors *= 180 / np.pi

errors2 = errors[:, int((model.N_STIM_OFF[0].cpu().numpy()-model.N_STEADY) / model.N_WINDOW)]
# print(errors2.shape)

error_list = []
for i in range(errors.shape[0]):
    # idx_stim = model.start_indices[1, i%N_TARGETS].cpu().numpy()
    idx_stim = model.start_indices[1, i].cpu().numpy()
    idx = int((idx_stim - model.N_STEADY) / model.N_WINDOW)

    error_list.append(errors[i, idx])
# errors = errors[:, int((model.N_STIM_ON[1].cpu().numpy()-model.N_STEADY) / model.N_WINDOW)-1]
errors = np.array(error_list)
# print(errors.shape, errors2.shape, target_loc.shape)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[41], line 1
: ----> 1 m0, m1, phi = decode_bump(rates, axis=-1)
:       2 print(phi.shape, labels.shape)
:       4 target_loc = labels.cpu().numpy()
:
: NameError: name 'rates' is not defined
:END:


#+begin_src ipython
targets = (target_loc + np.pi) % (2 * np.pi) - np.pi

fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
# ax[0].hist(targets[:, 0] * 180 / np.pi , bins=32 , histtype='step')
ax[0].hist(errors2, bins=32, histtype='step')
ax[0].set_xlabel('Encoding Errors (°)')

ax[1].hist(errors, bins=32)
ax[1].set_xlabel('Memory Errors (°)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: NameError                                 Traceback (most recent call last)
: Cell In[42], line 1
: ----> 1 targets = (target_loc + np.pi) % (2 * np.pi) - np.pi
:       3 fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
:       4 # ax[0].hist(targets[:, 0] * 180 / np.pi , bins=32 , histtype='step')
:
: NameError: name 'target_loc' is not defined
:END:

* Connectivity

 #+begin_src ipython
print(seed)
model_state_dict = torch.load('../models/odr/odr_%d.pth' % seed);
model.load_state_dict(model_state_dict);
model.eval();
#+end_src

#+RESULTS:
: 1

#+begin_src ipython
from src.lr_utils import LowRankWeights, clamp_tensor
Cij = model.GAIN * ( model.W_stp_T  + model.Wab_train[model.slices[0], model.slices[0]])
# Cij = model.Wab_train / model.Na[0] * model.J_STP
# Cij[Cij>0]= 1
Cij = clamp_tensor(Cij, 0, model.slices).cpu().detach().numpy()

Cij0 = pkl_load('matrix', path=".")
Kj0 = pkl_load( 'Kj', path=".")
Ki0 = pkl_load( 'Ki', path=".")
#+end_src

#+RESULTS:


#+begin_src ipython
  plt.figure(figsize=(2.5*width, 1.5*height))  # Set the figure size (width, height) in inches

  ax1 = plt.subplot2grid((2, 3), (0, 0), rowspan=2)
  im = ax1.imshow(Cij, cmap='jet', aspect=1, vmin=0)
  ax1.set_xlabel("Presynaptic")
  ax1.set_ylabel("Postsynaptic")

  # Second column, first row
  ax2 = plt.subplot2grid((2, 3), (0, 1))
  Kj = np.sum(Cij, axis=0)  # sum over pres
  ax2.plot(circcvl(Kj-Kj0, windowSize=75))
  # ax2.set_xticklabels([])
  ax2.set_ylabel("$K_j$")

  # # Second column, second row
  ax3 = plt.subplot2grid((2, 3), (1, 1))
  Ki = np.sum(Cij, axis=1)  # sum over pres
  ax3.plot(circcvl(Ki-Ki0, windowSize=75))
  ax3.set_ylabel("$K_i$")

  ax4 = plt.subplot2grid((2, 3), (0, 2), rowspan=2)
  diags = []
  for i in range(int(Cij.shape[0] / 2)):
      diags.append(np.trace(Cij, offset=i) / Cij.shape[0])
  diags = np.array(diags)
  ax4.plot(diags)
  ax4.set_xlabel("Neuron #")
  ax4.set_ylabel("$P_{ij}$")

  plt.tight_layout()
  plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_45.png]]


#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height], sharey=1)

  Dij = Cij.flatten()
  np.random.shuffle(Dij)
  Dij = Dij.reshape(Cij.shape)

  im = ax[0].imshow(Dij, cmap='jet', aspect=1, vmin=0)
  ax[0].set_xlabel("Presynaptic")
  ax[0].set_ylabel("Postsynaptic")
  ax[0].set_title('Naive')
  # ax[0].set_xticks(np.linspace(0, 750, 4))
  # ax[0].set_yticks(np.linspace(0, 750, 4))

  im = ax[1].imshow(Cij, cmap='jet', aspect=1, vmin=0)
  ax[1].set_xlabel("Presynaptic")
  ax[1].set_ylabel("Postsynaptic")
  ax[1].set_title('Trained')
  # ax[1].set_xticks(np.linspace(0, 750, 4))
  # ax[1].set_yticks(np.linspace(0, 750, 4))
  plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_46.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
