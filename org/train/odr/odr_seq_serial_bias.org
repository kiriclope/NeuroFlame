#+STARTUP: fold
#+TITLE: ODR Sequential Serial Bias
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session odr_sb :kernel torch :exports results :output-dir ./figures/odr_sb :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../../../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, TensorDataset, DataLoader
from scipy.stats import binned_statistic
#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../../../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import *
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
  from src.utils import clear_cache
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl
  import os

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
def map2center(angles):
    """Map angles from [0, 2π] to [-π, π] using PyTorch tensors."""
    return np.where(angles > np.pi, angles - 2 * np.pi, angles)

def map2pos(angles):
    """Map angles from [-π, π] to [0, 2π] using PyTorch tensors."""
    return np.where(angles < 0, angles + 2 * np.pi, angles)
#+end_src

#+RESULTS:

#+begin_src ipython
def maptens2center(angles):
    """Map angles from [0, 2π] to [-π, π] using PyTorch tensors."""
    return torch.where(angles > torch.pi, angles - 2 * torch.pi, angles)

def maptens2pos(angles):
    """Map angles from [-π, π] to [0, 2π] using PyTorch tensors."""
    return torch.where(angles < 0, angles + 2 * torch.pi, angles)
#+end_src

#+RESULTS:

#+begin_src ipython
def add_vlines(model, ax=None):

    if ax is None:
        for i in range(len(model.T_STIM_ON)):
            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)
    else:
        for i in range(len(model.T_STIM_ON)):
            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)

#+end_src

#+RESULTS:

* Model

#+begin_src ipython
kwargs = {
    'GAIN': 1.0,
    'DURATION': 12.0,
    'T_STEADY': 2,
    'T_STIM_ON': [1.0, 5.0, 7.0, 11.0],
    'T_STIM_OFF': [2.0, 6.0, 8.0, 12.0],
    'I0': [1.0, -2.0, 1.0, -2.0],
    'PHI0': [180.0, 180, 180, 180],
    'SIGMA0': [1.0, 0.0, 1.0, 0.0],
    'RANDOM_DELAY': 0,
    'MIN_DELAY': 2,
    'MAX_DELAY': 5,
    'IF_ADAPT': 1,
    'A_ADAPT': 0.25,
    'TAU_ADAPT': [150.0, 150.0],
}
#+end_src

#+RESULTS:

#+begin_src ipython
REPO_ROOT = "/home/leon/models/NeuroFlame"
conf_name = "train_odr_EI.yml"
DEVICE = 'cuda'
seed = np.random.randint(0, 1e6)

seed = 1
print('seed', seed)
#+end_src

#+RESULTS:
: seed 1

#+begin_src ipython
N_BATCH = 768
model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH, **kwargs)
#+end_src

#+RESULTS:

#+begin_src ipython
model_state_dict = torch.load('../models/odr/odr_%d.pth' % seed)
model.load_state_dict(model_state_dict);
model.eval();
#+end_src

#+RESULTS:

#+begin_src ipython
print(model.J_STP)
model.J_STP = torch.nn.Parameter(torch.tensor(3.0).to(model.device))
#+end_src

#+RESULTS:
: Parameter containing:
: tensor(3.5521, device='cuda:0', requires_grad=True)

* Batching Inputs

#+begin_src ipython
model.N_BATCH = N_BATCH

# continuous odr
model.PHI0 = torch.randint(low=0, high=360, size=(N_BATCH, len(model.I0), 1), device=DEVICE, dtype=torch.float)

# n target odr
# angles = torch.linspace(0, 360, steps=8+1, device=DEVICE)[:-1]  # exclude 360
# idx = torch.randint(0, 8, size=(N_BATCH, len(model.I0), 1), device=DEVICE)
# model.PHI0 = angles[idx]

with torch.no_grad():
    ff_input = model.init_ff_input()
    rates_tensor = model.forward(ff_input=ff_input)
    # del ff_input
    clear_cache()
#+end_src

#+RESULTS:

#+begin_src ipython
_, _, phi_ext = decode_bump_torch(ff_input, axis=-1, RET_TENSOR=0)
_, _, phi = decode_bump_torch(rates_tensor, axis=-1, RET_TENSOR=0)
print(phi.shape, model.PHI0.shape)
#+end_src

#+RESULTS:
: (768, 121) torch.Size([768, 4, 1])

#+begin_src ipython
import matplotlib.cm as cm
colors = cm.tab10.colors  # or cm.viridis.colors, etc.

fig, ax = plt.subplots(1, 2, figsize=[2*width, height])

for i in range(5):
    ax[0].plot(phi_ext[i].T, color=colors[i], alpha=.4)
    ax[0].axhline(model.PHI0[i, 0, 0].cpu().detach(), xmin=0, xmax=0.5, ls='--', color=colors[i])
    ax[0].axhline(model.PHI0[i, 2, 0].cpu().detach(), xmin=0.5, ls='--', color=colors[i])

    ax[1].plot(phi[i].T, color=colors[i], alpha=.4)
    ax[1].axhline(model.PHI0[i, 0, 0].cpu().detach(), xmin=0, xmax=0.5, ls='--', color=colors[i])
    ax[1].axhline(model.PHI0[i, 2, 0].cpu().detach(), xmin=0.5, ls='--', color=colors[i])
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_14.png]]


#+begin_src ipython
num_epochs = 50

rates_list = [rates_tensor.cpu().detach()]
phi0_list = [model.PHI0.cpu().detach()]
thresh_list = [model.thresh.cpu().detach()]

for epoch in tqdm(range(num_epochs)):
    with torch.no_grad():
        model.PHI0 = torch.randint(low=0, high=360, size=(N_BATCH, len(model.I0), 1), device=DEVICE, dtype=torch.float)

        # idx = torch.randint(0, 8, size=(N_BATCH, len(model.I0), 1), device=DEVICE)
        # model.PHI0 = angles[idx]

        ff_input = model.init_ff_input()
        rates = model.forward(ff_input=ff_input, IF_INIT=0)

        phi0_list.append(model.PHI0.cpu().detach())
        rates_list.append(rates.cpu().detach())
        thresh_list.append(model.thresh.cpu().detach())

        del ff_input, model.PHI0
        clear_cache()

rates_list = np.stack(rates_list)
thresh_list = np.stack(thresh_list)
phi0_list = np.stack(phi0_list)

print('rates', rates_list.shape, 'thresh', thresh_list.shape, 'phi0', phi0_list.shape)
#+end_src

#+RESULTS:
:RESULTS:
: 100% 50/50 [00:50<00:00,  1.01s/it]
:
: rates (51, 768, 121, 750) thresh (51, 768, 1000) phi0 (51, 768, 4, 1)
:END:

#+begin_src ipython
plt.imshow(thresh_list[:,0, :750].T, aspect='auto', cmap='jet', vmin=0)
plt.xlabel('Trial Pair')
plt.ylabel('Neuron #')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_14.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].scatter(rates_list[0, 0, -1], rates_list[-1, 0, -1])
ax[1].scatter(thresh_list[0, 0], thresh_list[-1, 0])

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_15.png]]

#+begin_src ipython
plt.plot(thresh_list[:, 0, :10])
plt.xlabel('Trial Pair')
plt.ylabel('Threshold')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_16.png]]

* Errors

#+begin_src ipython
n_half = num_epochs // 5
n_half = 6
phi0_ini =  (phi0_list[:n_half]) * 180.0 / np.pi
phi0_last = (phi0_list[-n_half:]) * 180.0 / np.pi
print(phi0_ini.shape, phi0_last.shape)
#+end_src

#+RESULTS:
: (6, 768, 4, 1) (6, 768, 4, 1)

#+begin_src ipython
_, _, phi_ini = decode_bump_torch(rates_list[:n_half], axis=-1, RET_TENSOR=0)
print(phi_ini.shape)
#+end_src

#+RESULTS:
: (6, 768, 121)

#+begin_src ipython
_, _, phi_last = decode_bump_torch(rates_list[-n_half:], axis=-1, RET_TENSOR=0)
print(phi_last.shape)
#+end_src

#+RESULTS:
: (6, 768, 121)

#+begin_src ipython
def get_rel_tar_error(phi, phi0):
    target_loc = phi0[:, :, 2]

    rel_loc = (phi0[:, :, 0] - phi0[:, :, 2]) * np.pi / 180.0
    rel_loc = (rel_loc + np.pi) % (2 * np.pi) - np.pi
    rel_loc *= 180 / np.pi

    error_curr = (phi - phi0[:, :, 2] * np.pi / 180.0)
    error_curr = (error_curr + np.pi) % (2 * np.pi) - np.pi
    error_curr *= 180 / np.pi

    error_prev = ((phi - phi0[:, :,0] * np.pi / 180.0))
    error_prev = (error_prev + np.pi) % (2 * np.pi) - np.pi
    error_prev *= 180 / np.pi

    errors = np.stack((error_prev, error_curr), 1)

    return np.vstack(target_loc), np.vstack(rel_loc), errors
#+end_src

#+RESULTS:

#+begin_src ipython
def get_end_point(model, errors):

    stim_start_idx = ((model.start_indices - model.N_STEADY) / model.N_WINDOW).to(int).cpu().numpy()

    end_point = []
    for i, j in enumerate([1, 3]):
        end_ = []
        for k in range(errors.shape[2]):
            idx = stim_start_idx[j][k]
            end_.append(errors[:, i, k, idx])

        end_point.append(end_)

    return np.vstack(np.array(end_point).T).T
#+end_src

#+RESULTS:

#+begin_src ipython
targ_ini, rel_ini, errors_ini = get_rel_tar_error(phi_ini, phi0_ini)
targ_last, rel_last, errors_last = get_rel_tar_error(phi_last, phi0_last)
print(targ_ini.shape, rel_ini.shape, errors_ini.shape)
#+end_src

#+RESULTS:
: (4608, 1) (4608, 1) (6, 2, 768, 121)

#+begin_src ipython
end_point_ini = get_end_point(model, errors_ini)
end_point_last = get_end_point(model, errors_last)
print(end_point_ini.shape, end_point_last.shape)
#+end_src

#+RESULTS:
: (2, 4608) (2, 4608)

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[3*width, height])

ax[0].hist(targ_ini[:, 0])
ax[1].hist(end_point_ini[1])
ax[2].hist(end_point_last[1])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_24.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* Biases

#+begin_src ipython
print(targ_ini.shape, rel_ini.shape, end_point_ini.shape)
#+end_src

#+RESULTS:
: (4608, 1) (4608, 1) (2, 4608)

#+begin_src ipython
n_bins = 8
data_ini = pd.DataFrame({'target_loc': targ_ini[:, -1], 'rel_loc': rel_ini[:, -1], 'errors': end_point_ini[1]})
data_last = pd.DataFrame({'target_loc': targ_last[:, -1], 'rel_loc': rel_last[:, -1], 'errors': end_point_last[1]})
#+end_src

#+RESULTS:

#+begin_src ipython
def get_correct_error(nbins, df, thresh=None):
    if thresh is not None:
        data = df[(df['errors'] >= -thresh) & (df['errors'] <= thresh)].copy()
    else:
        data = df.copy()

    # 1. Bias-correct both error and error_half
    bin_edges = np.linspace(0, 360, n_bins + 1)
    data['bin_target'] = pd.cut(data['target_loc'], bins=bin_edges, include_lowest=True)
    mean_errors_per_bin = data.groupby('bin_target')['errors'].mean()
    data['adjusted_errors'] = data['errors'] - data['bin_target'].map(mean_errors_per_bin).astype(float)


    # 2. Bin by relative location for both sessions (full version, [-180, 180])
    data['bin_rel'] = pd.cut(data['rel_loc'], bins=n_bins)
    bin_rel = data.groupby('bin_rel')['adjusted_errors'].agg(['mean', 'sem']).reset_index()
    edges = bin_rel['bin_rel'].cat.categories
    centers = (edges.left + edges.right) / 2

    # 3. FLIP SIGN for abs(rel_loc): defects on the left (-) are flipped so all bins reflect the same "direction"
    data['rel_loc_abs'] = np.abs(data['rel_loc'])
    data['bin_rel_abs'] = pd.cut(data['rel_loc_abs'], bins=n_bins, include_lowest=True)

    # Flip errors for abs plot:
    data['adjusted_errors_abs'] = data['adjusted_errors'] * np.sign(data['rel_loc'])

    bin_rel_abs = data.groupby('bin_rel_abs')['adjusted_errors_abs'].agg(['mean', 'sem']).reset_index()
    edges_abs = bin_rel_abs['bin_rel_abs'].cat.categories
    centers_abs = (edges_abs.left + edges_abs.right) / 2

    # 4. Bin by target location for target-centered analysis (optional)
    bin_target = data.groupby('bin_target')['adjusted_errors'].agg(['mean', 'sem']).reset_index()
    edges_target = bin_target['bin_target'].cat.categories
    target_centers = (edges_target.left + edges_target.right) / 2

    return centers, bin_rel, centers_abs, bin_rel_abs
#+end_src

#+RESULTS:

#+begin_src ipython
centers_ini, bin_rel_ini, centers_abs_ini, bin_rel_abs_ini = get_correct_error(n_bins, data_ini)
centers_last, bin_rel_last, centers_abs_last, bin_rel_abs_last = get_correct_error(n_bins, data_last)
#+end_src

#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])

# Panel 2: By Relative Location (Full vs Half session, -180..180)
ax[0].plot(centers_ini, bin_rel_ini['mean'], 'r', label='ini')
ax[0].fill_between(centers_ini, bin_rel_ini['mean'] - bin_rel_ini['sem'], bin_rel_ini['mean'] + bin_rel_ini['sem'], color='r', alpha=0.2)

ax[0].plot(centers_last, bin_rel_last['mean'], 'b', label='last')
ax[0].fill_between(centers_last, bin_rel_last['mean'] - bin_rel_last['sem'], bin_rel_last['mean'] + bin_rel_last['sem'], color='b', alpha=0.2)

ax[0].axhline(0, color='k', linestyle=":")
ax[0].set_xlabel('Rel. Loc. (°)')
ax[0].set_ylabel('Corrected Error (°)')


# Panel 3: By |Relative Location| (Full and Half)
ax[1].plot(centers_abs_ini, bin_rel_abs_ini['mean'], 'r', label='ini')
ax[1].fill_between(centers_abs_ini, bin_rel_abs_ini['mean'] - bin_rel_abs_ini['sem'], bin_rel_abs_ini['mean'] + bin_rel_abs_ini['sem'], color='r', alpha=0.2)

ax[1].plot(centers_abs_last, bin_rel_abs_last['mean'], 'b', label='last')
ax[1].fill_between(centers_abs_last, bin_rel_abs_last['mean'] - bin_rel_abs_last['sem'], bin_rel_abs_last['mean'] + bin_rel_abs_last['sem'], color='b', alpha=0.2)

ax[1].axhline(0, color='k', linestyle=":")
ax[1].set_xlabel('|Rel. Loc.| (°)')
ax[1].set_ylabel('Corrected Error (°)')
ax[1].legend(fontsize=12)

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_30.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
