#+STARTUP: fold
#+TITLE: ODR Serial Bias and Reference Bias
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session odr_sb :kernel torch :exports results :output-dir ./figures/odr_sb :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  import torch.nn.functional as F
  from torch.utils.data import Dataset, TensorDataset, DataLoader
  from scipy.stats import binned_statistic
#+end_src

#+RESULTS:

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl, decode_bump_torch
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl
  import os

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
def add_vlines(model, ax=None):

    if ax is None:
        for i in range(len(model.T_STIM_ON)):
            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)
    else:
        for i in range(len(model.T_STIM_ON)):
            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)

#+end_src

#+RESULTS:


#+begin_src ipython
import torch
import numpy as np

def generate_weighted_phase_samples(N_BATCH, angles, preferred_angle, sigma):
    # Convert angles list to a tensor
    angles_tensor = torch.tensor(angles)

    # Calculate Gaussian probability distribution centered at preferred_angle
    probs = np.exp(-0.5 * ((angles - preferred_angle) / sigma) ** 2)
    probs /= probs.sum()  # Normalize to get probabilities

    # Create a categorical distribution from the computed probabilities
    distribution = torch.distributions.Categorical(torch.tensor(probs))

    # Sample from the distribution
    indices = distribution.sample((N_BATCH,))

    # Map indices to angles and reshape to (N_BATCH, 1)
    phase_samples = angles_tensor[indices].reshape(N_BATCH, 1)

    return phase_samples
#+end_src

#+RESULTS:

#+begin_src ipython
import torch
import numpy as np
import matplotlib.pyplot as plt

def continuous_biased_phases(N_BATCH, preferred_angle, sigma):
    # Generate samples from a normal distribution using PyTorch
    phase_samples = torch.normal(mean=preferred_angle, std=sigma, size=(N_BATCH, 1))

    # Normalize angles to the range [0, 360)
    phase_samples = phase_samples % 360

    return phase_samples
    #+end_src

    #+RESULTS:

* Model

#+begin_src ipython
REPO_ROOT = "/home/leon/models/NeuroFlame"
conf_name = "test_odr_EI.yml"
DEVICE = 'cuda:1'
seed = np.random.randint(0, 1e6)

seed = 1975
# seed = 3
print(seed)

IF_BIASED_PHASES = 1
IF_BIAS = 1
IF_RAND_REF=0
reference = 0

if IF_RAND_REF:
    reference = np.random.randint(0, 360)

sigma = 60.  # Standard deviation of the Gaussian
#+end_src

#+RESULTS:
: 1975

#+begin_src ipython
N_BATCH = 960
model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=1)
#+end_src

#+RESULTS:

#+begin_src ipython
import torch
import math

def periodic_gaussian(x, mean, std, period):
    # Ensure x is a tensor
    if not isinstance(x, torch.Tensor):
        x = torch.tensor(x, dtype=torch.float32)

    # Compute the periodic Gaussian
    adjusted_x = torch.fmod(x - mean + period / 2, period) - period / 2
    gaussian = torch.exp(-0.5 * (adjusted_x / std) ** 2)
    normalization_factor = 1 / (std * math.sqrt(2 * math.pi))

    return gaussian * normalization_factor

#+end_src

#+RESULTS:

#+begin_src ipython
theta = torch.linspace(0, 2.0 * torch.pi, model.Na[0]+1)[:-1].to(DEVICE)

theta_0 = reference * torch.pi / 180.0
sigma_0 = 1.0 #  sigma * torch.pi / 180.0
period = 2.0 * torch.pi

thresh = 2 * periodic_gaussian(theta, theta_0, sigma_0, period)
plt.plot(thresh.cpu())
plt.show()

#model.thresh[0, model.slices[0]] = thresh
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_10.png]]

#+begin_src ipython
if IF_BIAS:
    print('Biased ODR')
    if IF_RAND_REF:
        print('models/odr/odr_bias_rand_ref_%d.pth' % seed)
        model_state_dict = torch.load('models/odr/odr_bias_rand_ref_%d.pth' % seed)
    else:
        model_state_dict = torch.load('models/odr/odr_bias_%d_ref_%d.pth' % (reference, seed) )
else:
    model_state_dict = torch.load('models/odr/odr_%d.pth' % seed)

model.load_state_dict(model_state_dict)
model.eval()
#+end_src

#+RESULTS:
:RESULTS:
: Biased ODR
: Network(
:   (dropout): Dropout(p=0.0, inplace=False)
: )
:END:

* Batching Inputs

#+begin_src ipython
model.N_BATCH = N_BATCH

if IF_BIASED_PHASES:
    model.PHI0 = torch.zeros(size=(N_BATCH, 3, 1), device=DEVICE, dtype=torch.float)
    model.PHI0[:, 0] = continuous_biased_phases(N_BATCH, reference, sigma)
    model.PHI0[:, -1] = continuous_biased_phases(N_BATCH, reference, sigma)
else:
    model.PHI0 = torch.randint(low=0, high=360, size=(N_BATCH, 3, 1), device=DEVICE, dtype=torch.float)

ff_input = model.init_ff_input()

m0, m1, phase = decode_bump_torch(ff_input[..., model.slices[0]], axis=-1)
#+end_src

#+RESULTS:
: torch.Size([1, 750]) torch.Size([960, 1])
: torch.Size([1, 750]) torch.Size([960, 1])
: torch.Size([1, 750]) torch.Size([960, 1])

#+begin_src ipython
print(reference, model.PHI0[1, 0, 0].item() * 180 / torch.pi, phase[1, model.N_STIM_ON[0]].item() * 180 / torch.pi)
plt.plot(ff_input[1, model.N_STIM_ON[0], model.slices[0]].cpu().numpy())
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: 0 281.39608935114154 281.5762970622032
[[./figures/odr_sb/figure_13.png]]
:END:

#+begin_src ipython
idx = np.random.randint(32)
xtime = np.linspace(0, model.DURATION, phase.shape[-1])
plt.plot(xtime, phase[idx].cpu().detach().numpy() * 180 / np.pi)
plt.axhline(model.PHI0[idx,0,0].cpu() * 180/np.pi, color='k', ls='--')

print(model.PHI0[idx, 0, 0].cpu()*180/np.pi)
# print(phase[idx, window_size].cpu().detach().numpy() * 180 / np.pi)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: tensor(352.6117)
[[./figures/odr_sb/figure_14.png]]
:END:

#+begin_src ipython
# model.N_BATCH = 96
# ff_input = []
# labels = []

# phase_list =  torch.tensor([  0.,  45.,  90., 135., 180., 225., 270., 315.], device=DEVICE)

# model.PHI0 = torch.ones((model.N_BATCH, 3, 1), device=DEVICE, dtype=torch.float
#                         )

# for i in range(len(phase_list)):
#     model.PHI0[:, 0] = phase_list[i]
#     model.PHI0[:, -1] = phase_list[torch.randint(0, len(phase_list), (model.N_BATCH,))].unsqueeze(1)

#     label0 = torch.ones(model.N_BATCH, device=DEVICE, dtype=torch.float) * model.PHI0[:, 0, 0] * torch.pi / 180.0
#     label1 = torch.ones(model.N_BATCH, device=DEVICE, dtype=torch.float) * model.PHI0[:, -1, 0] * torch.pi / 180.0

#     labels.append(torch.vstack((label0, label1)))
#     ff_input.append(model.init_ff_input())

# labels = torch.hstack(labels).T
# ff_input = torch.vstack(ff_input)
# print('ff_input', ff_input.shape, 'labels', labels.shape)
# PHI0 = labels.unsqueeze(-1)
#+end_src

#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].hist(model.PHI0[:, 0, 0].cpu(), bins=15)
ax[1].hist(model.PHI0[:,-1, 0].cpu(), bins=15)
plt.show()
 #+end_src

#+RESULTS:
[[./figures/odr_sb/figure_16.png]]

#+begin_src ipython
rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
print('rates', rates.shape)
#+end_src

#+RESULTS:
: rates (960, 111, 750)

#+begin_src ipython
m0, m1, phi = decode_bump(rates, axis=-1)
# m0, m1, phi = get_fourier_moments(rates, axis=-1)
# m0, m1, phi = compute_fourier_moments(rates, dim=-1)
# print(phi.shape)
#+end_src

#+RESULTS:

#+begin_src ipython
idx = np.random.randint(32)
xtime = np.linspace(0, model.DURATION, phi.shape[-1])
plt.plot(xtime, phi[idx]* 180 / np.pi)
plt.axhline(model.PHI0[idx,0,0].cpu() * 180/np.pi, color='k', ls='--')

print(model.PHI0[idx, 0, 0].cpu()*180/np.pi)
# print(phi[idx, window_size]* 180 / np.pi)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: tensor(4.0436)
[[./figures/odr_sb/figure_19.png]]
:END:

* Results
** Rates

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.5*width, height])

idx = np.random.randint(0, model.N_BATCH)
ax[0].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=2, origin='lower', extent=[0, model.DURATION, 0, model.Na[0].cpu()])
ax[0].set_ylabel('Pref. Location (°)')
ax[0].set_yticks(np.linspace(0, model.Na[0].cpu(), 5), np.linspace(0, 360, 5).astype(int))
ax[0].set_xlabel('Time (s)')

xtime = np.linspace(0, model.DURATION, phi.shape[-1])
idx = np.random.randint(0, model.N_BATCH, 8)
ax[1].plot(xtime, m1[idx].T)
ax[1].set_ylabel('m1 (Hz)')
ax[1].set_xlabel('Time (s)')
add_vlines(model, ax[1])

ax[2].plot(xtime, phi[idx].T * 180 / np.pi, alpha=0.5)
ax[2].set_yticks(np.linspace(0, 360, 5).astype(int), np.linspace(0, 360, 5).astype(int))
ax[2].set_ylabel('Bump Center (°)')
ax[2].set_xlabel('Time (s)')
add_vlines(model, ax[2])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_20.png]]

#+begin_src ipython
PHI0 = model.PHI0.cpu().detach().numpy() * 180.0 / np.pi
print(PHI0.shape)

idx = np.random.randint(0, 32)
print(PHI0[idx, 0, 0])
window_size = int((model.N_STIM_ON[1]-model.N_STEADY) / model.N_WINDOW)
print(phi[idx, window_size] * 180 / np.pi)
#+end_src

#+RESULTS:
: (960, 3, 1)
: 311.3306
: 305.1320922165059

** errors

#+begin_src ipython
target_loc = PHI0[:, -1]

rel_loc = (PHI0[:, 0] - target_loc) * np.pi / 180.0
rel_loc = (rel_loc + np.pi) % (2 * np.pi) - np.pi
rel_loc *= 180 / np.pi

ref_loc = (PHI0[:, -1] - reference) * np.pi / 180.0
ref_loc = (ref_loc + np.pi) % (2 * np.pi) - np.pi
ref_loc *= 180 / np.pi

window_size = int((model.N_STIM_OFF[-1]-model.N_STEADY) / model.N_WINDOW)
# errors = phi - phi[:, window_size][:, np.newaxis]
errors = (phi - target_loc * np.pi / 180.0)
errors = (errors + np.pi) % (2 * np.pi) - np.pi
errors *= 180 / np.pi

window_size = int((model.N_STIM_OFF[0]-model.N_STEADY) / model.N_WINDOW)
errors2 = ((phi - PHI0[:, 0] * np.pi / 180.0))
# errors2 = phi - phi[:, window_size][:, np.newaxis]
errors2 = (errors2 + np.pi) % (2 * np.pi) - np.pi
errors2 *= 180 / np.pi

print(errors.shape, target_loc.shape, rel_loc.shape, ref_loc.shape)
#+end_src

#+RESULTS:
: (960, 111) (960, 1) (960, 1) (960, 1)

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].plot(np.linspace(0, model.DURATION, errors.shape[-1]), errors2[:32].T)
add_vlines(model, ax[0])
# ax[0].set_xlim([2.5, 4.5])
ax[0].set_xlabel('t')
ax[0].set_ylabel('prev. error (°)')

ax[1].plot(np.linspace(0, model.DURATION, errors.shape[-1]), errors[:32].T)
add_vlines(model, ax[1])
ax[1].set_xlabel('t')
ax[1].set_ylabel('curr. error (°)')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_23.png]]


#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.75*width, height])
ax[0].hist(rel_loc[:, 0], bins='auto')
ax[0].set_xlabel('Rel. Location (°)')

ax[1].hist(errors2[:, int((model.N_STIM_ON[1]-model.N_STEADY)/model.N_WINDOW)], bins='auto')
ax[1].set_xlabel('Prev. Errors (°)')

ax[2].hist(errors[:, -1], bins=64)
ax[2].set_xlabel('Curr. Errors (°)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_24.png]]

#+begin_src ipython
mask = np.abs(errors) <= 45
print(mask.shape)

errors = np.where(mask, errors, np.nan)[:, -1]
print(errors.shape)
rel_loc = rel_loc[~np.isnan(errors)]
ref_loc = ref_loc[~np.isnan(errors)]
target_loc = target_loc[:, -1][~np.isnan(errors), np.newaxis]
errors = errors[~np.isnan(errors), np.newaxis]
# errors = errors[mask]
print(errors.shape, target_loc.shape, rel_loc.shape, ref_loc.shape)
#+end_src

#+RESULTS:
: (960, 111)
: (960,)
: (960, 1) (960, 1) (960, 1) (960, 1)

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.75*width, height])
ax[0].hist(rel_loc[:, 0], bins='auto')
ax[0].set_xlabel('Rel. Location (°)')

ax[1].hist(errors2[:, int((model.N_STIM_ON[1]-model.N_STEADY)/model.N_WINDOW)], bins='auto')
ax[1].set_xlabel('Prev. Errors (°)')

ax[2].hist(errors[:, -1], bins='auto')
ax[2].set_xlabel('Curr. Errors (°)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_26.png]]

** biases

#+begin_src ipython
data = pd.DataFrame({'target_loc': target_loc[:, -1], 'rel_loc': rel_loc[:, -1], 'errors': errors[:, -1], 'ref_loc': ref_loc[:, -1]})

try:
    df_naive = pkl_load('df_naive_%d' % seed, path="./figures/odr")
except:
    df_naive = data
#+end_src

#+RESULTS:
: loading from ./figures/odr/df_naive_1975.pkl

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[3*width, height])

n_bins=16
ax[0].plot(df_naive['target_loc'], df_naive['errors'], 'o', alpha=.1)
ax[0].set_xlabel('Target Loc. (°)')
ax[0].set_ylabel('Error (°)')

stt = binned_statistic(df_naive['target_loc'], df_naive['errors'], statistic='mean', bins=n_bins, range=[0, 360])
dstt = np.mean(np.diff(stt.bin_edges))
ax[0].plot(stt.bin_edges[:-1]+dstt/2,stt.statistic,'r')

ax[0].axhline(color='k', linestyle=":")

ax[1].plot(rel_loc[:, 0], errors[:,-1], 'bo', alpha=.1)
ax[1].set_xlabel('Rel. Loc. (°)')
ax[1].set_ylabel('Error (°)')

stt = binned_statistic(rel_loc[:, 0], errors[:, -1], statistic='mean', bins=n_bins, range=[-180, 180])
dstt = np.mean(np.diff(stt.bin_edges))
ax[1].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')

ax[2].plot(ref_loc[:, 0], errors[:,-1], 'bo', alpha=.1)
ax[2].set_xlabel('Ref. Loc. (°)')
ax[2].set_ylabel('Error (°)')

stt = binned_statistic(ref_loc[:, 0], errors[:, -1], statistic='mean', bins=n_bins, range=[-180, 180])
dstt = np.mean(np.diff(stt.bin_edges))
ax[2].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_28.png]]

#+begin_src ipython
n_bins = 16
angle_min = 0
angle_max = 360

bin_edges = np.linspace(angle_min, angle_max, n_bins + 1)
data['bin_target'] = pd.cut(data['target_loc'], bins=bin_edges, include_lowest=True)

mean_errors_per_bin = data.groupby('bin_target')['errors'].mean()
data['adjusted_errors'] = data.apply(
    lambda row: row['errors'] - mean_errors_per_bin.loc[row['bin_target']],
    axis=1
)

if IF_BIAS:
   df_naive['bin_target'] = pd.cut(df_naive['target_loc'], bins=bin_edges, include_lowest=True)

   mean_errors_per_bin = df_naive.groupby('bin_target')['errors'].mean()
   data['errors_naive'] = data.apply(
      lambda row: row['errors'] - mean_errors_per_bin.loc[row['bin_target']],
      axis=1
   )

bin_target = data.groupby('bin_target')['adjusted_errors'].agg(['mean', 'sem']).reset_index()
edges = bin_target['bin_target'].cat.categories
target_centers = (edges.left + edges.right) / 2

data['bin_rel'] = pd.cut(data['rel_loc'], bins=n_bins)
bin_rel = data.groupby('bin_rel')['adjusted_errors'].agg(['mean', 'sem']).reset_index()

edges = bin_rel['bin_rel'].cat.categories
centers = (edges.left + edges.right) / 2

data['bin_ref'] = pd.cut(data['ref_loc'], bins=n_bins)
if IF_BIAS:
   bin_ref = data.groupby('bin_ref')['errors_naive'].agg(['mean', 'sem']).reset_index()
else:
   bin_ref = data.groupby('bin_ref')['adjusted_errors'].agg(['mean', 'sem']).reset_index()

ref_edges = bin_ref['bin_ref'].cat.categories
ref_centers = (ref_edges.left + ref_edges.right) / 2
#+end_src

#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[3*width, height])
ax[0].plot(centers, bin_target['mean'], 'b')
ax[0].fill_between(centers,
                   bin_target['mean'] - bin_target['sem'],
                   bin_target['mean'] + bin_target['sem'],
                   color='b', alpha=0.2)

ax[0].axhline(color='k', linestyle=":")
ax[0].set_xlabel('Target Loc. (°)')
ax[0].set_ylabel('Curr. Error (°)')

ax[1].plot(centers, bin_rel['mean'], 'b')
ax[1].fill_between(centers,
                bin_rel['mean'] - bin_rel['sem'],
                bin_rel['mean'] + bin_rel['sem'],
                color='b', alpha=0.2)

ax[1].axhline(color='k', linestyle=":")
ax[1].set_xlabel('Rel. Loc. (°)')
ax[1].set_ylabel('Curr. Error (°)')

ax[2].plot(ref_centers, bin_ref['mean'], 'b')
ax[2].fill_between(ref_centers,
                bin_ref['mean'] - bin_ref['sem'],
                bin_ref['mean'] + bin_ref['sem'],
                color='b', alpha=0.2)

ax[2].axhline(color='k', linestyle=":")
ax[2].set_xlabel('Ref. Loc. (°)')
ax[2].set_ylabel('Curr. Error (°)')

if IF_BIAS:
    plt.savefig('./figures/odr/odr_biases_train.svg', dpi=300)
else:
    plt.savefig('./figures/odr/odr_biases_naive.svg', dpi=300)

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_30.png]]

#+begin_src ipython
if IF_BIAS==0:
   pkl_save(data, 'df_naive_%d' %seed, path="./figures/odr")
#+end_src

#+RESULTS:
