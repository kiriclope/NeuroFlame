#+STARTUP: fold
#+TITLE: Serial Biases in the ODR
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session odr_sb :kernel torch :exports results :output-dir ./figures/odr :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  import torch.nn.functional as F
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl, decode_bump_torch
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl
  import os

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

* Helpers
#+begin_src ipython
def compute_fourier_moments(signal, dim=-1):
    # Perform the FFT
    fft_coeffs = torch.fft.fft(signal, dim=dim)

    # Calculate the zero, first, and second Fourier moments
    zero_moment = fft_coeffs[..., 0]
    first_moment = fft_coeffs[..., 1]
    # second_moment = fft_coeffs[..., 2]

    # Calculate magnitude m0, m1, and m2
    m0 = torch.abs(zero_moment) / signal.size(dim)  # Normalize m0 by the signal length
    m1 = 2.0 * torch.abs(first_moment) / signal.size(dim)
    # m2 = 2.0 * torch.abs(second_moment) / signal.size(dim)

    # Calculate the phase of the signal
    phases = torch.angle(first_moment) % (2.0 * torch.pi)

    return m0, m1, phases
#+end_src

#+RESULTS:

#+begin_src ipython
def get_fourier_moments(signal, axis=-1):
    # Perform the FFT
    fft_coeffs = np.fft.fft(signal, axis=axis)

    # Calculate the zero, first, and second Fourier moments
    zero_moment = fft_coeffs[..., 0]
    first_moment = fft_coeffs[..., 1]

    # Calculate magnitude m0, m1, and m2
    m0 = np.abs(zero_moment) / signal.shape[axis]  # Normalize m0 by the signal length
    m1 = 2.0 * np.abs(first_moment) / signal.shape[axis]

    # Calculate the phase of the signal
    phases = np.angle(first_moment) % (2.0 * torch.pi)

    return m0, m1, phases
#+end_src

#+RESULTS:

#+begin_src ipython
def add_vlines(model, ax=None):

    if ax is None:
        for i in range(len(model.T_STIM_ON)):
            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)
    else:
        for i in range(len(model.T_STIM_ON)):
            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)

#+end_src

#+RESULTS:

* Bias targets

#+begin_src ipython
import torch
import numpy as np

def generate_weighted_phase_samples(N_BATCH, angles, preferred_angle, sigma):
    # Convert angles list to a tensor
    angles_tensor = torch.tensor(angles)

    # Calculate Gaussian probability distribution centered at preferred_angle
    probs = np.exp(-0.5 * ((angles - preferred_angle) / sigma) ** 2)
    probs /= probs.sum()  # Normalize to get probabilities

    # Create a categorical distribution from the computed probabilities
    distribution = torch.distributions.Categorical(torch.tensor(probs))

    # Sample from the distribution
    indices = distribution.sample((N_BATCH,))

    # Map indices to angles and reshape to (N_BATCH, 1)
    phase_samples = angles_tensor[indices].reshape(N_BATCH, 1)

    return phase_samples

# Parameters
N_BATCH = 1000
angles = np.array([0., 45., 90., 135., 180., 225., 270., 315.])
reference = 90.  # Example preferred angle
sigma = 75.  # Standard deviation of the Gaussian

# Generate samples
phase_samples = generate_weighted_phase_samples(N_BATCH, angles, reference, sigma)
print(phase_samples.shape)
plt.hist(phase_samples[:,0], bins=8);
#+end_src

#+RESULTS:
:RESULTS:
: torch.Size([1000, 1])
[[./figures/odr/figure_7.png]]
:END:

#+begin_src ipython
import torch
import numpy as np
import matplotlib.pyplot as plt

def continuous_biased_phases(N_BATCH, preferred_angle, sigma):
    # Generate samples from a normal distribution using PyTorch
    phase_samples = torch.normal(mean=preferred_angle, std=sigma, size=(N_BATCH, 1))

    # Normalize angles to the range [0, 360)
    phase_samples = phase_samples % 360

    return phase_samples

# Parameters
N_BATCH = 1000
reference = 90.0  # Example preferred angle
sigma = 75.0  # Standard deviation of the Gaussian

# Generate continuous samples
phase_samples = continuous_biased_phases(N_BATCH, reference, sigma)
print(phase_samples.shape)
# Convert to numpy for plotting
phase_samples_np = phase_samples.numpy()

plt.hist(phase_samples_np[:, 0], bins=36, range=(0, 360))
plt.xlabel('Angle (degrees)')
plt.ylabel('Frequency')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: torch.Size([1000, 1])
[[./figures/odr/figure_8.png]]
:END:


#+begin_src ipython

#+end_src

#+RESULTS:

* Model

#+begin_src ipython
REPO_ROOT = "/home/leon/models/NeuroFlame"
conf_name = "test_odr_EI.yml"
DEVICE = 'cuda:1'
seed = np.random.randint(0, 1e6)
print(seed)

seed = 181678
seed = 1975532
seed = 197553
IF_BIASED_PHASES = 1

#+end_src

#+RESULTS:
: 269977

#+begin_src ipython
model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=1, LIVE_FF_UPDATE=0)
#+end_src

#+RESULTS:

#+begin_src ipython
if IF_BIASED_PHASES:
    model_state_dict = torch.load('models/odr_bias_%d.pth' % seed)
else:
    model_state_dict = torch.load('models/odr_%d.pth' % seed)

model.load_state_dict(model_state_dict)
model.eval()
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
Cell In[12], line 2
      1 if IF_BIASED_PHASES:
----> 2     model_state_dict = torch.load('models/odr_bias_%d.pth' % seed)
      3 else:
      4     model_state_dict = torch.load('models/odr_%d.pth' % seed)

File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/serialization.py:998, in load(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)
    995 if 'encoding' not in pickle_load_args.keys():
    996     pickle_load_args['encoding'] = 'utf-8'
--> 998 with _open_file_like(f, 'rb') as opened_file:
    999     if _is_zipfile(opened_file):
   1000         # The zipfile reader is going to advance the current file position.
   1001         # If we want to actually tail call to torch.jit.load, we need to
   1002         # reset back to the original position.
   1003         orig_position = opened_file.tell()

File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/serialization.py:445, in _open_file_like(name_or_buffer, mode)
    443 def _open_file_like(name_or_buffer, mode):
    444     if _is_path(name_or_buffer):
--> 445         return _open_file(name_or_buffer, mode)
    446     else:
    447         if 'w' in mode:

File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/serialization.py:426, in _open_file.__init__(self, name, mode)
    425 def __init__(self, name, mode):
--> 426     super().__init__(open(name, mode))

FileNotFoundError: [Errno 2] No such file or directory: 'models/odr_bias_197553.pth'
#+end_example
:END:

#+begin_src ipython
print(model.J_STP)
#+end_src

#+RESULTS:
: Parameter containing:
: tensor(20., device='cuda:1', requires_grad=True)

* Batching Inputs Sequentially

#+begin_src ipython
768+128
#+end_src

#+RESULTS:
: 896

#+begin_src ipython
N_BATCH = 800
model.N_BATCH = N_BATCH

if IF_BIASED_PHASES:
    model.PHI0 = torch.zeros(size=(N_BATCH, 3, 1), device=DEVICE, dtype=torch.float)
    model.PHI0[:, 0] = continuous_biased_phases(N_BATCH, reference, sigma)
    model.PHI0[:, -1] = continuous_biased_phases(N_BATCH, reference, sigma)
else:
    model.PHI0 = torch.randint(low=0, high=360, size=(N_BATCH, 3, 1), device=DEVICE, dtype=torch.float)

ff_input = model.init_ff_input()

# m0, m1, phi = decode_bump_torch(ff_input[..., model.slices[0]], axis=-1)
# m0, m1, phi = decode_bump(ff_input.cpu().numpy()[..., model.slices[0]], axis=-1)
# m0, m1, phi = get_fourier_moments(ff_input.cpu().numpy()[..., model.slices[0]], axis=-1)
m0, m1, phase = compute_fourier_moments(ff_input[..., model.slices[0]], dim=-1)
window_size = int((model.N_STIM_ON[0]-model.N_STEADY+1) / model.N_WINDOW)
#+end_src

#+RESULTS:
: torch.Size([1, 750]) torch.Size([800, 1])
: torch.Size([1, 750]) torch.Size([800, 1])
: torch.Size([1, 750]) torch.Size([800, 1])

#+begin_src ipython
idx = np.random.randint(32)
xtime = np.linspace(0, model.DURATION, phase.shape[-1])
plt.plot(xtime, phase[idx].cpu().detach().numpy() * 180 / np.pi)
plt.axhline(model.PHI0[idx,0,0].cpu() * 180/np.pi, color='k', ls='--')

print(model.PHI0[idx, 0, 0].cpu()*180/np.pi)
# print(phase[idx, window_size].cpu().detach().numpy() * 180 / np.pi)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: tensor(122.4382)
[[./figures/odr/figure_16.png]]
:END:

#+begin_src ipython
# model.N_BATCH = 96
# ff_input = []
# labels = []

# phase_list =  torch.tensor([  0.,  45.,  90., 135., 180., 225., 270., 315.], device=DEVICE)

# model.PHI0 = torch.ones((model.N_BATCH, 3, 1), device=DEVICE, dtype=torch.float
#                         )

# for i in range(len(phase_list)):
#     model.PHI0[:, 0] = phase_list[i]
#     model.PHI0[:, -1] = phase_list[torch.randint(0, len(phase_list), (model.N_BATCH,))].unsqueeze(1)

#     label0 = torch.ones(model.N_BATCH, device=DEVICE, dtype=torch.float) * model.PHI0[:, 0, 0] * torch.pi / 180.0
#     label1 = torch.ones(model.N_BATCH, device=DEVICE, dtype=torch.float) * model.PHI0[:, -1, 0] * torch.pi / 180.0

#     labels.append(torch.vstack((label0, label1)))
#     ff_input.append(model.init_ff_input())

# labels = torch.hstack(labels).T
# ff_input = torch.vstack(ff_input)
# print('ff_input', ff_input.shape, 'labels', labels.shape)
# PHI0 = labels.unsqueeze(-1)
#+end_src

#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].hist(model.PHI0[:, 0, 0].cpu(), bins=15)
ax[1].hist(model.PHI0[:,-1, 0].cpu(), bins=15)
plt.show()
 #+end_src

#+RESULTS:
[[./figures/odr/figure_18.png]]

#+begin_src ipython
rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
print('rates', rates.shape)
#+end_src

#+RESULTS:
: rates (800, 91, 750)

#+begin_src ipython
# m0, m1, phi = decode_bump_torch(rates, axis=-1)
m0, m1, phi = get_fourier_moments(rates, axis=-1)
# m0, m1, phi = compute_fourier_moments(rates, dim=-1)
# print(phi.shape)
#+end_src

#+RESULTS:

#+begin_src ipython
idx = np.random.randint(32)
xtime = np.linspace(0, model.DURATION, phi.shape[-1])
plt.plot(xtime, phi[idx]* 180 / np.pi)
plt.axhline(model.PHI0[idx,0,0].cpu() * 180/np.pi, color='k', ls='--')

print(model.PHI0[idx, 0, 0].cpu()*180/np.pi)
# print(phi[idx, window_size]* 180 / np.pi)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: tensor(73.4401)
[[./figures/odr/figure_21.png]]
:END:


* Results
** Rates

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.5*width, height])

idx = np.random.randint(0, model.N_BATCH)
ax[0].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=2, origin='lower', extent=[0, model.DURATION, 0, model.Na[0].cpu()])
ax[0].set_ylabel('Pref. Location (°)')
ax[0].set_yticks(np.linspace(0, model.Na[0].cpu(), 5), np.linspace(0, 360, 5).astype(int))
ax[0].set_xlabel('Time (s)')

xtime = np.linspace(0, model.DURATION, phi.shape[-1])
idx = np.random.randint(0, model.N_BATCH, 8)
ax[1].plot(xtime, m1[idx].T)
ax[1].set_ylabel('m1 (Hz)')
ax[1].set_xlabel('Time (s)')
add_vlines(model, ax[1])

ax[2].plot(xtime, phi[idx].T * 180 / np.pi, alpha=0.5)
ax[2].set_yticks(np.linspace(0, 360, 5).astype(int), np.linspace(0, 360, 5).astype(int))
ax[2].set_ylabel('Bump Center (°)')
ax[2].set_xlabel('Time (s)')
add_vlines(model, ax[2])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_22.png]]

#+begin_src ipython
PHI0 = model.PHI0.cpu().detach().numpy() * 180.0 / np.pi
print(PHI0.shape)

idx = np.random.randint(0, 32)
print(PHI0[idx, 0, 0])
window_size = int((model.N_STIM_ON[1]-model.N_STEADY) / model.N_WINDOW)
print(phi[idx, window_size] * 180 / np.pi)
#+end_src

#+RESULTS:
: (800, 3, 1)
: 49.40541
: 55.13599427461926

** errors

#+begin_src ipython
target_loc = PHI0[:, -1]

rel_loc = (PHI0[:, 0] - target_loc) * np.pi / 180.0
rel_loc = (rel_loc + np.pi) % (2 * np.pi) - np.pi
rel_loc *= 180 / np.pi

ref_loc = (PHI0[:, 0] - reference) * np.pi / 180.0
ref_loc = (ref_loc + np.pi) % (2 * np.pi) - np.pi
ref_loc *= 180 / np.pi

window_size = int((model.N_STIM_OFF[-1]-model.N_STEADY) / model.N_WINDOW)
# errors = phi - phi[:, window_size][:, np.newaxis]
errors = (phi - target_loc * np.pi / 180.0)
errors = (errors + np.pi) % (2 * np.pi) - np.pi
errors *= 180 / np.pi

window_size = int((model.N_STIM_OFF[0]-model.N_STEADY) / model.N_WINDOW)
errors2 = ((phi - PHI0[:, 0] * np.pi / 180.0))
# errors2 = phi - phi[:, window_size][:, np.newaxis]
errors2 = (errors2 + np.pi) % (2 * np.pi) - np.pi
errors2 *= 180 / np.pi

print(errors.shape, target_loc.shape, rel_loc.shape, ref_loc.shape)
#+end_src

#+RESULTS:
: (800, 91) (800, 1) (800, 1) (800, 1)

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].plot(np.linspace(0, model.DURATION, errors.shape[-1]), errors2[:32].T)
add_vlines(model, ax[0])
# ax[0].set_xlim([2.5, 4.5])
ax[0].set_xlabel('t')
ax[0].set_ylabel('prev. error (°)')

ax[1].plot(np.linspace(0, model.DURATION, errors.shape[-1]), errors[:32].T)
add_vlines(model, ax[1])
ax[1].set_xlabel('t')
ax[1].set_ylabel('curr. error (°)')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_25.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.75*width, height])
ax[0].hist(rel_loc[:, 0], bins='auto')
ax[0].set_xlabel('Rel. Location (°)')

ax[1].hist(errors2[:, int((model.N_STIM_ON[1]-model.N_STEADY)/model.N_WINDOW)], bins='auto')
ax[1].set_xlabel('Prev. Errors (°)')

ax[2].hist(errors[:, -1], bins=64)
ax[2].set_xlabel('Curr. Errors (°)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_26.png]]

#+begin_src ipython
mask = np.abs(errors) <= 45
print(mask.shape)

errors = np.where(mask, errors, np.nan)[:, -1]
print(errors.shape)
rel_loc = rel_loc[~np.isnan(errors)]
ref_loc = ref_loc[~np.isnan(errors)]
target_loc = target_loc[:, -1][~np.isnan(errors), np.newaxis]
errors = errors[~np.isnan(errors), np.newaxis]
# errors = errors[mask]
print(errors.shape, target_loc.shape, rel_loc.shape, ref_loc.shape)
#+end_src

#+RESULTS:
: (800, 91)
: (800,)
: (215, 1) (215, 1) (215, 1) (215, 1)

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.75*width, height])
ax[0].hist(rel_loc[:, 0], bins='auto')
ax[0].set_xlabel('Rel. Location (°)')

ax[1].hist(errors2[:, int((model.N_STIM_ON[1]-model.N_STEADY)/model.N_WINDOW)], bins='auto')
ax[1].set_xlabel('Prev. Errors (°)')

ax[2].hist(errors[:, -1], bins='auto')
ax[2].set_xlabel('Curr. Errors (°)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_28.png]]

** biases

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.5*width, height])

ax[0].plot(target_loc[:, 0], errors[:,-1], 'o', alpha=.1)
ax[0].set_xlabel('Target Loc. (°)')
ax[0].set_ylabel('Error (°)')

from scipy.stats import binned_statistic
stt = binned_statistic(target_loc[:,0], errors[:,-1], statistic='mean', bins=3, range=[0, 360])
dstt = np.mean(np.diff(stt.bin_edges))
ax[0].plot(stt.bin_edges[:-1]+dstt/2,stt.statistic,'r')

ax[0].axhline(color='k', linestyle=":")

ax[1].plot(rel_loc[:, 0], errors[:,-1], 'bo', alpha=.1)
# ax[1].plot(rel_loc2[:, 0], errors2[:,-1], 'ro')
ax[1].set_xlabel('Rel. Loc. (°)')
ax[1].set_ylabel('Error (°)')

stt = binned_statistic(rel_loc[:, 0], errors[:, -1], statistic='mean', bins=6, range=[-180, 180])
dstt = np.mean(np.diff(stt.bin_edges))
ax[1].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')

ax[2].plot(ref_loc[:, 0], errors[:,-1], 'bo', alpha=.1)
# ax[2].plot(ref_loc2[:, 0], errors2[:,-1], 'ro')
ax[2].set_xlabel('Ref. Loc. (°)')
ax[2].set_ylabel('Error (°)')

stt = binned_statistic(ref_loc[:, 0], errors[:, -1], statistic='mean', bins=6, range=[-180, 180])
dstt = np.mean(np.diff(stt.bin_edges))
ax[2].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')

# stt = binned_statistic(rel_loc2[:, 0], errors2[:, -1], statistic='mean', bins=6, range=[-180, 180])
# dstt = np.mean(np.diff(stt.bin_edges))
# ax[1].plot(stt.bin_edges[:-1]+dstt/2,stt.statistic, 'r')
# ax[1].set_ylim([-120, 120])
# ax[1].axhline(color='k', linestyle=":")

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_29.png]]

#+begin_src ipython
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Assuming rel_loc and errors are defined earlier
data = pd.DataFrame({'target_loc': target_loc[:, -1], 'rel_loc': rel_loc[:, -1], 'errors': errors[:, -1], 'ref_loc': ref_loc[:, -1]})

# Bin data using pandas cut
data['bin'] = pd.cut(data['rel_loc'], bins=6)
# Calculate mean and standard error for each bin
means = data.groupby('target_loc')['errors'].apply('mean')
binned_data = data.groupby('bin')['errors'].agg(['mean', 'sem'])

bin_edges = binned_data.index.get_level_values(0)
bin_centers = (bin_edges.categories.left + bin_edges.categories.right) / 2

# Plot
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].plot(bin_centers, binned_data['mean'], 'b')
ax[0].fill_between(bin_centers,
                binned_data['mean'] - binned_data['sem'],
                binned_data['mean'] + binned_data['sem'],
                color='b', alpha=0.2)

ax[0].axhline(color='k', linestyle=":")
ax[0].set_xlabel('Rel. Loc. (°)')
ax[0].set_ylabel('Curr. Error (°)')

data['bin'] = pd.cut(data['ref_loc'], bins=6)
binned_data = data.groupby('bin')['errors'].agg(['mean', 'sem'])
bin_edges = binned_data.index.get_level_values(0)
bin_centers = (bin_edges.categories.left + bin_edges.categories.right) / 2

ax[1].plot(bin_centers, binned_data['mean'], 'b')
ax[1].fill_between(bin_centers,
                binned_data['mean'] - binned_data['sem'],
                binned_data['mean'] + binned_data['sem'],
                color='b', alpha=0.2)
ax[1].axhline(color='k', linestyle=":")
ax[1].set_xlabel('Ref. Loc. (°)')
ax[1].set_ylabel('Curr. Error (°)')

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_30.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
