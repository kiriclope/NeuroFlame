#+STARTUP: fold
#+TITLE: Serial Biases in the ODR
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session odr_sb :kernel torch :exports results :output-dir ./figures/odr_sb :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  import torch.nn.functional as F
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl, decode_bump_torch
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl
  import os

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

* Helpers
#+begin_src ipython
def compute_fourier_moments(signal, dim=-1):
    # Perform the FFT
    fft_coeffs = torch.fft.fft(signal, dim=dim)

    # Calculate the zero, first, and second Fourier moments
    zero_moment = fft_coeffs[..., 0]
    first_moment = fft_coeffs[..., 1]
    # second_moment = fft_coeffs[..., 2]

    # Calculate magnitude m0, m1, and m2
    m0 = torch.abs(zero_moment) / signal.size(dim)  # Normalize m0 by the signal length
    m1 = 2.0 * torch.abs(first_moment) / signal.size(dim)
    # m2 = 2.0 * torch.abs(second_moment) / signal.size(dim)

    # Calculate the phase of the signal
    phases = torch.angle(first_moment) % (2.0 * torch.pi)

    return m0, m1, phases
#+end_src

#+RESULTS:

#+begin_src ipython
def get_fourier_moments(signal, axis=-1):
    # Perform the FFT
    fft_coeffs = np.fft.fft(signal, axis=axis)

    # Calculate the zero, first, and second Fourier moments
    zero_moment = fft_coeffs[..., 0]
    first_moment = fft_coeffs[..., 1]

    # Calculate magnitude m0, m1, and m2
    m0 = np.abs(zero_moment) / signal.shape[axis]  # Normalize m0 by the signal length
    m1 = 2.0 * np.abs(first_moment) / signal.shape[axis]

    # Calculate the phase of the signal
    phases = np.angle(first_moment) % (2.0 * torch.pi)

    return m0, m1, phases
#+end_src

#+RESULTS:

#+begin_src ipython
def add_vlines(model, ax=None):

    if ax is None:
        for i in range(len(model.T_STIM_ON)):
            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)
    else:
        for i in range(len(model.T_STIM_ON)):
            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)

#+end_src

#+RESULTS:

* Bias targets

#+begin_src ipython
import torch
import numpy as np

def generate_weighted_phase_samples(N_BATCH, angles, preferred_angle, sigma):
    # Convert angles list to a tensor
    angles_tensor = torch.tensor(angles)

    # Calculate Gaussian probability distribution centered at preferred_angle
    probs = np.exp(-0.5 * ((angles - preferred_angle) / sigma) ** 2)
    probs /= probs.sum()  # Normalize to get probabilities

    # Create a categorical distribution from the computed probabilities
    distribution = torch.distributions.Categorical(torch.tensor(probs))

    # Sample from the distribution
    indices = distribution.sample((N_BATCH,))

    # Map indices to angles and reshape to (N_BATCH, 1)
    phase_samples = angles_tensor[indices].reshape(N_BATCH, 1)

    return phase_samples
#+end_src

#+RESULTS:

#+begin_src ipython
import torch
import numpy as np
import matplotlib.pyplot as plt

def continuous_biased_phases(N_BATCH, preferred_angle, sigma):
    # Generate samples from a normal distribution using PyTorch
    phase_samples = torch.normal(mean=preferred_angle, std=sigma, size=(N_BATCH, 1))

    # Normalize angles to the range [0, 360)
    phase_samples = phase_samples % 360

    return phase_samples

# Parameters
N_BATCH = 1000
reference = 180  # Example preferred angle
sigma = 75.0  # Standard deviation of the Gaussian

# Generate continuous samples
phase_samples = continuous_biased_phases(N_BATCH, reference, sigma)
print(phase_samples.shape)
# Convert to numpy for plotting
phase_samples_np = phase_samples.numpy()

plt.hist(phase_samples_np[:, 0], bins=36, range=(0, 360))
plt.xlabel('Angle (degrees)')
plt.ylabel('Frequency')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: torch.Size([1000, 1])
[[./figures/odr_sb/figure_8.png]]
:END:


#+begin_src ipython

#+end_src

#+RESULTS:

* Model

#+begin_src ipython
REPO_ROOT = "/home/leon/models/NeuroFlame"
conf_name = "test_odr_EI.yml"
DEVICE = 'cuda:1'
seed = np.random.randint(0, 1e6)
print(seed)

seed = 181678
seed = 1975532
seed = 1975

IF_BIASED_PHASES = 0
IF_BIAS = 1

reference = 0.  # Example preferred angle
sigma = 75.  # Standard deviation of the Gaussian
#+end_src

#+RESULTS:
: 527944

#+begin_src ipython
model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=1)
#+end_src

#+RESULTS:

#+begin_src ipython
if IF_BIAS:
    print('Biased ODR')
    model_state_dict = torch.load('models/odr_bias_%d_ref_%d.pth' % (reference, seed) )
    # model_state_dict = torch.load('models/odr_bias_%d.pth' % seed)
else:
    model_state_dict = torch.load('models/odr_%d.pth' % seed)

model.load_state_dict(model_state_dict)
model.eval()
#+end_src

#+RESULTS:
:RESULTS:
: Biased ODR
: Network(
:   (dropout): Dropout(p=0.0, inplace=False)
: )
:END:

#+begin_src ipython
print(model.J_STP)
#+end_src

#+RESULTS:
: Parameter containing:
: tensor(26.5926, device='cuda:1', requires_grad=True)

* Batching Inputs Sequentially

#+begin_src ipython
N_BATCH = 800
model.N_BATCH = N_BATCH

if IF_BIASED_PHASES:
    model.PHI0 = torch.zeros(size=(N_BATCH, 3, 1), device=DEVICE, dtype=torch.float)
    model.PHI0[:, 0] = continuous_biased_phases(N_BATCH, reference, sigma)
    model.PHI0[:, -1] = continuous_biased_phases(N_BATCH, reference, sigma)
else:
    model.PHI0 = torch.randint(low=0, high=360, size=(N_BATCH, 3, 1), device=DEVICE, dtype=torch.float)

ff_input = model.init_ff_input()

m0, m1, phase = decode_bump_torch(ff_input[..., model.slices[0]], axis=-1)
# m0, m1, phase = compute_fourier_moments(ff_input[..., model.slices[0]], dim=-1)
window_size = int((model.N_STIM_ON[0]-model.N_STEADY+1) / model.N_WINDOW)
#+end_src

#+RESULTS:
: torch.Size([1, 750]) torch.Size([800, 1])
: torch.Size([1, 750]) torch.Size([800, 1])
: torch.Size([1, 750]) torch.Size([800, 1])

#+begin_src ipython
idx = np.random.randint(32)
xtime = np.linspace(0, model.DURATION, phase.shape[-1])
plt.plot(xtime, phase[idx].cpu().detach().numpy() * 180 / np.pi)
plt.axhline(model.PHI0[idx,0,0].cpu() * 180/np.pi, color='k', ls='--')

print(model.PHI0[idx, 0, 0].cpu()*180/np.pi)
# print(phase[idx, window_size].cpu().detach().numpy() * 180 / np.pi)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: tensor(172.)
[[./figures/odr_sb/figure_15.png]]
:END:

#+begin_src ipython
# model.N_BATCH = 96
# ff_input = []
# labels = []

# phase_list =  torch.tensor([  0.,  45.,  90., 135., 180., 225., 270., 315.], device=DEVICE)

# model.PHI0 = torch.ones((model.N_BATCH, 3, 1), device=DEVICE, dtype=torch.float
#                         )

# for i in range(len(phase_list)):
#     model.PHI0[:, 0] = phase_list[i]
#     model.PHI0[:, -1] = phase_list[torch.randint(0, len(phase_list), (model.N_BATCH,))].unsqueeze(1)

#     label0 = torch.ones(model.N_BATCH, device=DEVICE, dtype=torch.float) * model.PHI0[:, 0, 0] * torch.pi / 180.0
#     label1 = torch.ones(model.N_BATCH, device=DEVICE, dtype=torch.float) * model.PHI0[:, -1, 0] * torch.pi / 180.0

#     labels.append(torch.vstack((label0, label1)))
#     ff_input.append(model.init_ff_input())

# labels = torch.hstack(labels).T
# ff_input = torch.vstack(ff_input)
# print('ff_input', ff_input.shape, 'labels', labels.shape)
# PHI0 = labels.unsqueeze(-1)
#+end_src

#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].hist(model.PHI0[:, 0, 0].cpu(), bins=15)
ax[1].hist(model.PHI0[:,-1, 0].cpu(), bins=15)
plt.show()
 #+end_src

#+RESULTS:
[[./figures/odr_sb/figure_17.png]]

#+begin_src ipython
rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
print('rates', rates.shape)
#+end_src

#+RESULTS:
: rates (800, 91, 750)

#+begin_src ipython
m0, m1, phi = decode_bump(rates, axis=-1)
# m0, m1, phi = get_fourier_moments(rates, axis=-1)
# m0, m1, phi = compute_fourier_moments(rates, dim=-1)
# print(phi.shape)
#+end_src

#+RESULTS:

#+begin_src ipython
idx = np.random.randint(32)
xtime = np.linspace(0, model.DURATION, phi.shape[-1])
plt.plot(xtime, phi[idx]* 180 / np.pi)
plt.axhline(model.PHI0[idx,0,0].cpu() * 180/np.pi, color='k', ls='--')

print(model.PHI0[idx, 0, 0].cpu()*180/np.pi)
# print(phi[idx, window_size]* 180 / np.pi)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: tensor(172.)
[[./figures/odr_sb/figure_20.png]]
:END:

* Results
** Rates

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.5*width, height])

idx = np.random.randint(0, model.N_BATCH)
ax[0].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=2, origin='lower', extent=[0, model.DURATION, 0, model.Na[0].cpu()])
ax[0].set_ylabel('Pref. Location (°)')
ax[0].set_yticks(np.linspace(0, model.Na[0].cpu(), 5), np.linspace(0, 360, 5).astype(int))
ax[0].set_xlabel('Time (s)')

xtime = np.linspace(0, model.DURATION, phi.shape[-1])
idx = np.random.randint(0, model.N_BATCH, 8)
ax[1].plot(xtime, m1[idx].T)
ax[1].set_ylabel('m1 (Hz)')
ax[1].set_xlabel('Time (s)')
add_vlines(model, ax[1])

ax[2].plot(xtime, phi[idx].T * 180 / np.pi, alpha=0.5)
ax[2].set_yticks(np.linspace(0, 360, 5).astype(int), np.linspace(0, 360, 5).astype(int))
ax[2].set_ylabel('Bump Center (°)')
ax[2].set_xlabel('Time (s)')
add_vlines(model, ax[2])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_21.png]]

#+begin_src ipython
PHI0 = model.PHI0.cpu().detach().numpy() * 180.0 / np.pi
print(PHI0.shape)

idx = np.random.randint(0, 32)
print(PHI0[idx, 0, 0])
window_size = int((model.N_STIM_ON[1]-model.N_STEADY) / model.N_WINDOW)
print(phi[idx, window_size] * 180 / np.pi)
#+end_src

#+RESULTS:
: (800, 3, 1)
: 249.0
: 250.09466251516002

** errors

#+begin_src ipython
target_loc = PHI0[:, -1]

rel_loc = (PHI0[:, 0] - target_loc) * np.pi / 180.0
rel_loc = (rel_loc + np.pi) % (2 * np.pi) - np.pi
rel_loc *= 180 / np.pi

ref_loc = (PHI0[:, -1] - reference) * np.pi / 180.0
ref_loc = (ref_loc + np.pi) % (2 * np.pi) - np.pi
ref_loc *= 180 / np.pi

window_size = int((model.N_STIM_OFF[-1]-model.N_STEADY) / model.N_WINDOW)
# errors = phi - phi[:, window_size][:, np.newaxis]
errors = (phi - target_loc * np.pi / 180.0)
errors = (errors + np.pi) % (2 * np.pi) - np.pi
errors *= 180 / np.pi

window_size = int((model.N_STIM_OFF[0]-model.N_STEADY) / model.N_WINDOW)
errors2 = ((phi - PHI0[:, 0] * np.pi / 180.0))
# errors2 = phi - phi[:, window_size][:, np.newaxis]
errors2 = (errors2 + np.pi) % (2 * np.pi) - np.pi
errors2 *= 180 / np.pi

print(errors.shape, target_loc.shape, rel_loc.shape, ref_loc.shape)
#+end_src

#+RESULTS:
: (800, 91) (800, 1) (800, 1) (800, 1)

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].plot(np.linspace(0, model.DURATION, errors.shape[-1]), errors2[:32].T)
add_vlines(model, ax[0])
# ax[0].set_xlim([2.5, 4.5])
ax[0].set_xlabel('t')
ax[0].set_ylabel('prev. error (°)')

ax[1].plot(np.linspace(0, model.DURATION, errors.shape[-1]), errors[:32].T)
add_vlines(model, ax[1])
ax[1].set_xlabel('t')
ax[1].set_ylabel('curr. error (°)')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_24.png]]

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.75*width, height])
ax[0].hist(rel_loc[:, 0], bins='auto')
ax[0].set_xlabel('Rel. Location (°)')

ax[1].hist(errors2[:, int((model.N_STIM_ON[1]-model.N_STEADY)/model.N_WINDOW)], bins='auto')
ax[1].set_xlabel('Prev. Errors (°)')

ax[2].hist(errors[:, -1], bins=64)
ax[2].set_xlabel('Curr. Errors (°)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_25.png]]

#+begin_src ipython
mask = np.abs(errors) <= 450
print(mask.shape)

errors = np.where(mask, errors, np.nan)[:, -1]
print(errors.shape)
rel_loc = rel_loc[~np.isnan(errors)]
ref_loc = ref_loc[~np.isnan(errors)]
target_loc = target_loc[:, -1][~np.isnan(errors), np.newaxis]
errors = errors[~np.isnan(errors), np.newaxis]
# errors = errors[mask]
print(errors.shape, target_loc.shape, rel_loc.shape, ref_loc.shape)
#+end_src

#+RESULTS:
: (800, 91)
: (800,)
: (800, 1) (800, 1) (800, 1) (800, 1)

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.75*width, height])
ax[0].hist(rel_loc[:, 0], bins='auto')
ax[0].set_xlabel('Rel. Location (°)')

ax[1].hist(errors2[:, int((model.N_STIM_ON[1]-model.N_STEADY)/model.N_WINDOW)], bins='auto')
ax[1].set_xlabel('Prev. Errors (°)')

ax[2].hist(errors[:, -1], bins='auto')
ax[2].set_xlabel('Curr. Errors (°)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_27.png]]

** biases

#+begin_src ipython
   df_naive = pkl_load('df_naive', path="./figures/odr")
#+end_src

#+RESULTS:
: loading from ./figures/odr/df_naive.pkl

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[3*width, height])

n_bins=12
ax[0].plot(df_naive['target_loc'], df_naive['errors'], 'o', alpha=.1)
ax[0].set_xlabel('Target Loc. (°)')
ax[0].set_ylabel('Error (°)')

from scipy.stats import binned_statistic
stt = binned_statistic(df_naive['target_loc'], df_naive['errors'], statistic='mean', bins=n_bins, range=[0, 360])
dstt = np.mean(np.diff(stt.bin_edges))
ax[0].plot(stt.bin_edges[:-1]+dstt/2,stt.statistic,'r')

ax[0].axhline(color='k', linestyle=":")

ax[1].plot(rel_loc[:, 0], errors[:,-1], 'bo', alpha=.1)
# ax[1].plot(rel_loc2[:, 0], errors2[:,-1], 'ro')
ax[1].set_xlabel('Rel. Loc. (°)')
ax[1].set_ylabel('Error (°)')

stt = binned_statistic(rel_loc[:, 0], errors[:, -1], statistic='mean', bins=n_bins, range=[-180, 180])
dstt = np.mean(np.diff(stt.bin_edges))
ax[1].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')

ax[2].plot(ref_loc[:, 0], errors[:,-1], 'bo', alpha=.1)
# ax[2].plot(ref_loc2[:, 0], errors2[:,-1], 'ro')
ax[2].set_xlabel('Ref. Loc. (°)')
ax[2].set_ylabel('Error (°)')

stt = binned_statistic(ref_loc[:, 0], errors[:, -1], statistic='mean', bins=n_bins, range=[-180, 180])
dstt = np.mean(np.diff(stt.bin_edges))
ax[2].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')

# stt = binned_statistic(rel_loc2[:, 0], errors2[:, -1], statistic='mean', bins=6, range=[-180, 180])
# dstt = np.mean(np.diff(stt.bin_edges))
# ax[1].plot(stt.bin_edges[:-1]+dstt/2,stt.statistic, 'r')
# ax[1].set_ylim([-120, 120])
# ax[1].axhline(color='k', linestyle=":")

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_29.png]]


#+begin_src ipython
data = pd.DataFrame({'target_loc': target_loc[:, -1], 'rel_loc': rel_loc[:, -1], 'errors': errors[:, -1], 'ref_loc': ref_loc[:, -1]})
n_bins = 16
angle_min = 0
angle_max = 360

bin_edges = np.linspace(angle_min, angle_max, n_bins + 1)
data['bin_target'] = pd.cut(data['target_loc'], bins=bin_edges, include_lowest=True)

mean_errors_per_bin = data.groupby('bin_target')['errors'].mean()
data['adjusted_errors'] = data.apply(
    lambda row: row['errors'] - mean_errors_per_bin.loc[row['bin_target']],
    axis=1
)

if IF_BIAS:
   df_naive['bin_target'] = pd.cut(df_naive['target_loc'], bins=bin_edges, include_lowest=True)

   mean_errors_per_bin = df_naive.groupby('bin_target')['errors'].mean()
   data['errors_naive'] = data.apply(
      lambda row: row['errors'] - mean_errors_per_bin.loc[row['bin_target']],
      axis=1
   )

bin_target = data.groupby('bin_target')['adjusted_errors'].agg(['mean', 'sem']).reset_index()
edges = bin_target['bin_target'].cat.categories
target_centers = (edges.left + edges.right) / 2

data['bin_rel'] = pd.cut(data['rel_loc'], bins=n_bins)
bin_rel = data.groupby('bin_rel')['adjusted_errors'].agg(['mean', 'sem']).reset_index()

edges = bin_rel['bin_rel'].cat.categories
centers = (edges.left + edges.right) / 2

data['bin_ref'] = pd.cut(data['ref_loc'], bins=n_bins)
if IF_BIAS:
   bin_ref = data.groupby('bin_ref')['errors_naive'].agg(['mean', 'sem']).reset_index()
else:
   bin_ref = data.groupby('bin_ref')['adjusted_errors'].agg(['mean', 'sem']).reset_index()

ref_edges = bin_ref['bin_ref'].cat.categories
ref_centers = (ref_edges.left + ref_edges.right) / 2
#+end_src

#+RESULTS:

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[3*width, height])
ax[0].plot(centers, bin_target['mean'], 'b')
ax[0].fill_between(centers,
                   bin_target['mean'] - bin_target['sem'],
                   bin_target['mean'] + bin_target['sem'],
                   color='b', alpha=0.2)

ax[0].axhline(color='k', linestyle=":")
ax[0].set_xlabel('Target Loc. (°)')
ax[0].set_ylabel('Curr. Error (°)')

ax[1].plot(centers, bin_rel['mean'], 'b')
ax[1].fill_between(centers,
                bin_rel['mean'] - bin_rel['sem'],
                bin_rel['mean'] + bin_rel['sem'],
                color='b', alpha=0.2)

ax[1].axhline(color='k', linestyle=":")
ax[1].set_xlabel('Rel. Loc. (°)')
ax[1].set_ylabel('Curr. Error (°)')

ax[2].plot(ref_centers, bin_ref['mean'], 'b')
ax[2].fill_between(ref_centers,
                bin_ref['mean'] - bin_ref['sem'],
                bin_ref['mean'] + bin_ref['sem'],
                color='b', alpha=0.2)

ax[2].axhline(color='k', linestyle=":")
ax[2].set_xlabel('Ref. Loc. (°)')
ax[2].set_ylabel('Curr. Error (°)')

if IF_BIAS:
    plt.savefig('./figures/odr/odr_biases_train.svg', dpi=300)
else:
    plt.savefig('./figures/odr/odr_biases_naive.svg', dpi=300)

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr_sb/figure_31.png]]


#+begin_src ipython
if IF_BIAS==0:
   pkl_save(data, 'df_naive', path="./figures/odr")
#+end_src

#+RESULTS:
