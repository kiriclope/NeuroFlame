#+STARTUP: fold
#+TITLE: Training Low Rank RNNs
#+PROPERTY: header-args:ipython :var B0="1.0" :results both :exports both :async yes :session dual_rd :kernel torch :tangle ./train.py

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run ../notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'

REPO_ROOT = "/home/leon/models/NeuroFlame"
pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
import torch
import torch.nn as nn
import torch.optim as optim
import torchmetrics
from torch.utils.data import Dataset, TensorDataset, DataLoader

DEVICE = 'cuda:0'
#+end_src

#+RESULTS:

#+begin_src ipython
import sys
sys.path.insert(0, '../')

import pandas as pd
import torch.nn as nn
from time import perf_counter
from scipy.stats import circmean

from src.network import Network
from src.plot_utils import plot_con
from src.decode import decode_bump, circcvl
from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

* Helpers
** Data Split

#+begin_src ipython
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

def split_data(X, Y, train_perc=0.8, batch_size=32):

    if Y.ndim==3:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0, 0].cpu().numpy(),
                                                          shuffle=True)
    else:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0].cpu().numpy(),
                                                          shuffle=True)

    print(X_train.shape, X_test.shape)
    print(Y_train.shape, Y_test.shape)

    train_dataset = TensorDataset(X_train, Y_train)
    val_dataset = TensorDataset(X_test, Y_test)

    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
def torch_angle_AB(U, V):
      # Calculate the dot product
      dot_product = torch.dot(U, V)

      # Calculate the magnitudes of U and V
      magnitude_U = torch.linalg.norm(U)
      magnitude_V = torch.linalg.norm(V)

      # Compute the cosine of the angle
      cos_theta = dot_product / (magnitude_U * magnitude_V + .00001)

      # Calculate the angle in radians, then convert to degrees
      angle_radians = torch.acos(cos_theta)
      return torch.round(torch.rad2deg(angle_radians))
#+end_src

#+RESULTS:

#+begin_src ipython
def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1, clip_grad=0, zero_grad=None):

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          X, y = X.to(model.device), y.to(model.device)

          rates = model(X)
          loss = loss_fn(model.readout, y)

          loss.backward()

          if zero_grad is not None:
              try:
                  model.low_rank.U.grad[:, zero_grad] = 0
                  model.low_rank.V.grad[:, zero_grad] = 0
              except:
                  pass

          if clip_grad:
              torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
              #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)

          optimizer.step()
          optimizer.zero_grad()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
def validation_step(dataloader, model, loss_fn):
      num_batches = len(dataloader)
      model.eval()

      val_loss = 0.0
      with torch.no_grad():
          for X, y in dataloader:
              X, y = X.to(model.device), y.to(model.device)

              rates = model(X)
              loss = loss_fn(model.readout, y)
              val_loss += loss.item()

          val_loss /= num_batches

      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
def optimization(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=.005, zero_grad=None):
      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')
      model.to(device)

      loss_list = []
      val_loss_list = []
      angle_list = []

      for epoch in range(num_epochs):
          loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, zero_grad=zero_grad)
          val_loss = validation_step(val_loader, model, loss_fn)

          scheduler.step(val_loss)
          loss_list.append(loss.item())
          val_loss_list.append(val_loss)

          memory = model.low_rank.U[model.slices[0], 0]
          readout = model.low_rank.V[model.slices[0], 1]

          angle = torch_angle_AB(memory, readout).item()
          angle_list.append(angle)

          print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}, Angle(U, W) : {angle} Â°')

          if val_loss < thresh and loss < thresh:
              print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')
              break

          if val_loss > 300:
              print(f'Stopping training as loss is too high: {val_loss}')
              break

          if torch.isnan(loss):
              print(f'Stopping training as loss is NaN.')
              break

      return loss_list, val_loss_list
#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
def imbalance_func(target, imbalance):
    output = torch.zeros_like(target)

    output[target == 0] = imbalance
    output[target == 1] = 1

    return output
#+end_src

#+RESULTS:

#+begin_src ipython
import torch
import torch.nn as nn
import torch.nn.functional as F

class SignBCELoss(nn.Module):
      def __init__(self, alpha=1.0, thresh=4.0, imbalance=0):
            super(SignBCELoss, self).__init__()
            self.alpha = alpha
            self.thresh = thresh

            self.imbalance = imbalance
            self.bce_with_logits = nn.BCEWithLogitsLoss()

      def forward(self, readout, targets):
            if self.alpha != 1.0:
                  bce_loss = self.bce_with_logits(readout, targets)
            else:
                  bce_loss = 0.0

            # average readout over bins
            mean_readout = readout.mean(dim=1).unsqueeze(-1)

            # only penalizing not licking when pair
            if self.imbalance == -1:
                  sign_overlap = torch.sign(targets) * mean_readout
                  self.imbalance = 0
            else:
                  sign_overlap = torch.sign(2 * targets - 1) * mean_readout

            if self.imbalance > 1.0:
                  sign_loss = F.relu(torch.sign(targets) * self.thresh - imbalance_func(targets, self.imbalance) * sign_overlap)
            elif self.imbalance == 0:
                  sign_loss = F.relu(imbalance_func(targets, self.imbalance) * self.thresh - sign_overlap)
            else:
                  sign_loss = F.relu(self.thresh - sign_overlap)

            combined_loss = (1-self.alpha) * bce_loss + self.alpha * sign_loss

            return combined_loss.mean()

#+end_src

#+RESULTS:

#+begin_src ipython
class DualLoss(nn.Module):
      def __init__(self, alpha=1.0, thresh=4.0, cue_idx=[], rwd_idx=-1, zero_idx=[], read_idx=-1, imbalance=0):
            super(DualLoss, self).__init__()
            self.alpha = alpha
            self.thresh = thresh

            self.imbalance = imbalance

            # BL idx
            self.zero_idx = zero_idx
            # rwd idx for DRT
            self.cue_idx = torch.tensor(cue_idx, dtype=torch.int, device=DEVICE)
            # rwd idx for DPA
            self.rwd_idx = torch.tensor(rwd_idx, dtype=torch.int, device=DEVICE)

            # readout idx
            self.read_idx = read_idx

            self.loss = SignBCELoss(self.alpha, self.thresh, self.imbalance)
            self.l1loss = nn.SmoothL1Loss()
            # self.l1loss = nn.MSELoss()

      def forward(self, readout, targets):

            zeros = torch.zeros_like(readout[:, self.zero_idx])
            BL_loss = self.l1loss(readout[:, self.zero_idx], zeros)

            is_empty = (self.cue_idx.numel() == 0)

            if is_empty:
                  DPA_loss = self.loss(readout[:,  self.rwd_idx, self.read_idx], targets)
                  return DPA_loss + BL_loss
            else:
                  self.loss.imbalance = self.imbalance[0]
                  DPA_loss = self.loss(readout[:,  self.rwd_idx, self.read_idx], targets[:, 0, :self.rwd_idx.shape[0]])

                  self.loss.imbalance = self.imbalance[1]
                  DRT_loss = self.loss(readout[:, self.cue_idx, self.read_idx], targets[:, 1, :self.cue_idx.shape[0]])

                  return DPA_loss + DRT_loss + BL_loss
#+end_src

#+RESULTS:

** Other

#+begin_src ipython
def angle_AB(A, B):
      A_norm = A / (np.linalg.norm(A) + 1e-5)
      B_norm = B / (np.linalg.norm(B) + 1e-5)

      return int(np.arccos(A_norm @ B_norm) * 180 / np.pi)
#+end_src

#+RESULTS:

#+begin_src ipython
def get_theta(a, b, GM=0, IF_NORM=0):

      u, v = a, b

      if GM:
          v = b - np.dot(b, a) / np.dot(a, a) * a

      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)

      return np.arctan2(v, u) % (2.0 * np.pi)
#+end_src

#+RESULTS:

#+begin_src ipython
def get_idx(model, rank=2):
      ksi = torch.hstack((model.low_rank.U, model.low_rank.V)).T
      ksi = ksi[:, :model.Na[0]]

      try:
            readout = model.low_rank.linear.weight.data
            ksi = torch.vstack((ksi, readout))
      except:
            pass

      print('ksi', ksi.shape)

      ksi = ksi.cpu().detach().numpy()
      theta = get_theta(ksi[0], ksi[rank])

      return theta.argsort()
#+end_src

#+RESULTS:

#+begin_src ipython
def get_overlap(model, rates):
      ksi = model.odors.cpu().detach().numpy()
      return rates @ ksi.T / rates.shape[-1]
#+end_src

#+RESULTS:

#+begin_src ipython
import scipy.stats as stats

def plot_smooth(data, ax, color):
      mean = data.mean(axis=0)
      ci = smooth.std(axis=0, ddof=1) * 1.96

      # Plot
      ax.plot(mean, color=color)
      ax.fill_between(range(data.shape[1]), mean - ci, mean + ci, alpha=0.25, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

** plots

#+begin_src ipython
def add_vlines(ax=None, mouse=""):
    t_BL = [0, 1]
    t_STIM = [1 , 2]
    t_ED = [2, 3]
    t_DIST = [3 , 4]
    t_MD = [4 , 5]
    t_CUE = [5 , 5.5]
    t_RWD = [5.5, 6.0]
    t_LD = [6.0 , 7.0]
    t_TEST = [7.0, 8.0]
    t_RWD2 = [11 , 12]

    time_periods = [t_STIM, t_DIST, t_TEST, t_CUE]
    colors = ["b", "b", "b", "g"]

    if ax is None:
        for period, color in zip(time_periods, colors):
            plt.axvspan(period[0], period[1], alpha=0.1, color=color)
    else:
        for period, color in zip(time_periods, colors):
            ax.axvspan(period[0], period[1], alpha=0.1, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
def plot_rates_selec(rates, idx, thresh=0.5, figname='fig.svg'):
        ordered = rates[..., idx]
        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
        r_max = thresh * np.max(rates[0])

        ax[0].imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[0].set_ylabel('Neuron #')
        ax[0].set_xlabel('Step')

        ax[1].imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[1].set_yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))
        ax[1].set_ylabel('Pref. Location (Â°)')
        ax[1].set_xlabel('Step')
        plt.savefig(figname, dpi=300)
        plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_overlap(rates, memory, readout, labels=['A', 'B'], figname='fig.svg'):
      fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
      overlap =(rates @ memory) / rates.shape[-1]

      time = np.linspace(0, 8, overlap.T.shape[0])
      if overlap.shape[0]>2:
          ax[0].plot(time, overlap.T[..., :2], label=labels[0])
          ax[0].plot(time, overlap.T[..., 2:], '--', label=labels[1])
      else:
          ax[0].plot(time, overlap.T[..., 0], label=labels[0])
          ax[0].plot(time, overlap.T[..., 1], '--', label=labels[1])

      ax[0].set_xlabel('Time (s)')
      ax[0].set_ylabel('Sample Overlap (Hz)')
      # ax[0].set_title('Memory')
      add_vlines(ax[0])
      overlap =(rates @ readout) / rates.shape[-1]

      if overlap.shape[0]>2:
          ax[1].plot(time, overlap.T[..., :2], label=labels[0])
          ax[1].plot(time, overlap.T[..., 2:], '--', label=labels[1])
      else:
          ax[1].plot(time, overlap.T[..., 0], label=labels[0])
          ax[1].plot(time, overlap.T[..., 1], '--', label=labels[1])

      ax[1].set_xlabel('Time (s)')
      ax[1].set_ylabel('Readout (Hz)')
      # ax[1].set_title('Readout')
      add_vlines(ax[1])

      # plt.legend(fontsize=10, frameon=False)
      plt.savefig(figname, dpi=300)
      plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
def plot_m0_m1_phi(rates, idx, figname='fig.svg'):

      m0, m1, phi = decode_bump(rates[..., idx], axis=-1)
      fig, ax = plt.subplots(1, 3, figsize=[3*width, height])

      time = np.linspace(0, 8, m0.T.shape[0])

      ax[0].plot(time, m0[:2].T)
      ax[0].plot(time, m0[2:].T, '--')
      #ax[0].set_ylim([0, 360])
      #ax[0].set_yticks([0, 90, 180, 270, 360])
      ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
      ax[0].set_ylabel('Activity (Hz)')
      ax[0].set_xlabel('Time (s)')
      add_vlines(ax[0])

      ax[1].plot(time, m1[:2].T)
      ax[1].plot(time, m1[2:].T, '--')
      # ax[1].set_ylim([0, 360])
      # ax[1].set_yticks([0, 90, 180, 270, 360])
      ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
      ax[1].set_ylabel('Bump Amplitude (Hz)')
      ax[1].set_xlabel('Time (s)')
      add_vlines(ax[1])

      ax[2].plot(time, phi[:2].T * 180 / np.pi)
      ax[2].plot(time, phi[2:].T * 180 / np.pi, '--')
      ax[2].set_ylim([0, 360])
      ax[2].set_yticks([0, 90, 180, 270, 360])
      ax[2].set_ylabel('Bump Center (Â°)')
      ax[2].set_xlabel('Time (s)')
      add_vlines(ax[2])

      plt.savefig(figname, dpi=300)
      plt.show()
    #+end_src

#+RESULTS:

* Model

#+begin_src ipython
REPO_ROOT = "/home/leon/models/NeuroFlame"
conf_name = "train_dual_rd.yml"
DEVICE = 'cuda:0'

N_BATCH = 512

seed = np.random.randint(0, 1e6)
# seed = 21881
print(seed)
# 789395
# 453642
# : 577806

A0 = 1.0
B0 = 1.0
C0 = 0.0
#+end_src

#+RESULTS:
: 345650

#+begin_src ipython
model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH)
print(model.device)
# model.odors[2] = model.odors[1] # cue same as Go
#+end_src

#+RESULTS:
: cuda:0

* Sample Classification
** Training
*** Parameters

#+begin_src ipython
for name, param in model.named_parameters():
    if param.requires_grad:
        print(name, param.shape)
#+end_src

#+RESULTS:
: J_STP torch.Size([])
: low_rank.U torch.Size([750, 2])
: low_rank.V torch.Size([750, 2])
: low_rank.lr_kappa torch.Size([1])

Testing the network on steps from sample odor offset to test odor onset

#+begin_src ipython
steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
rwd_idx = np.where(mask)[0]
print('rwd', rwd_idx)

model.lr_eval_win = rwd_idx.shape[0]

stim_mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0].cpu().numpy() - model.N_STEADY))

zero_idx = np.where(~mask & ~stim_mask )[0]
print('zero', zero_idx)
#+end_src

#+RESULTS:
: rwd [10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33
:  34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
:  58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80]
: zero [0 1 2 3 4 5 6 7 8 9]

#+begin_src ipython
model.N_BATCH = N_BATCH
rwd_mask = torch.zeros((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)), device=DEVICE, dtype=torch.bool)
print('rwd_mask', rwd_mask.shape)

for i in range(model.N_BATCH):
    # from first stim onset to second stim onset
    mask = torch.arange((model.start_indices[0, i] - model.N_STEADY)/ model.N_WINDOW,
                        (model.N_STEPS - model.N_STEADY) / model.N_WINDOW).to(torch.int)
    # print(mask)
    rwd_mask[i, mask] = True

idx = np.random.randint(N_BATCH)
print('rwd_idx', torch.where(rwd_mask[idx]==1)[0])
print('zero_idx', torch.where(rwd_mask[idx]==0)[0])
#+end_src

#+RESULTS:
: rwd_mask torch.Size([512, 81])
: rwd_idx tensor([15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,
:         33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,
:         51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,
:         69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], device='cuda:0')
: zero_idx tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],
:        device='cuda:0')


*** Inputs and Labels

#+begin_src ipython
mask = torch.tensor([1, 0, 0, 1])
sign = (2 * torch.randint(0, 2, (32, 4))-1)

I0 = sign * mask
label = torch.prod(torch.sign(I0[I0!=0]))

print(I0.shape, label.shape)
#+end_src

#+RESULTS:
: torch.Size([32, 4]) torch.Size([])

#+begin_src ipython
    if IF_BIASED_PHASES:
        labels = continuous_biased_phases(N_BATCH, reference, sigma)
    else:
        labels = torch.randint(0, 360, (N_BATCH, 1)).to(DEVICE)

    model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)
    model.PHI0[:, 0] = labels * np.pi / 180.0

    window_size = int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)
    labels = labels.repeat(1, window_size) * np.pi / 180.0
    labels[~rwd_mask] = -999

    ff_input = model.init_ff_input()
    print(model.PHI0.shape, ff_input.shape, labels.shape)
#+end_src

#+RESULTS:
: 37e08c22-3021-4470-bc46-a2728333bf24

#+begin_src ipython
model.N_BATCH = 128

model.I0[0] = A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

A = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

B = model.init_ff_input()

ff_input = torch.cat((A, B))
print(ff_input.shape)
#+end_src

#+RESULTS:
: 4af26625-ecb8-4dcd-9c98-9894601e4d23

#+begin_src ipython
labels_A = torch.ones((model.N_BATCH, rwd_idx.shape[0]))
labels_B = torch.zeros((model.N_BATCH, rwd_idx.shape[0]))
labels = torch.cat((labels_A, labels_B))

print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([256, 61])

*** Run

#+begin_src ipython
batch_size = 16
train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([204, 505, 1000]) torch.Size([52, 505, 1000])
: torch.Size([204, 61]) torch.Size([52, 61])

#+begin_src ipython
criterion = DualLoss(alpha=1.0, thresh=5.0, rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=1, read_idx=0)
learning_rate = 0.1
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
num_epochs = 15
start = perf_counter()
loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=1)
end = perf_counter()
print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
#+begin_example
Epoch 1/15, Training Loss: 4.9847, Validation Loss: 4.9868, Angle(U, W) : 86.0 Â°
Epoch 2/15, Training Loss: 4.9760, Validation Loss: 4.9748, Angle(U, W) : 86.0 Â°
Epoch 3/15, Training Loss: 4.9575, Validation Loss: 4.9285, Angle(U, W) : 86.0 Â°
Epoch 4/15, Training Loss: 4.7284, Validation Loss: 4.6973, Angle(U, W) : 86.0 Â°
Epoch 5/15, Training Loss: 3.5876, Validation Loss: 3.5735, Angle(U, W) : 87.0 Â°
Epoch 6/15, Training Loss: 0.6132, Validation Loss: 0.0923, Angle(U, W) : 88.0 Â°
Epoch 7/15, Training Loss: 0.1722, Validation Loss: 0.0706, Angle(U, W) : 87.0 Â°
Epoch 8/15, Training Loss: 0.0284, Validation Loss: 0.0248, Angle(U, W) : 87.0 Â°
Epoch 9/15, Training Loss: 0.0038, Validation Loss: 0.0108, Angle(U, W) : 87.0 Â°
Epoch 10/15, Training Loss: 0.0053, Validation Loss: 0.0121, Angle(U, W) : 87.0 Â°
Epoch 11/15, Training Loss: 0.0069, Validation Loss: 0.0077, Angle(U, W) : 87.0 Â°
Epoch 12/15, Training Loss: 0.0059, Validation Loss: 0.0060, Angle(U, W) : 87.0 Â°
Epoch 13/15, Training Loss: 0.0059, Validation Loss: 0.0051, Angle(U, W) : 87.0 Â°
Epoch 14/15, Training Loss: 0.0081, Validation Loss: 0.0050, Angle(U, W) : 87.0 Â°
Epoch 15/15, Training Loss: 0.0050, Validation Loss: 0.0083, Angle(U, W) : 87.0 Â°
Elapsed (with compilation) = 0h 2m 45s
#+end_example

** Testing

 #+begin_src ipython
model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights()
:   (dropout): Dropout(p=0.0, inplace=False)
: )

#+begin_src ipython
model.N_BATCH = 10

model.I0[0] = 2
model.I0[1] = 0
model.I0[2] = 0

A = model.init_ff_input()

model.I0[0] = -2
model.I0[1] = 0
model.I0[2] = 0

B = model.init_ff_input()

ff_input = torch.cat((A, B))
print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([20, 505, 1000])

#+begin_src ipython
rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
print('rates', rates.shape)
#+end_src

#+RESULTS:
: rates (20, 81, 750)

#+begin_src ipython
memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
# readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
plot_overlap(rates, memory, readout, labels=['A', 'B'])
#+end_src

#+RESULTS:
[[./.ob-jupyter/0558c055efde43cb867c271aa09733f5464fea8f.png]]

#+begin_src ipython
idx = get_idx(model, -1)
plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([4, 750])
[[./.ob-jupyter/5a8e782fe21587850a4b7d8ddcd1f236215d1ff3.png]]
:END:

#+begin_src ipython
plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[./.ob-jupyter/128dfa6b9b520b40ee39a65ebe071074cc0f55d2.png]]

* DPA
** Training
*** Parameters

#+begin_src ipython
model.low_rank.lr_kappa.requires_grad = False
model.low_rank.U.data[:, 1] = torch.randn(model.low_rank.U.T.data[1].shape) * 0.01
model.low_rank.V.data[:, 1] = torch.randn(model.low_rank.U.T.data[1].shape) * 0.01

import torch.nn.init as init

# if model.LR_FIX_READ==0:
#     init.xavier_uniform_(model.low_rank.linear.weight)
#     if model.low_rank.linear.bias is not None:
#         model.low_rank.linear.bias.data.zero_()  # Common practice is to set biases to zero
#+end_src

#+RESULTS:

#+begin_src ipython
model.LR_TRAIN = 1
model.LR_READOUT = 0
model.IF_RL = 0
#+end_src

#+RESULTS:

Here we only evaluate performance from test onset to test offset

#+begin_src ipython
steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
# mask = (steps >= (model.N_STIM_OFF[2] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
mask = (steps >= (model.N_STIM_ON[4].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
rwd_idx = np.where(mask)[0]
print('rwd', rwd_idx)

model.lr_eval_win = rwd_idx.shape[0]

stim_mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0].cpu().numpy() - model.N_STEADY))

stim_mask1 = (steps >= (model.N_STIM_ON[4].cpu().numpy() - model.N_STEADY)) # & (steps < (model.N_STIM_OFF[3] - model.N_STEADY))

mask_zero = ~mask & ~stim_mask & ~stim_mask1
zero_idx = np.where(mask_zero)[0]
print('zero', zero_idx)
#+end_src

#+RESULTS:
: rwd [ 70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87
:   88  89  90  91  92  93  94  95  96  97  98  99 100]
: zero [ 0  1  2  3  4  5  6  7  8  9 20 21 22 23 24 25 26 27 28 29 30 31 32 33
:  34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
:  58 59 60 61 62 63 64 65 66 67 68 69]

#+begin_src ipython
model.N_BATCH = N_BATCH
rwd_mask = torch.zeros((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)), device=DEVICE, dtype=torch.bool)
print('rwd_mask', rwd_mask.shape)

for i in range(model.N_BATCH):
    # from first stim onset to second stim onset
    mask = torch.arange((model.start_indices[4, i] - model.N_STEADY)/ model.N_WINDOW,
                        (model.N_STEPS - model.N_STEADY) / model.N_WINDOW).to(torch.int)
    # print(mask)
    rwd_mask[i, mask] = True

idx = np.random.randint(N_BATCH)
print('rwd_idx', torch.where(rwd_mask[idx]==1)[0])
print('zero_idx', torch.where(rwd_mask[idx]==0)[0])
#+end_src

#+RESULTS:
: rwd_mask torch.Size([128, 101])
: rwd_idx tensor([ 87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100],
:        device='cuda:1')
: zero_idx tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
:         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
:         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,
:         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86],
:        device='cuda:1')

*** Inputs and Labels

#+begin_src ipython
model.N_BATCH = 128

model.I0[0] = A0 # sample
model.I0[1] = 0 # distractor
model.I0[2] = 0 # cue
model.I0[3] = 0 # drt rwd
model.I0[4] = A0 # test

AC_pair = model.init_ff_input()

model.I0[0] = A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = -A0

AD_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = A0

BC_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = -A0

BD_pair = model.init_ff_input()

ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([512, 505, 1000])

 #+begin_src ipython
labels_pair = torch.ones((2 * model.N_BATCH, model.lr_eval_win))
labels_unpair = torch.zeros((2 * model.N_BATCH, model.lr_eval_win))

labels = torch.cat((labels_pair, labels_unpair))
print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([512, 11])

*** Run

#+begin_src ipython
batch_size = 16
train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([409, 505, 1000]) torch.Size([103, 505, 1000])
: torch.Size([409, 11]) torch.Size([103, 11])

  #+begin_src ipython
criterion = DualLoss(alpha=1.0, thresh=5.0, rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=-1, read_idx=1)
learning_rate = 0.1
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
print('training DPA')
num_epochs = 30
start = perf_counter()
loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=0)
end = perf_counter()
print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
#+begin_example
training DPA
Epoch 1/30, Training Loss: 3.6930, Validation Loss: 2.5146, Angle(U, W) : 102.0 Â°
Epoch 2/30, Training Loss: 1.8408, Validation Loss: 2.5169, Angle(U, W) : 102.0 Â°
Epoch 3/30, Training Loss: 2.2921, Validation Loss: 2.5184, Angle(U, W) : 102.0 Â°
Epoch 4/30, Training Loss: 3.6059, Validation Loss: 2.5191, Angle(U, W) : 102.0 Â°
Epoch 5/30, Training Loss: 3.1757, Validation Loss: 2.5200, Angle(U, W) : 102.0 Â°
Epoch 6/30, Training Loss: 1.6903, Validation Loss: 2.5253, Angle(U, W) : 101.0 Â°
Epoch 7/30, Training Loss: 1.3494, Validation Loss: 2.5340, Angle(U, W) : 101.0 Â°
Epoch 8/30, Training Loss: 2.7622, Validation Loss: 2.5347, Angle(U, W) : 101.0 Â°
Epoch 9/30, Training Loss: 1.8551, Validation Loss: 2.5344, Angle(U, W) : 100.0 Â°
Epoch 10/30, Training Loss: 2.0465, Validation Loss: 2.5369, Angle(U, W) : 100.0 Â°
Epoch 11/30, Training Loss: 2.0366, Validation Loss: 2.5402, Angle(U, W) : 100.0 Â°
Epoch 12/30, Training Loss: 2.7608, Validation Loss: 2.5489, Angle(U, W) : 99.0 Â°
Epoch 14/30, Training Loss: 3.2687, Validation Loss: 2.5471, Angle(U, W) : 98.0 Â°
Epoch 15/30, Training Loss: 2.9676, Validation Loss: 2.5549, Angle(U, W) : 98.0 Â°
#+end_example

#+begin_src ipython
torch.save(model.state_dict(), 'models/dpa_%d.pth' % seed)
#+end_src

#+RESULTS:
: 2d43546d-5d2d-491c-af74-c1749e6ece59

#+begin_src ipython
plt.plot(loss)
plt.plot(val_loss)
plt.xlabel('epochs')
plt.ylabel('Loss')
plt.show()
#+end_src

#+RESULTS:
: c390c8c6-0909-4680-a490-a7ce3742c5b2

#+begin_src ipython
odors = model.odors.cpu().numpy()
U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]
W = V
# W = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]

print('   U  V  W  S  D')
print('U ', angle_AB(U, U), angle_AB(U, V), angle_AB(U, W), angle_AB(U, odors[0]), angle_AB(U, odors[1]))
print('V ', 'XXX', angle_AB(V, V), angle_AB(V, W), angle_AB(V, odors[0]), angle_AB(V, odors[1]))
print('W ', 'XXX', 'XXX', angle_AB(W, W), angle_AB(W, odors[0]), angle_AB(W, odors[1]))
print('S ', 'XXX', 'XXX', 'XXX', angle_AB(odors[0], odors[0]), angle_AB(odors[0], odors[1]))
print('D ', 'XXX', 'XXX', 'XXX', 'XXX', angle_AB(odors[1], odors[1]))

#+end_src

#+RESULTS:
: a53a6f2f-b3d2-4151-93b4-2c1d77edd494

** Testing

#+begin_src ipython
model.DURATION = 8
model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
model.eval()
#+end_src

#+RESULTS:
: 40d83c92-ec1a-45aa-9a21-eb5638468fa5

#+begin_src ipython
model.N_BATCH = 1
A0 = 1

model.I0[0] = A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = A0

AC_pair = model.init_ff_input()

model.I0[0] = A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = -A0

AD_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = A0

BC_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = -A0

BD_pair = model.init_ff_input()

ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: d5703499-218b-4179-ab59-27dd35b61051

 #+begin_src ipython
labels_pair = torch.ones((2 * model.N_BATCH, 2))
labels_unpair = torch.zeros((2 * model.N_BATCH, 2))

labels = torch.cat((labels_pair, labels_unpair))
print('labels', labels.shape)
#+end_src

#+RESULTS:
: 76961667-822c-424c-86a0-e6284c2e95ad

#+begin_src ipython
rates = model.forward(ff_input=ff_input).detach().cpu().numpy()
print(rates.shape)
#+end_src

#+RESULTS:
: 222a5322-dec2-42f5-a5d5-5b9f4a300bdc

#+begin_src ipython
print(rates.shape)
print(labels.shape)
#+end_src

#+RESULTS:
: 4ae05837-b4d8-45d4-8b78-bc7f5107a136

#+begin_src ipython
memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
# readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dpa_overlap.svg')
#+end_src

#+RESULTS:
: bb665e9a-fc1b-4b86-aa07-2c0fe468aa28

#+begin_src ipython
idx = get_idx(model, 1)
plot_rates_selec(rates, idx, figname='dpa_raster.svg')
#+end_src

#+RESULTS:
: 159fdb03-0ec3-40d0-bda5-888acb44026f

#+begin_src ipython
plot_m0_m1_phi(rates, idx, figname='dpa_fourier.svg')
#+end_src

#+RESULTS:
: 4bd1c9f8-565a-443a-ada9-984688e936ed

#+begin_src ipython

#+end_src

#+RESULTS:
: 2acb0c8f-8060-4e48-9df7-5cf1757a9287

** Fixed points

#+begin_src ipython
model.DURATION = 20
model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
model.IF_RL = 0
#+end_src

#+RESULTS:
: 5cdda485-8edd-43f7-80f4-eecdfe82a5ab

#+begin_src ipython
model.eval()
#+end_src

#+RESULTS:
: d1a2dd37-0c14-4c50-8139-591774a18570


#+begin_src ipython
model.N_BATCH = 1

model.I0[0] = A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

AC_pair = model.init_ff_input()

model.I0[0] = A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

AD_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

BC_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

BD_pair = model.init_ff_input()

ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
print('ff_input', ff_input.shape, ff_input[0, 0, :4])
#+end_src

#+RESULTS:
: 90eedd6f-b022-4ea6-9e3d-c3012a9ebf78

#+begin_src ipython
rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
print(rates.shape)
#+end_src

#+RESULTS:
: e43154ab-e39d-4cc5-9f7e-77f4a39b29ed

#+begin_src ipython
memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
# readout = model.low_rank.linear.weight.data[0].cpu().detach().numpy()
plot_overlap(rates, memory, readout, labels=['pair', 'unpair'])
#+end_src

#+RESULTS:
: 121f8a98-1d6d-42e6-b378-d47335f63279

#+begin_src ipython
idx = get_idx(model, 1)
plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
: c047cc8e-2b0f-4736-bee9-70fe471195ac

#+begin_src ipython
plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
: 5bc2bd5f-e88b-4c3a-a663-560f47aecde5

    #+begin_src ipython
print(rates.shape)
#+end_src

#+RESULTS:
: 1ec55e2a-f2fe-40df-a137-f98044cdcdb3

#+begin_src ipython
from matplotlib.patches import Circle
m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

x = m1 / m0 * np.cos(phi)
y = m1 / m0 * np.sin(phi)

xA = x
yA = y

fig, ax = plt.subplots(1, 1, figsize=[height, height])

# ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
# ax.plot(xA.T, yA.T, '-', alpha=.5)
ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=20)
# ax.set_xlim([-.9, .9])
# ax.set_ylim([-.9, .9])
circle = Circle((0., 0.), 1.8, fill=False, edgecolor='k')
ax.add_patch(circle)

# Set the aspect of the plot to equal to make the circle circular
ax.set_aspect('equal')
plt.savefig('fp_dpa.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
: 3c3a5205-24f0-45db-95dc-0923bef796d4


#+begin_src ipython

#+end_src

#+RESULTS:
: 893e7dce-29a4-4e56-955f-f7333528f296


* Go/NoGo

#+begin_src ipython
model_state_dict = torch.load('models/dpa_%d.pth' % seed)
model.load_state_dict(model_state_dict)
#+end_src

#+RESULTS:
: <All keys matched successfully>

** Training

#+begin_src ipython
model.low_rank.lr_kappa.requires_grad = False
model.J_STP.requires_grad = False

# readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
# idx = readout.argsort()[:250]
# model.low_rank.lr_mask[idx, :1000] = 0

# for param in model.low_rank.linear.parameters():
#     param.requires_grad = True

# model.low_rank.linear.bias.requires_grad = True
# model.low_rank.linear.bias.data.zero_()  # Common practice is to set biases to zero

# model.low_rank.U.requires_grad = False
# model.low_rank.V.requires_grad = False

#+end_src

#+RESULTS:

#+begin_src ipython
for name, param in model.named_parameters():
      if param.requires_grad:
            print(name, param.shape)
#+end_src

#+RESULTS:
: low_rank.U torch.Size([750, 2])
: low_rank.V torch.Size([750, 2])

#+begin_src ipython
model.DURATION = 4.0
model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW

model.T_STIM_ON =  [1.0, 3.0]
model.T_STIM_OFF =  [2.0, 4.0]

# model.T_STIM_ON =  [1.0, 3.0, 3.5]
# model.T_STIM_OFF =  [2.0, 3.5, 4.0]

model.N_STIM_ON = np.array(
    [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_ON]
)

model.N_STIM_OFF = [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_OFF]
#+end_src

#+RESULTS:

#+begin_src ipython
model.LR_TRAIN = 1
model.LR_READOUT = 0
model.IF_RL = 0 # 1
model.RWD = 2 # 1/2
#+end_src

#+RESULTS:

#+begin_src ipython
steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
# mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[1] - model.N_STEADY))
mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps <= (model.N_STIM_OFF[0] - model.N_STEADY))
# mask = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))

rwd_idx = np.where(mask)[0]
print('rwd', rwd_idx)

mask_cue = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))
# mask_cue = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY))  & (steps < (model.N_STIM_ON[1] - model.N_STEADY))
cue_idx = np.where(mask_cue)[0]

# cue_idx = []

print('cue', cue_idx)

stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) # & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))

mask_zero = ~mask & ~stim_mask
zero_idx = np.where(mask_zero)[0]
print('zero', zero_idx)

# model.lr_eval_win = rwd_idx.shape[0]
model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))
#+end_src

#+RESULTS:
: rwd [10 11 12 13 14 15 16 17 18 19 20]
: cue [30 31 32 33 34 35 36 37 38 39 40]
: zero [0 1 2 3 4 5 6 7 8 9]

#+begin_src ipython
# switching sample and distractor odors
odors = model.odors.clone()
model.odors[0] = odors[1] # distractor Go
model.odors[5] = odors[5+1] # distractor NoGo

model.odors[1] = odors[2] # cue same as Go
model.odors[2] = odors[3] # rwd

model.N_BATCH = 128

model.I0[0] = A0
model.I0[1] = float(B0) # cue
model.I0[2] = 0.0 # float(C0) * model.IF_RL  # reward
model.I0[3] = 0
model.I0[4] = 0

Go = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = float(B0) # cue
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

NoGo = model.init_ff_input()

ff_input = torch.cat((Go, NoGo))
print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([256, 305, 1000])

#+begin_src ipython
labels_Go = torch.ones((model.N_BATCH, model.lr_eval_win))
labels_NoGo = torch.zeros((model.N_BATCH, model.lr_eval_win))
labels = torch.cat((labels_Go, labels_NoGo))
print(labels.shape)
# print(labels)
labels =  labels.repeat((2, 1, 1))
labels = torch.transpose(labels, 0, 1)
print('labels', labels.shape)
#+end_src

#+RESULTS:
: torch.Size([256, 11])
: labels torch.Size([256, 2, 11])

#+begin_src ipython
batch_size = 16
train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([204, 305, 1000]) torch.Size([52, 305, 1000])
: torch.Size([204, 2, 11]) torch.Size([52, 2, 11])

#+begin_src ipython
criterion = DualLoss(alpha=1.0, thresh=5.0, rwd_idx=rwd_idx, zero_idx=zero_idx, cue_idx=cue_idx, imbalance=[1.0, -1.0])

# SGD, Adam, Adam
learning_rate = 0.1
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
print('training DRT')
num_epochs = 15
start = perf_counter()
model.readout_idx=1
loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=None)
end = perf_counter()
print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

# switching back sample and distractor odors
model.odors = odors
#+end_src

#+RESULTS:
#+begin_example
training DRT
Epoch 1/15, Training Loss: 3.3162, Validation Loss: 3.8316, Angle(U, W) : 85.0 Â°
Epoch 2/15, Training Loss: 1.1733, Validation Loss: 0.9586, Angle(U, W) : 86.0 Â°
Epoch 3/15, Training Loss: 0.0473, Validation Loss: 0.0086, Angle(U, W) : 87.0 Â°
Epoch 4/15, Training Loss: 0.0404, Validation Loss: 0.0154, Angle(U, W) : 87.0 Â°
Epoch 5/15, Training Loss: 0.0079, Validation Loss: 0.0079, Angle(U, W) : 87.0 Â°
Epoch 6/15, Training Loss: 0.0069, Validation Loss: 0.0065, Angle(U, W) : 87.0 Â°
Epoch 7/15, Training Loss: 0.0081, Validation Loss: 0.0057, Angle(U, W) : 87.0 Â°
Epoch 8/15, Training Loss: 0.0040, Validation Loss: 0.0053, Angle(U, W) : 87.0 Â°
Epoch 9/15, Training Loss: 0.0060, Validation Loss: 0.0047, Angle(U, W) : 87.0 Â°
Epoch 10/15, Training Loss: 0.0076, Validation Loss: 0.0045, Angle(U, W) : 87.0 Â°
Epoch 11/15, Training Loss: 0.0060, Validation Loss: 0.0051, Angle(U, W) : 87.0 Â°
Epoch 12/15, Training Loss: 0.0065, Validation Loss: 0.0045, Angle(U, W) : 87.0 Â°
Epoch 13/15, Training Loss: 0.0052, Validation Loss: 0.0045, Angle(U, W) : 87.0 Â°
Epoch 14/15, Training Loss: 0.0055, Validation Loss: 0.0046, Angle(U, W) : 87.0 Â°
Epoch 15/15, Training Loss: 0.0047, Validation Loss: 0.0061, Angle(U, W) : 87.0 Â°
Elapsed (with compilation) = 0h 1m 35s
#+end_example

:RESULTS:

#+begin_src ipython
torch.save(model.state_dict(), 'models/dual_naive_%d.pth' % seed)
#+end_src

#+RESULTS:

** Test

  #+begin_src ipython
model.eval()
  #+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights()
:   (dropout): Dropout(p=0.0, inplace=False)
: )

 #+begin_src ipython
odors = model.odors.clone()
model.odors[0] = odors[1] # distractor Go
model.odors[5] = odors[5+1] # distractor NoGo

model.odors[1] = odors[2] # cue
model.odors[2] = odors[3] # rwd
  #+end_src

#+RESULTS:

  #+begin_src ipython
model.N_BATCH = 1

model.I0[0] = A0 # Go
model.I0[1] = float(B0) # cue
model.I0[2] = 0.0 # float(C0) * model.IF_RL # rwd
model.I0[3] = 0.0
model.I0[4] = 0.0

A = model.init_ff_input()

model.I0[0] = -A0 # NoGo
model.I0[1] = float(B0) # cue
model.I0[2] = 0.0 # rwd
model.I0[3] = 0.0
model.I0[4] = 0.0

B = model.init_ff_input()

ff_input = torch.cat((A, B))
print('ff_input', ff_input.shape)
  #+end_src

#+RESULTS:
: ff_input torch.Size([2, 305, 1000])

  #+begin_src ipython
rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
model.odors = odors
print(rates.shape)
  #+end_src

#+RESULTS:
: (2, 41, 750)

  #+begin_src ipython
memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
# readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
plot_overlap(rates, memory, readout, labels=['Go', 'NoGo'])
  #+end_src

#+RESULTS:
[[./.ob-jupyter/0211a42bbedeb9c5042b91be49f49b8c52490318.png]]

  #+begin_src ipython
memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
# readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
# readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
# plot_overlap(rates, memory, readout, labels=['Go', 'NoGo'])
  #+end_src

#+RESULTS:

  #+begin_src ipython
idx = get_idx(model, 1)
plot_rates_selec(rates, idx)
  #+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([4, 750])
[[./.ob-jupyter/c5d447f8d8f502f7259b53efc34b38339b9f6645.png]]
:END:

#+begin_src ipython
plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[./.ob-jupyter/65c310d4669db138ac6eb7dc5f6cc642297d1951.png]]

* Dual
** Parameters

#+begin_src ipython
model.DURATION = 8
model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
model.IF_RL = 0 # 1
model.RWD = 22 # 2/3
#+end_src

#+RESULTS:

#+begin_src ipython
model.T_STIM_ON = [1.0, 3.0, 5.0, 5.5, 7.0]
model.T_STIM_OFF = [2.0, 4.0, 5.5, 6.0, 8.0]

model.N_STIM_ON = np.array(
    [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_ON]
)

model.N_STIM_OFF = [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_OFF]
#+end_src

#+RESULTS:

** Testing

#+begin_src ipython
model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights()
:   (dropout): Dropout(p=0.0, inplace=False)
: )

#+begin_src ipython
model.N_BATCH = 1

model.I0[0] = A0 # sample A
model.I0[1] = A0 # distractor Go
model.I0[2] = float(B0) # cue
model.I0[3] = 0.0 # float(C0) * model.IF_RL # rwd
model.I0[4] = A0 # test

AC_pair = model.init_ff_input()

model.I0[0] = A0
model.I0[1] = A0
model.I0[2] = float(B0)
model.I0[3] = float(C0) * model.IF_RL # rwd
model.I0[4] = -A0

AD_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = A0
model.I0[2] = float(B0)
model.I0[3] = float(C0) * model.IF_RL # rwd
model.I0[4] = A0

BC_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = A0
model.I0[2] = float(B0)
model.I0[3] = float(C0) * model.IF_RL # rwd
model.I0[4] = -A0

BD_pair = model.init_ff_input()

ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 505, 1000])

#+begin_src ipython
labels_pair = torch.ones((2 * model.N_BATCH, 2))
labels_unpair = torch.zeros((2 * model.N_BATCH, 2))

labels = torch.cat((labels_pair, labels_unpair))
print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([4, 2])

#+begin_src ipython
rates = model.forward(ff_input=ff_input).detach()
print(rates.shape)
#+end_src

#+RESULTS:
: torch.Size([4, 81, 750])

#+begin_src ipython
rates = rates.cpu().numpy()
memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_naive_overlap.svg')
#+end_src

#+RESULTS:
[[./.ob-jupyter/6f1e72d84a6b4807f9c212204b7ee2e163de455f.png]]

#+begin_src ipython
memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
# readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
# plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_naive_overlap.svg')
#+end_src

#+RESULTS:

#+begin_src ipython
idx = get_idx(model, 1)
plot_rates_selec(rates, idx, figname='dual_naive_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([4, 750])
[[./.ob-jupyter/177d614f273fff2fea63d831221dd1b965490c79.png]]
:END:


#+begin_src ipython
plot_m0_m1_phi(rates, idx, figname='dual_naive_fourier.svg')
#+end_src

#+RESULTS:
[[./.ob-jupyter/f8f5f63b012e1a76c22bf119d1cd9e23d49be336.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

** Fixed points

#+begin_src ipython
model.DURATION = 20
model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
model.IF_RL = 0
#+end_src

#+RESULTS:

#+begin_src ipython
model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights()
:   (dropout): Dropout(p=0.0, inplace=False)
: )

#+begin_src ipython
model.N_BATCH = 1

model.I0[0] = A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

AC_pair = model.init_ff_input()

model.I0[0] = A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

AD_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

BC_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

BD_pair = model.init_ff_input()

ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
print('ff_input', ff_input.shape, ff_input[0, 0, :4])
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 1105, 1000]) tensor([20.2703, 19.5137, 20.3663, 20.5473], device='cuda:1')

#+begin_src ipython
rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
print(rates.shape)
#+end_src

#+RESULTS:
: (4, 201, 750)

#+begin_src ipython
plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[./.ob-jupyter/7427682172b94260747d3ee0f87d904c330cad45.png]]

#+begin_src ipython
from matplotlib.patches import Circle
m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

x = m1 / m0 * np.cos(phi)
y = m1 / m0 * np.sin(phi)

xA = x
yA = y

fig, ax = plt.subplots(1, 1, figsize=[height, height])

# ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
# ax.plot(xA.T, yA.T, '-', alpha=.5)
ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=20)
# ax.set_xlim([-.9, .9])
# ax.set_ylim([-.9, .9])
circle = Circle((0., 0.), 1.8, fill=False, edgecolor='k')
ax.add_patch(circle)

# Set the aspect of the plot to equal to make the circle circular
ax.set_aspect('equal')
plt.savefig('fp_dual_naive.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/69dcbd0b97cb7d36aded59ddda9458fc115b835a.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

** Training

#+begin_src ipython
# for param in model.low_rank.linear.parameters():
#     param.requires_grad = False

model.low_rank.U.requires_grad = True
model.low_rank.V.requires_grad = True

# init.xavier_uniform_(model.low_rank.linear.weight)
# if model.low_rank.linear.bias is not None:
#     model.low_rank.linear.bias.data.zero_()  # Common practice is to set biases to zero
  #+end_src

#+RESULTS:

#+begin_src ipython
model.DURATION = 8
model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
model.IF_RL = 0 # 1

model.LR_TRAIN = 1
model.LR_READOUT = 0
model.RWD = 2 # 2/3
#+end_src

#+RESULTS:

#+begin_src ipython
steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

mask_rwd = (steps >= (model.N_STIM_ON[-1] - model.N_STEADY))
rwd_idx = np.where(mask_rwd)[0]
print('rwd', rwd_idx)

# mask_dist = (steps >= (model.N_STIM_ON[1] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[-1] - model.N_STEADY))
# # mask_dist = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))
# dist_idx = np.where(mask_dist)[0]
# print('dist', dist_idx)

mask_cue = (steps >= (model.N_STIM_ON[2] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[-1] - model.N_STEADY))
# mask_cue = (steps >= (model.N_STIM_ON[1] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[-1] - model.N_STEADY))
# mask_cue = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))
cue_idx = np.where(mask_cue)[0]
print('cue', cue_idx)

stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY))

mask_zero = ~mask_rwd & ~mask_cue & ~stim_mask
zero_idx = np.where(mask_zero)[0]
print('zero', zero_idx)
#+end_src

#+RESULTS:
: rwd [70 71 72 73 74 75 76 77 78 79 80]
: cue [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]
: zero [0 1 2 3 4 5 6 7 8 9]

#+begin_src ipython
model.N_BATCH = 128

model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))
# model.lr_eval_win = np.max( (rwd_idx.shape[0], dist_idx.shape[0], cue_idx.shape[0]))

ff_input = []
labels = np.zeros((2, 12, model.N_BATCH, model.lr_eval_win))
# labels = np.zeros((3, 12, model.N_BATCH, model.lr_eval_win))

# if model.IF_RL==0:
#     B0 = 0

print(float(B0), float(C0))

l=0
for i in [-1, 1]:
    for j in [-1, 0, 1]:
        for k in [-1, 1]:

            model.I0[0] = i # sample
            model.I0[1] = j # distractor
            model.I0[4] = k # test

            if i==k: # Pair Trials
                labels[0, l] = np.ones((model.N_BATCH, model.lr_eval_win))

            if j==1: # Go
                model.I0[2] = float(B0) # cue
                model.I0[3] = float(C0) * model.IF_RL # rwd

                labels[1, l] = np.ones((model.N_BATCH, model.lr_eval_win))
            elif j==-1: # NoGo
                model.I0[2] = float(B0) # cue
                model.I0[3] = 0.0 # rwd
            else: # DPA
                model.I0[2] = 0 # cue
                model.I0[3] = 0 # rwd

            l+=1

            ff_input.append(model.init_ff_input())

labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(2, -1, model.lr_eval_win).transpose(0, 1)
# labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(3, -1, model.lr_eval_win).transpose(0, 1)
ff_input = torch.vstack(ff_input)
print('ff_input', ff_input.shape, 'labels', labels.shape)
#+end_src

#+RESULTS:
: 0.0 0.0
: ff_input torch.Size([1536, 505, 1000]) labels torch.Size([1536, 2, 21])

#+begin_src ipython
batch_size = 16
train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([1228, 505, 1000]) torch.Size([308, 505, 1000])
: torch.Size([1228, 2, 21]) torch.Size([308, 2, 21])

#+begin_src ipython
criterion = DualLoss(alpha=1.0, thresh=5.0, cue_idx=cue_idx, rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=[1.0, 0.0])

# SGD, Adam, Adam
learning_rate = 0.1
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
print('training Dual')
num_epochs = 15
start = perf_counter()
model.readout_idx=1
loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=None)
end = perf_counter()
print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
: training Dual
: Epoch 1/15, Training Loss: 0.0109, Validation Loss: 0.0100, Angle(U, W) : 88.0 Â°
: Epoch 2/15, Training Loss: 0.0066, Validation Loss: 0.0052, Angle(U, W) : 89.0 Â°
: Epoch 3/15, Training Loss: 0.0041, Validation Loss: 0.0045, Angle(U, W) : 89.0 Â°
: Stopping training as loss has fallen below the threshold: 0.004135192837566137, 0.004542860749643296
: Elapsed (with compilation) = 0h 3m 7s

#+begin_src ipython
torch.save(model.state_dict(), 'models/dual_train_%d.pth' % seed)
#+end_src

#+RESULTS:

#+begin_src ipython
odors = model.odors.cpu().numpy()
U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]
# W = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]

print('   U  V  W  S  D')
print('U ', angle_AB(U, U), angle_AB(U, V), angle_AB(U, W), angle_AB(U, odors[0]), angle_AB(U, odors[1]))
print('V ', 'XXX', angle_AB(V, V), angle_AB(V, W), angle_AB(V, odors[0]), angle_AB(V, odors[1]))
print('W ', 'XXX', 'XXX', angle_AB(W, W), angle_AB(W, odors[0]), angle_AB(W, odors[1]))
print('S ', 'XXX', 'XXX', 'XXX', angle_AB(odors[0], odors[0]), angle_AB(odors[0], odors[1]))
print('D ', 'XXX', 'XXX', 'XXX', 'XXX', angle_AB(odors[1], odors[1]))

#+end_src

#+RESULTS:
:    U  V  W  S  D
: U  0 71 69 73 88
: V  XXX 0 26 82 92
: W  XXX XXX 0 81 92
: S  XXX XXX XXX 0 90
: D  XXX XXX XXX XXX 0

** Re-Testing

#+begin_src ipython
model.DURATION = 8
model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

    #+begin_src ipython
model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights()
:   (dropout): Dropout(p=0.0, inplace=False)
: )

#+begin_src ipython
model.N_BATCH = 1

model.I0[0] = A0
model.I0[1] = A0
model.I0[2] = float(B0)
model.I0[3] = float(C0) * model.IF_RL # rwd
model.I0[4] = A0

AC_pair = model.init_ff_input()

model.I0[0] = A0
model.I0[1] = A0
model.I0[2] = float(B0)
model.I0[3] = float(C0) * model.IF_RL # rwd
model.I0[4] = -A0

AD_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = A0
model.I0[2] = float(B0)
model.I0[3] = float(C0) * model.IF_RL # rwd
model.I0[4] = A0

BC_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = A0
model.I0[2] = float(B0)
model.I0[3] = float(C0) * model.IF_RL # rwd
model.I0[4] = -A0

BD_pair = model.init_ff_input()

ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 505, 1000])

#+begin_src ipython
labels_A = torch.ones((2*model.N_BATCH, 2))
labels_B = torch.zeros((2*model.N_BATCH, 2))
labels = torch.cat((labels_A, labels_B))

print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([4, 2])

#+begin_src ipython
rates = model.forward(ff_input=ff_input).detach()
print(rates.shape)
#+end_src

#+RESULTS:
: torch.Size([4, 81, 750])

 #+begin_src ipython
rates = rates.cpu().detach().numpy()
memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_train_overlap.svg')
#+end_src

#+RESULTS:
[[./.ob-jupyter/0df52a963e89c7a44a094d127b7d33159f213001.png]]

 #+begin_src ipython
memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
# readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
# readout = model.low_rank.linear.weight.data[0].cpu().detach().numpy()
# plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_train_overlap.svg')
#+end_src

#+RESULTS:

#+begin_src ipython
idx = get_idx(model, 1)
plot_rates_selec(rates, idx, figname='dual_train_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([4, 750])
[[./.ob-jupyter/47c3ab449b96e4b8883f2a9b5b18d92c5af256b3.png]]
:END:

#+begin_src ipython
plot_m0_m1_phi(rates, idx, figname='dual_train_fourier.svg')
#+end_src

#+RESULTS:
[[./.ob-jupyter/a902aebf2b90e384e680d08777ce35f1ef81bd85.png]]


#+begin_src ipython

#+end_src

#+RESULTS:

** Fixed points

#+begin_src ipython
model.DURATION = 20
model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
model.IF_RL = 0
#+end_src

#+RESULTS:

#+begin_src ipython
model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights()
:   (dropout): Dropout(p=0.0, inplace=False)
: )

#+begin_src ipython
model.N_BATCH = 1

model.I0[0] = A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

AC_pair = model.init_ff_input()

model.I0[0] = A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

AD_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

BC_pair = model.init_ff_input()

model.I0[0] = -A0
model.I0[1] = 0
model.I0[2] = 0
model.I0[3] = 0
model.I0[4] = 0

BD_pair = model.init_ff_input()

ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
print('ff_input', ff_input.shape, ff_input[0, 0, :4])
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 1105, 1000]) tensor([19.1880, 18.1476, 21.4242, 19.8595], device='cuda:1')


#+begin_src ipython
rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
print(rates.shape)
#+end_src

#+RESULTS:
: (4, 201, 750)


#+begin_src ipython
idx = get_idx(model, 1)
plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([4, 750])
[[./.ob-jupyter/01e49be60738c38ed7fc3e253d7a04cb2a5f08d0.png]]
:END:

#+begin_src ipython
plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[./.ob-jupyter/61ff49187d1e805d789582299ebd88b402806bfc.png]]

#+begin_src ipython
from matplotlib.patches import Circle
m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

x = m1 / m0 * np.cos(phi)
y = m1 / m0 * np.sin(phi)

xA = x
yA = y

fig, ax = plt.subplots(1, 1, figsize=[height, height])

# ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
# ax.plot(xA.T, yA.T, '-', alpha=.5)
ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=20)
# ax.set_xlim([-.9, .9])
# ax.set_ylim([-.9, .9])
circle = Circle((0., 0.), 1.7, fill=False, edgecolor='k')
ax.add_patch(circle)

# Set the aspect of the plot to equal to make the circle circular
ax.set_aspect('equal')
plt.savefig('fp_dual_train.svg', dpi=300)
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/6614cddbf794cfb0a162fd98b1258f0458216f8e.png]]

    #+begin_src ipython

  #+end_src

  #+RESULTS:
