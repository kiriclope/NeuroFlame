* Sequential Serial Bias
:PROPERTIES:
:CUSTOM_ID: sequential-serial-bias
:END:
** Notebook Settings
:PROPERTIES:
:CUSTOM_ID: notebook-settings
:END:
#+begin_src python
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run ../notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'
#+end_src

#+begin_example
The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
Python exe
/home/aiswarya/miniconda3/envs/Ntorchmodel/bin/python
#+end_example

** Imports
:PROPERTIES:
:CUSTOM_ID: imports
:END:
#+begin_src python
import sys
sys.path.insert(0, '../')

import torch
import gc
import pandas as pd
import numpy as np
from time import perf_counter
from scipy.stats import binned_statistic

from src.network import Network
from src.decode import decode_bump_torch
from src.utils import clear_cache
#+end_src

** Helpers
:PROPERTIES:
:CUSTOM_ID: helpers
:END:
#+begin_src python
def convert_seconds(seconds):
    h = seconds // 3600
    m = (seconds % 3600) // 60
    s = seconds % 60
    return h, m, s
#+end_src

** Configuration
:PROPERTIES:
:CUSTOM_ID: configuration
:END:
#+begin_src python
REPO_ROOT = '/home/aiswarya/Model2/NeuroFlame/'
conf_name = 'config_SB.yml'
DEVICE = 'cuda'
#+end_src

** Sequential Serial Bias
:PROPERTIES:
:CUSTOM_ID: sequential-serial-bias-1
:END:
*** Stimuli sequences
:PROPERTIES:
:CUSTOM_ID: stimuli-sequences
:END:
Here we will study how Serial Bias (SB) depends on trial history. So we
are going to compute SB over multiple previous trials

#+begin_src python
N_TRIALS = 10
#+end_src

A trial consist of a stimulation followed by a silencing of the bump
after a delay.

First, we define a sequence of stimuli intensities and footprints

#+begin_src python
# Stimuli strength
I0 = [1.75, -5] * N_TRIALS
print('I0', I0)

# Stimuli footprint
SIGMA0 =  [1, 0] * N_TRIALS
print('SIGMA0', SIGMA0)
#+end_src

#+begin_example
I0 [1.75, -5, 1.75, -5, 1.75, -5, 1.75, -5, 1.75, -5, 1.75, -5, 1.75, -5, 1.75, -5, 1.75, -5, 1.75, -5]
SIGMA0 [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]
#+end_example

Then, we create a sequence of stimuli onsets and offsets

#+begin_src python
a = [1 + i * 3.5 for i in range(N_TRIALS)]
b = [3 + i * 3.5 for i in range(N_TRIALS)]

T_STIM_ON = [val for pair in zip(a, b) for val in pair]

print(T_STIM_ON)
#+end_src

#+begin_example
[1.0, 3.0, 4.5, 6.5, 8.0, 10.0, 11.5, 13.5, 15.0, 17.0, 18.5, 20.5, 22.0, 24.0, 25.5, 27.5, 29.0, 31.0, 32.5, 34.5]
#+end_example

#+begin_src python
c = [2 + i * 3.5 for i in range(N_TRIALS)]
d = [3.5 + i * 3.5 for i in range(N_TRIALS)]


T_STIM_OFF = [val for pair in zip(c, d) for val in pair]
print(T_STIM_OFF)

DURATION = T_STIM_OFF[-1] + 1
print(DURATION)
#+end_src

#+begin_example
[2.0, 3.5, 5.5, 7.0, 9.0, 10.5, 12.5, 14.0, 16.0, 17.5, 19.5, 21.0, 23.0, 24.5, 26.5, 28.0, 30.0, 31.5, 33.5, 35.0]
36.0
#+end_example

*** Phase Batches
:PROPERTIES:
:CUSTOM_ID: phase-batches
:END:
Now, we need to create batches of stimuli phases to simulate to compute
SB.

Let's batch the phases!

#+begin_src python
N_BATCH = 512

PHI0 = torch.ones((1, 2 * N_TRIALS), device=DEVICE)
PHI0 = PHI0.unsqueeze(-1).repeat((N_BATCH, 1, 1))

# for each stimulus we generate a set of random locations in degrees
for i in range(PHI0.shape[1]):
    PHI0[:, i] = torch.randint(0, 360, (N_BATCH,), device=DEVICE).unsqueeze(1)

print('PHI0', PHI0.shape)
# PHI0 should be of size (N_BATCH, N_STIMULI, 1) the last dimension is there for safety reasons
#+end_src

#+begin_example
PHI0 torch.Size([512, 20, 1])
#+end_example

#+begin_src python
plt.hist(PHI0[:, 0, 0].cpu().numpy())
plt.xlabel('Phase (°)')
plt.ylabel('Count')
plt.show()
#+end_src

#+caption: png
[[file:seq_serial_bias_files/seq_serial_bias_21_0.png]]

*** Model
:PROPERTIES:
:CUSTOM_ID: model
:END:
#+begin_src python
model = Network(conf_name, REPO_ROOT, IF_STP=1, VERBOSE=0, LIVE_FF_UPDATE=1,
                N_BATCH=N_BATCH, DURATION=DURATION,
                I0=I0, SIGMA0=SIGMA0, PHI0=PHI0,
                T_STIM_ON=T_STIM_ON, T_STIM_OFF=T_STIM_OFF,
                TAU_FAC= 1,
                J_STP=7.5)
#+end_src

*** Simulations
:PROPERTIES:
:CUSTOM_ID: simulations
:END:
Let's run the simulation!

#+begin_src python
rates = model()
#+end_src

#+begin_example
I0 1.75 torch.Size([1, 20, 500])



---------------------------------------------------------------------------

RuntimeError                              Traceback (most recent call last)

Cell In[18], line 1
----> 1 rates = model()


File ~/miniconda3/envs/Ntorchmodel/lib/python3.11/site-packages/torch/nn/modules/module.py:1511, in Module._wrapped_call_impl(self, *args, **kwargs)
   1509     return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]
   1510 else:
-> 1511     return self._call_impl(*args, **kwargs)


File ~/miniconda3/envs/Ntorchmodel/lib/python3.11/site-packages/torch/nn/modules/module.py:1520, in Module._call_impl(self, *args, **kwargs)
   1515 # If we don't have any hooks, we want to skip the rest of the logic in
   1516 # this function, and just call forward.
   1517 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
   1518         or _global_backward_pre_hooks or _global_backward_hooks
   1519         or _global_forward_hooks or _global_forward_pre_hooks):
-> 1520     return forward_call(*args, **kwargs)
   1522 try:
   1523     result = None


File ~/Model2/NeuroFlame/notebooks/../src/network.py:294, in Network.forward(self, ff_input, REC_LAST_ONLY, RET_FF, RET_STP)
    291 for step in range(self.N_STEPS):
    292     # update dynamics
    293     if self.LIVE_FF_UPDATE:
--> 294         ff_input, noise = live_ff_input(self, step, ff_input)
    295         if self.RATE_NOISE:
    296             rates, rec_input = self.update_dynamics(rates, ff_input, rec_input)


File ~/Model2/NeuroFlame/notebooks/../src/ff_input.py:85, in live_ff_input(model, step, ff_input)
     82         stimulus = Stimulus(model.I0[i], model.SIGMA0[i], model.PHI0[:, i])
     83         print("I0", model.I0[i], stimulus.shape)
---> 85     ff_input[:, model.slices[0]] = (
     86         model.Ja0[:, 0] + torch.sqrt(model.Ka[0]) * model.M0 * stimulus
     87     )
     88     print(ff_input.shape)
     89 if step in model.N_STIM_OFF:


RuntimeError: The expanded size of the tensor (512) must match the existing size (20) at non-singleton dimension 0.  Target sizes: [512, 500].  Tensor sizes: [20, 500]
#+end_example

*** SB analysis
:PROPERTIES:
:CUSTOM_ID: sb-analysis
:END:
Let's decode the bumps!

#+begin_src python
m0, m1, phi = decode_bump_torch(rates)
print(m0.shape)
#+end_src

#+begin_example
torch.Size([512, 361])
#+end_example

#+begin_src python
targets = PHI0[:,::2,0].cpu().numpy() * np.pi / 180
#+end_src

#+begin_src python
steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

mask = 0
for i in range(0, 2 * N_TRIALS, 2):
        mask = mask | (steps == (model.N_STIM_OFF[i] + 9 * model.N_WINDOW - model.N_STEADY))

idx = np.where(mask)[0]

print(idx)

phi_off = phi[:, idx].cpu().numpy()
print('delay phase', phi_off.shape)

print(targets[0, 0] * 180 / np.pi, phi_off[0,0] *180/np.pi)
#+end_src

#+begin_example
[ 29  64  99 134 169 204 239 274 309 344]
delay phase (512, 10)
106.000000672989 111.73899882120052
#+end_example

#+begin_src python
errors =  targets - phi_off
print(errors[0, 0])
errors = (errors + np.pi) % (2.0*np.pi) - np.pi

print('errors', errors.shape)
#+end_src

#+begin_example
-0.10016441
errors (512, 10)
#+end_example

#+begin_src python
fig, ax = plt.subplots(1, 2, figsize=(2*width, height))
r_max = 30

ax[0].imshow(rates[0].T.cpu().numpy(), aspect='auto',
             cmap='jet', vmin=0, vmax=r_max,
             origin='lower', extent=[0, model.DURATION, 0, model.N_NEURON* model.frac[0]])

ax[0].set_xlabel('Time (s)')
ax[0].set_ylabel('Pref. Location (°)')
ax[0].set_yticks(np.linspace(0, model.Na[0].cpu(), 5), np.linspace(0, 360, 5).astype(int))

cbar = plt.colorbar(ax[0].images[0], ax=ax[0], fraction=0.046, pad=0.04)
cbar.set_label('Firing Rate (Hz)')

ax[1].plot(phi[0].T.cpu().numpy() * 180 / np.pi, alpha=1)

# for i in range(targets.shape[1]):
#    ax[1].axhline(targets[0, i] * 180.0 / np.pi, 0, model.DURATION, color='k', ls='--')

for i in range(targets.shape[1]):
   ax[1].axvline(idx[i], 0, 360, color='r', ls='--')

ax[1].set_ylabel('Phase (°)')
ax[1].set_xlabel('Step')
ax[1].set_ylim([0, 360])
ax[1].set_yticks(np.linspace(0, 360, 5).astype(int))
plt.show()
#+end_src

#+caption: png
[[file:seq_serial_bias_files/seq_serial_bias_33_0.png]]

#+begin_src python
plt.hist(errors, bins=5)
plt.xlabel('Errors (°)')
plt.ylabel('Count')
plt.show()
#+end_src

#+caption: png
[[file:seq_serial_bias_files/seq_serial_bias_34_0.png]]

#+begin_src python
rel_loc = np.diff(targets, axis=1)
rel_loc = (rel_loc + np.pi ) % (2*np.pi) - np.pi
print(rel_loc.shape)
#+end_src

#+begin_example
(512, 9)
#+end_example

#+begin_src python
plt.hist(rel_loc *180 /np.pi)
plt.xlabel('Rel. Loc (°)')
plt.ylabel('Count')
plt.show()
#+end_src

#+caption: png
[[file:seq_serial_bias_files/seq_serial_bias_36_0.png]]

#+begin_src python
pal = sns.color_palette("rocket_r", n_colors= N_TRIALS)

for i in range(0, rel_loc.shape[1], 2):
    stt = binned_statistic(rel_loc[:, i] * 180 / np.pi,
                           errors[:, i+1] * 180 / np.pi,
                           statistic='mean',
                           bins=15, range=[-180, 180])

    dstt = np.mean(np.diff(stt.bin_edges))
    # plt.plot(rel_loc[:, i]* 180 / np.pi, errors[:, i+1] * 180 / np.pi , 'o', alpha=.25, color=pal[i])
    plt.plot(stt.bin_edges[:-1]+dstt/2,stt.statistic, color=pal[i], label='trial %d' % i, alpha=1)

plt.axhline(color='k', linestyle=":")
plt.xlabel('Rel. Loc. (°)')
plt.ylabel('Error (°)')
plt.ylim([-50, 50])
plt.legend(frameon=False, loc='best', fontsize=10)
plt.show()
#+end_src

#+caption: png
[[file:seq_serial_bias_files/seq_serial_bias_37_0.png]]

#+begin_src python
#+end_src
