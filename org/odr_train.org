#+STARTUP: fold
#+TITLE: Training RNNs on ODR
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session odr :kernel torch :exports results :output-dir ./figures/odr :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
:RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python
: <Figure size 600x370.82 with 0 Axes>
:END:

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  import torchmetrics
  import torch.nn.functional as F
  from torch.utils.data import Dataset, TensorDataset, DataLoader

  DEVICE = 'cuda:0'
#+end_src

#+RESULTS:

#+RESULTS:

#+begin_src ipython

  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl, decode_bump_torch
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

* Helpers
** plots

#+begin_src ipython
def plot_rates_selec(rates, idx=0, thresh=0.5, figname='fig.svg'):
        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
        r_max = thresh * np.max(rates[idx])

        ax[0].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[0].set_ylabel('Neuron #')
        ax[0].set_xlabel('Step')

        plt.savefig(figname, dpi=300)
        plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_m0_m1_phi(rates, idx, figname='fig.svg'):

      m0, m1, phi = decode_bump(rates, axis=-1)
      fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

      ax[0].plot(m0.T)
      #ax[0].set_ylim([0, 360])
      #ax[0].set_yticks([0, 90, 180, 270, 360])
      ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
      ax[0].set_xlabel('Step')

      ax[1].plot(m1.T)
      # ax[1].set_ylim([0, 360])
      # ax[1].set_yticks([0, 90, 180, 270, 360])
      ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
      ax[1].set_xlabel('Step')

      ax[2].plot(phi.T * 180 / np.pi, alpha=.5)
      ax[2].set_ylim([0, 360])
      ax[2].set_yticks([0, 90, 180, 270, 360])
      ax[2].set_ylabel('Phase (Â°)')
      ax[2].set_xlabel('Step')

      plt.savefig(figname, dpi=300)
      plt.show()
    #+end_src

#+RESULTS:

** Data Split

#+begin_src ipython
  from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

  def split_data(X, Y, train_perc=0.8, batch_size=32):

     X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                         train_size=train_perc,
                                                         stratify=Y[:, 0].cpu().numpy(),
                                                         shuffle=True)

     print(X_train.shape, X_test.shape)
     print(Y_train.shape, Y_test.shape)

     train_dataset = TensorDataset(X_train, Y_train)
     val_dataset = TensorDataset(X_test, Y_test)

     # Create data loaders
     train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
     val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

     return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
  def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=.001, clip_grad=0, zero_grad=0):
      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          X, y = X.to(device), y.to(device)

          optimizer.zero_grad()

          rates = model(X)
          loss = loss_fn(rates, y)

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()

          # Clip gradients
          if clip_grad:
              torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
              #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)

          optimizer.step()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def validation_step(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0

      with torch.no_grad():
          for X, y in dataloader:
              X, y = X.to(device), y.to(device)

              rates = model(X)
              loss = loss_fn(rates, y)

              val_loss += loss.item() * X.size(0)

          val_loss /= size
          # acc = metric.compute()
          # print(f"Accuracy: {acc}")
          # metric.reset()
      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def optimization(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=.005, zero_grad=0):
      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')
      model.to(device)

      loss_list = []
      val_loss_list = []
      accuracies = []
      angle_list = []

      for epoch in range(num_epochs):
          loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, zero_grad=zero_grad)
          val_loss = validation_step(val_loader, model, loss_fn)

          scheduler.step(val_loss)

          loss_list.append(loss.item())
          val_loss_list.append(val_loss)
          # if epoch % int(num_epochs  / 10) == 0:
          print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

          if val_loss < thresh and loss < thresh:
              print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')
              break

          if val_loss > 300:
              print(f'Stopping training as loss is too high: {val_loss}')
              break

          if torch.isnan(loss):
              print(f'Stopping training as loss is NaN.')
              break

      return loss_list, val_loss_list
#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
def compute_fourier_moments(signal, dim=-1):
    # Perform the FFT
    fft_coeffs = torch.fft.fft(signal, dim=dim)

    # Calculate the zero, first, and second Fourier moments
    zero_moment = fft_coeffs[..., 0]
    first_moment = fft_coeffs[..., 1]
    second_moment = fft_coeffs[..., 2]

    # Calculate magnitude m0, m1, and m2
    m0 = torch.abs(zero_moment) / signal.size(dim)  # Normalize m0 by the signal length
    m1 = 2.0 * torch.abs(first_moment) / signal.size(dim)
    m2 = 2.0 * torch.abs(second_moment) / signal.size(dim)

    # Calculate the phase of the signal
    phases = torch.angle(first_moment) % (2.0 * torch.pi)

    return m0, m1, m2, phases
#+end_src

#+RESULTS:

#+begin_src ipython
import torch
import torch.nn as nn

class AngularErrorLoss2(nn.Module):
    def __init__(self, rwd_idx=-1):
        super(AngularErrorLoss, self).__init__()
        self.loss = nn.SmoothL1Loss()
        self.rwd_idx = rwd_idx

    def forward(self, readout, targets):
        # Ensure the readout and targets are in the same shape
        predicted_angles = readout[:, self.rwd_idx]

        # Compute the angular difference
        angular_diff = torch.atan2(torch.sin(predicted_angles - targets), torch.cos(predicted_angles - targets))

        # Use MSE loss on angular differences
        loss = self.loss(angular_diff)
        return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.nn.functional as F

  class AngularErrorLoss(nn.Module):
      def __init__(self, rwd_idx=-1, zero_idx=0):
          super(AngularErrorLoss, self).__init__()
          self.mse_loss = nn.MSELoss()
          self.loss = nn.SmoothL1Loss()
          self.rwd_idx = rwd_idx
          self.zero_idx = zero_idx

      def forward(self, readout, targets):
          # m0_pred, m1_pred , y_pred = decode_bump_torch(readout)
          # fourier = torch.fft.fft(readout, dim=-1)
          m0, m1, m2, phi = compute_fourier_moments(readout, dim=-1)

          ones = torch.ones_like(m0[:, self.rwd_idx])
          zeros = torch.zeros_like(m0[:, self.zero_idx])

          predicted_sin = torch.sin(phi[:, self.rwd_idx])
          predicted_cos = torch.cos(phi[:, self.rwd_idx])

          target_sin = torch.sin(targets)
          target_cos = torch.cos(targets)

          loss = 0
          loss_sin = self.mse_loss(predicted_sin, target_sin)
          loss_cos = self.mse_loss(predicted_cos, target_cos)
          loss += (loss_sin + loss_cos) / 2  # Average sin and cos loss for this target

          # unique_targets = torch.unique(targets)
          # loss = 0
          # for unique_target in unique_targets:
          #     mask = (targets == unique_target)
          #     if mask.sum() > 0:  # Only compute loss if there are samples for this target
          #         loss_sin = self.mse_loss(predicted_sin[mask], target_sin[mask])
          #         loss_cos = self.mse_loss(predicted_cos[mask], target_cos[mask])
          #         loss += (loss_sin + loss_cos) / 2  # Average sin and cos loss for this target
          # loss /= unique_targets.size(0)  # Normalize by the number of unique targets

          loss += self.mse_loss(m1[:, self.zero_idx], zeros)
          # loss += self.mse_loss(m2[:, self.zero_idx], zeros) / 2.0
          loss += self.mse_loss(m1[:, self.rwd_idx] / m0[:, self.rwd_idx], ones)

          # loss += self.mse_loss(m1_pred[:, self.zero_idx], zeros)
          # loss += self.mse_loss(m1_pred[:, self.rwd_idx]/m0_pred[:, self.rwd_idx], 2.0 * ones)
          return loss
#+end_src

#+RESULTS:

** Other

#+begin_src ipython
  def angle_AB(A, B):
      A_norm = A / (np.linalg.norm(A) + 1e-5)
      B_norm = B / (np.linalg.norm(B) + 1e-5)

      return int(np.arccos(A_norm @ B_norm) * 180 / np.pi)
#+end_src

#+RESULTS:

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

* Model

#+begin_src ipython
    REPO_ROOT = "/home/leon/models/NeuroFlame"
    conf_name = "train_odr_EI.yml"
    DEVICE = 'cuda:0'
    seed = np.random.randint(0, 1e6)
    print(seed)
#+end_src

#+RESULTS:
: 88958

#+begin_src ipython
  model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=1)
#+end_src

#+RESULTS:

* Training
*** Parameters

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: Wab_train torch.Size([500, 500])

Testing the network on steps from sample odor offset to test odor onset

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

  # mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[1] - model.N_STEADY))

  rwd_idx = np.where(mask)[0]
  print('rwd', rwd_idx)

  model.lr_eval_win = rwd_idx.shape[0]
  print(model.lr_eval_win)

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[1] - model.N_STEADY))

  # stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY))

  zero_idx = np.where(~mask & ~stim_mask )[0]
  print('zero', zero_idx)
#+end_src

#+RESULTS:
: rwd [20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40]
: 21
: zero [ 0  1  2  3  4  5  6  7  8  9 41 42 43 44 45 46 47 48 49 50 51 52 53 54
:  55 56 57 58 59 60]

*** Inputs and Labels

#+begin_src ipython
  phase_list = np.linspace(0, 360, 9)[:-1]
  print(phase_list)
#+end_src

#+RESULTS:
: [  0.  45.  90. 135. 180. 225. 270. 315.]

#+begin_src ipython
  print(model.PHI0.shape)
#+end_src

#+RESULTS:
: torch.Size([1, 2])


#+begin_src ipython
  model.N_BATCH = 320

  ff_input = []
  labels = []

  model.PHI0 = torch.ones((1, model.N_POP), device=DEVICE, dtype=torch.float)

  for i in range(len(phase_list)):
      model.PHI0[0] = phase_list[i]
      labels.append(torch.ones((model.N_BATCH, model.lr_eval_win), device=DEVICE, dtype=torch.float) * phase_list[i] * torch.pi / 180.0)

      ff_input.append(model.init_ff_input())

  labels = torch.vstack(labels)
  ff_input = torch.vstack(ff_input)
  print('ff_input', ff_input.shape, 'labels', labels.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([2560, 355, 1000]) labels torch.Size([2560, 21])

*** Run

#+begin_src ipython
  batch_size = 32
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([2048, 355, 1000]) torch.Size([512, 355, 1000])
: torch.Size([2048, 21]) torch.Size([512, 21])

#+begin_src ipython
  criterion = AngularErrorLoss(rwd_idx=rwd_idx, zero_idx=zero_idx)
  # SGD, Adam, Adam
  learning_rate = 0.1
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 15
  start = perf_counter()
  loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
#+begin_example
Epoch 1/15, Training Loss: 1.9092, Validation Loss: 1.8725
Epoch 2/15, Training Loss: 1.7573, Validation Loss: 1.7508
Epoch 3/15, Training Loss: 1.7836, Validation Loss: 1.6940
Epoch 4/15, Training Loss: 1.6249, Validation Loss: 1.6504
Epoch 5/15, Training Loss: 0.8834, Validation Loss: 0.9617
Epoch 6/15, Training Loss: 0.7439, Validation Loss: 0.6875
Epoch 7/15, Training Loss: 0.6013, Validation Loss: 0.5904
Epoch 8/15, Training Loss: 0.4765, Validation Loss: 0.5102
Epoch 9/15, Training Loss: 0.4599, Validation Loss: 0.4455
Epoch 10/15, Training Loss: 0.4010, Validation Loss: 0.3739
Epoch 11/15, Training Loss: 0.3654, Validation Loss: 0.3632
Epoch 12/15, Training Loss: 0.2903, Validation Loss: 0.2497
Epoch 13/15, Training Loss: 0.2084, Validation Loss: 0.2119
Epoch 14/15, Training Loss: 0.1926, Validation Loss: 0.1999
Epoch 15/15, Training Loss: 0.1787, Validation Loss: 0.1865
Elapsed (with compilation) = 0h 12m 29s
#+end_example

#+begin_src ipython
torch.save(model.state_dict(), 'models/odr.pth')
#+end_src

#+RESULTS:

#+begin_src ipython

#+end_src

#+RESULTS:

* Testing

   #+begin_src emacs-lisp
;;   (conda-env-activate "dual_data")
   #+end_src

#+RESULTS:

#+begin_src ipython
model_state_dict = torch.load('models/odr.pth')
# model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=4)
model.load_state_dict(model_state_dict)
model.eval()  # Set to evaluation mode
#+end_src

#+RESULTS:
: Network()

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
: Network()

#+begin_src ipython
print(phase_list)
#+end_src

#+RESULTS:
: [  0.  45.  90. 135. 180. 225. 270. 315.]

#+begin_src ipython
  model.N_BATCH = 8

  ff_input = []
  labels = []

  model.PHI0 = torch.ones((1, model.N_POP), device=DEVICE, dtype=torch.float)

  for i in range(len(phase_list)):
      model.PHI0[0] = phase_list[i]
      ff_input.append(model.init_ff_input())

ff_input = torch.vstack(ff_input)
print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([64, 355, 1000])

#+begin_src ipython
print(model.PHI0)
#+end_src

#+RESULTS:
: tensor([[315., 315.]], device='cuda:0')

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print('rates', rates.shape)
#+end_src

#+RESULTS:
: rates (64, 61, 500)

#+begin_src ipython
print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([64, 355, 1000])

#+begin_src ipython
plot_rates_selec(rates=ff_input.cpu().detach().numpy(), idx=20, thresh=.5)
#+end_src

#+RESULTS:
[[./figures/odr/figure_34.png]]

#+begin_src ipython
plot_m0_m1_phi(ff_input.cpu().numpy()[..., :500], 10)
#+end_src

#+RESULTS:
[[./figures/odr/figure_35.png]]

#+begin_src ipython
m0, m1, phi = decode_bump(ff_input.cpu().numpy()[..., :500], axis=-1)
#+end_src

#+RESULTS:


#+begin_src ipython
plot_rates_selec(rates, idx=3, thresh=.1)
#+end_src

#+RESULTS:
[[./figures/odr/figure_37.png]]


#+begin_src ipython
plot_m0_m1_phi(rates, 3)
#+end_src

#+RESULTS:
[[./figures/odr/figure_38.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
