#+STARTUP: fold
#+TITLE: Serial Biases in the ODR
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session odr_sb :kernel torch :exports results :output-dir ./figures/odr :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  import torch.nn.functional as F
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl, decode_bump_torch
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

#+begin_src ipython :tangle ../src/torch/utils.py
  import pickle as pkl
  import os

  def pkl_save(obj, name, path="."):
      os.makedirs(path, exist_ok=True)
      destination = path + "/" + name + ".pkl"
      print("saving to", destination)
      pkl.dump(obj, open(destination, "wb"))


  def pkl_load(name, path="."):
      source = path + "/" + name + '.pkl'
      print('loading from', source)
      return pkl.load(open( source, "rb"))

#+end_src

#+RESULTS:

* Serial Bias
** Bias targets

#+begin_src ipython
import torch
import numpy as np

def generate_weighted_phase_samples(N_BATCH, angles, preferred_angle, sigma):
    # Convert angles list to a tensor
    angles_tensor = torch.tensor(angles)

    # Calculate Gaussian probability distribution centered at preferred_angle
    probs = np.exp(-0.5 * ((angles - preferred_angle) / sigma) ** 2)
    probs /= probs.sum()  # Normalize to get probabilities

    # Create a categorical distribution from the computed probabilities
    distribution = torch.distributions.Categorical(torch.tensor(probs))

    # Sample from the distribution
    indices = distribution.sample((N_BATCH,))

    # Map indices to angles and reshape to (N_BATCH, 1)
    phase_samples = angles_tensor[indices].reshape(N_BATCH, 1)

    return phase_samples

# Parameters
N_BATCH = 10000
angles = np.array([0., 45., 90., 135., 180., 225., 270., 315.])
preferred_angle = 90.  # Example preferred angle
sigma = 75.  # Standard deviation of the Gaussian

# Generate samples
phase_samples = generate_weighted_phase_samples(N_BATCH, angles, preferred_angle, sigma)
print(phase_samples.shape)
plt.hist(phase_samples[:,0], bins=8);
#+end_src

#+RESULTS:
:RESULTS:
: torch.Size([10000, 1])
[[./figures/odr/figure_4.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

** Model

#+begin_src ipython
REPO_ROOT = "/home/leon/models/NeuroFlame"
conf_name = "test_odr_EI.yml"
DEVICE = 'cuda:1'
seed = np.random.randint(0, 1e6)
print(seed)
#+end_src

#+RESULTS:
: 405492

#+begin_src ipython
model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=16, LIVE_FF_UPDATE=1)
#+end_src

#+RESULTS:

#+begin_src ipython
model_state_dict = torch.load('models/odr.pth')
# model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=4)
model.load_state_dict(model_state_dict)
model.eval()  # Set to evaluation mode
#+end_src

#+RESULTS:
: Network(
:   (dropout): Dropout(p=0.0, inplace=False)
: )

** Batching Live Inputs

#+begin_src ipython
  N_PHASE = 512 + 256 + 128
  print(model.PHI0.shape)

  PHI0 = model.PHI0.unsqueeze(-1).repeat((N_PHASE, 1, 1))

  # print(PHI0.shape)
  # PHI0[:, -1] = torch.randint(0, 360, (N_PHASE,)).unsqueeze(1)
  # PHI0[:, 0] = torch.randint(0, 360, (N_PHASE,)).unsqueeze(1)
  # print(PHI0[:, :, 0])

  phases =  [  0.,  45.,  90., 135., 180., 225., 270., 315.]
  phases_tensor = torch.tensor(phases)
  PHI0[:, 0] = phases_tensor[torch.randint(0, len(phases), (N_PHASE,))].unsqueeze(1)
  PHI0[:, -1] = phases_tensor[torch.randint(0, len(phases), (N_PHASE,))].unsqueeze(1)
  print(PHI0.shape)

  # PHI0[:, 0] = generate_weighted_phase_samples(N_PHASE, angles, preferred_angle, sigma)
  # PHI0[:, 1] = generate_weighted_phase_samples(N_PHASE, angles, preferred_angle, sigma)
  # print(PHI0.shape)

 #+end_src

#+RESULTS:
: torch.Size([1, 3])
: torch.Size([896, 3, 1])

#+begin_src ipython
  model.PHI0 = PHI0
  model.N_BATCH = N_PHASE
  rates = model(RET_FF=0).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
: (896, 91, 500)

#+begin_src ipython
name = 'rates_2'
pkl_save(rates, '%s' % name, path="../data/serial_bias/")
name = 'PHI0_2'
pkl_save(PHI0.cpu().detach().numpy(), '%s' % name, path="../data/serial_bias/")
#+end_src

#+RESULTS:
: saving to ../data/serial_bias//rates_2.pkl
: saving to ../data/serial_bias//PHI0_2.pkl

#+begin_src ipython
  m0, m1, phi = decode_bump(rates, axis=-1)
  print(phi.shape)
#+end_src

#+RESULTS:
: (896, 91)

** Results

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.5*width, height])

idx = np.random.randint(0, model.N_BATCH)
ax[0].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=2, origin='lower')
ax[0].set_ylabel('Pref. Location (°)')
ax[0].set_yticks(np.linspace(0, model.Na[0].cpu(), 5), np.linspace(0, 360, 5).astype(int))
ax[0].set_xlabel('Step')

idx = np.random.randint(0, model.N_BATCH, 8)
ax[1].plot(m1[idx].T)
# ax[1].set_yticks(np.linspace(0, 360, 5).astype(int), np.linspace(0, 360, 5).astype(int))
ax[1].set_ylabel('m1 (Hz)')
ax[1].set_xlabel('Step')

ax[2].plot(phi[idx].T * 180 / np.pi, alpha=0.5)
ax[2].set_yticks(np.linspace(0, 360, 5).astype(int), np.linspace(0, 360, 5).astype(int))
ax[2].set_ylabel('Pref. Location (°)')
ax[2].set_xlabel('Step')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_13.png]]

#+begin_src ipython
PHI0 = PHI0.cpu().detach().numpy()
print(PHI0.shape)
#+end_src

#+RESULTS:
: (896, 3, 1)

** errors

#+begin_src ipython
target_loc = PHI0[:, -1]

rel_loc = (PHI0[:, 0] - target_loc) * np.pi / 180.0
rel_loc = (rel_loc + np.pi) % (2 * np.pi) - np.pi
rel_loc *= 180 / np.pi
rel_loc = rel_loc[:, -1]

ref_loc = (PHI0[:, 0] - preferred_angle) * np.pi / 180.0
ref_loc = (ref_loc + np.pi) % (2 * np.pi) - np.pi
ref_loc *= 180 / np.pi
ref_loc = ref_loc[:, -1]

errors = (phi - target_loc * np.pi / 180.0) % (2*np.pi)
errors = (errors + np.pi) % (2 * np.pi) - np.pi
errors *= 180 / np.pi

# errors = errors[:, -1]
# target_loc = target_loc[:, -1]

mask = np.abs(errors) <= 25
# print(mask.shape)

errors = np.where(mask, errors, np.nan)[:, -1]
rel_loc = rel_loc[~np.isnan(errors), np.newaxis]
ref_loc = ref_loc[~np.isnan(errors), np.newaxis]
target_loc = target_loc[:, -1][~np.isnan(errors), np.newaxis]
errors = errors[~np.isnan(errors), np.newaxis]
# errors = errors[mask]

print(errors.shape, target_loc.shape, rel_loc.shape, ref_loc.shape)
#+end_src

#+RESULTS:
: (241, 1) (241, 1) (241, 1) (241, 1)

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].hist(rel_loc[:, 0], bins=15)
ax[0].set_xlabel('Rel. Location (°)')

ax[1].hist(errors[:, -1], bins='auto')
ax[1].set_xlabel('Errors (°)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_16.png]]

** biases

#+begin_src ipython
fig, ax = plt.subplots(1, 3, figsize=[2.5*width, height])

ax[0].plot(target_loc[:, 0], errors[:,-1], 'o')
ax[0].set_xlabel('Target Loc. (°)')
ax[0].set_ylabel('Error (°)')

from scipy.stats import binned_statistic
stt = binned_statistic(target_loc[:,0], errors[:,-1], statistic='mean', bins=6, range=[0, 360])
dstt = np.mean(np.diff(stt.bin_edges))
ax[0].plot(stt.bin_edges[:-1]+dstt/2,stt.statistic,'r')

ax[0].axhline(color='k', linestyle=":")

ax[1].plot(rel_loc[:, 0], errors[:,-1], 'bo')
# ax[1].plot(rel_loc2[:, 0], errors2[:,-1], 'ro')
ax[1].set_xlabel('Rel. Loc. (°)')
ax[1].set_ylabel('Error (°)')

stt = binned_statistic(rel_loc[:, 0], errors[:, -1], statistic='mean', bins=6, range=[-180, 180])
dstt = np.mean(np.diff(stt.bin_edges))
ax[1].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')

ax[2].plot(ref_loc[:, 0], errors[:,-1], 'bo')
# ax[2].plot(ref_loc2[:, 0], errors2[:,-1], 'ro')
ax[2].set_xlabel('Ref. Loc. (°)')
ax[2].set_ylabel('Error (°)')

stt = binned_statistic(ref_loc[:, 0], errors[:, -1], statistic='mean', bins=6, range=[-180, 180])
dstt = np.mean(np.diff(stt.bin_edges))
ax[2].plot(stt.bin_edges[:-1]+dstt/2, stt.statistic, 'b')

# stt = binned_statistic(rel_loc2[:, 0], errors2[:, -1], statistic='mean', bins=6, range=[-180, 180])
# dstt = np.mean(np.diff(stt.bin_edges))
# ax[1].plot(stt.bin_edges[:-1]+dstt/2,stt.statistic, 'r')
# ax[1].set_ylim([-120, 120])
# ax[1].axhline(color='k', linestyle=":")

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_17.png]]

#+begin_src ipython
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Assuming rel_loc and errors are defined earlier
data = pd.DataFrame({'rel_loc': rel_loc[:, 0], 'errors': errors[:, -1], 'ref_loc': ref_loc[:, -1]})

# Bin data using pandas cut
data['bin'] = pd.cut(data['rel_loc'], bins=8)
# Calculate mean and standard error for each bin
binned_data = data.groupby('bin')['errors'].agg(['mean', 'sem'])
# Get bin centers
bin_edges = binned_data.index.get_level_values(0)
bin_centers = (bin_edges.categories.left + bin_edges.categories.right) / 2

# Plot
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].plot(bin_centers, binned_data['mean'], 'b')
ax[0].fill_between(bin_centers,
                binned_data['mean'] - binned_data['sem'],
                binned_data['mean'] + binned_data['sem'],
                color='b', alpha=0.2)
# ax[0].set_ylim([-30, 30])
ax[0].axhline(color='k', linestyle=":")
ax[0].set_xlabel('Rel. Loc. (°)')
ax[0].set_ylabel('Error (°)')

data['bin'] = pd.cut(data['ref_loc'], bins=8)
# Calculate mean and standard error for each bin
binned_data = data.groupby('bin')['errors'].agg(['mean', 'sem'])
# Get bin centers
bin_edges = binned_data.index.get_level_values(0)
bin_centers = (bin_edges.categories.left + bin_edges.categories.right) / 2

ax[1].plot(bin_centers, binned_data['mean'], 'b')
ax[1].fill_between(bin_centers,
                binned_data['mean'] - binned_data['sem'],
                binned_data['mean'] + binned_data['sem'],
                color='b', alpha=0.2)
# ax[1].set_ylim([-30, 30])
ax[1].axhline(color='k', linestyle=":")
ax[1].set_xlabel('Ref. Loc. (°)')
ax[1].set_ylabel('Error (°)')

plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_18.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
