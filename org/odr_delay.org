#+STARTUP: fold
#+TITLE: Training RNNs on ODR
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session odr :kernel torch :exports results :output-dir ./figures/odr :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run ../notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'

REPO_ROOT = "/home/leon/models/NeuroFlame"
pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  import torchmetrics
  import torch.nn.functional as F
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+begin_src ipython

  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl, decode_bump_torch
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

* Helpers
** plots

#+begin_src ipython
def add_vlines(model, ax=None):

    if ax is None:
        for i in range(len(model.T_STIM_ON)):
            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)
    else:
        for i in range(len(model.T_STIM_ON)):
            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)

#+end_src

#+RESULTS:

#+begin_src ipython
def plot_rates_selec(rates, idx=0, thresh=0.5, figname='fig.svg'):
        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
        r_max = thresh * np.max(rates[idx])

        idx = np.random.randint(0, 96*8)
        ax[0].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[0].set_ylabel('Neuron #')
        ax[0].set_xlabel('Step')

        idx = np.random.randint(0, 96*8)
        ax[1].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[1].set_ylabel('Neuron #')
        ax[1].set_xlabel('Step')
        # ax[1].set_ylim([745, 755])
        # plt.savefig(figname, dpi=300)
        plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_m0_m1_phi(model, rates, idx, figname='fig.svg'):

      m0, m1, phi = decode_bump(rates, axis=-1)
      # m0, m1, phi = get_fourier_moments(rates, axis=-1)
      fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

      xtime = np.linspace(0, model.DURATION, m0.shape[-1])
      idx = np.random.randint(0, 96*8, 16)
      print(idx)

      ax[0].plot(xtime, m0[idx].T)
      #ax[0].set_ylim([0, 360])
      #ax[0].set_yticks([0, 90, 180, 270, 360])
      ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
      ax[0].set_xlabel('Time (s)')
      add_vlines(model, ax[0])

      ax[1].plot(xtime, m1[idx].T)
      # ax[1].set_ylim([0, 360])
      # ax[1].set_yticks([0, 90, 180, 270, 360])
      ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
      ax[1].set_xlabel('Time (s)')
      add_vlines(model, ax[1])

      ax[2].plot(xtime, phi[idx].T * 180 / np.pi, alpha=.5)
      ax[2].set_ylim([0, 360])
      ax[2].set_yticks([0, 90, 180, 270, 360])
      ax[2].set_ylabel('Phase (°)')
      ax[2].set_xlabel('Time (s)')
      add_vlines(model, ax[2])

      plt.savefig(figname, dpi=300)
      plt.show()
    #+end_src

#+RESULTS:

** Data Split

#+begin_src ipython
  from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

  def split_data(X, Y, train_perc=0.8, batch_size=32, shuffle=True):

      if shuffle:
          X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                              train_size=train_perc,
                                                              stratify=Y[:, 0].cpu().numpy(),
                                                              shuffle=True)
      else:
          X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                              train_size=train_perc,
                                                              stratify=None,
                                                              shuffle=False)

      plt.hist(Y_train[Y_train!=-999].cpu() * 180 / np.pi, bins=15, label='train')
      plt.hist(Y_test[Y_test!=-999].cpu() * 180 / np.pi, bins=15, label='test')
      plt.xlabel('Target Loc. (°)')
      plt.ylabel('Count')
      plt.show()

      print(X_train.shape, X_test.shape)
      print(Y_train.shape, Y_test.shape)

      train_dataset = TensorDataset(X_train, Y_train)
      val_dataset = TensorDataset(X_test, Y_test)

      # Create data loaders
      train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=shuffle)
      val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

      return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
  def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=.001, clip_grad=0, zero_grad=0):
      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          X, y = X.to(device), y.to(device)

          optimizer.zero_grad()

          rates = model(X)
          loss = loss_fn(rates, y)

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()

          # Clip gradients
          if clip_grad:
              torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
              #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)

          optimizer.step()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def validation_step(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0

      with torch.no_grad():
          for X, y in dataloader:
              X, y = X.to(device), y.to(device)

              rates = model(X)
              loss = loss_fn(rates, y)

              val_loss += loss.item() * X.size(0)

          val_loss /= size
      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def optimization(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=.005, zero_grad=0):
      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')
      model.to(device)

      loss_list = []
      val_loss_list = []
      accuracies = []
      angle_list = []

      for epoch in range(num_epochs):
          loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, zero_grad=zero_grad)
          val_loss = validation_step(val_loader, model, loss_fn)

          scheduler.step(val_loss)

          loss_list.append(loss.item())
          val_loss_list.append(val_loss)
          # if epoch % int(num_epochs  / 10) == 0:
          print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

          if val_loss < thresh and loss < thresh:
              print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')
              break

          if val_loss > 300:
              print(f'Stopping training as loss is too high: {val_loss}')
              break

          if torch.isnan(loss):
              print(f'Stopping training as loss is NaN.')
              break

      return loss_list, val_loss_list
#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
import torch
import torch.nn as nn
import torch.nn.functional as F

class AngularErrorLoss(nn.Module):
    def __init__(self, rwd_idx=-1):
        super(AngularErrorLoss, self).__init__()
        # self.loss = nn.SmoothL1Loss(reduction='none')
        self.loss = nn.MSELoss(reduction='none')
        self.rwd_idx = rwd_idx

    def forward(self, readout, targets):
        m0, m1, phi = decode_bump_torch(readout, axis=-1)

        total_loss = 0
        for i in range(targets.shape[0]):
            self.rwd_idx = torch.where(targets[i]!=-999)[0]
            self.zero_idx = torch.where(targets[i]==-999)[0]

            ones = torch.ones_like(m0[i, self.rwd_idx])
            zeros = torch.zeros_like(m0[i, self.zero_idx])

            predicted_sin = torch.sin(phi[i, self.rwd_idx])
            predicted_cos = torch.cos(phi[i, self.rwd_idx])

            target_sin = torch.sin(targets[i, self.rwd_idx])
            target_cos = torch.cos(targets[i, self.rwd_idx])

            loss_sin = self.loss(predicted_sin, target_sin)
            loss_cos = self.loss(predicted_cos, target_cos)
            loss_angular = (loss_sin + loss_cos).mean()
            total_loss += loss_angular

            # Regularization losses
            loss_zero = self.loss(m1[i, self.zero_idx], zeros).mean()
            regularization = F.relu(ones * m0[i, self.rwd_idx]- m1[i, self.rwd_idx]).mean()
            total_loss += loss_zero + regularization

        return total_loss / targets.shape[0]
#+end_src

#+RESULTS:

** Other

#+begin_src ipython
import torch
import numpy as np
import matplotlib.pyplot as plt

def continuous_biased_phases(N_BATCH, preferred_angle, sigma):
    phase_samples = torch.normal(mean=preferred_angle, std=sigma, size=(N_BATCH, 1))
    phase_samples = phase_samples % 360

    return phase_samples

#+end_src

#+RESULTS:

#+begin_src ipython
import torch
import numpy as np

def generate_weighted_phase_samples(N_BATCH, angles, preferred_angle, sigma):
    # Convert angles list to a tensor
    angles_tensor = torch.tensor(angles)

    # Calculate Gaussian probability distribution centered at preferred_angle
    probs = np.exp(-0.5 * ((angles - preferred_angle) / sigma) ** 2)
    probs /= probs.sum()  # Normalize to get probabilities

    # Create a categorical distribution from the computed probabilities
    distribution = torch.distributions.Categorical(torch.tensor(probs))

    # Sample from the distribution
    indices = distribution.sample((N_BATCH,))

    # Map indices to angles and reshape to (N_BATCH, 1)
    phase_samples = angles_tensor[indices].reshape(N_BATCH, 1)

    return phase_samples
#+end_src

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

* Model

#+begin_src ipython
REPO_ROOT = "/home/leon/models/NeuroFlame"
conf_name = "train_odr_EI.yml"
DEVICE = 'cuda:0'

IF_BIASED_PHASES = 1
IF_RAND_REF = 0
reference = np.random.randint(0, 360)
reference = 110
print(reference)

sigma = 75

N_BATCH = int(96 * 8)

seed = np.random.randint(0, 1e6)
seed = 19
# seed = 1975
print(seed)
#+end_src

#+RESULTS:
: 110
: 19

#+begin_src ipython
model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH)
try:
    if IF_RAND_REF:
        model_state_dict = torch.load('models/odr_bias_rand_ref_%d.pth' % seed)
        print('rand_ref')
    else:
        model_state_dict = torch.load('models/odr_%d.pth' % seed)
    model.load_state_dict(model_state_dict)
except:
     pass
#+end_src

#+RESULTS:

#+begin_src ipython
print(model.random_shifts.shape)
plt.hist(model.random_shifts.cpu().numpy() * model.DT)
plt.xlabel('Delay (s)')
plt.ylabel('Count')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: torch.Size([768])
[[./figures/odr/figure_16.png]]
:END:

* Training

#+begin_src ipython
if IF_RAND_REF:
    reference = np.random.randint(0, 360)
print(reference)
    #+end_src

#+RESULTS:
: 110

*** Parameters

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: Wab_train torch.Size([750, 750])
: J_STP torch.Size([])

#+begin_src ipython
model.N_BATCH = N_BATCH
rwd_mask = torch.zeros((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)), device=DEVICE, dtype=torch.bool)
print('rwd_mask', rwd_mask.shape)

for i in range(model.N_BATCH):
    # from first stim onset to second stim onset
    mask = torch.arange((model.start_indices[0, i] - model.N_STEADY)/ model.N_WINDOW,
                        (model.start_indices[1, i] - model.N_STEADY) / model.N_WINDOW).to(torch.int)
    # print(mask)
    rwd_mask[i, mask] = True

idx = np.random.randint(N_BATCH)
print(torch.where(rwd_mask[idx]==1)[0])

# rwd_mask = rwd_mask.repeat(N_TARGETS, 1)
# print('rwd_mask', rwd_mask.shape)
# print(torch.where(rwd_mask[idx+32]==1)[0])
#+end_src

#+RESULTS:
: rwd_mask torch.Size([768, 81])
: tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,
:         28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,
:         46, 47, 48, 49, 50, 51, 52, 53, 54, 55], device='cuda:0')

*** Inputs and Labels

#+begin_src ipython
    if IF_BIASED_PHASES:
        labels = continuous_biased_phases(N_BATCH, reference, sigma)
    else:
        labels = torch.randint(0, 360, (N_BATCH, 1)).to(DEVICE)

    model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)
    model.PHI0[:, 0] = labels * np.pi / 180.0

    window_size = int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)
    labels = labels.repeat(1, window_size) * np.pi / 180.0
    labels[~rwd_mask] = -999

    ff_input = model.init_ff_input()
    print(model.PHI0.shape, ff_input.shape, labels.shape)
#+end_src

#+RESULTS:
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([768, 2, 1]) torch.Size([768, 505, 1000]) torch.Size([768, 81])

#+begin_src ipython
# N_BATCH = 32
# N_SESSION = 8
# model.N_BATCH = N_BATCH
# print(model.N_BATCH)
# ff_input = []
# labels = []

# model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)
# window_size = int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)

# for i in range(N_SESSION):
#         reference = torch.randint(low=0, high=360, size=(1,), device=DEVICE, dtype=torch.float)
#         label = continuous_biased_phases(N_BATCH, reference[0], sigma)
#         model.PHI0[:, 0] = label * np.pi / 180.0

#         label = label.repeat(1, window_size) * np.pi / 180.0
#         label[~rwd_mask[:32]] = -999
#         labels.append(label)

#         ff_input.append(model.init_ff_input())

# labels = torch.vstack(labels)
# ff_input = torch.vstack(ff_input)
# print('ff_input', ff_input.shape, 'labels', labels.shape)
#+end_src

#+RESULTS:

#+begin_src ipython
print(labels[labels!=-999].shape)
plt.hist(labels[labels!=-999].cpu() * 180 / np.pi, bins=15)
plt.xlabel('Target Loc. (°)')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: torch.Size([34655])
[[./figures/odr/figure_22.png]]
:END:

*** Run

#+begin_src ipython
  batch_size = 32 # 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
:RESULTS:
[[./figures/odr/figure_23.png]]
: torch.Size([614, 505, 1000]) torch.Size([154, 505, 1000])
: torch.Size([614, 81]) torch.Size([154, 81])
:END:

#+begin_src ipython
  criterion = AngularErrorLoss(rwd_idx=rwd_mask)
  # SGD, Adam, Adam
  learning_rate = 0.1
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

        #+begin_src ipython
  num_epochs = 10
  start = perf_counter()
  loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
#+begin_example
Epoch 1/10, Training Loss: 0.0046, Validation Loss: 0.0063
Epoch 2/10, Training Loss: 0.0053, Validation Loss: 0.0062
Epoch 3/10, Training Loss: 0.0057, Validation Loss: 0.0063
Epoch 4/10, Training Loss: 0.0051, Validation Loss: 0.0061
Epoch 5/10, Training Loss: 0.0059, Validation Loss: 0.0060
Epoch 6/10, Training Loss: 0.0053, Validation Loss: 0.0061
Epoch 7/10, Training Loss: 0.0047, Validation Loss: 0.0060
Epoch 8/10, Training Loss: 0.0060, Validation Loss: 0.0059
Epoch 9/10, Training Loss: 0.0076, Validation Loss: 0.0060
Epoch 10/10, Training Loss: 0.0052, Validation Loss: 0.0059
Elapsed (with compilation) = 0h 3m 15s
#+end_example

#+begin_src ipython
if IF_BIASED_PHASES:
    if IF_RAND_REF:
        torch.save(model.state_dict(), 'models/odr_bias_rand_ref_%d.pth' % seed)
    else:
        torch.save(model.state_dict(), 'models/odr_bias_%d_ref_%d.pth' % (reference, seed) )
else:
    torch.save(model.state_dict(), 'models/odr_%d.pth' % seed)
#+end_src

#+RESULTS:

* Testing

 #+begin_src ipython
if IF_BIASED_PHASES:
    print('Biased ODR')
    if IF_RAND_REF:
        model_state_dict = torch.load('models/odr_bias_rand_ref_%d.pth' % seed )
    else:
        model_state_dict = torch.load('models/odr_bias_%d_ref_%d.pth' % (reference, seed) )
else:
    model_state_dict = torch.load('models/odr_%d.pth' % seed)
model.load_state_dict(model_state_dict)
model.eval()
#+end_src

#+RESULTS:
:RESULTS:
: Biased ODR
: Network(
:   (dropout): Dropout(p=0.0, inplace=False)
: )
:END:

#+begin_src ipython
    model.N_BATCH = N_BATCH
    if IF_BIASED_PHASES:
        model.PHI0 = torch.zeros(size=(N_BATCH, 3, 1), device=DEVICE, dtype=torch.float)
        labels = continuous_biased_phases(N_BATCH, reference, sigma) * torch.pi / 180.0
        model.PHI0[:, 0] = labels
    else:
        labels = torch.randint(0, 360, (N_BATCH, 1)).to(DEVICE) * torch.pi / 180.0
        model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)
        model.PHI0[:, 0] = labels

    ff_input = model.init_ff_input()
    print(model.PHI0.shape, ff_input.shape, labels.shape)
#+end_src

#+RESULTS:
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([768, 3, 1]) torch.Size([768, 505, 1000]) torch.Size([768, 1])

#+begin_src ipython
#     model.N_BATCH = N_BATCH
#     ff_input = []
#     labels = []

#     model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)

#     for i in range(len(phase_list)):
#         model.PHI0[:, 0] = phase_list[i]
#         label = torch.ones(model.N_BATCH, device=DEVICE, dtype=torch.float) * phase_list[i] * torch.pi / 180.0

#         labels.append(label)
#         ff_input.append(model.init_ff_input())

#     labels = torch.hstack(labels)
#     ff_input = torch.vstack(ff_input)
#     print('ff_input', ff_input.shape, 'labels', labels.shape)
 #+end_src

#+RESULTS:

#+begin_src ipython
plt.hist(labels[:, 0].cpu() * 180 / np.pi, bins=15)
plt.xlabel('Target Loc. (°)')
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_30.png]]

#+begin_src ipython
rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
print('ff_input', ff_input.shape)
print('rates', rates.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([768, 505, 1000])
: rates (768, 81, 750)

 #+begin_src ipython
plot_rates_selec(rates=ff_input.cpu().detach().numpy(), idx=20, thresh=.5)
#+end_src

#+RESULTS:
[[./figures/odr/figure_32.png]]

#+begin_src ipython
plot_m0_m1_phi(model, ff_input.cpu().numpy()[..., model.slices[0]], 10)
#+end_src

#+RESULTS:
:RESULTS:
: [584 342 485 429 638 527 694 481   5 573 370  62 402 686 218 268]
[[./figures/odr/figure_33.png]]
:END:

#+begin_src ipython
plot_rates_selec(rates, idx=20, thresh=.1)
#+end_src

#+RESULTS:
[[./figures/odr/figure_34.png]]

        #+begin_src ipython
plot_m0_m1_phi(model, rates, 3)
#+end_src

#+RESULTS:
:RESULTS:
: [517 498 428 142 578 578 112  41 113 309 304 454 122 689 143 327]
[[./figures/odr/figure_35.png]]
:END:

#+begin_src ipython
m0, m1, phi = decode_bump(rates, axis=-1)
print(phi.shape, labels.shape)

target_loc = labels.cpu().numpy()
# print(target_loc.shape)

errors = (phi - target_loc)
errors = (errors + np.pi) % (2 * np.pi) - np.pi
errors *= 180 / np.pi

errors2 = errors[:, int((model.N_STIM_OFF[0].cpu().numpy()-model.N_STEADY) / model.N_WINDOW)]
# print(errors2.shape)

error_list = []
for i in range(errors.shape[0]):
    # idx_stim = model.start_indices[1, i%N_TARGETS].cpu().numpy()
    idx_stim = model.start_indices[1, i].cpu().numpy()
    idx = int((idx_stim - model.N_STEADY) / model.N_WINDOW)

    error_list.append(errors[i, idx])
# errors = errors[:, int((model.N_STIM_ON[1].cpu().numpy()-model.N_STEADY) / model.N_WINDOW)-1]
errors = np.array(error_list)
# print(errors.shape, errors2.shape, target_loc.shape)
#+end_src

#+RESULTS:
: (768, 81) torch.Size([768, 1])

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].hist(errors2, bins=32)
ax[0].set_xlabel('Encoding Errors (°)')

ax[1].hist(errors, bins=32)
ax[1].set_xlabel('Memory Errors (°)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_37.png]]

#+begin_src ipython
from src.lr_utils import LowRankWeights, clamp_tensor
Cij = model.Wab_train / model.Na[0] * model.J_STP
Cij = clamp_tensor(Cij, 0, model.slices).cpu().detach().numpy()
#+end_src

#+RESULTS:

#+begin_src ipython
  plt.figure(figsize=(2.5*width, 1.5*height))  # Set the figure size (width, height) in inches

  ax1 = plt.subplot2grid((2, 3), (0, 0), rowspan=2)
  im = ax1.imshow(Cij, cmap='jet', aspect=1, vmin=0, vmax=.1)
  ax1.set_xlabel("Presynaptic")
  ax1.set_ylabel("Postsynaptic")

  # Second column, first row
  ax2 = plt.subplot2grid((2, 3), (0, 1))
  Kj = np.sum(Cij, axis=0)  # sum over pres
  ax2.plot(Kj)
  # ax2.set_xticklabels([])
  ax2.set_ylabel("$K_j$")

  # # Second column, second row
  ax3 = plt.subplot2grid((2, 3), (1, 1))
  Ki = np.sum(Cij, axis=1)  # sum over pres
  ax3.plot(Kj)
  ax3.set_ylabel("$K_i$")

  ax4 = plt.subplot2grid((2, 3), (0, 2), rowspan=2)
  diags = []
  for i in range(int(Cij.shape[0] / 2)):
      diags.append(np.trace(Cij, offset=i) / Cij.shape[0])
  diags = np.array(diags)
  ax4.plot(diags)
  ax4.set_xlabel("Neuron #")
  ax4.set_ylabel("$P_{ij}$")

  plt.tight_layout()
  plt.show()

#+end_src

#+RESULTS:
[[./figures/odr/figure_39.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

[[./figures/odr/figure_38.png]]
