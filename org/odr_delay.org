#+STARTUP: fold
#+TITLE: Training RNNs on ODR
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session odr :kernel torch :exports results :output-dir ./figures/odr :file (lc/org-babel-tangle-figure-filename)

* Notebook Settings

#+begin_src ipython
%load_ext autoreload
%autoreload 2
%reload_ext autoreload

%run ../notebooks/setup.py
%matplotlib inline
%config InlineBackend.figure_format = 'png'

REPO_ROOT = "/home/leon/models/NeuroFlame"
pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  import torchmetrics
  import torch.nn.functional as F
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+begin_src ipython

  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl, decode_bump_torch
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

* Helpers
** plots

#+begin_src ipython
def add_vlines(model, ax=None):

    if ax is None:
        for i in range(len(model.T_STIM_ON)):
            plt.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)
    else:
        for i in range(len(model.T_STIM_ON)):
            ax.axvspan(model.T_STIM_ON[i], model.T_STIM_OFF[i], alpha=0.25)

#+end_src

#+RESULTS:

#+begin_src ipython
def plot_rates_selec(rates, idx=0, thresh=0.5, figname='fig.svg'):
        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
        r_max = thresh * np.max(rates[idx])

        idx = np.random.randint(0, 96*8)
        ax[0].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[0].set_ylabel('Neuron #')
        ax[0].set_xlabel('Step')

        idx = np.random.randint(0, 96*8)
        ax[1].imshow(rates[idx].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[1].set_ylabel('Neuron #')
        ax[1].set_xlabel('Step')
        # ax[1].set_ylim([745, 755])
        # plt.savefig(figname, dpi=300)
        plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_m0_m1_phi(model, rates, idx, figname='fig.svg'):

      m0, m1, phi = decode_bump(rates, axis=-1)
      # m0, m1, phi = get_fourier_moments(rates, axis=-1)
      fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

      xtime = np.linspace(0, model.DURATION, m0.shape[-1])
      idx = np.random.randint(0, 96*8, 16)
      print(idx)

      ax[0].plot(xtime, m0[idx].T)
      #ax[0].set_ylim([0, 360])
      #ax[0].set_yticks([0, 90, 180, 270, 360])
      ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
      ax[0].set_xlabel('Time (s)')
      add_vlines(model, ax[0])

      ax[1].plot(xtime, m1[idx].T)
      # ax[1].set_ylim([0, 360])
      # ax[1].set_yticks([0, 90, 180, 270, 360])
      ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
      ax[1].set_xlabel('Time (s)')
      add_vlines(model, ax[1])

      ax[2].plot(xtime, phi[idx].T * 180 / np.pi, alpha=.5)
      ax[2].set_ylim([0, 360])
      ax[2].set_yticks([0, 90, 180, 270, 360])
      ax[2].set_ylabel('Phase (째)')
      ax[2].set_xlabel('Time (s)')
      add_vlines(model, ax[2])

      plt.savefig(figname, dpi=300)
      plt.show()
    #+end_src

#+RESULTS:

** Data Split

#+begin_src ipython
  from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

  def split_data(X, Y, train_perc=0.8, batch_size=32):

     X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                         train_size=train_perc,
                                                         stratify=Y[:, 0].cpu().numpy(),
                                                         shuffle=True)

     plt.hist(Y_train[Y_train!=-999].cpu(), bins=15, label='train')
     plt.hist(Y_test[Y_test!=-999].cpu(), bins=15, label='test')
     plt.xlabel('Target Loc. (째)')
     plt.ylabel('Count')
     plt.show()

     print(X_train.shape, X_test.shape)
     print(Y_train.shape, Y_test.shape)

     train_dataset = TensorDataset(X_train, Y_train)
     val_dataset = TensorDataset(X_test, Y_test)

     # Create data loaders
     train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
     val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

     return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
  def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=.001, clip_grad=0, zero_grad=0):
      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          X, y = X.to(device), y.to(device)

          optimizer.zero_grad()

          rates = model(X)
          loss = loss_fn(rates, y)

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()

          # Clip gradients
          if clip_grad:
              torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
              #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)

          optimizer.step()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def validation_step(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0

      with torch.no_grad():
          for X, y in dataloader:
              X, y = X.to(device), y.to(device)

              rates = model(X)
              loss = loss_fn(rates, y)

              val_loss += loss.item() * X.size(0)

          val_loss /= size
      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def optimization(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=.005, zero_grad=0):
      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')
      model.to(device)

      loss_list = []
      val_loss_list = []
      accuracies = []
      angle_list = []

      for epoch in range(num_epochs):
          loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, zero_grad=zero_grad)
          val_loss = validation_step(val_loader, model, loss_fn)

          scheduler.step(val_loss)

          loss_list.append(loss.item())
          val_loss_list.append(val_loss)
          # if epoch % int(num_epochs  / 10) == 0:
          print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

          if val_loss < thresh and loss < thresh:
              print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')
              break

          if val_loss > 300:
              print(f'Stopping training as loss is too high: {val_loss}')
              break

          if torch.isnan(loss):
              print(f'Stopping training as loss is NaN.')
              break

      return loss_list, val_loss_list
#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
def get_fourier_moments(signal, axis=-1):
    # Perform the FFT
    fft_coeffs = np.fft.fft(signal, axis=axis)

    # Calculate the zero, first, and second Fourier moments
    zero_moment = fft_coeffs[..., 0]
    first_moment = fft_coeffs[..., 1]

    # Calculate magnitude m0, m1, and m2
    m0 = np.abs(zero_moment) / signal.shape[axis]  # Normalize m0 by the signal length
    m1 = 2.0 * np.abs(first_moment) / signal.shape[axis]

    # Calculate the phase of the signal
    phases = np.angle(first_moment) % (2.0 * torch.pi)

    return m0, m1, phases
#+end_src

#+RESULTS:

#+begin_src ipython
def compute_fourier_moments(signal, dim=-1):
    # Perform the FFT
    fft_coeffs = torch.fft.fft(signal, dim=dim)

    # Calculate the zero, first, and second Fourier moments
    zero_moment = fft_coeffs[..., 0]
    first_moment = fft_coeffs[..., 1]
    # second_moment = fft_coeffs[..., 2]

    # Calculate magnitude m0, m1, and m2
    m0 = torch.abs(zero_moment) / signal.size(dim)  # Normalize m0 by the signal length
    m1 = 2.0 * torch.abs(first_moment) / signal.size(dim)
    # m2 = 2.0 * torch.abs(second_moment) / signal.size(dim)

    # Calculate the phase of the signal
    phases = torch.angle(first_moment) % (2.0 * torch.pi)

    return m0, m1, phases
#+end_src

#+RESULTS:

#+begin_src ipython
import torch
import torch.nn as nn
import torch.nn.functional as F

class AngularErrorLoss(nn.Module):
    def __init__(self, rwd_idx=-1, zero_idx=0, stim_idx=0):
        super(AngularErrorLoss, self).__init__()
        self.loss = nn.SmoothL1Loss(reduction='none')
        self.loss = nn.MSELoss(reduction='none')

        self.rwd_idx = rwd_idx
        self.zero_idx = zero_idx
        self.stim_idx = stim_idx

    def forward(self, readout, targets):
        m0, m1, phi = compute_fourier_moments(readout, dim=-1)
        # m0, m1, phi = decode_bump_torch(readout, dim=-1)

        total_loss = 0
        for i in range(targets.shape[0]):
            self.rwd_idx = torch.where(targets[i]!=-999)[0]
            self.zero_idx = torch.where(targets[i]==-999)[0]

            ones = torch.ones_like(m0[i, self.rwd_idx])
            zeros = torch.zeros_like(m0[i, self.zero_idx])

            predicted_sin = torch.sin(phi[i, self.rwd_idx])
            predicted_cos = torch.cos(phi[i, self.rwd_idx])

            target_sin = torch.sin(targets[i, self.rwd_idx])
            target_cos = torch.cos(targets[i, self.rwd_idx])

            loss_sin = self.loss(predicted_sin, target_sin)
            loss_cos = self.loss(predicted_cos, target_cos)
            loss_angular = (loss_sin + loss_cos).mean()
            total_loss += loss_angular

            # Regularization losses
            loss_zero = self.loss(m1[i, self.zero_idx], zeros).mean()
            regularization = F.relu(ones * m0[i, self.rwd_idx]- m1[i, self.rwd_idx]).mean()
            total_loss += loss_zero + regularization

        return total_loss / targets.shape[0]
#+end_src

#+RESULTS:

** Other
#+begin_src ipython
import torch
import numpy as np
import matplotlib.pyplot as plt

def continuous_biased_phases(N_BATCH, preferred_angle, sigma):
    # Generate samples from a normal distribution using PyTorch
    phase_samples = torch.normal(mean=preferred_angle, std=sigma, size=(N_BATCH, 1))

    # Normalize angles to the range [0, 360)
    phase_samples = phase_samples % 360

    return phase_samples

# Parameters
N_BATCH = 1000
reference = 90.0  # Example preferred angle
sigma = 75.0  # Standard deviation of the Gaussian

# Generate continuous samples
phase_samples = continuous_biased_phases(N_BATCH, reference, sigma)
print(phase_samples.shape)
# Convert to numpy for plotting
phase_samples_np = phase_samples.numpy()

plt.hist(phase_samples_np[:, 0], bins=36, range=(0, 360))
plt.xlabel('Angle (degrees)')
plt.ylabel('Frequency')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: torch.Size([1000, 1])
[[./figures/odr/figure_13.png]]
:END:

#+begin_src ipython
import torch
import numpy as np

def generate_weighted_phase_samples(N_BATCH, angles, preferred_angle, sigma):
    # Convert angles list to a tensor
    angles_tensor = torch.tensor(angles)

    # Calculate Gaussian probability distribution centered at preferred_angle
    probs = np.exp(-0.5 * ((angles - preferred_angle) / sigma) ** 2)
    probs /= probs.sum()  # Normalize to get probabilities

    # Create a categorical distribution from the computed probabilities
    distribution = torch.distributions.Categorical(torch.tensor(probs))

    # Sample from the distribution
    indices = distribution.sample((N_BATCH,))

    # Map indices to angles and reshape to (N_BATCH, 1)
    phase_samples = angles_tensor[indices].reshape(N_BATCH, 1)

    return phase_samples
#+end_src

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

* Model

#+begin_src ipython
    REPO_ROOT = "/home/leon/models/NeuroFlame"
    conf_name = "train_odr_EI.yml"
    DEVICE = 'cuda:0'
    seed = np.random.randint(0, 1e6)
    print(seed)

    IF_RANDOM_PHASES = 1
    IF_BIASED_PHASES = 1

    if IF_RANDOM_PHASES:
        N_BATCH = int(96 * 8)
    else:
        N_BATCH = 96
#+end_src

#+RESULTS:
: 664505

#+begin_src ipython
seed = 197553
#+end_src
#+RESULTS:

#+begin_src ipython
96 * 32 / 4
#+end_src

#+RESULTS:
: 768.0

#+BEGIN_SRC ipython

#+END_SRC

#+RESULTS:

#+begin_src ipython
N_TARGETS = 8
phase_list = np.linspace(0, 360, N_TARGETS+1)[:-1]
print(phase_list)

reference = 90.  # Example preferred angle
sigma = 75.  # Standard deviation of the Gaussian
#+end_src

#+RESULTS:
: [  0.  45.  90. 135. 180. 225. 270. 315.]

#+begin_src ipython
model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=N_BATCH)
#+end_src

#+RESULTS:

#+begin_src ipython
print(model.random_shifts.shape)
plt.hist(model.random_shifts.cpu().numpy() * model.DT)
plt.xlabel('Delay (s)')
plt.ylabel('Count')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: torch.Size([768])
[[./figures/odr/figure_22.png]]
:END:

* Training
*** Parameters

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: Wab_train torch.Size([750, 750])
: J_STP torch.Size([])

Testing the network on steps from sample odor offset to test odor onset

#+begin_src ipython
model.N_BATCH = N_BATCH
#+end_src

#+RESULTS:

#+begin_src ipython
stim_mask = torch.zeros((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)), device=DEVICE, dtype=torch.bool)
print('stim_mask', stim_mask.shape)

for j in range(model.N_BATCH):
        # from ith stim onset to stim offset
        mask = torch.arange((model.start_indices[0, j] - model.N_STEADY)/ model.N_WINDOW,
                            (model.end_indices[0, j] - model.N_STEADY) / model.N_WINDOW).to(torch.int)
        stim_mask[j, mask] = True

idx = np.random.randint(N_BATCH)
print(torch.where(stim_mask[1]==1)[0])
# stim_mask = stim_mask.repeat(N_TARGETS, 1)
# print('stim_mask', stim_mask.shape)
# print(torch.where(stim_mask[31]==1)[0])
#+end_src

#+RESULTS:
: stim_mask torch.Size([768, 81])
: tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,
:         28, 29], device='cuda:0')

#+begin_src ipython
rwd_mask = torch.zeros((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)), device=DEVICE, dtype=torch.bool)
print('rwd_mask', rwd_mask.shape)

for i in range(model.N_BATCH):
    # from first stim onset to second stim onset
    mask = torch.arange((model.start_indices[0, i] - model.N_STEADY)/ model.N_WINDOW,
                        (model.start_indices[1, i] - model.N_STEADY) / model.N_WINDOW).to(torch.int)
    # print(mask)
    rwd_mask[i, mask] = True

idx = np.random.randint(N_BATCH)
print(torch.where(rwd_mask[idx]==1)[0])
# model.lr_eval_win = torch.max(torch.sum(rwd_mask==1, axis=-1))

# rwd_mask = rwd_mask.repeat(N_TARGETS, 1)
# print('rwd_mask', rwd_mask.shape)
# print(torch.where(rwd_mask[idx+32]==1)[0])
#+end_src

#+RESULTS:
: rwd_mask torch.Size([768, 81])
: tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,
:         28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,
:         46, 47, 48, 49, 50, 51, 52], device='cuda:0')

#+begin_src ipython
zero_mask = torch.zeros((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)), device=DEVICE, dtype=torch.bool)
print('zero_mask', zero_mask.shape)

for i in range(model.N_BATCH):
    mask = ~rwd_mask[i]
    zero_mask[i, mask] = True

idx = np.random.randint(N_BATCH)
print(torch.where(zero_mask[idx]==1)[0])

# zero_mask = zero_mask.repeat(N_TARGETS, 1)
# print('zero_mask', zero_mask.shape)
#+end_src

#+RESULTS:
: zero_mask torch.Size([768, 81])
: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 41, 42, 43, 44, 45, 46, 47, 48,
:         49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,
:         67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80],
:        device='cuda:0')

#+begin_src ipython
steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

# mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
stim_mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STIM_OFF[0].cpu().numpy() - model.N_STEADY))

stim_idx = np.where(stim_mask)[0]
print('stim', stim_idx)

mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STIM_ON[1].cpu().numpy() - model.N_STEADY))
rwd_idx = np.where(mask)[0]
print('rwd', rwd_idx)

model.lr_eval_win = rwd_idx.shape[0]

stim_mask = (steps >= (model.N_STIM_ON[0].cpu().numpy() - model.N_STEADY)) & (steps <= (model.N_STIM_ON[1].cpu().numpy() - model.N_STEADY))

# stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY))

zero_idx = np.where(~mask & ~stim_mask )[0]
print('zero', zero_idx)
#+end_src

#+RESULTS:
: stim [10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30]
: rwd [10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33
:  34 35 36 37 38 39 40]
: zero [ 0  1  2  3  4  5  6  7  8  9 41 42 43 44 45 46 47 48 49 50 51 52 53 54
:  55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78
:  79 80]

*** Inputs and Labels

#+begin_src ipython
if IF_RANDOM_PHASES:
    if IF_BIASED_PHASES:
        labels = continuous_biased_phases(N_BATCH, reference, sigma)
    else:
        labels = torch.randint(0, 360, (N_BATCH, 1)).to(DEVICE)

    model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)
    model.PHI0[:, 0] = labels * np.pi / 180.0

    window_size = int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)
    labels = labels.repeat(1, window_size) * np.pi / 180.0
    labels[~rwd_mask] = -999

    ff_input = model.init_ff_input()
    print(model.PHI0.shape, ff_input.shape, labels.shape)
#+end_src

#+RESULTS:
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([768, 2, 1]) torch.Size([768, 505, 1000]) torch.Size([768, 81])

#+begin_src ipython
if IF_RANDOM_PHASES==0:
    model.N_BATCH = N_BATCH
    ff_input = []
    labels = []

    model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)

    for i in range(len(phase_list)):
        model.PHI0[:, 0] = phase_list[i] * torch.pi / 180.0

        label = torch.ones((model.N_BATCH, int((model.N_STEPS-model.N_STEADY) / model.N_WINDOW)),
                           device=DEVICE, dtype=torch.float) * phase_list[i] * torch.pi / 180.0

        label[~rwd_mask] = -999
        labels.append(label)

        ff_input.append(model.init_ff_input())

    labels = torch.vstack(labels)
    ff_input = torch.vstack(ff_input)
    print('ff_input', ff_input.shape, 'labels', labels.shape)
#+end_src

#+RESULTS:

#+begin_src ipython
print(labels[labels!=-999].shape)
plt.hist(labels[labels!=-999].cpu(), bins=15)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: torch.Size([35262])
[[./figures/odr/figure_31.png]]
:END:

*** Run

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
:RESULTS:
[[./figures/odr/figure_32.png]]
: torch.Size([614, 505, 1000]) torch.Size([154, 505, 1000])
: torch.Size([614, 81]) torch.Size([154, 81])
:END:

#+begin_src ipython
  criterion = AngularErrorLoss(rwd_idx=rwd_mask, zero_idx=zero_mask, stim_idx=stim_mask)
  # SGD, Adam, Adam
  learning_rate = 0.1
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

        #+begin_src ipython
  num_epochs = 15
  start = perf_counter()
  loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
#+begin_example
Epoch 1/15, Training Loss: 0.0396, Validation Loss: 0.0581
Epoch 2/15, Training Loss: 0.0688, Validation Loss: 0.0470
Epoch 3/15, Training Loss: 0.0440, Validation Loss: 0.0430
Epoch 4/15, Training Loss: 0.0338, Validation Loss: 0.0423
Epoch 5/15, Training Loss: 0.0453, Validation Loss: 0.0397
Epoch 6/15, Training Loss: 0.0326, Validation Loss: 0.0377
Epoch 7/15, Training Loss: 0.0386, Validation Loss: 0.0417
Epoch 8/15, Training Loss: 0.0487, Validation Loss: 0.0376
Epoch 9/15, Training Loss: 0.0247, Validation Loss: 0.0392
Epoch 10/15, Training Loss: 0.0382, Validation Loss: 0.0410
Epoch 11/15, Training Loss: 0.0101, Validation Loss: 0.0380
Epoch 12/15, Training Loss: 0.0518, Validation Loss: 0.0343
Epoch 13/15, Training Loss: 0.0205, Validation Loss: 0.0323
Epoch 14/15, Training Loss: 0.0083, Validation Loss: 0.0330
Epoch 15/15, Training Loss: 0.0202, Validation Loss: 0.0330
Elapsed (with compilation) = 0h 8m 35s
#+end_example

#+begin_src ipython
if IF_BIASED_PHASES:
    torch.save(model.state_dict(), 'models/odr_bias_%d.pth' % seed)
else:
    torch.save(model.state_dict(), 'models/odr_%d.pth' % seed)
#+end_src

#+RESULTS:

#+begin_src ipython

#+end_src

#+RESULTS:

* Testing

 #+begin_src ipython
if IF_BIASED_PHASES:
    model_state_dict = torch.load('models/odr_bias_%d.pth' % seed)
else:
    model_state_dict = torch.load('models/odr_%d.pth' % seed)
model.load_state_dict(model_state_dict)
#+end_src

#+RESULTS:
: <All keys matched successfully>

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
: Network(
:   (dropout): Dropout(p=0.0, inplace=False)
: )

#+begin_src ipython
 model.N_BATCH = N_BATCH
 if IF_RANDOM_PHASES:
    labels = torch.randint(0, 360, (N_BATCH, 1)).to(DEVICE) * torch.pi / 180.0
    model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)
    model.PHI0[:, 0] = labels

    ff_input = model.init_ff_input()
    print(model.PHI0.shape, ff_input.shape, labels.shape)
#+end_src

#+RESULTS:
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([1, 750]) torch.Size([768, 1])
: torch.Size([768, 2, 1]) torch.Size([768, 505, 1000]) torch.Size([768, 1])

#+begin_src ipython
if IF_RANDOM_PHASES==0:
    model.N_BATCH = N_BATCH
    ff_input = []
    labels = []

    model.PHI0 = torch.ones((N_BATCH, 2, 1), device=DEVICE, dtype=torch.float)

    for i in range(len(phase_list)):
        model.PHI0[:, 0] = phase_list[i]
        label = torch.ones(model.N_BATCH, device=DEVICE, dtype=torch.float) * phase_list[i] * torch.pi / 180.0

        labels.append(label)
        ff_input.append(model.init_ff_input())

    labels = torch.hstack(labels)
    ff_input = torch.vstack(ff_input)
    print('ff_input', ff_input.shape, 'labels', labels.shape)
#+end_src

#+RESULTS:

#+begin_src ipython
rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
print('ff_input', ff_input.shape)
print('rates', rates.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([768, 505, 1000])
: rates (768, 81, 750)

#+begin_src ipython
plot_rates_selec(rates=ff_input.cpu().detach().numpy(), idx=20, thresh=.5)
#+end_src

#+RESULTS:
[[./figures/odr/figure_42.png]]

#+begin_src ipython
plot_m0_m1_phi(model, ff_input.cpu().numpy()[..., model.slices[0]], 10)
#+end_src

#+RESULTS:
:RESULTS:
: [549 275 661 402 242 767 342 151 384 613 103 215 648 390 332 450]
[[./figures/odr/figure_43.png]]
:END:

#+begin_src ipython
plot_rates_selec(rates, idx=20, thresh=.1)
#+end_src

#+RESULTS:
[[./figures/odr/figure_44.png]]

        #+begin_src ipython
plot_m0_m1_phi(model, rates, 3)
#+end_src

#+RESULTS:
:RESULTS:
: [ 40 716  53  55 244 247 133 543 438 681 366 717 340 372  44 503]
[[./figures/odr/figure_45.png]]
:END:

#+begin_src ipython
m0, m1, phi = get_fourier_moments(rates, axis=-1)
# m0, m1, phi = decode_bump(rates, axis=-1)
print(phi.shape, labels.shape)

target_loc = labels.cpu().numpy()
print(target_loc.shape)

errors = (phi - target_loc)
errors = (errors + np.pi) % (2 * np.pi) - np.pi
errors *= 180 / np.pi

errors2 = errors[:, int((model.N_STIM_OFF[0].cpu().numpy()-model.N_STEADY) / model.N_WINDOW)]
print(errors2.shape)

error_list = []
for i in range(errors.shape[0]):
    idx_stim = model.start_indices[1, i%N_TARGETS].cpu().numpy()
    idx = int((idx_stim - model.N_STEADY) / model.N_WINDOW)

    error_list.append(errors[i, idx])
# errors = errors[:, int((model.N_STIM_ON[1].cpu().numpy()-model.N_STEADY) / model.N_WINDOW)-1]
errors = np.array(error_list)
print(errors.shape, errors2.shape, target_loc.shape)
#+end_src

#+RESULTS:
: (768, 81) torch.Size([768, 1])
: (768, 1)
: (768,)
: (768,) (768,) (768, 1)

#+begin_src ipython
fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
ax[0].hist(errors2, bins=32)
ax[0].set_xlabel('Encoding Errors (째)')

ax[1].hist(errors, bins=32)
ax[1].set_xlabel('Memory Errors (째)')
# ax[1].set_xlim([-45, 45])
plt.show()
#+end_src

#+RESULTS:
[[./figures/odr/figure_47.png]]

#+begin_src ipython
print(model.J_STP)
#+end_src

#+RESULTS:
: Parameter containing:
: tensor(39.9862, device='cuda:0', requires_grad=True)
