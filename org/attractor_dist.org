#+STARTUP: fold
#+TITLE: Dual Task Readout Rotation
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session dist :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import torch
  import gc
  import pandas as pd
  from time import perf_counter

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, decode_bump_torch
  from src.utils import clear_cache
#+end_src

#+RESULTS:

* Helpers

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython 
  import numpy as np
  def get_theta(a, b, GM=0, IF_NORM=0):

      u, v = a, b

      if GM:
          v = b - np.dot(b, a) / np.dot(a, a) * a

      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)

      return np.arctan2(v, u)
#+end_src

#+RESULTS:

#+begin_src ipython 
  def get_idx(model):
      ksi = model.PHI0.cpu().detach().numpy()
      theta = get_theta(ksi[0], ksi[2], GM=0, IF_NORM=0)
      return theta.argsort()
#+end_src

#+RESULTS:

#+begin_src ipython 
  def get_overlap(model, rates):
      return rates @ model.PHI0.T / rates.shape[-1]
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_correct_perf(rates, d_phi, n_ini=50):
      m0, m1, phi = decode_bump(rates, axis=-1)
      x = m1[..., -1] / m0[..., -1] * np.cos(phi[..., -1] - d_phi * np.pi / 180)
      performance = (x[:n_ini] < 0).mean() * 100
      performance += (x[n_ini:] > 0).mean() * 100

      return performance / 2
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_perf(model, rates, n_ini):
      overlap = get_overlap(model, rates)
      
      readoutA = overlap[:n_ini, -5:, 0]
      readoutB = overlap[n_ini:, -5:, 0]

      readout = torch.stack((readoutA, readoutB))

      perf = (1.0 * (readout[0]>0)).mean((0, 1))
      perf += (1.0 * (readout[1]<0)).mean((0,1))

      return perf / 2.0
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_avg_phi(centers):
      x_c1, y_c1 = centers[0]
      x_c2, y_c2 = centers[1]

      radius = np.sqrt(x_c1**2 + y_c1**2)

      # Midpoint M of A and B
      xM, yM = (x_c1 + x_c2) / 2, (y_c1 + y_c2) / 2

      phi1 = np.arctan2(y_c1, x_c1)
      phi2 = np.arctan2(y_c2, x_c2)

      phi0 = ( (phi1 + phi2) / 2 ) % np.pi
      psi0 = (phi0 + np.pi) % (2 * np.pi)

      xPhi = radius * np.cos(phi0)
      yPhi = radius * np.sin(phi0)

      xPsi = radius * np.cos(psi0)
      yPsi = radius * np.sin(psi0)

      dist = [np.sqrt((xPhi - xM)**2 + (yPhi - yM)**2),
              np.sqrt((xPsi - xM)**2 + (yPsi - yM)**2)]
      
      if dist[0]>dist[1]:
          mean_phi = phi0 * 180 / np.pi
      else:
          mean_phi = psi0 * 180 / np.pi

      return mean_phi
#+end_src

#+RESULTS:

#+begin_src ipython
  from sklearn.cluster import KMeans
  kmeans = KMeans(n_clusters=2)

  def get_centers(x, y):
      data = np.stack((x,y)).T
      kmeans.fit(data)
      centers = kmeans.cluster_centers_

      return centers

  def get_coord(rates):
      m0, m1, phi = decode_bump_torch(rates, axis=-1)

      x = m1 / m0 * torch.cos(phi)
      y = m1 / m0 * torch.sin(phi)

      return x.real, y.real
#+end_src

#+RESULTS:

* Dual task with rotating readout
** Parameters

#+begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroTorch"
  conf_name = "config_EI.yml"
  name = "low_rank_ini"

  n_ini  = 32

  LR_COV = [[1.0, 1.0, 0.0, 0.0],
            [0.8, 1.0, 0.0, 0.0],
            [0.0, 0.0, 1.0, 0.8],
            [0.0, 0.0, 0.8, 1.0]]
  
#+end_src

#+RESULTS:

** Fixed Points
*** Simulation

#+begin_src ipython
  from sklearn.cluster import KMeans
  kmeans = KMeans(n_clusters=2)
#+end_src

#+RESULTS:

#+begin_src ipython
  start = perf_counter()

  rates_fp = []
  rates_list = []
  perf_list = []
  perf_cr = []

  distance_list = []
  centers_list = []
  phi0_list = []

  for i in range(50):
      seed = np.random.randint(10000)

      model = Network(conf_name, name, REPO_ROOT, VERBOSE=0, DEVICE='cuda:1',
                      N_BATCH=2*n_ini, SEED=seed, LR_COV=LR_COV,
                      TASK='dual_rand', LIVE_FF_UPDATE=1, DURATION=30)

      idx = get_idx(model)
      
      rates = model(REC_LAST_ONLY=1)[..., idx]
      rates_fp.append(rates)

      x, y = get_coord(rates)
      centers = get_centers(x.cpu().numpy(), y.cpu().numpy())
      mean_phi = get_avg_phi(centers)

      centers_list.append(centers)
      phi0_list.append(mean_phi)
      distance_list.append(np.linalg.norm(centers))

      model = Network(conf_name, name, REPO_ROOT, VERBOSE=0, DEVICE='cuda:1',
                      N_BATCH=2*n_ini, SEED=seed, LR_COV=LR_COV,
                      TASK='dual', LIVE_FF_UPDATE=1, DURATION=10)

      # model.TASK = 'dual'
      # model.DURATION = 10
      # model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW

      rates = model()
      rates_list.append(rates[..., idx])
      perf_list.append(get_perf(model, rates, n_ini))

      # model.PHI1 = torch.tensor([0, 180-mean_phi], device='cuda:1')
      # model.TASK = 'dual_odr'

      model = Network(conf_name, name, REPO_ROOT, VERBOSE=0, DEVICE='cuda:1',
                      N_BATCH=2*n_ini, SEED=seed, LR_COV=LR_COV,
                      TASK='dual_odr', LIVE_FF_UPDATE=1, DURATION=10)

      rates_cr = model()[..., idx].cpu().numpy()

      perf1 = get_correct_perf(rates_cr, mean_phi, n_ini)
      perf2 = get_correct_perf(rates_cr, 180-mean_phi, n_ini)
      perf = np.max((perf1, perf2))
      perf_cr.append(perf)

      del model

  end = perf_counter()

  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

#+end_src

#+RESULTS:
: 68a54ac3-eeab-4dfe-a81e-cee952371307

#+begin_src ipython
  rates_list = torch.stack(rates_list).cpu().numpy()
  perf_list = torch.stack(perf_list).cpu().numpy()
  perf_cr = np.array(perf_cr)
  rates_fp = torch.stack(rates_fp).cpu().numpy()
#+end_src

#+RESULTS:
: 7298de56-8181-4394-9ffe-5e388a5bfa7d

#+begin_src ipython
  print(rates_list.shape)
#+end_src

#+RESULTS:
: 6f4ecf62-19cb-4815-b175-ffeed5accd08

#+begin_src ipython
  centers_list = np.array(centers_list)
  distance_list = np.array(distance_list)
  phi0_list = np.array(phi0_list)
#+end_src

#+RESULTS:
: e644e412-74f2-459e-b9de-e77f02dc347b

#+begin_src ipython
  fig, ax = plt.subplots(1, 1, figsize=[height, height])

  m0, m1, phi = decode_bump(rates_fp, axis=-1)

  # plot clouds
  x_cloud = m1 / m0 * np.cos(phi)
  y_cloud = m1 / m0 * np.sin(phi)

  # plot centers
  for i in range(centers_list.shape[0]):      
      color = np.random.rand(3,)

      ax.plot(x_cloud[i], y_cloud[i], 'o', alpha=.25, color=color)

      x_c1, y_c1 = centers_list[i, 0]
      x_c2, y_c2 = centers_list[i, 1]

      ax.plot(x_c1, y_c1, 'x', alpha=1, ms=20, color=color, lw=10)
      ax.plot(x_c2, y_c2, 'x', alpha=1, ms=20, color=color, lw=10)

      # plot separatrix
      x = 1.75 * np.cos(phi0_list[i] * np.pi / 180)
      y = 1.75 * np.sin(phi0_list[i] * np.pi / 180)

      # Draw an arrow using plt.arrow(x, y, dx, dy, **kwargs)
      plt.arrow(0, 0, x, y, head_width=0.25, head_length=0.25, fc=color)
      
      mean = np.array([phi0_list[i], phi0_list[i] - 180 ]) * np.pi/180

      x = 1.75 * np.cos(mean)
      y = 1.75 * np.sin(mean)
      ax.plot(x, y, '--', color=color)

  ax.set_xlim([-2, 2])
  ax.set_ylim([-2, 2])

  plt.show()
  #+end_src

  #+RESULTS:
  : 7853836e-5b65-4c13-ab64-40383b494a92

#+begin_src ipython
  i = 7
#+end_src

#+RESULTS:
: ef195ad7-af3d-4e17-ba69-344af94d399a

#+begin_src ipython
  fig, ax = plt.subplots(figsize=(height, height))

  m0, m1, phi = decode_bump(rates_list[i], axis=-1)

  x = m1 / m0 * np.cos(phi)
  y = m1 / m0 * np.sin(phi)

  x = x[:5]
  y = y[:5]

  ax.plot(x.T[0], y.T[0], 'ob', alpha=.25, ms=10)
  ax.plot(x.T, y.T, '-b', alpha=.5)
  ax.plot(x.T[-1], y.T[-1], 'sb', alpha=.25, ms=10)

  x = m1 / m0 * np.cos(phi)
  y = m1 / m0 * np.sin(phi)

  x = x[-5:]
  y = y[-5:]
  ax.plot(x.T[0], y.T[0], 'or', alpha=.25, ms=10)
  ax.plot(x.T, y.T, '-r', alpha=.5)
  ax.plot(x.T[-1], y.T[-1], 'sr', alpha=.25, ms=10)

  x_c1, y_c1 = centers_list[i, 0]
  x_c2, y_c2 = centers_list[i, 1]

  ax.plot(x_c1, y_c1, 'x', alpha=1, ms=20, color='k', lw=10)
  ax.plot(x_c2, y_c2, 'x', alpha=1, ms=20, color='k', lw=10)

  # plot separatrix
  x = 1.75 * np.cos(phi0_list[i] * np.pi / 180)
  y = 1.75 * np.sin(phi0_list[i] * np.pi / 180)

  # Draw an arrow using plt.arrow(x, y, dx, dy, **kwargs)
  plt.arrow(0, 0, x, y, head_width=0.25, head_length=0.25, fc='k')

  mean = np.array([phi0_list[i], phi0_list[i] - 180 ]) * np.pi/180

  x = 1.75 * np.cos(mean)
  y = 1.75 * np.sin(mean)
  ax.plot(x, y, '--', color='k')

  ax.set_xlim([-2, 2])
  ax.set_ylim([-2, 2])
  plt.show()
#+end_src

#+RESULTS:
: 3dc26ec7-5704-4da9-bfe4-2747219fc824

#+begin_src ipython
  print('dist', distance_list)
  print('perf_list',perf_list*100)
  print('perf_cr', perf_cr)
#+end_src

#+RESULTS:
: 24f48734-3e3a-4946-9eef-b2d803e366c0

#+begin_src ipython
  plt.plot(distance_list[distance_list.argsort()]/2, perf_list[distance_list.argsort()]*100, 'b')
  plt.plot(distance_list[distance_list.argsort()]/2, perf_cr[distance_list.argsort()], 'r')
  plt.xlabel('Distance')
  plt.ylabel('Performance')
  plt.show()
#+end_src

#+RESULTS:
: d466f4e5-353d-44d2-b179-b7b635f41d62

#+begin_src ipython
  plt.plot(phi0_list[phi0_list.argsort()], perf_list[phi0_list.argsort()]*100, 'b')
  plt.plot(phi0_list[phi0_list.argsort()], perf_cr[phi0_list.argsort()], 'r')
  plt.show()
#+end_src

#+RESULTS:
: 655fe660-d06f-45d1-b5ba-7374cbf39de0

#+begin_src ipython

#+end_src

#+RESULTS:
: 8b355964-aa02-4b62-9a60-d949b606ad68
