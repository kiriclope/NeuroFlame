#+STARTUP: fold
#+TITLE: RNN with pytorch
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session test :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import torch
  import pandas as pd
  from time import perf_counter  

  from src.network import Network
  from src.lif_network import LIFNetwork
  from src.plot_utils import plot_con
  from src.decode import decode_bump
#+end_src

#+RESULTS:

* Helpers
** Random

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      if GM:          
          b = b - np.dot(b, a) / np.dot(a, a) * a

      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)
      else:
          u=a
          v=b

      return np.arctan2(v, u)
#+end_src

#+RESULTS:

#+begin_src ipython
  def normalize(v):
      return v / np.linalg.norm(v)

  def project(x, u):
      return x * u
  # return np.dot(x, u) * u

  def sort_by_angle(x, u, v):
      u_hat = normalize(u)
      v_hat = normalize(v)

      x_proj_u = project(x, u_hat)
      x_proj_v = project(x, v_hat)
      # x_proj = x_proj_u + x_proj_v
      theta = np.arctan2(x_proj_v, x_proj_u) + np.pi

      # cos_theta = np.dot(x_proj, u_hat) / np.linalg.norm(x_proj) * u_hat
      # sin_theta = np.dot(x_proj, v_hat) / np.linalg.norm(x_proj) * v_hat
      # theta = np.arctan2(sin_theta, cos_theta)

      # Pair up each element of x with the corresponding angle
      # x_angle_pairs = list(zip(x, theta))

      # Sort based on the angle
      # x_angle_pairs.sort(key=lambda pair: pair[1])

      # Extract the sorted elements
      # sorted_x = [pair[0] for pair in x_angle_pairs]

      return theta
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_idx(model):
      ksi = model.PHI0.cpu().detach().numpy()
      print(ksi.shape)

      idx = np.arange(0, len(ksi[0]))
      theta = get_theta(ksi[0], ksi[2], GM=0, IF_NORM=0)

      return theta.argsort()
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_overlap(model, rates):
      ksi = model.PHI0.cpu().detach().numpy()
      return rates @ ksi.T / rates.shape[-1]
  
#+end_src

#+RESULTS:

* Connectivity
** Imports

#+begin_src ipython
  from src.connectivity import Connectivity
#+end_src

#+RESULTS:

** ODR

#+begin_src ipython
  Cij = Connectivity(1000, 1000, 100)('sparse', 'cosine', kappa=1.0, sigma=0, phase=0)
#+end_src

#+RESULTS:

#+begin_src ipython
  Cij = Cij.cpu().detach().numpy()
  print(Cij.shape)
#+end_src

#+RESULTS:
: (1000, 1000)

#+begin_src ipython
  plt.figure(figsize=(12, 5))  # Set the figure size (width, height) in inches

  ax1 = plt.subplot2grid((2, 3), (0, 0), rowspan=2)
  im = ax1.imshow(Cij, cmap='jet', aspect=1)
  ax1.set_xlabel("Presynaptic")
  ax1.set_ylabel("Postsynaptic")

  # Second column, first row
  ax2 = plt.subplot2grid((2, 3), (0, 1))
  Kj = np.sum(Cij, axis=0)  # sum over pres
  ax2.plot(Kj)
  # ax2.set_xticklabels([])
  ax2.set_ylabel("$K_j$")

  # # Second column, second row
  ax3 = plt.subplot2grid((2, 3), (1, 1))
  Ki = np.sum(Cij, axis=1)  # sum over pres
  ax3.plot(Kj)
  ax3.set_ylabel("$K_i$")

  ax4 = plt.subplot2grid((2, 3), (0, 2), rowspan=2)
  diags = []
  for i in range(int(Cij.shape[0] / 2)):
      diags.append(np.trace(Cij, offset=i) / Cij.shape[0])
  diags = np.array(diags)
  ax4.plot(diags)
  ax4.set_xlabel("Neuron #")
  ax4.set_ylabel("$P_{ij}$")

  plt.tight_layout()
  plt.show()

#+end_src

#+RESULTS:
[[file:./.ob-jupyter/af5d45fae0b40e95ad18a3a6ac798240b326657f.png]]

** Dual Task

#+begin_src ipython
  Con = Connectivity(1000, 1000, 100, verbose=1)
  Cij = Con('sparse', 'lr', kappa=10, lr_mean=[0, 0], lr_cov=[[1, 0], [0, 1]])
#+end_src

#+RESULTS:
: Generating low rank vectors
: ksi torch.Size([2, 1000])
: low rank probability
: Sparse random connectivity
: with weak low rank structure, KAPPA 10.00

#+begin_src ipython
  Cij = Cij.cpu().detach().numpy()
  print(Cij.shape)
#+end_src

#+RESULTS:
: (1000, 1000)

#+begin_src ipython
  plt.figure(figsize=(12, 5))  # Set the figure size (width, height) in inches

  ax1 = plt.subplot2grid((2, 3), (0, 0), rowspan=2)
  im = ax1.imshow(Cij, cmap='jet', aspect=1)
  ax1.set_xlabel("Presynaptic")
  ax1.set_ylabel("Postsynaptic")

  # Second column, first row
  ax2 = plt.subplot2grid((2, 3), (0, 1))
  Kj = np.sum(Cij, axis=0)  # sum over pres
  ax2.plot(Kj)
  # ax2.set_xticklabels([])
  ax2.set_ylabel("$K_j$")

  # # Second column, second row
  ax3 = plt.subplot2grid((2, 3), (1, 1))
  Ki = np.sum(Cij, axis=1)  # sum over pres
  ax3.plot(Kj)
  ax3.set_ylabel("$K_i$")

  ax4 = plt.subplot2grid((2, 3), (0, 2), rowspan=2)
  diags = []
  for i in range(int(Cij.shape[0] / 2)):
      diags.append(np.trace(Cij, offset=i) / Cij.shape[0])
  diags = np.array(diags)
  ax4.plot(diags)
  ax4.set_xlabel("Neuron #")
  ax4.set_ylabel("$P_{ij}$")

  plt.tight_layout()
  plt.show()

#+end_src

#+RESULTS:
[[file:./.ob-jupyter/3c321c7ad0c258cea890c8dd486bc4aa280ac221.png]]

#+begin_src ipython
  ksi = Con.ksi.cpu().detach().numpy()
  print('ksi', ksi.shape)
  idx = np.arange(0, len(ksi[0]))
  # print(theta.shape)
  theta = get_theta(ksi[0], ksi[1], GM=0, IF_NORM=1)
  theta = np.arctan2(ksi[1], ksi[0])
  index_order = theta.argsort()
  # print(index_order)
  Cij_ordered = Cij[index_order][index_order]
  print(Cij_ordered.shape)
#+end_src

#+RESULTS:
: ksi (2, 1000)
: (1000, 1000)

#+begin_src ipython
  plt.figure(figsize=(12, 5))  # Set the figure size (width, height) in inches

  ax1 = plt.subplot2grid((2, 3), (0, 0), rowspan=2)
  im = ax1.imshow(Cij_ordered, cmap='jet', aspect=1)
  ax1.set_xlabel("Presynaptic")
  ax1.set_ylabel("Postsynaptic")

  # Second column, first row
  ax2 = plt.subplot2grid((2, 3), (0, 1))
  Kj = np.sum(Cij_ordered, axis=0)  # sum over pres
  ax2.plot(Kj)
  # ax2.set_xticklabels([])
  ax2.set_ylabel("$K_j$")

  # # Second column, second row
  ax3 = plt.subplot2grid((2, 3), (1, 1))
  Ki = np.sum(Cij_ordered, axis=1)  # sum over pres
  ax3.plot(Kj)
  ax3.set_ylabel("$K_i$")

  ax4 = plt.subplot2grid((2, 3), (0, 2), rowspan=2)
  diags = []
  for i in range(int(Cij_ordered.shape[0] / 2)):
      diags.append(np.trace(Cij_ordered, offset=i) / Cij_ordered.shape[0])
  diags = np.array(diags)
  ax4.plot(diags)
  ax4.set_xlabel("Neuron #")
  ax4.set_ylabel("$P_{ij}$")

  plt.tight_layout()
  plt.show()

#+end_src

#+RESULTS:
[[file:./.ob-jupyter/7044ca7b355c351e5832a88319970eca7909aa1f.png]]

#+begin_src ipython

#+end_src

** Sparse

#+begin_src ipython
    REPO_ROOT = "/home/leon/models/NeuroTorch"
    model = Network('config_EI.yml', 'test', REPO_ROOT, VERBOSE=1, DEVICE='cuda', TASK='odr',
                    PROBA_TYPE=['cosine', '', '',''], KAPPA=[1, 0, 0, 0])
#+end_src

#+RESULTS:
: Na tensor([8000, 2000], device='cuda:0', dtype=torch.int32) Ka tensor([500., 500.], device='cuda:0') csumNa tensor([    0,  8000, 10000], device='cuda:0')
: Jab [1.0, -1.5, 1, -1]
: Ja0 [2.0, 1.0]

#+begin_src ipython
  import torch

  # Simulate a large dense matrix
  # Example is small for demonstration purposes, adjust sizes accordingly
  # dense_matrix = torch.tensor([[0, 0, 3], [4, 0, 0], [0, 0, 5]], dtype=torch.float32)

  N = 10000
  K = 1000

  # dense_matrix = 1.0 * (torch.rand(N, N, device='cuda') <= (K / float(N)))
  dense_matrix = model.Wab_T.T
  
  # Define variables to store indices and values of non-zero elements
  nnz_indices = []
  nnz_values = []

  # Define chunk size (adjust based on your memory constraints)
  chunk_size = 4  # Here, a chunk consists of 1 row for simplicity

  # Loop through chunks of the matrix
  for i in range(0, dense_matrix.size(0), chunk_size):
      # Get the current chunk
      chunk = dense_matrix[i:i+chunk_size, :]

      # Find non-zero elements in the chunk
      chunk_nnz_indices = torch.nonzero(chunk, as_tuple=False).t()  # Transpose to match COO format
      chunk_nnz_values = chunk[chunk_nnz_indices[0], chunk_nnz_indices[1]]

      # Adjust chunk indices to global indices
      chunk_nnz_indices[0] += i  # Adjust row indices for chunks beyond the first

      # Append current chunk's non-zero elements to the lists
      nnz_indices.append(chunk_nnz_indices)
      nnz_values.append(chunk_nnz_values)

  # Concatenate all non-zero indices and values
  nnz_indices = torch.cat(nnz_indices, dim=1)  # Concatenate along columns
  nnz_values = torch.cat(nnz_values)

  # Create sparse tensor
  sparse_matrix = torch.sparse_coo_tensor(nnz_indices, nnz_values, dense_matrix.size())

  print(sparse_matrix)
#+end_src

#+RESULTS:
: tensor(indices=tensor([[   0,    0,    0,  ..., 9999, 9999, 9999],
:                        [   7,    8,   10,  ..., 9990, 9994, 9996]]),
:        values=tensor([ 0.0447,  0.0447,  0.0447,  ..., -0.0447, -0.0447,
:                       -0.0447]),
:        device='cuda:0', size=(10000, 10000), nnz=10000299,
:        layout=torch.sparse_coo)

#+begin_src ipython  
  plot_con(sparse_matrix.to_dense().cpu().detach().numpy().T)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/150232b2d43b109da6dcaf5c5118316817735ae5.png]]

** Von Mises

#+begin_src ipython
  Cij = Connectivity(1000, 1000, 1.0)('all2all', 'von_mises', kappa=1.0, sigma=0, phase=0)
#+end_src

#+RESULTS:

#+begin_src ipython
  Cij = Cij.cpu().detach().numpy()
  print(Cij.shape)
#+end_src

#+RESULTS:
: (1000, 1000)

#+begin_src ipython
  plt.figure(figsize=(12, 5))  # Set the figure size (width, height) in inches

  ax1 = plt.subplot2grid((2, 3), (0, 0), rowspan=2)
  im = ax1.imshow(Cij, cmap='jet', aspect=1)
  ax1.set_xlabel("Presynaptic")
  ax1.set_ylabel("Postsynaptic")

  # Second column, first row
  ax2 = plt.subplot2grid((2, 3), (0, 1))
  Kj = np.sum(Cij, axis=0)  # sum over pres
  ax2.plot(Kj)
  # ax2.set_xticklabels([])
  ax2.set_ylabel("$K_j$")

  # # Second column, second row
  ax3 = plt.subplot2grid((2, 3), (1, 1))
  Ki = np.sum(Cij, axis=1)  # sum over pres
  ax3.plot(Kj)
  ax3.set_ylabel("$K_i$")

  ax4 = plt.subplot2grid((2, 3), (0, 2), rowspan=2)
  diags = []
  for i in range(int(Cij.shape[0] / 2)):
      diags.append(np.trace(Cij, offset=i) / Cij.shape[0])
  diags = np.array(diags)
  ax4.plot(diags)
  ax4.set_xlabel("Neuron #")
  ax4.set_ylabel("$P_{ij}$")

  plt.tight_layout()
  plt.show()

#+end_src

#+RESULTS:
[[file:./.ob-jupyter/063bd67c90e50bbfef9b5fe334589105198dfacf.png]]

* Stimuli
** Imports

#+begin_src ipython
  from src.stimuli import Stimuli
#+end_src

#+RESULTS:

** ODR

#+begin_src ipython
  ff_input = Stimuli(task='odr', size=(1, 1000))(1, 1, 0).cpu().detach().numpy() 
  print(ff_input.shape)
  plt.plot(ff_input)
  plt.xlabel('Neuron #')
  plt.ylabel('Input Strength')
  plt.title('ODR')
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (1000,)
[[file:./.ob-jupyter/f10bdc01e2a8555af8b2cba16bda2923182df89d.png]]
:END:

** Dual Task

#+begin_src ipython
  xi = torch.randn((2, 1000), device='cuda')
  ff_input = Stimuli(task='dual', size=(1, 1000))(1, 1, xi[0]).cpu().detach().numpy()  
  print(ff_input.shape)
  
  theta = get_theta(xi[0].cpu().numpy(), xi[1].cpu().numpy(), GM=0, IF_NORM=0)
  theta = np.arctan2(xi[1].cpu().numpy(), xi[0].cpu().numpy())
  index_order = theta.argsort()

  ff_input = ff_input[index_order]
  plt.plot(ff_input)
  plt.xlabel('Neuron #')
  plt.ylabel('Input Strength')
  plt.title('Dual Task')
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (1000,)
[[file:./.ob-jupyter/16677d3ec5e5eafa315dfa4966462f1df7d37162.png]]
:END:

* FF Inputs
** ODR

#+begin_src ipython
    REPO_ROOT = "/home/leon/models/NeuroTorch"
    model = Network('config_EI.yml', 'test', REPO_ROOT, VERBOSE=1, DEVICE='cuda', TASK='odr',
                    PROBA_TYPE=['cosine', '', '',''])
#+end_src

#+RESULTS:
: Na tensor([8000, 2000], device='cuda:0', dtype=torch.int32) Ka tensor([500., 500.], device='cuda:0') csumNa tensor([    0,  8000, 10000], device='cuda:0')
: Jab [1.0, -1.5, 1, -1]
: Ja0 [2.0, 1.0]

#+begin_src ipython
  ff_input = model.init_ff_input().cpu().detach().numpy()
  print(ff_input.shape)
#+end_src

#+RESULTS:
: (1, 1125, 10000)

#+begin_src ipython
  plt.plot(ff_input[0, :, :5])
  plt.plot(ff_input[0, :, -5:])
  plt.xlabel('Step')
  plt.ylabel('FF Input')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/77d1c1eab3e144ead8fb8b6c0f95da5e4571adf2.png]]

#+begin_src ipython
  plt.imshow(ff_input[0].T, cmap='jet', vmin=0, vmax=55, aspect='auto')
  plt.xlabel('Step')
  plt.ylabel('Neuron #')
  plt.ylim([0, 7500])
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/326904e9582ba172c16a1d23efd7424b3c982add.png]]

** Dual Task

#+begin_src ipython
    REPO_ROOT = "/home/leon/models/NeuroTorch"
    model = Network('config_EI.yml', 'test', REPO_ROOT, VERBOSE=1, DEVICE='cuda', TASK='dual',
                    PROBA_TYPE=['lr', '', '',''])
#+end_src

#+RESULTS:
: Na tensor([8000, 2000], device='cuda:0', dtype=torch.int32) Ka tensor([500., 500.], device='cuda:0') csumNa tensor([    0,  8000, 10000], device='cuda:0')
: [[1.0, 0.9, 0.0, 0.0], [0.9, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.9], [0.0, 0.0, 0.9, 1.0]]
: Jab [1.0, -1.5, 1, -1]
: Ja0 [2.0, 1.0]

#+begin_src ipython
  ff_input = model.init_ff_input().cpu().detach().numpy()
  print(ff_input.shape)
#+end_src

#+RESULTS:
: (1, 1125, 10000)

#+begin_src ipython
  plt.plot(ff_input[0, :, :5])
  plt.plot(ff_input[0, :, -5:])
  plt.xlabel('Step')
  plt.ylabel('FF Input')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/9a4c7ec074ebfcb42646a8d2319ec6e1811c9ce1.png]]

#+begin_src ipython
  plt.imshow(ff_input[0].T, cmap='jet', vmin=0, vmax=55, aspect='auto')
  plt.xlabel('Step')
  plt.ylabel('Neuron #')
  plt.ylim([0, 7500])
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/c78cf7f973451df247d56a259208afcf16bd5f42.png]]

#+begin_src ipython
  ksi = model.PHI0.cpu().detach().numpy()
  print(ksi.shape)
  idx = np.arange(0, len(ksi[0]))
  theta = get_theta(ksi[0], ksi[1], GM=0, IF_NORM=1)
  index_order = theta.argsort()
  ff_ordered = ff_input[..., index_order]
#+end_src

#+RESULTS:
: (4, 8000)

#+begin_src ipython
  plt.imshow(ff_ordered[0].T, cmap='jet', vmin=0, aspect='auto')
  plt.xlabel('Step')
  plt.ylabel('Pref Loc. (Â°)')
  plt.yticks(np.linspace(0, 7500, 5), np.linspace(0, 360, 5).astype(int))
  # plt.ylim([0, 10])
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/0567909b66d6446f5f1628a365d3d08e0252fe33.png]]

* STP
** from class
#+begin_src ipython
  from src.plasticity import Plasticity
#+end_src

#+RESULTS:

#+begin_src ipython
  stp = Plasticity(0.03, 0.65, 0.25, 0.01, (1,1000))
  
  A_u_x = []
  for i in range(300):
      rates = torch.randn((2, 1000), device='cuda')
      A_u_x.append( stp(rates)[0].cpu().detach().numpy())

  A_u_x = np.array(A_u_x)
#+end_src

#+RESULTS:

#+begin_src ipython
  plt.plot(A_u_x.mean(1))
  plt.xlabel('Step')
  plt.ylabel('$A_{ux}$')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/5bc5582682d7afd17924d618bdbeb6cb8545427f.png]]

#+begin_src ipython
  stp = Plasticity(0.03, 0.65, 0.25, 0.01, (1,1000))

  A_u_x = []
  for i in range(100):
      rates = i + torch.randn((2, 1000), device='cuda')
      A_u_x.append(stp(rates)[0].cpu().detach().numpy())

  A_u_x = np.array(A_u_x)
  print(A_u_x.shape)
#+end_src

#+RESULTS:
: (100, 1000)

#+begin_src ipython
  plt.plot(A_u_x.mean(1))
  plt.xlabel('Rate (Hz)')
  plt.ylabel('$A_{ux}$')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/478dddcbb71fa79e20c3a05f6253383890756054.png]]

** from model

#+begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroTorch"
  model = Network('config_EI.yml', 'odr', REPO_ROOT, VERBOSE=0, DEVICE='cuda', IF_STP=1, LR_TRAIN=0, N_BATCH=1, DT=0.005)
  rates = model(REC_LAST_ONLY=0).cpu().detach().numpy()
#+end_src

#+RESULTS:
: [[1.0, 0.9, 0.0, 0.0], [0.9, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.9], [0.0, 0.0, 0.9, 1.0]]

#+begin_src ipython
  print(rates.shape)
  r_max = 2 # * np.max(rates[-1, :15000])
  plt.imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max, origin='lower')
  plt.ylabel('Neuron #')
  plt.xlabel('Step')
  plt.colorbar()
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (1, 41, 8000)
[[file:./.ob-jupyter/f6ccd9cb0d5e156e9e3bc0846dc258b48634f3d1.png]]
:END:

* Single Trial
** Model

#+begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroTorch"
  model = LIFNetwork('config_2pop.yml', 'test', REPO_ROOT, VERBOSE=1, DEVICE='cuda', TASK='None', LR_TRAIN=0)
#+end_src

#+RESULTS:
: Na tensor([5000, 5000], device='cuda:0', dtype=torch.int32) Ka tensor([250., 250.], device='cuda:0') csumNa tensor([    0,  5000, 10000], device='cuda:0')
: Jab [1.0, -1.5, 1, -1]
: Ja0 [2.0, 1.0]

** Dynamics

#+begin_src ipython
  rates = model.forward()[0].cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
#+begin_example
  generating ff input
  times (s) 0.0 rates (Hz) [6.31, 11.98]
  times (s) 0.22 rates (Hz) [6.1, 11.68]
  times (s) 0.44 rates (Hz) [6.41, 11.88]
  times (s) 0.67 rates (Hz) [6.4, 11.96]
  times (s) 0.89 rates (Hz) [6.28, 11.8]
  times (s) 1.11 rates (Hz) [6.47, 11.98]
  times (s) 1.33 rates (Hz) [6.38, 11.96]
  times (s) 1.56 rates (Hz) [6.44, 11.92]
  times (s) 1.78 rates (Hz) [6.36, 11.91]
  times (s) 2.0 rates (Hz) [6.2, 11.75]
  times (s) 2.22 rates (Hz) [6.42, 11.92]
  times (s) 2.44 rates (Hz) [6.39, 11.87]
  times (s) 2.67 rates (Hz) [6.39, 11.95]
  times (s) 2.89 rates (Hz) [6.32, 11.88]
  times (s) 3.11 rates (Hz) [6.36, 11.94]
  times (s) 3.33 rates (Hz) [6.33, 11.87]
  times (s) 3.56 rates (Hz) [6.48, 11.96]
  times (s) 3.78 rates (Hz) [6.41, 11.95]
  times (s) 4.0 rates (Hz) [6.45, 11.97]
  times (s) 4.22 rates (Hz) [6.2, 11.81]
  times (s) 4.44 rates (Hz) [6.2, 11.75]
  times (s) 4.67 rates (Hz) [6.33, 11.81]
  times (s) 4.89 rates (Hz) [6.47, 11.94]
  times (s) 5.11 rates (Hz) [6.46, 11.92]
  times (s) 5.33 rates (Hz) [6.19, 11.68]
  times (s) 5.56 rates (Hz) [6.2, 11.74]
  times (s) 5.78 rates (Hz) [6.28, 11.78]
  times (s) 6.0 rates (Hz) [6.43, 11.96]
  times (s) 6.22 rates (Hz) [6.27, 11.85]
  times (s) 6.44 rates (Hz) [6.38, 11.84]
  times (s) 6.67 rates (Hz) [6.31, 11.87]
  times (s) 6.89 rates (Hz) [6.34, 11.88]
  times (s) 7.11 rates (Hz) [6.41, 11.94]
  times (s) 7.33 rates (Hz) [6.36, 11.89]
  times (s) 7.56 rates (Hz) [6.18, 11.73]
  times (s) 7.78 rates (Hz) [6.42, 11.93]
  times (s) 8.0 rates (Hz) [6.4, 11.81]
  times (s) 8.22 rates (Hz) [6.21, 11.72]
  times (s) 8.44 rates (Hz) [6.37, 11.88]
  times (s) 8.67 rates (Hz) [6.34, 11.85]
  times (s) 8.89 rates (Hz) [6.47, 11.99]
  Elapsed (with compilation) = 5.953561099246144s
  (41, 10000)
#+end_example

#+begin_src ipython
  import matplotlib.colors
  # Color for False and True
  cmap = matplotlib.colors.ListedColormap(['blue', 'yellow'])

  r_max = 10
  
  plt.imshow(rates.T, aspect='auto', origin='lower', vmax=r_max, cmap='jet')
  plt.colorbar()
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/2914392137f0a8d78863823d66ea2e844044e081.png]]

#+RESULTS:

** Connectivity

#+begin_src ipython
  Cij = model.Wab_T.cpu().detach().numpy().T
  print(Cij.shape)

  plt.figure(figsize=(12, 5))  # Set the figure size (width, height) in inches

  ax1 = plt.subplot2grid((2, 3), (0, 0), rowspan=2)
  im = ax1.imshow(Cij, cmap='jet', aspect=1)
  ax1.set_xlabel("Presynaptic")
  ax1.set_ylabel("Postsynaptic")

  # Second column, first row
  ax2 = plt.subplot2grid((2, 3), (0, 1))
  Kj = np.sum(Cij, axis=0)  # sum over pres
  ax2.set_title('$<K_j>= %d$' % np.mean(Kj))
  ax2.plot(Kj)
  # ax2.set_xticklabels([])
  ax2.set_ylabel("$K_j$")

  # # Second column, second row
  ax3 = plt.subplot2grid((2, 3), (1, 1))
  Ki = np.sum(Cij, axis=1)  # sum over pres
  ax3.set_title('$<K_i>= %d$' % np.mean(Ki))
  ax3.plot(Kj)
  ax3.set_ylabel("$K_i$")

  ax4 = plt.subplot2grid((2, 3), (0, 2), rowspan=2)
  diags = []
  for i in range(int(Cij.shape[0] / 2)):
      diags.append(np.trace(Cij, offset=i) / Cij.shape[0])
  diags = np.array(diags)
  ax4.plot(diags)
  ax4.set_xlabel("Neuron #")
  ax4.set_ylabel("$P_{ij}$")

  plt.tight_layout()
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (10000, 10000)
[[file:./.ob-jupyter/29aed35cf0a63c81a46bf79cc066e8912998d04b.png]]
:END:

** FF Inputs

#+begin_src ipython
  ff_input = model.ff_input.cpu().detach().numpy()
  print(ff_input.shape)
  
  fig, ax = plt.subplots(1, 2)

  ax[0].plot(ff_input[0, :, :5])
  ax[0].plot(ff_input[0, :, -5:])
  ax[0].set_xlabel('Step')
  ax[0].set_ylabel('FF Input')

  ax[1].imshow(ff_input[0].T, cmap='jet', vmin=0, aspect='auto')
  ax[1].set_xlabel('Step')
  ax[1].set_ylabel('Neuron #')
  ax[1].set_ylim([0, 10000])
  plt.show()
#+end_src
  
#+RESULTS:
:RESULTS:
: (1, 500, 10000)
[[file:./.ob-jupyter/437eb044167792bde5794ef5f334f2ae2100fb0e.png]]
:END:

* Balance

#+begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroTorch"
  K_list = [500, 1000, 1500, 2000, 2500, 3000]
  rates_list = []
  
  for K in K_list:
      model = LIFNetwork('config_2pop.yml', 'balance', REPO_ROOT, VERBOSE=0, DEVICE='cuda', K=K)
      rates = model.forward()
      rates_list.append(rates[0].cpu().detach().numpy())

#+end_src

#+RESULTS:

#+begin_src ipython
  rates = np.array(rates_list)
  print(rates.shape)
  
  plt.plot(np.sqrt(K_list), np.mean(rates[..., 8000]) * np.sqrt(K_list), '-o')
  plt.xlabel('$\sqrt{K}$')
  plt.ylabel('$\sqrt{K}$ Rates')
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (6, 41, 10000)
[[file:./.ob-jupyter/d3f09a8c678cca33a2797e5df9664a637068a3dc.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:
