#+STARTUP: fold
#+TITLE: Training Low Rank RNNs
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session dual :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroTorch"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Helpers
** Training
*** split data

#+begin_src ipython
  from sklearn.model_selection import train_test_split

  def split_data(X, Y, train_perc=0.8, batch_size=32):

    X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                        train_size=train_perc,
                                                        shuffle=True)

    train_dataset = TensorDataset(X_train, Y_train)
    val_dataset = TensorDataset(X_test, Y_test)

    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
  def train(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1):
      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):          
          X, y = X.to(device), y.to(device)
          # Compute prediction error
          y_pred = model(X)
          loss = loss_fn(y_pred, y)

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()
          optimizer.step()
          optimizer.zero_grad()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def test(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0
      with torch.no_grad():
          for data, targets in dataloader:
              data, targets = data.to(device), targets.to(device)
              
              outputs = model(data)
              loss = loss_fn(outputs, targets)
              val_loss += loss.item() * data.size(0)
          val_loss /= size

      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def run_optim(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=.005):
      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
      model.to(device)

      loss_list = []
      val_loss_list = []

      # Training loop.
      for epoch in range(num_epochs):
          loss = train(train_loader, model, loss_fn, optimizer, penalty, lbd)
          val_loss = test(val_loader, model, loss_fn)
          scheduler.step(val_loss)

          loss_list.append(loss.item())
          val_loss_list.append(val_loss)

          # if epoch % int(num_epochs  / 10) == 0:
          print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

          if val_loss < thresh:
              print(f'Stopping training as loss has fallen below the threshold: {loss}')
              break
          if torch.isnan(loss):
              print(f'Stopping training as loss is NaN.')
              break

      return loss_list, val_loss_list
#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
  def correlation_loss(output, target):
      # Subtract the mean of each vector
      output_mean = output - torch.mean(output)
      target_mean = target - torch.mean(target)
    
      # Compute the covariance between output and target
      covariance = torch.mean(output_mean * target_mean)
      
      # Compute the standard deviations of the vectors
      output_std = torch.std(output)
      target_std = torch.std(target)
    
      # Calculate the Pearson correlation coefficient
      correlation = covariance / (output_std * target_std)
    
      # Since we want to increase the correlation, we minimize its negative
      loss = -correlation  # Maximizing correlation by minimizing its negative
    
      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
    import torch
    import torch.nn as nn

    def sign_constrained_loss(output, xi, target_sign):
        dot_product = torch.dot(output.flatten(), xi.flatten())
        if target_sign > 0:
            loss = torch.relu(-dot_product)  # Encourages positive dot product
        else:
            loss = torch.relu(dot_product)   # Encourages negative dot product
        return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  class CosineLoss(nn.Module):
      def __init__(self):
          super(CosineLoss, self).__init__()
          self.cosine_similarity = nn.CosineSimilarity(dim=-1)
          
      def forward(self, input1, input2):
          # Calculate cosine similarity
          cosine_sim = self.cosine_similarity(input1, input2)
          # Calculate the loss as 1 - cosine_similarity
          loss = 1 - cosine_sim
          # Return the mean loss over the batch
          return loss.mean()
#+end_src

#+RESULTS:


#+RESULTS:

** Other

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      u, v = a, b

      if GM:          
          v = b - np.dot(b, a) / np.dot(a, a) * a
          
      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)

      return np.arctan2(v, u)
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_idx(model, rank=2):
      print(model.U.shape)
      ksi = torch.hstack((model.U, model.V)).T
      print('ksi', ksi.shape)

      ksi = ksi.cpu().detach().numpy()
      # ksi = model.PHI0.cpu().detach().numpy()

      print(ksi.shape)

      theta = get_theta(ksi[0], ksi[rank], GM=0, IF_NORM=0)
      theta = get_theta(ksi[0][:model.Na[0]], ksi[rank][:model.Na[0]], GM=0, IF_NORM=0)

      return theta.argsort()
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_overlap(model, rates):
      ksi = model.PHI0.cpu().detach().numpy()
      return rates @ ksi.T / rates.shape[-1]
  
#+end_src

#+RESULTS:

#+begin_src ipython
  import scipy.stats as stats

  def plot_smooth(data, ax, color):
      mean = data.mean(axis=0)  
      ci = smooth.std(axis=0, ddof=1) * 1.96
      
      # Plot
      ax.plot(mean, color=color)
      ax.fill_between(range(data.shape[1]), mean - ci, mean + ci, alpha=0.25, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter  
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl
#+end_src

#+RESULTS:

* Model

#+begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroTorch"
  conf_name = "config_train.yml"
#+end_src

#+RESULTS:

#+begin_src ipython
  start = perf_counter()
  model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE='cuda', SEED=0)
#+end_src

#+RESULTS:

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: U torch.Size([1000, 2])
: V torch.Size([1000, 2])
: lr_kappa torch.Size([1])
: linear.weight torch.Size([1, 800])
: linear.bias torch.Size([1])

* Sample Classification
** Training

#+begin_src ipython
  model.LR_TRAIN=1
  model.LR_EVAL_WIN = 2
  model.lr_eval_win = int(model.LR_EVAL_WIN / model.DT / model.N_WINDOW)

  model.DURATION = 3
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 32

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([64, 510, 1000])

#+begin_src ipython
  labels_A = torch.zeros((model.N_BATCH, model.lr_eval_win))
  labels_B = torch.ones((model.N_BATCH, model.lr_eval_win))
  labels = torch.cat((labels_A, labels_B))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([64, 20])

#+begin_src ipython
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)

  learning_rate = 0.1

  # CosineLoss, BCELoss, BCEWithLogitLoss
  # criterion = nn.CrossEntropyLoss()
  criterion = nn.BCEWithLogitsLoss()

  # SGD, Adam, AdamW
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)

  num_epochs = 100
  loss, val_loss = 0, 0
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
#+End_src

#+RESULTS:
#+begin_example
  Epoch 1/100, Training Loss: 54.5551, Validation Loss: 16.3908
  Epoch 2/100, Training Loss: 11.7804, Validation Loss: 4.7572
  Epoch 3/100, Training Loss: 2.7478, Validation Loss: 6.2228
  Epoch 4/100, Training Loss: 3.2182, Validation Loss: 1.4739
  Epoch 5/100, Training Loss: 4.0449, Validation Loss: 0.3356
  Epoch 6/100, Training Loss: 6.8605, Validation Loss: 0.9621
  Epoch 7/100, Training Loss: 3.1775, Validation Loss: 2.8638
  Epoch 8/100, Training Loss: 0.0135, Validation Loss: 7.2755
  Epoch 9/100, Training Loss: 3.7822, Validation Loss: 0.6280
  Epoch 10/100, Training Loss: 0.4930, Validation Loss: 1.6882
  Epoch 11/100, Training Loss: 6.5850, Validation Loss: 0.2960
  Epoch 12/100, Training Loss: 3.1128, Validation Loss: 2.2743
  Epoch 13/100, Training Loss: 0.3038, Validation Loss: 2.7913
  Epoch 14/100, Training Loss: 2.0203, Validation Loss: 0.6089
  Epoch 15/100, Training Loss: 0.8978, Validation Loss: 0.9234
  Epoch 16/100, Training Loss: 0.8257, Validation Loss: 4.2334
  Epoch 17/100, Training Loss: 0.5494, Validation Loss: 0.7162
  Epoch 18/100, Training Loss: 0.0007, Validation Loss: 0.5193
  Epoch 19/100, Training Loss: 0.2107, Validation Loss: 0.2321
  Epoch 20/100, Training Loss: 0.5025, Validation Loss: 0.5980
  Epoch 21/100, Training Loss: 0.2728, Validation Loss: 1.2613
  Epoch 22/100, Training Loss: 0.2298, Validation Loss: 0.3244
  Epoch 23/100, Training Loss: 0.5271, Validation Loss: 1.1786
  Epoch 24/100, Training Loss: 0.3881, Validation Loss: 0.2095
  Epoch 25/100, Training Loss: 0.2259, Validation Loss: 0.2378
  Epoch 26/100, Training Loss: 0.9526, Validation Loss: 0.2456
  Epoch 27/100, Training Loss: 0.2183, Validation Loss: 0.6484
  Epoch 28/100, Training Loss: 0.2022, Validation Loss: 0.2283
  Epoch 29/100, Training Loss: 0.5215, Validation Loss: 0.2342
  Epoch 30/100, Training Loss: 0.0805, Validation Loss: 1.3437
  Epoch 31/100, Training Loss: 0.2853, Validation Loss: 0.4493
  Epoch 32/100, Training Loss: 1.5297, Validation Loss: 1.3518
  Epoch 33/100, Training Loss: 1.5342, Validation Loss: 3.0952
  Epoch 34/100, Training Loss: 0.2592, Validation Loss: 0.3019
  Epoch 35/100, Training Loss: 0.3612, Validation Loss: 0.2717
  Epoch 36/100, Training Loss: 0.8444, Validation Loss: 0.6332
  Epoch 37/100, Training Loss: 0.3040, Validation Loss: 0.2401
  Epoch 38/100, Training Loss: 0.4445, Validation Loss: 0.5434
  Epoch 39/100, Training Loss: 0.2393, Validation Loss: 0.2499
  Epoch 40/100, Training Loss: 0.2714, Validation Loss: 0.4280
  Epoch 41/100, Training Loss: 0.1098, Validation Loss: 0.4436
  Epoch 42/100, Training Loss: 0.2863, Validation Loss: 0.2968
  Epoch 43/100, Training Loss: 0.3473, Validation Loss: 0.3234
  Epoch 44/100, Training Loss: 0.2204, Validation Loss: 0.2534
  Epoch 45/100, Training Loss: 0.2233, Validation Loss: 0.4499
  Epoch 46/100, Training Loss: 0.2170, Validation Loss: 0.3678
  Epoch 47/100, Training Loss: 0.3378, Validation Loss: 0.2796
  Epoch 48/100, Training Loss: 0.2374, Validation Loss: 0.4923
  Epoch 49/100, Training Loss: 0.2312, Validation Loss: 0.2272
  Epoch 50/100, Training Loss: 0.2237, Validation Loss: 0.6108
  Epoch 51/100, Training Loss: 0.4506, Validation Loss: 0.3066
  Epoch 52/100, Training Loss: 0.2344, Validation Loss: 0.2498
  Epoch 53/100, Training Loss: 0.4717, Validation Loss: 0.4144
  Epoch 54/100, Training Loss: 0.3375, Validation Loss: 0.2306
  Epoch 55/100, Training Loss: 0.2283, Validation Loss: 0.5241
  Epoch 56/100, Training Loss: 0.2929, Validation Loss: 0.2333
  Epoch 57/100, Training Loss: 0.2681, Validation Loss: 0.4404
  Epoch 58/100, Training Loss: 0.8936, Validation Loss: 0.2988
  Epoch 59/100, Training Loss: 0.8566, Validation Loss: 0.2573
  Epoch 60/100, Training Loss: 0.4184, Validation Loss: 1.0380
  Epoch 61/100, Training Loss: 0.2132, Validation Loss: 0.2294
  Epoch 62/100, Training Loss: 0.5536, Validation Loss: 0.3845
  Epoch 63/100, Training Loss: 0.4200, Validation Loss: 0.9355
  Epoch 64/100, Training Loss: 0.2812, Validation Loss: 0.2309
  Epoch 65/100, Training Loss: 0.4627, Validation Loss: 0.2522
  Epoch 66/100, Training Loss: 0.6101, Validation Loss: 0.7013
  Epoch 67/100, Training Loss: 0.2622, Validation Loss: 0.2519
  Epoch 68/100, Training Loss: 0.4418, Validation Loss: 0.3007
  Epoch 69/100, Training Loss: 0.2572, Validation Loss: 0.6276
  Epoch 70/100, Training Loss: 0.4797, Validation Loss: 0.2819
  Epoch 71/100, Training Loss: 0.2744, Validation Loss: 0.2361
  Epoch 72/100, Training Loss: 0.2485, Validation Loss: 0.4759
  Epoch 73/100, Training Loss: 0.7215, Validation Loss: 0.4349
  Epoch 74/100, Training Loss: 0.5979, Validation Loss: 0.2375
  Epoch 75/100, Training Loss: 0.3878, Validation Loss: 0.4834
  Epoch 76/100, Training Loss: 0.3508, Validation Loss: 0.3336
  Epoch 77/100, Training Loss: 0.4509, Validation Loss: 0.2630
  Epoch 78/100, Training Loss: 0.1361, Validation Loss: 0.5652
  Epoch 79/100, Training Loss: 0.7448, Validation Loss: 0.4156
  Epoch 80/100, Training Loss: 0.4688, Validation Loss: 0.2357
  Epoch 81/100, Training Loss: 0.2800, Validation Loss: 0.3998
  Epoch 82/100, Training Loss: 0.2591, Validation Loss: 0.4780
  Epoch 83/100, Training Loss: 0.2705, Validation Loss: 0.2870
  Epoch 84/100, Training Loss: 0.2530, Validation Loss: 0.3002
  Epoch 85/100, Training Loss: 0.2515, Validation Loss: 0.3888
  Epoch 86/100, Training Loss: 0.2464, Validation Loss: 0.4763
  Epoch 87/100, Training Loss: 0.2937, Validation Loss: 0.3044
  Epoch 88/100, Training Loss: 0.2509, Validation Loss: 0.4041
  Epoch 89/100, Training Loss: 0.1941, Validation Loss: 0.3951
  Epoch 90/100, Training Loss: 0.3138, Validation Loss: 0.3248
  Epoch 91/100, Training Loss: 0.2562, Validation Loss: 0.2669
  Epoch 92/100, Training Loss: 0.2940, Validation Loss: 0.3794
  Epoch 93/100, Training Loss: 0.3427, Validation Loss: 0.2629
  Epoch 94/100, Training Loss: 0.3578, Validation Loss: 0.3309
  Epoch 95/100, Training Loss: 0.0704, Validation Loss: 0.5803
  Epoch 96/100, Training Loss: 0.2339, Validation Loss: 0.2396
  Epoch 97/100, Training Loss: 0.3069, Validation Loss: 0.4571
  Epoch 98/100, Training Loss: 0.5069, Validation Loss: 0.4468
  Epoch 99/100, Training Loss: 0.4035, Validation Loss: 0.2426
  Epoch 100/100, Training Loss: 0.2561, Validation Loss: 0.6149
#+end_example

#+begin_src ipython
  plt.plot(loss)
  plt.plot(val_loss)
  plt.xlabel('epochs')
  plt.ylabel('Loss')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/fc2a0984f077d7a74fb8ba25711523be4807ddc1.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

** Test

 #+begin_src ipython
  Wij = model.Wab_T.clone()
#+end_src

#+RESULTS:

#+begin_src ipython
  model.eval()

  lr = model.lr_kappa * (model.lr_mask * (model.U @ model.V.T)) / (1.0 * model.Na[0])
  model.Wab_T = Wij + lr.T

  model.N_BATCH = 1
  model.LR_TRAIN=0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1
  model.DURATION = 6
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([2, 810, 1000])

#+begin_src ipython
  model.VERBOSE = 0
  rates = model.forward(ff_input=ff_input, RET_FF=1).cpu().detach().numpy()
  model.Wab_T = Wij
  print(rates.shape)
#+end_src

#+RESULTS:
: (2, 61, 800)

#+begin_src ipython
  idx = get_idx(model, 2)
  ordered = rates[..., idx]
  m0, m1, phi = decode_bump(ordered, axis=-1)
#+end_src

#+RESULTS:
: torch.Size([1000, 2])
: ksi torch.Size([4, 1000])
: (4, 1000)

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
  r_max = .5 * np.max(rates)

  ax[0].imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
  # ax[0].axvline((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, color='w', ls='--')
  # ax[0].axvline((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, color='w', ls='--')
  ax[0].set_ylabel('Neuron #')
  ax[0].set_xlabel('Step')

  ax[1].imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
  ax[1].set_yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))
  # ax[1].axvline((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  # ax[1].axvline((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  ax[1].set_ylabel('Pref. Location (°)')
  ax[1].set_xlabel('Step')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/a043421e71c728870db6a950795979e45de77add.png]]

#+begin_src ipython
  readout = model.linear.weight.data.cpu().detach().numpy()[0]
  overlap = -(rates @ readout) / rates.shape[-1]
  print(overlap.shape)

  plt.plot(overlap.T[..., :1], label='A')
  plt.plot(overlap.T[..., 1:], label='B')
  plt.legend(fontsize=10)
  plt.xlabel('Step')
  plt.ylabel('Overlap')

  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (2, 61)
[[file:./.ob-jupyter/26f4852ac96450afcde2029d72bc38c90620074c.png]]
:END:

#+begin_src ipython
  fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

  ax[0].plot(m0[:2].T)
  ax[0].plot(m0[2:].T, '--')
  #ax[0].set_ylim([0, 360])
  #ax[0].set_yticks([0, 90, 180, 270, 360])
  ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
  ax[0].set_xlabel('Step')

  ax[1].plot(m1[:2].T)
  ax[1].plot(m1[2:].T, '--')
  # ax[1].set_ylim([0, 360])
  # ax[1].set_yticks([0, 90, 180, 270, 360])
  ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
  ax[1].set_xlabel('Step')

  ax[2].plot(phi[:2].T * 180 / np.pi)
  ax[2].plot(phi[2:].T * 180 / np.pi, '--')
  ax[2].set_ylim([0, 360])
  ax[2].set_yticks([0, 90, 180, 270, 360])
  ax[2].set_ylabel('Phase (°)')
  ax[2].set_xlabel('Step')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/53020ae72eb6422016371b4c2e21cfed76532a8b.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* DPA
** Training

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_EVAL_WIN = 1
  model.lr_eval_win = int(model.LR_EVAL_WIN / model.DT / model.N_WINDOW)

  model.DURATION = 6.0
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 96

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 1

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = -1

  AD_pair = model.init_ff_input()

  # ff_input = torch.cat((AC_pair, AD_pair))

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = -1

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([384, 162, 1000])

#+begin_src ipython
  labels_pair = torch.zeros((2 * model.N_BATCH, model.lr_eval_win))
  labels_unpair = torch.ones((2 * model.N_BATCH, model.lr_eval_win))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([384, 10])

#+RESULTS:

#+begin_src ipython
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)

  learning_rate = 0.1

  # CosineLoss, BCELoss, BCEWithLogitLoss
  # criterion = nn.CrossEntropyLoss()
  criterion = nn.BCEWithLogitsLoss()

  # SGD, Adam, AdamW
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)

  num_epochs = 100
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
#+End_src

#+RESULTS:
#+begin_example
  Epoch 1/100, Training Loss: 8.3444, Validation Loss: 7.2784
  Epoch 2/100, Training Loss: 1.5018, Validation Loss: 3.2085
  Epoch 3/100, Training Loss: 3.0118, Validation Loss: 1.1196
  Epoch 4/100, Training Loss: 0.0001, Validation Loss: 3.4555
  Epoch 5/100, Training Loss: 1.0393, Validation Loss: 2.8578
  Epoch 6/100, Training Loss: 2.0959, Validation Loss: 1.0107
  Epoch 7/100, Training Loss: 0.4744, Validation Loss: 1.1796
  Epoch 8/100, Training Loss: 1.2408, Validation Loss: 0.7929
  Epoch 9/100, Training Loss: 1.1958, Validation Loss: 0.7413
  Epoch 10/100, Training Loss: 0.4798, Validation Loss: 3.5882
  Epoch 11/100, Training Loss: 4.8520, Validation Loss: 1.7066
  Epoch 12/100, Training Loss: 0.8828, Validation Loss: 0.7802
  Epoch 13/100, Training Loss: 1.1499, Validation Loss: 1.4056
  Epoch 14/100, Training Loss: 0.6391, Validation Loss: 0.8814
  Epoch 15/100, Training Loss: 0.7102, Validation Loss: 1.0177
  Epoch 16/100, Training Loss: 0.9480, Validation Loss: 0.7770
  Epoch 17/100, Training Loss: 0.6307, Validation Loss: 0.9187
  Epoch 18/100, Training Loss: 0.6382, Validation Loss: 1.6459
  Epoch 19/100, Training Loss: 1.0855, Validation Loss: 0.8119
  Epoch 20/100, Training Loss: 0.4480, Validation Loss: 1.1435
  Epoch 21/100, Training Loss: 0.9969, Validation Loss: 0.7522
  Epoch 22/100, Training Loss: 0.4709, Validation Loss: 0.9895
  Epoch 23/100, Training Loss: 0.7201, Validation Loss: 0.8437
  Epoch 24/100, Training Loss: 0.2587, Validation Loss: 0.9736
  Epoch 25/100, Training Loss: 1.1177, Validation Loss: 0.8081
  Epoch 26/100, Training Loss: 0.3834, Validation Loss: 1.1285
  Epoch 27/100, Training Loss: 0.4709, Validation Loss: 1.0448
  Epoch 28/100, Training Loss: 0.6666, Validation Loss: 1.0565
  Epoch 29/100, Training Loss: 0.5984, Validation Loss: 0.7848
  Epoch 30/100, Training Loss: 0.6780, Validation Loss: 0.7156
  Epoch 31/100, Training Loss: 0.5647, Validation Loss: 0.9417
  Epoch 32/100, Training Loss: 0.8610, Validation Loss: 0.7943
  Epoch 33/100, Training Loss: 1.2806, Validation Loss: 1.3708
  Epoch 34/100, Training Loss: 0.6565, Validation Loss: 0.7022
  Epoch 35/100, Training Loss: 0.7566, Validation Loss: 0.9093
  Epoch 36/100, Training Loss: 0.8418, Validation Loss: 0.6965
  Epoch 37/100, Training Loss: 0.9659, Validation Loss: 0.7706
  Epoch 38/100, Training Loss: 0.8349, Validation Loss: 0.8203
  Epoch 39/100, Training Loss: 0.8443, Validation Loss: 0.7221
  Epoch 40/100, Training Loss: 1.4839, Validation Loss: 0.7360
  Epoch 41/100, Training Loss: 0.8147, Validation Loss: 0.9770
  Epoch 42/100, Training Loss: 0.8598, Validation Loss: 0.9781
  Epoch 43/100, Training Loss: 0.7709, Validation Loss: 0.7979
  Epoch 44/100, Training Loss: 0.3484, Validation Loss: 0.8447
  Epoch 45/100, Training Loss: 0.9107, Validation Loss: 0.7213
  Epoch 46/100, Training Loss: 0.9661, Validation Loss: 0.7279
  Epoch 47/100, Training Loss: 0.6303, Validation Loss: 0.7690
  Epoch 48/100, Training Loss: 0.5299, Validation Loss: 0.7687
  Epoch 49/100, Training Loss: 0.7479, Validation Loss: 0.6940
  Epoch 50/100, Training Loss: 0.6499, Validation Loss: 0.7132
  Epoch 51/100, Training Loss: 0.2735, Validation Loss: 0.8942
  Epoch 52/100, Training Loss: 0.8304, Validation Loss: 0.7920
  Epoch 53/100, Training Loss: 0.5602, Validation Loss: 0.7104
  Epoch 54/100, Training Loss: 0.6258, Validation Loss: 0.7746
  Epoch 55/100, Training Loss: 1.0336, Validation Loss: 0.7814
  Epoch 56/100, Training Loss: 0.9126, Validation Loss: 0.8952
  Epoch 57/100, Training Loss: 0.7996, Validation Loss: 0.7302
  Epoch 58/100, Training Loss: 0.4574, Validation Loss: 0.8495
  Epoch 59/100, Training Loss: 0.7674, Validation Loss: 0.7308
  Epoch 60/100, Training Loss: 0.3553, Validation Loss: 0.7200
  Epoch 61/100, Training Loss: 0.9324, Validation Loss: 0.8599
  Epoch 62/100, Training Loss: 0.8445, Validation Loss: 0.7821
  Epoch 63/100, Training Loss: 1.1968, Validation Loss: 0.7192
  Epoch 64/100, Training Loss: 0.8898, Validation Loss: 0.7317
  Epoch 65/100, Training Loss: 0.8407, Validation Loss: 0.8644
  Epoch 66/100, Training Loss: 1.8143, Validation Loss: 0.8479
  Epoch 67/100, Training Loss: 0.5464, Validation Loss: 0.9107
  Epoch 68/100, Training Loss: 0.2759, Validation Loss: 0.8418
  Epoch 69/100, Training Loss: 1.4841, Validation Loss: 0.7125
  Epoch 70/100, Training Loss: 0.8337, Validation Loss: 0.7457
  Epoch 71/100, Training Loss: 0.7454, Validation Loss: 0.8199
  Epoch 72/100, Training Loss: 0.6779, Validation Loss: 0.7885
  Epoch 73/100, Training Loss: 0.7338, Validation Loss: 0.6934
  Epoch 74/100, Training Loss: 0.8769, Validation Loss: 0.7231
  Epoch 75/100, Training Loss: 0.7347, Validation Loss: 0.7450
  Epoch 76/100, Training Loss: 0.8373, Validation Loss: 0.7303
  Epoch 77/100, Training Loss: 0.7355, Validation Loss: 0.6927
  Epoch 78/100, Training Loss: 0.8544, Validation Loss: 0.7006
  Epoch 79/100, Training Loss: 1.0678, Validation Loss: 0.7147
  Epoch 80/100, Training Loss: 1.0049, Validation Loss: 0.7861
  Epoch 81/100, Training Loss: 0.5358, Validation Loss: 0.7998
  Epoch 82/100, Training Loss: 0.4594, Validation Loss: 0.8565
  Epoch 83/100, Training Loss: 0.4134, Validation Loss: 0.8646
  Epoch 84/100, Training Loss: 0.7034, Validation Loss: 0.6919
  Epoch 85/100, Training Loss: 0.4961, Validation Loss: 0.7383
  Epoch 86/100, Training Loss: 0.9342, Validation Loss: 0.6967
  Epoch 87/100, Training Loss: 0.5702, Validation Loss: 0.8681
  Epoch 88/100, Training Loss: 0.5977, Validation Loss: 0.7444
  Epoch 89/100, Training Loss: 0.5734, Validation Loss: 0.8060
  Epoch 90/100, Training Loss: 0.6659, Validation Loss: 0.9066
  Epoch 91/100, Training Loss: 0.6379, Validation Loss: 0.6964
  Epoch 92/100, Training Loss: 0.7901, Validation Loss: 0.7049
  Epoch 93/100, Training Loss: 1.2995, Validation Loss: 0.6958
  Epoch 94/100, Training Loss: 0.6338, Validation Loss: 0.7289
  Epoch 95/100, Training Loss: 0.4909, Validation Loss: 0.7788
  Epoch 96/100, Training Loss: 0.7502, Validation Loss: 0.7859
  Epoch 97/100, Training Loss: 0.7349, Validation Loss: 0.8039
  Epoch 98/100, Training Loss: 0.6962, Validation Loss: 0.7473
  Epoch 99/100, Training Loss: 0.4796, Validation Loss: 0.7805
  Epoch 100/100, Training Loss: 1.0616, Validation Loss: 0.7810
#+end_example

#+begin_src ipython
  plt.plot(loss)
  plt.plot(val_loss)
  plt.xlabel('epochs')
  plt.ylabel('Loss')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/7519f077c7a59011059fc64ece74a95b613530e9.png]]

** Test

 #+begin_src ipython
  Wij = model.Wab_T.clone()
#+end_src

#+RESULTS:

#+begin_src ipython
  model.eval()

  lr = model.lr_kappa * (model.lr_mask * (model.U @ model.V.T)) / (1.0 * model.Na[0])
  model.Wab_T = Wij + lr.T

  model.N_BATCH = 1
  model.VERBOSE=1
  model.LR_TRAIN=0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1
  model.DURATION = 6
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 1

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = -1

  AD_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = -1

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 162, 1000])

#+begin_src ipython
  model.VERBOSE = 0
  rates = model.forward(ff_input=ff_input, RET_FF=1).cpu().detach().numpy()
  model.Wab_T = Wij
  print(rates.shape)
#+end_src

#+RESULTS:
: (4, 61, 800)

#+begin_src ipython
  idx = get_idx(model, 2)
  ordered = rates[..., idx]
  m0, m1, phi = decode_bump(ordered, axis=-1)
#+end_src

#+RESULTS:
: torch.Size([1000, 2])
: ksi torch.Size([4, 1000])
: (4, 1000)

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
  r_max = .5 * np.max(rates)

  ax[0].imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
  # ax[0].axvlines((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  # ax[0].axvlines((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  ax[0].set_ylabel('Neuron #')
  ax[0].set_xlabel('Step')

  ax[1].imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
  ax[1].set_yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))
  # ax[1].axvlines((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  # ax[1].axvlines((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  ax[1].set_ylabel('Pref. Location (°)')
  ax[1].set_xlabel('Step')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/95d88d19520b7df9d086e96a2dc1073a959b6406.png]]

#+begin_src ipython
  readout = model.linear.weight.data.cpu().detach().numpy()[0]
  overlap = (rates @ readout) / rates.shape[-1]
  print(overlap.shape)

  plt.plot(overlap.T[..., :2], label='pair')
  plt.plot(overlap.T[..., 2:], '--', label='unpair')
  plt.legend(fontsize=10)
  plt.xlabel('Step')
  plt.ylabel('Overlap')

  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (4, 61)
[[file:./.ob-jupyter/cf07ad790eab00d71f1e9f46bca47af6152f2883.png]]
:END:

#+begin_src ipython
  fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

  ax[0].plot(m0[:2].T)
  ax[0].plot(m0[2:].T, '--')
  #ax[0].set_ylim([0, 360])
  #ax[0].set_yticks([0, 90, 180, 270, 360])
  ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
  ax[0].set_xlabel('Step')

  ax[1].plot(m1[:2].T)
  ax[1].plot(m1[2:].T, '--')
  # ax[1].set_ylim([0, 360])
  # ax[1].set_yticks([0, 90, 180, 270, 360])
  ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
  ax[1].set_xlabel('Step')

  ax[2].plot(phi[:2].T * 180 / np.pi)
  ax[2].plot(phi[2:].T * 180 / np.pi, '--')
  ax[2].set_ylim([0, 360])
  ax[2].set_yticks([0, 90, 180, 270, 360])
  ax[2].set_ylabel('Phase (°)')
  ax[2].set_xlabel('Step')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/eeb593d47abf14370d5b830f352a690f1cc113a3.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* Go/NoGo
** Training
#+begin_src ipython
  model.LR_TRAIN=1
  model.LR_EVAL_WIN = 2
  model.lr_eval_win = int(model.LR_EVAL_WIN / model.DT / model.N_WINDOW)

  model.DURATION = 3
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  for param in model.linear.parameters():
       param.requires_grad = False
#+end_src

#+RESULTS:

#+begin_src ipython
  odors = model.odors.clone()
  # switching samples and distractors to run short simulations
  model.odors[0] = odors[1]
  model.N_BATCH = 96

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 0

  Go = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 0

  NoGo = model.init_ff_input()

  ff_input = torch.cat((Go, NoGo))
  print(ff_input.shape)
  model.odors[0] = odors[0]
#+end_src

#+RESULTS:
: torch.Size([192, 82, 1000])

#+begin_src ipython
  labels_Go = torch.zeros((model.N_BATCH, model.lr_eval_win))
  labels_NoGo = torch.ones((model.N_BATCH, model.lr_eval_win))
  labels = torch.cat((labels_Go, labels_NoGo))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([192, 20])

#+begin_src ipython
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  batch_size = 32
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)

  learning_rate = 0.1

  # CosineLoss, BCELoss, BCEWithLogitLoss
  # criterion = nn.CrossEntropyLoss()
  criterion = nn.BCEWithLogitsLoss()

  # SGD, Adam, AdamW
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)

  num_epochs = 100
  loss, val_loss = 0, 0

  # switching Sample and distractor
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
  model.odors[0] = odors[0]
#+End_src

#+RESULTS:
: Epoch 1/100, Training Loss: 0.6623, Validation Loss: 0.9120
: Epoch 2/100, Training Loss: 0.3844, Validation Loss: 0.3618
: Epoch 3/100, Training Loss: 0.2098, Validation Loss: 0.1930
: Epoch 4/100, Training Loss: 0.1556, Validation Loss: 0.0756
: Epoch 5/100, Training Loss: 0.0409, Validation Loss: 0.0238
: Epoch 6/100, Training Loss: 0.0032, Validation Loss: 0.0039
: Stopping training as loss has fallen below the threshold: 0.0031560794450342655

#+begin_src ipython
  plt.plot(loss)
  plt.plot(val_loss)
  plt.xlabel('epochs')
  plt.ylabel('Loss')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/fff8e63bc06802028fbe0a7a9241c3b97c99bfde.png]]

** Test

 #+begin_src ipython
  Wij = model.Wab_T.clone()
#+end_src

#+RESULTS:

#+begin_src ipython
  model.eval()

  lr = model.lr_kappa * (model.lr_mask * (model.U @ model.V.T)) / (1.0 * model.Na[0])
  model.Wab_T = Wij + lr.T

  model.N_BATCH = 1
  model.LR_TRAIN=0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1
  model.DURATION = 3
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  odors = model.odors.clone()
  model.odors[0] = odors[1]
  model.N_BATCH = 1

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print('ff_input', ff_input.shape)
  model.odors[0] = odors[0]
#+end_src

#+RESULTS:
: ff_input torch.Size([2, 82, 1000])

#+begin_src ipython
  model.VERBOSE = 0
  rates = model.forward(ff_input=ff_input, RET_FF=1).cpu().detach().numpy()
  model.Wab_T = Wij
  print(rates.shape)
#+end_src

#+RESULTS:
: (2, 31, 800)

#+begin_src ipython
  idx = get_idx(model, 2)
  ordered = rates[..., idx]
  m0, m1, phi = decode_bump(ordered, axis=-1)
#+end_src

#+RESULTS:
: torch.Size([1000, 2])
: ksi torch.Size([4, 1000])
: (4, 1000)

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
  r_max = .5 * np.max(rates)

  ax[0].imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
  # ax[0].axvline((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, color='w', ls='--')
  # ax[0].axvline((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, color='w', ls='--')
  ax[0].set_ylabel('Neuron #')
  ax[0].set_xlabel('Step')

  ax[1].imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
  ax[1].set_yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))
  # ax[1].axvline((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  # ax[1].axvline((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  ax[1].set_ylabel('Pref. Location (°)')
  ax[1].set_xlabel('Step')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/5c86bcc7db9764f4e16fa254b496cae0b169f0cd.png]]

#+begin_src ipython
  readout = model.linear.weight.data.cpu().detach().numpy()[0]
  overlap = -(rates @ readout) / rates.shape[-1]
  print(overlap.shape)

  plt.plot(overlap.T[..., :1], label='A')
  plt.plot(overlap.T[..., 1:], label='B')
  plt.legend(fontsize=10)
  plt.xlabel('Step')
  plt.ylabel('Overlap')

  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (2, 31)
[[file:./.ob-jupyter/234a0968d1bca05e1940620b84f3e7a8f28248b3.png]]
:END:

#+begin_src ipython
  fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

  ax[0].plot(m0[:2].T)
  ax[0].plot(m0[2:].T, '--')
  #ax[0].set_ylim([0, 360])
  #ax[0].set_yticks([0, 90, 180, 270, 360])
  ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
  ax[0].set_xlabel('Step')

  ax[1].plot(m1[:2].T)
  ax[1].plot(m1[2:].T, '--')
  # ax[1].set_ylim([0, 360])
  # ax[1].set_yticks([0, 90, 180, 270, 360])
  ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
  ax[1].set_xlabel('Step')

  ax[2].plot(phi[:2].T * 180 / np.pi)
  ax[2].plot(phi[2:].T * 180 / np.pi, '--')
  ax[2].set_ylim([0, 360])
  ax[2].set_yticks([0, 90, 180, 270, 360])
  ax[2].set_ylabel('Phase (°)')
  ax[2].set_xlabel('Step')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/870dec8288fa191989c7b67a3ffd4d6c489559fc.png]]

* Dual
** Test

 #+begin_src ipython
  Wij = model.Wab_T.clone()
#+end_src

#+RESULTS:

#+begin_src ipython
  model.eval()

  lr = model.lr_kappa * (model.lr_mask * (model.U @ model.V.T)) / (1.0 * model.Na[0])
  model.Wab_T = Wij + lr.T

  model.N_BATCH = 1
  model.VERBOSE=1
  model.LR_TRAIN=0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1
  model.DURATION = 6
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 1

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = -1

  AD_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = -1

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 142, 1000])

#+begin_src ipython
  model.VERBOSE = 0
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  model.Wab_T = Wij
  print(rates.shape)
#+end_src

#+RESULTS:
: (4, 61, 800)

#+begin_src ipython
  idx = get_idx(model, 2)
  ordered = rates[..., idx]
  m0, m1, phi = decode_bump(ordered, axis=-1)
#+end_src

#+RESULTS:
: torch.Size([1000, 2])
: ksi torch.Size([4, 1000])
: (4, 1000)

#+begin_src ipython
  fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
  r_max = .5 * np.max(rates)

  ax[0].imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
  # ax[0].axvlines((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  # ax[0].axvlines((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  ax[0].set_ylabel('Neuron #')
  ax[0].set_xlabel('Step')

  ax[1].imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
  ax[1].set_yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))
  # ax[1].axvlines((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  # ax[1].axvlines((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  ax[1].set_ylabel('Pref. Location (°)')
  ax[1].set_xlabel('Step')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/ffcea575581433150cb922d74126d9a35d43fcaa.png]]

#+begin_src ipython
  readout = model.linear.weight.data.cpu().detach().numpy()[0]
  overlap = (rates @ readout) / rates.shape[-1]
  print(overlap.shape)

  plt.plot(overlap.T[..., :2], label='pair')
  plt.plot(overlap.T[..., 2:], '--', label='unpair')
  plt.legend(fontsize=10)
  plt.xlabel('Step')
  plt.ylabel('Overlap')

  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (4, 61)
[[file:./.ob-jupyter/4e1147b71de95c6a567b829636319ac7b5ff49a6.png]]
:END:

#+begin_src ipython
  fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

  ax[0].plot(m0[:2].T)
  ax[0].plot(m0[2:].T, '--')
  #ax[0].set_ylim([0, 360])
  #ax[0].set_yticks([0, 90, 180, 270, 360])
  ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
  ax[0].set_xlabel('Step')

  ax[1].plot(m1[:2].T)
  ax[1].plot(m1[2:].T, '--')
  # ax[1].set_ylim([0, 360])
  # ax[1].set_yticks([0, 90, 180, 270, 360])
  ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
  ax[1].set_xlabel('Step')

  ax[2].plot(phi[:2].T * 180 / np.pi)
  ax[2].plot(phi[2:].T * 180 / np.pi, '--')
  ax[2].set_ylim([0, 360])
  ax[2].set_yticks([0, 90, 180, 270, 360])
  ax[2].set_ylabel('Phase (°)')
  ax[2].set_xlabel('Step')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/1fa289ce28f4dd47cf324538d9ba2116447adb39.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

** Training

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_EVAL_WIN = 1
  model.lr_eval_win = int(model.LR_EVAL_WIN / model.DT / model.N_WINDOW)

  model.DURATION = 6.0
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 96

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 1

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = -1

  AD_pair = model.init_ff_input()

  # ff_input = torch.cat((AC_pair, AD_pair))

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = -1

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([384, 142, 1000])

#+begin_src ipython
  labels_pair = torch.zeros((2 * model.N_BATCH, model.lr_eval_win))
  labels_unpair = torch.ones((2 * model.N_BATCH, model.lr_eval_win))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([384, 10])

#+RESULTS:

#+begin_src ipython
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)

  learning_rate = 0.1

  # CosineLoss, BCELoss, BCEWithLogitLoss
  # criterion = nn.CrossEntropyLoss()
  criterion = nn.BCEWithLogitsLoss()

  # SGD, Adam, AdamW
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)

  num_epochs = 100
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
#+End_src

#+RESULTS:
#+begin_example
  Epoch 1/100, Training Loss: 6.3473, Validation Loss: 4.4960
  Epoch 2/100, Training Loss: 0.5083, Validation Loss: 1.2475
  Epoch 3/100, Training Loss: 0.7945, Validation Loss: 4.4799
  Epoch 4/100, Training Loss: 2.0577, Validation Loss: 2.5421
  Epoch 5/100, Training Loss: 2.7975, Validation Loss: 2.9921
  Epoch 6/100, Training Loss: 3.0394, Validation Loss: 7.0765
  Epoch 7/100, Training Loss: 6.2724, Validation Loss: 4.9136
  Epoch 8/100, Training Loss: 5.2531, Validation Loss: 2.0911
  Epoch 9/100, Training Loss: 12.2469, Validation Loss: 5.7125
  Epoch 10/100, Training Loss: 2.3129, Validation Loss: 5.2565
  Epoch 11/100, Training Loss: 6.9419, Validation Loss: 1.5622
  Epoch 12/100, Training Loss: 8.0773, Validation Loss: 7.1394
  Epoch 13/100, Training Loss: 5.7514, Validation Loss: 1.6511
  Epoch 14/100, Training Loss: 10.7142, Validation Loss: 2.2650
  Epoch 15/100, Training Loss: 1.6346, Validation Loss: 0.9270
  Epoch 16/100, Training Loss: 1.8334, Validation Loss: 1.1136
  Epoch 17/100, Training Loss: 2.8010, Validation Loss: 1.0445
  Epoch 18/100, Training Loss: 0.4948, Validation Loss: 0.4716
  Epoch 19/100, Training Loss: 0.7490, Validation Loss: 0.2992
  Epoch 20/100, Training Loss: 0.0658, Validation Loss: 0.0302
  Epoch 21/100, Training Loss: 0.0068, Validation Loss: 0.0048
  Stopping training as loss has fallen below the threshold: 0.006834016647189856
#+end_example

#+begin_src ipython
  plt.plot(loss)
  plt.plot(val_loss)
  plt.xlabel('epochs')
  plt.ylabel('Loss')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/7cfdf4958ad853b69449b370b492ac8ebbfc566e.png]]
