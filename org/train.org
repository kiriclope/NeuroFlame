#+STARTUP: fold
#+TITLE: Training Low Rank RNNs
#+PROPERTY: header-args:ipython :var B0="1.0" :results both :exports both :async yes :session dual :kernel torch :tangle ./train.py

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
:RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python
: <Figure size 600x370.82 with 0 Axes>
:END:

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  import torchmetrics
  from torch.utils.data import Dataset, TensorDataset, DataLoader

  DEVICE = 'cuda:1'
#+end_src

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

* Helpers
** Data Split

#+begin_src ipython
  from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

  def split_data(X, Y, train_perc=0.8, batch_size=32):

    if Y.ndim==3:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0, 0].cpu().numpy(),
                                                          shuffle=True)
    else:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0].cpu().numpy(),
                                                          shuffle=True)
    print(X_train.shape, X_test.shape)
    print(Y_train.shape, Y_test.shape)

    train_dataset = TensorDataset(X_train, Y_train)
    val_dataset = TensorDataset(X_test, Y_test)

    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader
#+end_src

** Optimization

#+begin_src ipython
  def accuracy_score(y_pred, labels):
    probs = torch.sigmoid(y_pred)
    # Assuming 'outputs' are logits from your model (raw scores before sigmoid)
    predicted = (probs > 0.5).float()  # Convert to 0 or 1 based on comparison with 0
    # 'labels' should be your ground truth labels for the binary classification, also in 0 or 1
    correct = (predicted == labels).sum()
    accuracy = correct / labels.size(0) / labels.size(-1)

    return accuracy
#+end_src

#+begin_src ipython
  def torch_angle_AB(U, V):
      # Calculate the dot product
      dot_product = torch.dot(U, V)

      # Calculate the magnitudes of U and V
      magnitude_U = torch.linalg.norm(U)
      magnitude_V = torch.linalg.norm(V)

      # Compute the cosine of the angle
      cos_theta = dot_product / (magnitude_U * magnitude_V)

      # Calculate the angle in radians, then convert to degrees
      angle_radians = torch.acos(cos_theta)
      return torch.round(torch.rad2deg(angle_radians))
#+end_src

#+begin_src ipython
  def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1, clip_grad=0, zero_grad=0, read_idx=1):
      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          X, y = X.to(device), y.to(device)

          rates = model(X)

          if read_idx < 0:
              y_pred = model.low_rank.linear(model.low_rank.dropout(rates)).squeeze(-1)
          else:
              y_pred = rates @ model.low_rank.U[model.slices[0], read_idx]

          # if zero_grad == 0:
          # overlap = rates @ model.low_rank.U[model.slices[0]] / model.Na[0]
          # elif zero_grad == 1:
          overlap = rates @ model.low_rank.U[model.slices[0], 0] / model.Na[0]
          # elif zero_grad == 2:
          #     overlap = rates @ model.low_rank.U[model.slices[0], 1] / model.Na[0]

          loss = loss_fn(y_pred, y) + F.relu(overlap[..., :9].abs()-0.1).mean()

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()

          if zero_grad > 0:
              try:
                  model.low_rank.U.grad[:, zero_grad-1] = 0
                  model.low_rank.V.grad[:, zero_grad-1] = 0
              except:
                  pass

          # Clip gradients
          if clip_grad:
              torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
              #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)

          optimizer.step()
          optimizer.zero_grad()

      return loss
#+end_src

#+begin_src ipython
  def validation_step(dataloader, model, loss_fn, zero_grad=0, read_idx=1):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")
      # metric = torchmetrics.classification.Accuracy(task="binary")

      # Validation loop.
      model.eval()
      val_loss = 0.0

      with torch.no_grad():
          for X, y in dataloader:
              X, y = X.to(device), y.to(device)

              rates = model(X)

              if read_idx < 0:
                  y_pred = model.low_rank.linear(model.low_rank.dropout(rates)).squeeze(-1)
              else:
                  y_pred = rates @ model.low_rank.U[model.slices[0], read_idx]

              # if zero_grad == 0:
              #     overlap = rates @ model.low_rank.U[model.slices[0]] / model.Na[0]
              # elif zero_grad == 1:
              overlap = rates @ model.low_rank.U[model.slices[0], 0] / model.Na[0]
              # elif zero_grad == 2:
              #     overlap = rates @ model.low_rank.U[model.slices[0], 1] / model.Na[0]

              loss = loss_fn(y_pred, y) + F.relu(overlap[..., :9].abs()-0.1).mean()

              # acc = metric(y_pred, y)

              val_loss += loss.item() * X.size(0)

          val_loss /= size
          # acc = metric.compute()
          # print(f"Accuracy: {acc}")
          # metric.reset()
      return val_loss
#+end_src

#+begin_src ipython
  def optimization(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=.005, zero_grad=0, read_idx=1):
      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')
      model.to(device)

      loss_list = []
      val_loss_list = []
      accuracies = []
      angle_list = []

      for epoch in range(num_epochs):
          loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, zero_grad=zero_grad, read_idx=read_idx)
          val_loss = validation_step(val_loader, model, loss_fn, zero_grad, read_idx=read_idx)

          scheduler.step(val_loss)

          loss_list.append(loss.item())
          val_loss_list.append(val_loss)

          memory = model.low_rank.U[model.slices[0], 0]

          if read_idx <0:
              readout = model.low_rank.linear.weight.data[0]
          else:
              readout = model.low_rank.U[model.slices[0], read_idx]

          angle = torch_angle_AB(memory, readout).item()
          angle_list.append(angle)

          # if epoch % int(num_epochs  / 10) == 0:
          print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}, Angle(U, W) : {angle} Â°')

          if val_loss < thresh and loss < thresh:
              print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')
              break

          if val_loss > 300:
              print(f'Stopping training as loss is too high: {val_loss}')
              break

          if torch.isnan(loss):
              print(f'Stopping training as loss is NaN.')
              break

      return loss_list, val_loss_list
#+end_src

** Loss

#+begin_src ipython
  def performance_score(model, rates, labels):
      print(rates.shape)
      y_pred = model.low_rank.linear(rates[:, -2:]).squeeze(-1)
      accuracy = accuracy_score(y_pred, labels)
      return accuracy
#+end_src

#+begin_src ipython
  def imbalance_func(target, imbalance):
    output = torch.zeros_like(target)

    # Update values
    output[target == 1] = 1
    output[target == 0] = imbalance

    return output
#+end_src

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.nn.functional as F

  class SignBCELoss(nn.Module):
      def __init__(self, alpha=1.0, thresh=4.0, N=1000, imbalance=0):
          super(SignBCELoss, self).__init__()
          self.alpha = alpha
          self.thresh = thresh
          self.N = N
          self.imbalance = imbalance
          self.bce_with_logits = nn.BCEWithLogitsLoss()

      def forward(self, readout, targets):
          if self.alpha != 1.0:
              bce_loss = self.bce_with_logits(readout, targets)
          else:
              bce_loss = 0.0

          mean_activation = readout.mean(dim=1).unsqueeze(-1)

          # if self.type == 'DPA':
          #     sign_overlap = torch.sign(2 * targets - 1) * mean_activation / (1.0 * self.N)
          #     sign_loss = F.relu(self.thresh - sign_overlap).mean()
          # else:
          #     sign_overlap = torch.sign(targets) * mean_activation / (1.0 * self.N)
          #     sign_loss = F.relu((sign_overlap>0) * self.thresh - sign_overlap).mean()

          # sign_loss = F.relu(self.thresh - sign_overlap).mean()

          # Let's penalize more the wrong licks

          # only penalizing not licking when pair
          if self.imbalance == -1:
              sign_overlap = torch.sign(targets) * mean_activation / (1.0 * self.N)
              self.imbalance = 0
          else:
              sign_overlap = torch.sign(2 * targets - 1) * mean_activation / (1.0 * self.N)

          if self.imbalance > 1.0:
              sign_loss = F.relu(torch.sign(targets) * self.thresh - imbalance_func(targets, self.imbalance) * sign_overlap).mean()
          elif self.imbalance == 0:
              sign_loss = F.relu(imbalance_func(targets, self.imbalance) * self.thresh - sign_overlap).mean()
          elif self.imbalance ==-1 :
              sign_loss = F.relu(imbalance_func(targets, self.imbalance) * self.thresh - sign_overlap).mean()
          else:
              sign_loss = F.relu(self.thresh - sign_overlap).mean()

          combined_loss = (1-self.alpha) * bce_loss + self.alpha * sign_loss
          return combined_loss
#+end_src

#+begin_src ipython
  class DualLoss(nn.Module):
      def __init__(self, alpha=1.0, thresh=4.0, N=1000, cue_idx=[], rwd_idx=-1, zero_idx=[], imbalance=0):
          super(DualLoss, self).__init__()
          self.alpha = alpha
          self.thresh = thresh
          self.N = N
          self.imbalance = imbalance

          self.zero_idx = zero_idx
          self.cue_idx = torch.tensor(cue_idx, dtype=torch.int, device=DEVICE)
          self.rwd_idx = torch.tensor(rwd_idx, dtype=torch.int, device=DEVICE)

          self.loss = SignBCELoss(self.alpha, self.thresh, self.N, self.imbalance)

      def forward(self, readout, targets):

          # ensuring zero bl overlap
          bl_loss = F.relu((readout[:, self.zero_idx] / self.N).abs() -1.0).mean()

          is_empty = self.cue_idx.numel() == 0
          if is_empty:
              self.DPA_loss = self.loss(readout[:, self.rwd_idx], targets)
              return (self.DPA_loss + bl_loss)
          else:
              self.loss.imbalance = self.imbalance[0]
              self.DPA_loss = self.loss(readout[:, self.rwd_idx], targets[:, 0, :self.rwd_idx.shape[0]])

              self.loss.imbalance = self.imbalance[1]
              self.DRT_loss = self.loss(readout[:, self.cue_idx], targets[:, 1, :self.cue_idx.shape[0]])

              return (0.5 * self.DPA_loss + 0.5 * self.DRT_loss) + bl_loss
#+end_src

#+begin_src ipython
  class AccuracyLoss(nn.Module):
      def __init__(self, N=1000, cue_idx=[], rwd_idx=-1):
          super(AccuracyLoss, self).__init__()
          self.N = N

          # self.loss = nn.BCEWithLogitsLoss()
          self.cue_idx = torch.tensor(cue_idx, dtype=torch.int, device=DEVICE)
          self.rwd_idx = torch.tensor(rwd_idx, dtype=torch.int, device=DEVICE)

      def forward(self, readout, targets):

          is_empty = self.cue_idx.numel() == 0
          if is_empty:
              self.DPA_loss = accuracy_score(readout[:, self.rwd_idx], targets)
              return self.DPA_loss
          else:
              self.DPA_loss = accuracy_score(readout[:, self.rwd_idx], targets[:, 0, :self.rwd_idx.shape[0]])
              self.DRT_loss = accuracy_score(readout[:, self.cue_idx], targets[:, 1, :self.cue_idx.shape[0]])
              return (self.DPA_loss + self.DRT_loss) / 2.0
#+end_src

** Other

#+begin_src ipython
  def angle_AB(A, B):
      A_norm = A / (np.linalg.norm(A) + 1e-5)
      B_norm = B / (np.linalg.norm(B) + 1e-5)

      return int(np.arccos(A_norm @ B_norm) * 180 / np.pi)
#+end_src

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      u, v = a, b

      if GM:
          v = b - np.dot(b, a) / np.dot(a, a) * a

      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)

      return np.arctan2(v, u) % (2.0 * np.pi)
#+end_src

#+begin_src ipython
  def get_idx(model, rank=2):
      ksi = torch.hstack((model.low_rank.U, model.low_rank.V)).T
      ksi = ksi[:, :model.Na[0]]

      readout = model.low_rank.linear.weight.data
      ksi = torch.vstack((ksi, readout))

      print('ksi', ksi.shape)

      ksi = ksi.cpu().detach().numpy()
      theta = get_theta(ksi[0], ksi[rank])

      return theta.argsort()
#+end_src

#+begin_src ipython
  def get_overlap(model, rates):
      ksi = model.odors.cpu().detach().numpy()
      return rates @ ksi.T / rates.shape[-1]
#+end_src

#+begin_src ipython
  import scipy.stats as stats

  def plot_smooth(data, ax, color):
      mean = data.mean(axis=0)
      ci = smooth.std(axis=0, ddof=1) * 1.96

      # Plot
      ax.plot(mean, color=color)
      ax.fill_between(range(data.shape[1]), mean - ci, mean + ci, alpha=0.25, color=color)

#+end_src

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

** plots

#+begin_src ipython
def add_vlines(ax=None, mouse=""):
    t_BL = [0, 1]
    t_STIM = [1 , 2]
    t_ED = [2, 3]
    t_DIST = [3 , 4]
    t_MD = [4 , 5]
    t_CUE = [5 , 5.5]
    t_RWD = [5.5, 6.0]
    t_LD = [6.0 , 7.0]
    t_TEST = [7.0, 8.0]
    t_RWD2 = [11 , 12]

    time_periods = [t_STIM, t_DIST, t_TEST, t_CUE]
    colors = ["b", "b", "b", "g"]

    if ax is None:
        for period, color in zip(time_periods, colors):
            plt.axvspan(period[0], period[1], alpha=0.1, color=color)
    else:
        for period, color in zip(time_periods, colors):
            ax.axvspan(period[0], period[1], alpha=0.1, color=color)

#+end_src

#+begin_src ipython
  def plot_rates_selec(rates, idx, thresh=0.5, figname='fig.svg'):
        ordered = rates[..., idx]
        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
        r_max = thresh * np.max(rates[0])

        ax[0].imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[0].set_ylabel('Neuron #')
        ax[0].set_xlabel('Step')

        ax[1].imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[1].set_yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))
        ax[1].set_ylabel('Pref. Location (Â°)')
        ax[1].set_xlabel('Step')
        plt.savefig(figname, dpi=300)
        plt.show()
#+end_src

#+begin_src ipython
  def plot_overlap(rates, memory, readout, labels=['A', 'B'], figname='fig.svg'):
      fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
      overlap =(rates @ memory) / rates.shape[-1]

      time = np.linspace(0, 8, overlap.T.shape[0])
      if overlap.shape[0]>2:
          ax[0].plot(time, overlap.T[..., :2], label=labels[0])
          ax[0].plot(time, overlap.T[..., 2:], '--', label=labels[1])
      else:
          ax[0].plot(time, overlap.T[..., 0], label=labels[0])
          ax[0].plot(time, overlap.T[..., 1], '--', label=labels[1])

      ax[0].set_xlabel('Time (s)')
      ax[0].set_ylabel('Sample Overlap (Hz)')
      # ax[0].set_title('Memory')
      add_vlines(ax[0])
      overlap =(rates @ readout) / rates.shape[-1]

      if overlap.shape[0]>2:
          ax[1].plot(time, overlap.T[..., :2], label=labels[0])
          ax[1].plot(time, overlap.T[..., 2:], '--', label=labels[1])
      else:
          ax[1].plot(time, overlap.T[..., 0], label=labels[0])
          ax[1].plot(time, overlap.T[..., 1], '--', label=labels[1])

      ax[1].set_xlabel('Time (s)')
      ax[1].set_ylabel('Readout (Hz)')
      # ax[1].set_title('Readout')
      add_vlines(ax[1])

      # plt.legend(fontsize=10, frameon=False)
      plt.savefig(figname, dpi=300)
      plt.show()
#+end_src

#+begin_src ipython
  def plot_m0_m1_phi(rates, idx, figname='fig.svg'):

      m0, m1, phi = decode_bump(rates[..., idx], axis=-1)
      fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

      time = np.linspace(0, 8, m0.T.shape[0])

      ax[0].plot(time, m0[:2].T)
      ax[0].plot(time, m0[2:].T, '--')
      #ax[0].set_ylim([0, 360])
      #ax[0].set_yticks([0, 90, 180, 270, 360])
      ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
      ax[0].set_ylabel('Activity (Hz)')
      ax[0].set_xlabel('Time (s)')
      add_vlines(ax[0])

      ax[1].plot(time, m1[:2].T)
      ax[1].plot(time, m1[2:].T, '--')
      # ax[1].set_ylim([0, 360])
      # ax[1].set_yticks([0, 90, 180, 270, 360])
      ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
      ax[1].set_ylabel('Bump Amplitude (Hz)')
      ax[1].set_xlabel('Time (s)')
      add_vlines(ax[1])

      ax[2].plot(time, phi[:2].T * 180 / np.pi)
      ax[2].plot(time, phi[2:].T * 180 / np.pi, '--')
      ax[2].set_ylim([0, 360])
      ax[2].set_yticks([0, 90, 180, 270, 360])
      ax[2].set_ylabel('Bump Center (Â°)')
      ax[2].set_xlabel('Time (s)')
      add_vlines(ax[2])

      plt.savefig(figname, dpi=300)
      plt.show()
    #+end_src

* Model

#+begin_src ipython
        REPO_ROOT = "/home/leon/models/NeuroFlame"
        conf_name = "config_train.yml"
        DEVICE = 'cuda:1'
        seed = np.random.randint(0, 1e6)
        # seed = 21881
        print(seed)
        # 789395
        # 453642
        # : 577806

        A0 = 1.0
        B0 = 1.0
        C0 = 0.0
#+end_src

#+RESULTS:
: 317675

#+begin_src ipython
  model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=16)
  # model.odors[2] = model.odors[1] # cue same as Go
#+end_src

* Sample Classification
** Training
*** Parameters

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: low_rank.U torch.Size([2000, 2])
: low_rank.V torch.Size([2000, 2])
: low_rank.lr_kappa torch.Size([1])


#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1
  model.IF_RL = 0
#+end_src

Testing the network on steps from sample odor offset to test odor onset

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

  mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  rwd_idx = np.where(mask)[0]
  print('rwd', rwd_idx)

  model.lr_eval_win = rwd_idx.shape[0]

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))

  zero_idx = np.where(~mask & ~stim_mask )[0]
  print('zero', zero_idx)
#+end_src

#+RESULTS:
: rwd [20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
:  44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
:  68 69 70 71 72 73 74 75 76 77 78 79 80]
: zero [0 1 2 3 4 5 6 7 8 9]


*** Inputs and Labels

#+begin_src ipython
  model.N_BATCH = 80

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  A = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([160, 455, 2000])

#+begin_src ipython
  labels_A = torch.ones((model.N_BATCH, rwd_idx.shape[0]))
  labels_B = torch.zeros((model.N_BATCH, rwd_idx.shape[0]))
  labels = torch.cat((labels_A, labels_B))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([160, 61])

*** Run

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([128, 455, 2000]) torch.Size([32, 455, 2000])
: torch.Size([128, 61]) torch.Size([32, 61])

#+begin_src ipython
  criterion = DualLoss(alpha=1.0, thresh=5.0, N=model.Na[0], rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=1)
  # SGD, Adam, Adam
  learning_rate = 0.05
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+begin_src ipython
  num_epochs = 15
  start = perf_counter()
  loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=2, read_idx=0)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
#+begin_example
  Epoch 1/15, Training Loss: 4.9799, Validation Loss: 4.9712, Angle(U, W) : nan Â°
  Epoch 2/15, Training Loss: 4.9499, Validation Loss: 4.9494, Angle(U, W) : 0.0 Â°
  Epoch 3/15, Training Loss: 4.9430, Validation Loss: 4.9214, Angle(U, W) : 0.0 Â°
  Epoch 4/15, Training Loss: 4.8608, Validation Loss: 4.8796, Angle(U, W) : 0.0 Â°
  Epoch 5/15, Training Loss: 4.8232, Validation Loss: 4.7984, Angle(U, W) : 0.0 Â°
  Epoch 6/15, Training Loss: 4.5994, Validation Loss: 4.5377, Angle(U, W) : 0.0 Â°
  Epoch 7/15, Training Loss: 2.4953, Validation Loss: 1.7577, Angle(U, W) : 0.0 Â°
  Epoch 8/15, Training Loss: 0.0078, Validation Loss: 0.0070, Angle(U, W) : nan Â°
  Epoch 9/15, Training Loss: 0.3734, Validation Loss: 0.0638, Angle(U, W) : 0.0 Â°
  Epoch 10/15, Training Loss: 0.1660, Validation Loss: 0.0493, Angle(U, W) : 0.0 Â°
  Epoch 11/15, Training Loss: 0.0565, Validation Loss: 0.0271, Angle(U, W) : 0.0 Â°
  Epoch 12/15, Training Loss: 0.0014, Validation Loss: 0.0050, Angle(U, W) : 0.0 Â°
  Stopping training as loss has fallen below the threshold: 0.0013650673208758235, 0.004966108885128051
  Elapsed (with compilation) = 0h 1m 12s
#+end_example

** Testing

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )

#+begin_src ipython
  model.N_BATCH = 10

  model.I0[0] = 2
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = -2
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([20, 455, 2000])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print('rates', rates.shape)
#+end_src

#+RESULTS:
: rates (20, 81, 1000)

#+begin_src ipython
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
  # readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
  plot_overlap(rates, memory, readout, labels=['A', 'B'])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/b2d950f38d30b21df4aacb36af7601c07082062f.png]]

#+begin_src ipython
  idx = get_idx(model, -1)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/eb5d6dbf39e6b4658ae9750d9c2606a9441d84e2.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/b23faec408d1d2b93bbcab928a9a09aa17eadc6c.png]]

* DPA
** Training
*** Parameters

#+begin_src ipython
  model.low_rank.lr_kappa.requires_grad = False
  model.low_rank.U.data[:, 1] = torch.randn(model.low_rank.U.T.data[1].shape) * 0.01
  model.low_rank.V.data[:, 1] = torch.randn(model.low_rank.U.T.data[1].shape) * 0.01

  import torch.nn.init as init

  if model.LR_FIX_READ==0:
      init.xavier_uniform_(model.low_rank.linear.weight)
      if model.low_rank.linear.bias is not None:
          model.low_rank.linear.bias.data.zero_()  # Common practice is to set biases to zero
#+end_src

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1
  model.IF_RL = 0
#+end_src

Here we only evaluate performance from test onset to test offset

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
  # mask = (steps >= (model.N_STIM_OFF[2] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  mask = (steps >= (model.N_STIM_ON[4] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  rwd_idx = np.where(mask)[0]
  print('rwd', rwd_idx)

  model.lr_eval_win = rwd_idx.shape[0]

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))

  stim_mask1 = (steps >= (model.N_STIM_ON[4] - model.N_STEADY)) # & (steps < (model.N_STIM_OFF[3] - model.N_STEADY))

  mask_zero = ~mask & ~stim_mask & ~stim_mask1
  zero_idx = np.where(mask_zero)[0]
  print('zero', zero_idx)
#+end_src

#+RESULTS:
: rwd [70 71 72 73 74 75 76 77 78 79 80]
: zero [ 0  1  2  3  4  5  6  7  8  9 20 21 22 23 24 25 26 27 28 29 30 31 32 33
:  34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
:  58 59 60 61 62 63 64 65 66 67 68 69]

*** Inputs and Labels

#+begin_src ipython
  model.N_BATCH = 80

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = A0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = -A0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = A0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = -A0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([320, 455, 2000])

 #+begin_src ipython
  labels_pair = torch.ones((2 * model.N_BATCH, model.lr_eval_win))
  labels_unpair = torch.zeros((2 * model.N_BATCH, model.lr_eval_win))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([320, 11])

*** Run

#+begin_src ipython
    batch_size = 16
    train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([256, 455, 2000]) torch.Size([64, 455, 2000])
: torch.Size([256, 11]) torch.Size([64, 11])

  #+begin_src ipython
    # Loss
    criterion = DualLoss(alpha=1.0, thresh=5.0, N=model.Na[0], rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=-1)

    # Optimizer: SGD, Adam, Adam
    learning_rate = 0.05
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+begin_src ipython
  print('training DPA')
  num_epochs = 30
  start = perf_counter()
  loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=1, read_idx=1)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
: training DPA
: Epoch 1/30, Training Loss: 2.1683, Validation Loss: 1.9003, Angle(U, W) : 89.0 Â°
: Epoch 2/30, Training Loss: 1.8690, Validation Loss: 1.4476, Angle(U, W) : 89.0 Â°
: Epoch 3/30, Training Loss: 1.1636, Validation Loss: 1.0091, Angle(U, W) : 90.0 Â°
: Epoch 4/30, Training Loss: 0.2068, Validation Loss: 0.0956, Angle(U, W) : 92.0 Â°
: Epoch 5/30, Training Loss: 0.0011, Validation Loss: 0.0017, Angle(U, W) : 94.0 Â°
: Stopping training as loss has fallen below the threshold: 0.0010572022292762995, 0.0016586251877015457
: Elapsed (with compilation) = 0h 1m 0s

#+begin_src ipython
    torch.save(model.state_dict(), 'models/dpa_%d.pth' % seed)
#+end_src

#+begin_src ipython
    plt.plot(loss)
    plt.plot(val_loss)
    plt.xlabel('epochs')
    plt.ylabel('Loss')
    plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/42974d09b608de6364a90780a510098c38c1a8d0.png]]

#+begin_src ipython
  odors = model.odors.cpu().numpy()
  U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]
  W = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]

  print('   U  V  W  S  D')
  print('U ', angle_AB(U, U), angle_AB(U, V), angle_AB(U, W), angle_AB(U, odors[0]), angle_AB(U, odors[1]))
  print('V ', 'XXX', angle_AB(V, V), angle_AB(V, W), angle_AB(V, odors[0]), angle_AB(V, odors[1]))
  print('W ', 'XXX', 'XXX', angle_AB(W, W), angle_AB(W, odors[0]), angle_AB(W, odors[1]))
  print('S ', 'XXX', 'XXX', 'XXX', angle_AB(odors[0], odors[0]), angle_AB(odors[0], odors[1]))
  print('D ', 'XXX', 'XXX', 'XXX', 'XXX', angle_AB(odors[1], odors[1]))

#+end_src

#+RESULTS:
:    U  V  W  S  D
: U  0 32 92 67 94
: V  XXX 0 91 66 95
: W  XXX XXX 0 91 91
: S  XXX XXX XXX 0 89
: D  XXX XXX XXX XXX 0

** Testing

#+begin_src ipython
  model.DURATION = 8
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW

  model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )

#+begin_src ipython
  model.N_BATCH = 1
  A0 = 1

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = A0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = -A0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = A0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = -A0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 455, 2000])

 #+begin_src ipython
  labels_pair = torch.ones((2 * model.N_BATCH, 2))
  labels_unpair = torch.zeros((2 * model.N_BATCH, 2))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([4, 2])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).detach().cpu().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
: (4, 81, 1000)

#+begin_src ipython
  print(rates.shape)
  print(labels.shape)
#+end_src

#+RESULTS:
: (4, 81, 1000)
: torch.Size([4, 2])

#+begin_src ipython
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
  # readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
  plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dpa_overlap.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/bc35d4fd0759057a971cbf0c71e44065e786fdd6.png]]

#+begin_src ipython
  idx = get_idx(model, 1)
  plot_rates_selec(rates, idx, figname='dpa_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/b32b5ca9e47994277f61477980193461b285cce8.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx, figname='dpa_fourier.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/d0d9656e8fa25b30fa16b56ad2e159c9eaaffaa8.png]]

#+begin_src ipython

#+end_src


** Fixed points

#+begin_src ipython
  model.DURATION = 20
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
  model.IF_RL = 0
#+end_src

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )


#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape, ff_input[0, 0, :4])
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 1055, 2000]) tensor([25.9014, 26.4005, 27.9669, 21.2066], device='cuda:1')

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
: (4, 201, 1000)

#+begin_src ipython
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
  # readout = model.low_rank.linear.weight.data[0].cpu().detach().numpy()
  plot_overlap(rates, memory, readout, labels=['pair', 'unpair'])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/4f3ab55d1bf5416d7df9f6adcf7c087c636a4b2f.png]]

#+begin_src ipython
  idx = get_idx(model, 1)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/bf2dde873a2dc4787c076595c01393f5acc0a7f9.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/1236d03abf4ffb5b447b0b2d85717ac950f85c04.png]]

    #+begin_src ipython
  print(rates.shape)
#+end_src

#+RESULTS:
: (4, 201, 1000)

#+begin_src ipython
  from matplotlib.patches import Circle
  m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

  x = m1 / m0 * np.cos(phi)
  y = m1 / m0 * np.sin(phi)

  xA = x
  yA = y

  fig, ax = plt.subplots(1, 1, figsize=[height, height])

  # ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
  # ax.plot(xA.T, yA.T, '-', alpha=.5)
  ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=20)
  # ax.set_xlim([-.9, .9])
  # ax.set_ylim([-.9, .9])
  circle = Circle((0., 0.), 1.8, fill=False, edgecolor='k')
  ax.add_patch(circle)

  # Set the aspect of the plot to equal to make the circle circular
  ax.set_aspect('equal')
  plt.savefig('fp_dpa.svg', dpi=300)
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/e6a89a873cdadb55da28292263d240e54368de4e.png]]


#+begin_src ipython

#+end_src

* Go/NoGo
** Training

#+begin_src ipython
  model.low_rank.lr_kappa.requires_grad = True

  # readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
  # idx = readout.argsort()[:250]
  # model.low_rank.lr_mask[idx, :1000] = 0

  # for param in model.low_rank.linear.parameters():
  #     param.requires_grad = True

  # model.low_rank.linear.bias.requires_grad = True
  # model.low_rank.linear.bias.data.zero_()  # Common practice is to set biases to zero

  # model.low_rank.U.requires_grad = False
  # model.low_rank.V.requires_grad = False

#+end_src

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: low_rank.U torch.Size([2000, 2])
: low_rank.V torch.Size([2000, 2])
: low_rank.lr_kappa torch.Size([1])

#+begin_src ipython
  model.DURATION = 4.0
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW

  model.T_STIM_ON =  [1.0, 3.0]
  model.T_STIM_OFF =  [2.0, 4.0]

  # model.T_STIM_ON =  [1.0, 3.0, 3.5]
  # model.T_STIM_OFF =  [2.0, 3.5, 4.0]

  model.N_STIM_ON = np.array(
        [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_ON]
    )

  model.N_STIM_OFF = [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_OFF]
#+end_src

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1
  model.IF_RL = 0 # 1
  model.RWD = 1 # 1/2
#+end_src

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
  # mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[1] - model.N_STEADY))
  mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps <= (model.N_STIM_OFF[0] - model.N_STEADY))
  # mask = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))

  rwd_idx = np.where(mask)[0]
  print('rwd', rwd_idx)

  mask_cue = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))
  # mask_cue = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY))  & (steps < (model.N_STIM_ON[1] - model.N_STEADY))
  cue_idx = np.where(mask_cue)[0]

  # cue_idx = []

  print('cue', cue_idx)

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) # & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))

  mask_zero = ~mask & ~stim_mask
  zero_idx = np.where(mask_zero)[0]
  print('zero', zero_idx)

  # model.lr_eval_win = rwd_idx.shape[0]
  model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))
#+end_src

#+RESULTS:
: rwd [10 11 12 13 14 15 16 17 18 19 20]
: cue [30 31 32 33 34 35 36 37 38 39 40]
: zero [0 1 2 3 4 5 6 7 8 9]

#+begin_src ipython
  # switching sample and distractor odors
  odors = model.odors.clone()
  model.odors[0] = odors[1] # distractor Go
  model.odors[5] = odors[5+1] # distractor NoGo

  model.odors[1] = odors[2] # cue same as Go
  model.odors[2] = odors[3] # rwd

  model.N_BATCH = 80

  # if model.IF_RL == 0:
  #     B0 = 0

  model.I0[0] = A0
  model.I0[1] = float(B0) # cue
  model.I0[2] = 0.0 # float(C0) * model.IF_RL  # reward
  model.I0[3] = 0
  model.I0[4] = 0

  Go = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = float(B0) # cue
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  NoGo = model.init_ff_input()

  ff_input = torch.cat((Go, NoGo))
  print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([160, 255, 2000])

#+begin_src ipython
  labels_Go = torch.ones((model.N_BATCH, model.lr_eval_win))
  labels_NoGo = torch.zeros((model.N_BATCH, model.lr_eval_win))
  labels = torch.cat((labels_Go, labels_NoGo))
  print(labels.shape)
  # print(labels)
  labels =  labels.repeat((2, 1, 1))
  labels = torch.transpose(labels, 0, 1)
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: torch.Size([160, 11])
: labels torch.Size([160, 2, 11])

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([128, 255, 2000]) torch.Size([32, 255, 2000])
: torch.Size([128, 2, 11]) torch.Size([32, 2, 11])

#+begin_src ipython
  # criterion = DualLoss(alpha=1.0, thresh=5.0, N=model.Na[0], rwd_idx=rwd_idx, zero_idx=zero_idx, cue_idx=cue_idx, imbalance=[1.0, 0.0])
  criterion = DualLoss(alpha=1.0, thresh=5.0, N=model.Na[0], rwd_idx=rwd_idx, zero_idx=zero_idx, cue_idx=cue_idx, imbalance=[1.0, -1.0])

  # SGD, Adam, Adam
  learning_rate = 0.05
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+begin_src ipython
  print('training DRT')
  num_epochs = 15
  start = perf_counter()
  loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=0, read_idx=1)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

  # switching back sample and distractor odors
  model.odors = odors
#+end_src

#+RESULTS:
#+begin_example
  training DRT
  Epoch 1/15, Training Loss: 2.0365, Validation Loss: 1.7533, Angle(U, W) : 101.0 Â°
  Epoch 2/15, Training Loss: 1.8091, Validation Loss: 1.0981, Angle(U, W) : 104.0 Â°
  Epoch 3/15, Training Loss: 0.8083, Validation Loss: 0.6260, Angle(U, W) : 105.0 Â°
  Epoch 4/15, Training Loss: 0.1653, Validation Loss: 0.0037, Angle(U, W) : 105.0 Â°
  Epoch 5/15, Training Loss: 0.1552, Validation Loss: 0.0622, Angle(U, W) : 105.0 Â°
  Epoch 6/15, Training Loss: 0.0116, Validation Loss: 0.0002, Angle(U, W) : 106.0 Â°
  Epoch 7/15, Training Loss: 0.0162, Validation Loss: 0.0060, Angle(U, W) : 105.0 Â°
  Epoch 8/15, Training Loss: 0.0066, Validation Loss: 0.0059, Angle(U, W) : 105.0 Â°
  Epoch 9/15, Training Loss: 0.0000, Validation Loss: 0.0000, Angle(U, W) : 105.0 Â°
  Stopping training as loss has fallen below the threshold: 0.0, 0.0
  Elapsed (with compilation) = 0h 0m 30s
#+end_example

:RESULTS:

#+begin_src ipython
    torch.save(model.state_dict(), 'models/dual_naive_%d.pth' % seed)
#+end_src

** Test

  #+begin_src ipython
    model.eval()
  #+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )

 #+begin_src ipython
   odors = model.odors.clone()
   model.odors[0] = odors[1] # distractor Go
   model.odors[5] = odors[5+1] # distractor NoGo

   model.odors[1] = odors[2] # cue
   model.odors[2] = odors[3] # rwd
  #+end_src

  #+begin_src ipython
    model.N_BATCH = 1

    model.I0[0] = A0 # Go
    model.I0[1] = float(B0) # cue
    model.I0[2] = 0.0 # float(C0) * model.IF_RL # rwd
    model.I0[3] = 0.0
    model.I0[4] = 0.0

    A = model.init_ff_input()

    model.I0[0] = -A0 # NoGo
    model.I0[1] = float(B0) # cue
    model.I0[2] = 0.0 # rwd
    model.I0[3] = 0.0
    model.I0[4] = 0.0

    B = model.init_ff_input()

    ff_input = torch.cat((A, B))
    print('ff_input', ff_input.shape)
  #+end_src

#+RESULTS:
: ff_input torch.Size([2, 255, 2000])

  #+begin_src ipython
      rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
      model.odors = odors
      print(rates.shape)
  #+end_src

#+RESULTS:
: (2, 41, 1000)

  #+begin_src ipython
    memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
    readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
    # readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
    plot_overlap(rates, memory, readout, labels=['Go', 'NoGo'])
  #+end_src

#+RESULTS:
[[file:./.ob-jupyter/62f9433f2083fa90257faa24f6e9c275878f3fba.png]]

  #+begin_src ipython
    memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
    # readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
    readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
    # plot_overlap(rates, memory, readout, labels=['Go', 'NoGo'])
  #+end_src

  #+begin_src ipython
    idx = get_idx(model, 1)
    plot_rates_selec(rates, idx)
  #+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/62a3ef6f43624926512130d2d2d9b6e22a87abe6.png]]
:END:

#+begin_src ipython
    plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/93392c63f28963fa7627763e09ae3f84a22e0133.png]]

* Dual
** Parameters

#+begin_src ipython
  model.DURATION = 8
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
  model.IF_RL = 0 # 1
  model.RWD = 22 # 2/3
#+end_src

#+begin_src ipython
  model.T_STIM_ON = [1.0, 3.0, 5.0, 5.5, 7.0]
  model.T_STIM_OFF = [2.0, 4.0, 5.5, 6.0, 8.0]

  model.N_STIM_ON = np.array(
      [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_ON]
  )

  model.N_STIM_OFF = [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_OFF]
#+end_src

** Testing

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = A0 # sample A
  model.I0[1] = A0 # distractor Go
  model.I0[2] = float(B0) # cue
  model.I0[3] = 0.0 # float(C0) * model.IF_RL # rwd
  model.I0[4] = A0 # test

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = -A0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = A0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = -A0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 455, 2000])

#+begin_src ipython
  labels_pair = torch.ones((2 * model.N_BATCH, 2))
  labels_unpair = torch.zeros((2 * model.N_BATCH, 2))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([4, 2])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).detach()
  print(rates.shape)
#+end_src

#+RESULTS:
: torch.Size([4, 81, 1000])

#+begin_src ipython
  rates = rates.cpu().numpy()
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
  plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_naive_overlap.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/c84de7615286e88d2d0cf0eba5e039945e5bb4f0.png]]

#+begin_src ipython
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
  # plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_naive_overlap.svg')
#+end_src


#+begin_src ipython
  idx = get_idx(model, 1)
  plot_rates_selec(rates, idx, figname='dual_naive_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/2dac127032a14dbd2e07023637387f0f87315e12.png]]
:END:


#+begin_src ipython
  plot_m0_m1_phi(rates, idx, figname='dual_naive_fourier.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/656e31e0d1ca19a03d96625f14d357774fffde9a.png]]


#+begin_src ipython

#+end_src

** Fixed points

#+begin_src ipython
  model.DURATION = 20
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
  model.IF_RL = 0
#+end_src

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape, ff_input[0, 0, :4])
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 1055, 2000]) tensor([30.2238, 31.3916, 28.3873, 27.9497], device='cuda:1')

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
: (4, 201, 1000)

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/e77ad64f9e0cf55536916030c05a336db64064bf.png]]

#+begin_src ipython
  from matplotlib.patches import Circle
  m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

  x = m1 / m0 * np.cos(phi)
  y = m1 / m0 * np.sin(phi)

  xA = x
  yA = y

  fig, ax = plt.subplots(1, 1, figsize=[height, height])

  # ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
  # ax.plot(xA.T, yA.T, '-', alpha=.5)
  ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=20)
  # ax.set_xlim([-.9, .9])
  # ax.set_ylim([-.9, .9])
  circle = Circle((0., 0.), 1.8, fill=False, edgecolor='k')
  ax.add_patch(circle)

  # Set the aspect of the plot to equal to make the circle circular
  ax.set_aspect('equal')
  plt.savefig('fp_dual_naive.svg', dpi=300)
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/3fd0b09f98bbd4d2423899dfca5528e71ee84786.png]]

#+begin_src ipython

#+end_src

** Training

#+begin_src ipython
  # for param in model.low_rank.linear.parameters():
  #     param.requires_grad = False

  model.low_rank.U.requires_grad = True
  model.low_rank.V.requires_grad = True

  # init.xavier_uniform_(model.low_rank.linear.weight)
  # if model.low_rank.linear.bias is not None:
  #     model.low_rank.linear.bias.data.zero_()  # Common practice is to set biases to zero
  #+end_src

#+begin_src ipython
  model.DURATION = 8
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
  model.IF_RL = 0 # 1

  model.LR_TRAIN = 1
  model.LR_READOUT = 1
  model.RWD = 2 # 2/3
#+end_src

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

  mask_rwd = (steps >= (model.N_STIM_ON[-1] - model.N_STEADY))
  rwd_idx = np.where(mask_rwd)[0]
  print('rwd', rwd_idx)

  # mask_dist = (steps >= (model.N_STIM_ON[1] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[-1] - model.N_STEADY))
  # # mask_dist = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))
  # dist_idx = np.where(mask_dist)[0]
  # print('dist', dist_idx)

  mask_cue = (steps >= (model.N_STIM_ON[2] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[-1] - model.N_STEADY))
  # mask_cue = (steps >= (model.N_STIM_ON[1] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[-1] - model.N_STEADY))
  # mask_cue = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))
  cue_idx = np.where(mask_cue)[0]
  print('cue', cue_idx)

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY))

  mask_zero = ~mask_rwd & ~mask_cue & ~stim_mask
  zero_idx = np.where(mask_zero)[0]
  print('zero', zero_idx)
#+end_src

#+RESULTS:
: rwd [70 71 72 73 74 75 76 77 78 79 80]
: cue [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]
: zero [0 1 2 3 4 5 6 7 8 9]

#+begin_src ipython
  model.N_BATCH = 80

  model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))
  # model.lr_eval_win = np.max( (rwd_idx.shape[0], dist_idx.shape[0], cue_idx.shape[0]))

  ff_input = []
  labels = np.zeros((2, 12, model.N_BATCH, model.lr_eval_win))
  # labels = np.zeros((3, 12, model.N_BATCH, model.lr_eval_win))

  # if model.IF_RL==0:
  #     B0 = 0

  print(float(B0), float(C0))

  l=0
  for i in [-1, 1]:
      for j in [-1, 0, 1]:
          for k in [-1, 1]:

              model.I0[0] = i # sample
              model.I0[1] = j # distractor
              model.I0[4] = k # test

              if i==k: # Pair Trials
                  labels[0, l] = np.ones((model.N_BATCH, model.lr_eval_win))

              if j==1: # Go
                  model.I0[2] = float(B0) # cue
                  model.I0[3] = float(C0) * model.IF_RL # rwd

                  labels[1, l] = np.ones((model.N_BATCH, model.lr_eval_win))
              elif j==-1: # NoGo
                  model.I0[2] = float(B0) # cue
                  model.I0[3] = 0.0 # rwd
              else: # DPA
                  model.I0[2] = 0 # cue
                  model.I0[3] = 0 # rwd

              l+=1

              ff_input.append(model.init_ff_input())

  labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(2, -1, model.lr_eval_win).transpose(0, 1)
  # labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(3, -1, model.lr_eval_win).transpose(0, 1)
  ff_input = torch.vstack(ff_input)
  print('ff_input', ff_input.shape, 'labels', labels.shape)
#+end_src

#+RESULTS:
: 1.0 0.0
: ff_input torch.Size([960, 455, 2000]) labels torch.Size([960, 2, 21])

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([768, 455, 2000]) torch.Size([192, 455, 2000])
: torch.Size([768, 2, 21]) torch.Size([192, 2, 21])

#+begin_src ipython
  criterion = DualLoss(alpha=1.0, thresh=5.0, N=model.Na[0], cue_idx=cue_idx, rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=[1.0, 0.0])

  # SGD, Adam, Adam
  learning_rate = 0.05
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+begin_src ipython
  print('training Dual')
  num_epochs = 15
  start = perf_counter()
  loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=0, read_idx=1)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
: training Dual
: Epoch 1/15, Training Loss: 0.4061, Validation Loss: 0.5537, Angle(U, W) : 94.0 Â°
: Epoch 2/15, Training Loss: 0.0007, Validation Loss: 0.0003, Angle(U, W) : 95.0 Â°
: Stopping training as loss has fallen below the threshold: 0.0007401235052384436, 0.0002939274351471492
: Elapsed (with compilation) = 0h 1m 12s

#+begin_src ipython
    torch.save(model.state_dict(), 'models/dual_train_%d.pth' % seed)
#+end_src

#+begin_src ipython
  odors = model.odors.cpu().numpy()
  U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]
  W = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]

  print('   U  V  W  S  D')
  print('U ', angle_AB(U, U), angle_AB(U, V), angle_AB(U, W), angle_AB(U, odors[0]), angle_AB(U, odors[1]))
  print('V ', 'XXX', angle_AB(V, V), angle_AB(V, W), angle_AB(V, odors[0]), angle_AB(V, odors[1]))
  print('W ', 'XXX', 'XXX', angle_AB(W, W), angle_AB(W, odors[0]), angle_AB(W, odors[1]))
  print('S ', 'XXX', 'XXX', 'XXX', angle_AB(odors[0], odors[0]), angle_AB(odors[0], odors[1]))
  print('D ', 'XXX', 'XXX', 'XXX', 'XXX', angle_AB(odors[1], odors[1]))

#+end_src

#+RESULTS:
:    U  V  W  S  D
: U  0 39 91 71 94
: V  XXX 0 91 66 97
: W  XXX XXX 0 91 91
: S  XXX XXX XXX 0 89
: D  XXX XXX XXX XXX 0

** Re-Testing

#+begin_src ipython
  model.DURATION = 8
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

    #+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = A0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = -A0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = A0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = -A0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 455, 2000])

#+begin_src ipython
  labels_A = torch.ones((2*model.N_BATCH, 2))
  labels_B = torch.zeros((2*model.N_BATCH, 2))
  labels = torch.cat((labels_A, labels_B))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([4, 2])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).detach()
  print(rates.shape)
#+end_src

#+RESULTS:
: torch.Size([4, 81, 1000])

 #+begin_src ipython
   rates = rates.cpu().detach().numpy()
   memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
   readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
   plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_train_overlap.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/a5a3d2604768594b583fcec9803183546ff28eb9.png]]


 #+begin_src ipython
   memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
   # readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
   readout = model.low_rank.linear.weight.data[0].cpu().detach().numpy()
   # plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_train_overlap.svg')
#+end_src

#+begin_src ipython
  idx = get_idx(model, 1)
  plot_rates_selec(rates, idx, figname='dual_train_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/bb1d7b878917e1fd02f27a1219a588cf5f8ba95b.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx, figname='dual_train_fourier.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/ebdde4aaeeea17d5309490a1c6e254f00f805d70.png]]


#+begin_src ipython

#+end_src

** Fixed points

#+begin_src ipython
  model.DURATION = 20
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
  model.IF_RL = 0
#+end_src

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )


#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape, ff_input[0, 0, :4])
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 1055, 2000]) tensor([25.8639, 29.0169, 29.0084, 30.5758], device='cuda:1')


#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
: (4, 201, 1000)


#+begin_src ipython
  idx = get_idx(model, 1)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/7607d05754611fbc60dd4361c0612275413633ec.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/3eb1029f63517bf3a7649a8a9e9a91cfa2509ba9.png]]

#+begin_src ipython
  from matplotlib.patches import Circle
  m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

  x = m1 / m0 * np.cos(phi)
  y = m1 / m0 * np.sin(phi)

  xA = x
  yA = y

  fig, ax = plt.subplots(1, 1, figsize=[height, height])

  # ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
  # ax.plot(xA.T, yA.T, '-', alpha=.5)
  ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=20)
  # ax.set_xlim([-.9, .9])
  # ax.set_ylim([-.9, .9])
  circle = Circle((0., 0.), 1.7, fill=False, edgecolor='k')
  ax.add_patch(circle)

  # Set the aspect of the plot to equal to make the circle circular
  ax.set_aspect('equal')
  plt.savefig('fp_dual_train.svg', dpi=300)
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/038dee1da4ef1f4e023e2d111cc67f50ae6fb341.png]]

    #+begin_src ipython

  #+end_src
