#+STARTUP: fold
#+TITLE: Training Low Rank RNNs
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session dual :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroTorch"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Helpers
** Training
*** split data

#+begin_src ipython
  def split_data(X, Y, train_perc=0.8, batch_size=32):

    # Split the dataset into training and validation sets
    train_size = int(train_perc * X.shape[0])

    X_train = X[:train_size]
    X_test = X[train_size:]

    Y_train = Y[:train_size]    
    Y_test = Y[train_size:]

    # print('X_train', X_train.shape, 'y_train', Y_train.shape)
    train_dataset = TensorDataset(X_train, Y_train)

    # print('X_test', X_test.shape, 'y_test', Y_test.shape)
    val_dataset = TensorDataset(X_test, Y_test)

    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)
    
    return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
  def train(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1):
      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):          
          X, y = X.to(device), y.to(device)
          # Compute prediction error
          y_pred = model(X)
          loss = loss_fn(y_pred, y)

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()
          optimizer.step()
          optimizer.zero_grad()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def test(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0
      with torch.no_grad():
          for data, targets in dataloader:
              data, targets = data.to(device), targets.to(device)
              
              outputs = model(data)
              loss = loss_fn(outputs, targets)
              val_loss += loss.item() * data.size(0)
          val_loss /= size

      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def run_optim(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1):
      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
      model.to(device)

      loss_list = []
      val_loss_list = []

      # Training loop.
      for epoch in range(num_epochs):
          loss = train(train_loader, model, loss_fn, optimizer, penalty, lbd)
          val_loss = test(val_loader, model, loss_fn)
          scheduler.step(val_loss)
          
          loss_list.append(loss.item())
          val_loss_list.append(val_loss)
          
          # if epoch % int(num_epochs  / 10) == 0:
          print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')
          
          if loss < .01:
              print(f'Stopping training as loss has fallen below the threshold: {loss}')
              break
          if torch.isnan(loss):
              print(f'Stopping training as loss is NaN.')
              break

      return loss_list, val_loss_list
#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
  def correlation_loss(output, target):
      # Subtract the mean of each vector
      output_mean = output - torch.mean(output)
      target_mean = target - torch.mean(target)
    
      # Compute the covariance between output and target
      covariance = torch.mean(output_mean * target_mean)
      
      # Compute the standard deviations of the vectors
      output_std = torch.std(output)
      target_std = torch.std(target)
    
      # Calculate the Pearson correlation coefficient
      correlation = covariance / (output_std * target_std)
    
      # Since we want to increase the correlation, we minimize its negative
      loss = -correlation  # Maximizing correlation by minimizing its negative
    
      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
    import torch
    import torch.nn as nn

    def sign_constrained_loss(output, xi, target_sign):
        dot_product = torch.dot(output.flatten(), xi.flatten())
        if target_sign > 0:
            loss = torch.relu(-dot_product)  # Encourages positive dot product
        else:
            loss = torch.relu(dot_product)   # Encourages negative dot product
        return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  class CosineLoss(nn.Module):
      def __init__(self):
          super(CosineLoss, self).__init__()
          self.cosine_similarity = nn.CosineSimilarity(dim=-1)
          
      def forward(self, input1, input2):
          # Calculate cosine similarity
          cosine_sim = self.cosine_similarity(input1, input2)
          # Calculate the loss as 1 - cosine_similarity
          loss = 1 - cosine_sim
          # Return the mean loss over the batch
          return loss.mean()
#+end_src

#+RESULTS:


#+RESULTS:

** Other

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      u, v = a, b

      if GM:          
          v = b - np.dot(b, a) / np.dot(a, a) * a
          
      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)

      return np.arctan2(v, u)
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_idx(model, rank=2):
      print(model.U.shape)
      ksi = torch.hstack((model.U, model.V)).T
      print('ksi', ksi.shape)

      ksi = ksi.cpu().detach().numpy()
      # ksi = model.PHI0.cpu().detach().numpy()

      print(ksi.shape)

      theta = get_theta(ksi[0], ksi[rank], GM=0, IF_NORM=0)
      theta = get_theta(ksi[0][:model.Na[0]], ksi[rank][:model.Na[0]], GM=0, IF_NORM=0)

      return theta.argsort()
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_overlap(model, rates):
      ksi = model.PHI0.cpu().detach().numpy()
      return rates @ ksi.T / rates.shape[-1]
  
#+end_src

#+RESULTS:

#+begin_src ipython
  import scipy.stats as stats

  def plot_smooth(data, ax, color):
      mean = data.mean(axis=0)  
      ci = smooth.std(axis=0, ddof=1) * 1.96
      
      # Plot
      ax.plot(mean, color=color)
      ax.fill_between(range(data.shape[1]), mean - ci, mean + ci, alpha=0.25, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter  
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl
#+end_src

#+RESULTS:

* Train RNN
** Parameters

#+begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroTorch"
  conf_name = "config_train.yml"
#+end_src

#+RESULTS:

** Model

#+begin_src ipython
  start = perf_counter()
  model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE='cuda', SEED=0)
#+end_src

#+RESULTS:

#+begin_src ipython
for name, param in model.named_parameters():
    if param.requires_grad:
        print(name, param.shape)
#+end_src

#+RESULTS:
: U torch.Size([1000, 2])
: V torch.Size([1000, 2])
: lr_kappa torch.Size([1])
: linear.weight torch.Size([1, 800])

** Inputs and labels
*** Samples

#+begin_src ipython
  model.LR_EVAL_WIN = 2
  model.lr_eval_win = int(model.LR_EVAL_WIN / model.DT / model.N_WINDOW)

  model.DURATION = 3
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 64

  model.I0[0] = 1
  model.I0[1] = 0 

  A = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0 

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([128, 82, 1000])

#+begin_src ipython
  labels_A = torch.zeros((model.N_BATCH, model.lr_eval_win))
  labels_B = torch.ones((model.N_BATCH, model.lr_eval_win))

  labels = torch.cat((labels_A, labels_B))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([128, 20])

#+begin_src ipython
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  batch_size = 32
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)

  learning_rate = 0.05

  # CosineLoss, BCELoss, BCEWithLogitLoss
  criterion = nn.BCEWithLogitsLoss()

  # SGD, Adam, AdamW
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)

  num_epochs = 100
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
#+End_src

#+RESULTS:
#+begin_example
  Epoch 1/100, Training Loss: 97.5130, Validation Loss: 75.0575
  Epoch 2/100, Training Loss: 44.0095, Validation Loss: 0.0000
  Epoch 3/100, Training Loss: 6.4587, Validation Loss: 33.5080
  Epoch 4/100, Training Loss: 21.7898, Validation Loss: 37.9368
  Epoch 5/100, Training Loss: 1.0982, Validation Loss: 0.2403
  Epoch 6/100, Training Loss: 0.0540, Validation Loss: 0.2973
  Epoch 7/100, Training Loss: 3.4054, Validation Loss: 8.1161
  Epoch 8/100, Training Loss: 1.4501, Validation Loss: 0.3311
  Epoch 9/100, Training Loss: 1.4816, Validation Loss: 4.7944
  Epoch 10/100, Training Loss: 2.7011, Validation Loss: 3.6679
  Epoch 11/100, Training Loss: 0.7142, Validation Loss: 0.6252
  Epoch 12/100, Training Loss: 0.9878, Validation Loss: 4.3385
  Epoch 13/100, Training Loss: 1.0522, Validation Loss: 1.3159
  Epoch 14/100, Training Loss: 1.1502, Validation Loss: 1.4592
  Epoch 15/100, Training Loss: 0.7816, Validation Loss: 1.9939
  Epoch 16/100, Training Loss: 0.8735, Validation Loss: 2.4005
  Epoch 17/100, Training Loss: 1.1141, Validation Loss: 2.3019
  Epoch 18/100, Training Loss: 0.9200, Validation Loss: 1.7877
  Epoch 19/100, Training Loss: 0.9660, Validation Loss: 1.4648
  Epoch 20/100, Training Loss: 1.0854, Validation Loss: 1.5743
  Epoch 21/100, Training Loss: 0.5191, Validation Loss: 1.9460
  Epoch 22/100, Training Loss: 1.3783, Validation Loss: 2.1762
  Epoch 23/100, Training Loss: 0.7553, Validation Loss: 1.8467
  Epoch 24/100, Training Loss: 0.9585, Validation Loss: 1.6009
  Epoch 25/100, Training Loss: 0.6043, Validation Loss: 1.5995
  Epoch 26/100, Training Loss: 0.5311, Validation Loss: 1.6252
  Epoch 27/100, Training Loss: 0.4494, Validation Loss: 1.6624
  Epoch 28/100, Training Loss: 0.5646, Validation Loss: 1.6954
  Epoch 29/100, Training Loss: 0.8846, Validation Loss: 1.7390
  Epoch 30/100, Training Loss: 0.4979, Validation Loss: 1.7603
  Epoch 31/100, Training Loss: 0.7085, Validation Loss: 1.7851
  Epoch 32/100, Training Loss: 0.7001, Validation Loss: 1.8053
  Epoch 33/100, Training Loss: 0.5461, Validation Loss: 1.8317
  Epoch 34/100, Training Loss: 0.4781, Validation Loss: 1.8320
  Epoch 35/100, Training Loss: 0.9714, Validation Loss: 1.8508
  Epoch 36/100, Training Loss: 0.4869, Validation Loss: 1.8540
  Epoch 37/100, Training Loss: 0.7527, Validation Loss: 1.8574
  Epoch 38/100, Training Loss: 0.9428, Validation Loss: 1.8602
  Epoch 39/100, Training Loss: 0.4260, Validation Loss: 1.8536
  Epoch 40/100, Training Loss: 0.8147, Validation Loss: 1.8519
  Epoch 41/100, Training Loss: 0.4914, Validation Loss: 1.8522
  Epoch 42/100, Training Loss: 1.1317, Validation Loss: 1.8470
  Epoch 43/100, Training Loss: 0.7489, Validation Loss: 1.8423
  Epoch 44/100, Training Loss: 0.7111, Validation Loss: 1.8453
  Epoch 45/100, Training Loss: 0.9307, Validation Loss: 1.8373
  Epoch 46/100, Training Loss: 0.6744, Validation Loss: 1.8351
  Epoch 47/100, Training Loss: 0.5338, Validation Loss: 1.8317
  Epoch 48/100, Training Loss: 1.0553, Validation Loss: 1.8354
  Epoch 49/100, Training Loss: 0.9236, Validation Loss: 1.8282
  Epoch 50/100, Training Loss: 0.7273, Validation Loss: 1.8362
  Epoch 51/100, Training Loss: 0.5885, Validation Loss: 1.8350
  Epoch 52/100, Training Loss: 0.5214, Validation Loss: 1.8327
  Epoch 53/100, Training Loss: 0.8664, Validation Loss: 1.8373
  Epoch 54/100, Training Loss: 0.5352, Validation Loss: 1.8311
  Epoch 55/100, Training Loss: 0.4273, Validation Loss: 1.8375
  Epoch 56/100, Training Loss: 0.8500, Validation Loss: 1.8341
  Epoch 57/100, Training Loss: 0.9241, Validation Loss: 1.8325
  Epoch 58/100, Training Loss: 0.9465, Validation Loss: 1.8335
  Epoch 59/100, Training Loss: 0.4676, Validation Loss: 1.8341
  Epoch 60/100, Training Loss: 0.8975, Validation Loss: 1.8313
  Epoch 61/100, Training Loss: 1.0579, Validation Loss: 1.8349
  Epoch 62/100, Training Loss: 0.5886, Validation Loss: 1.8352
  Epoch 63/100, Training Loss: 0.6373, Validation Loss: 1.8331
  Epoch 64/100, Training Loss: 0.8911, Validation Loss: 1.8341
  Epoch 65/100, Training Loss: 0.3355, Validation Loss: 1.8270
  Epoch 66/100, Training Loss: 0.7612, Validation Loss: 1.8289
  Epoch 67/100, Training Loss: 0.8732, Validation Loss: 1.8318
  Epoch 68/100, Training Loss: 0.7285, Validation Loss: 1.8327
  Epoch 69/100, Training Loss: 0.2412, Validation Loss: 1.8279
  Epoch 70/100, Training Loss: 0.5981, Validation Loss: 1.8261
  Epoch 71/100, Training Loss: 0.6850, Validation Loss: 1.8284
  Epoch 72/100, Training Loss: 0.9526, Validation Loss: 1.8338
  Epoch 73/100, Training Loss: 0.6095, Validation Loss: 1.8309
  Epoch 74/100, Training Loss: 0.7735, Validation Loss: 1.8293
  Epoch 75/100, Training Loss: 0.8635, Validation Loss: 1.8324
  Epoch 76/100, Training Loss: 0.7069, Validation Loss: 1.8327
  Epoch 77/100, Training Loss: 0.6885, Validation Loss: 1.8353
  Epoch 78/100, Training Loss: 0.4976, Validation Loss: 1.8326
  Epoch 79/100, Training Loss: 0.8235, Validation Loss: 1.8365
  Epoch 80/100, Training Loss: 0.5573, Validation Loss: 1.8329
  Epoch 81/100, Training Loss: 0.8530, Validation Loss: 1.8323
  Epoch 82/100, Training Loss: 0.5394, Validation Loss: 1.8283
  Epoch 83/100, Training Loss: 0.7916, Validation Loss: 1.8331
  Epoch 84/100, Training Loss: 0.6611, Validation Loss: 1.8346
  Epoch 85/100, Training Loss: 0.5101, Validation Loss: 1.8344
  Epoch 86/100, Training Loss: 0.8461, Validation Loss: 1.8289
  Epoch 87/100, Training Loss: 1.1005, Validation Loss: 1.8358
  Epoch 88/100, Training Loss: 1.0481, Validation Loss: 1.8260
  Epoch 89/100, Training Loss: 0.5243, Validation Loss: 1.8305
  Epoch 90/100, Training Loss: 0.5545, Validation Loss: 1.8390
  Epoch 91/100, Training Loss: 0.5398, Validation Loss: 1.8302
  Epoch 92/100, Training Loss: 0.4864, Validation Loss: 1.8330
  Epoch 93/100, Training Loss: 0.8770, Validation Loss: 1.8349
  Epoch 94/100, Training Loss: 0.5777, Validation Loss: 1.8288
  Epoch 95/100, Training Loss: 0.5048, Validation Loss: 1.8359
  Epoch 96/100, Training Loss: 0.9871, Validation Loss: 1.8343
  Epoch 97/100, Training Loss: 0.7557, Validation Loss: 1.8323
  Epoch 98/100, Training Loss: 0.6046, Validation Loss: 1.8320
  Epoch 99/100, Training Loss: 0.5672, Validation Loss: 1.8344
  Epoch 100/100, Training Loss: 0.5056, Validation Loss: 1.8329
#+end_example

#+begin_src ipython
  plt.plot(loss)
  plt.plot(val_loss)
  plt.xlabel('epochs')
  plt.ylabel('Loss')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/c1cede62fade1f75965fbc5d22631d333f8c85ca.png]]

*** Pairs

#+begin_src ipython
  model.LR_EVAL_WIN = 1
  model.lr_eval_win = int(model.LR_EVAL_WIN / model.DT / model.N_WINDOW)

  model.DURATION = 4
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 32

  model.I0[0] = 1
  model.I0[1] = 1 

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = -1

  AD_pair = model.init_ff_input()

  # ff_input = torch.cat((AC_pair, AD_pair))

  model.I0[0] = -1
  model.I0[1] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = -1
  
  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([128, 102, 1000])

#+begin_src ipython
  labels_pair = torch.zeros((2 * model.N_BATCH, model.lr_eval_win))
  labels_unpair = torch.ones((2 * model.N_BATCH, model.lr_eval_win))
  
  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([128, 10])

#+RESULTS:

#+begin_src ipython
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  batch_size = 32
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)

  learning_rate = 0.05

  # CosineLoss, BCELoss, BCEWithLogitLoss
  criterion = nn.BCEWithLogitsLoss()

  # SGD, Adam, AdamW
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
  
  num_epochs = 100
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
#+End_src

#+RESULTS:
#+begin_example
  Epoch 1/100, Training Loss: 2.5802, Validation Loss: 80.1503
  Epoch 2/100, Training Loss: 7.8107, Validation Loss: 69.1333
  Epoch 3/100, Training Loss: 9.7015, Validation Loss: 43.6789
  Epoch 4/100, Training Loss: 10.2445, Validation Loss: 53.0140
  Epoch 5/100, Training Loss: 4.9829, Validation Loss: 15.2225
  Epoch 6/100, Training Loss: 5.6433, Validation Loss: 5.8736
  Epoch 7/100, Training Loss: 2.9586, Validation Loss: 8.5594
  Epoch 8/100, Training Loss: 2.5856, Validation Loss: 0.3613
  Epoch 9/100, Training Loss: 1.0415, Validation Loss: 18.4963
  Epoch 10/100, Training Loss: 0.7971, Validation Loss: 21.3101
  Epoch 11/100, Training Loss: 0.2413, Validation Loss: 20.1261
  Epoch 12/100, Training Loss: 0.2516, Validation Loss: 17.1674
  Epoch 13/100, Training Loss: 0.7220, Validation Loss: 4.8998
  Epoch 14/100, Training Loss: 0.7800, Validation Loss: 6.9729
  Epoch 15/100, Training Loss: 0.4338, Validation Loss: 3.5687
  Epoch 16/100, Training Loss: 0.6099, Validation Loss: 5.1015
  Epoch 17/100, Training Loss: 0.5226, Validation Loss: 7.2863
  Epoch 18/100, Training Loss: 0.9419, Validation Loss: 9.0418
  Epoch 19/100, Training Loss: 0.7249, Validation Loss: 2.9465
  Epoch 20/100, Training Loss: 0.9206, Validation Loss: 3.3137
  Epoch 21/100, Training Loss: 0.2463, Validation Loss: 5.0058
  Epoch 22/100, Training Loss: 0.9027, Validation Loss: 6.2081
  Epoch 23/100, Training Loss: 0.3802, Validation Loss: 6.0394
  Epoch 24/100, Training Loss: 0.5073, Validation Loss: 5.4703
  Epoch 25/100, Training Loss: 0.3640, Validation Loss: 5.2421
  Epoch 26/100, Training Loss: 0.2189, Validation Loss: 5.4003
  Epoch 27/100, Training Loss: 0.3569, Validation Loss: 5.5447
  Epoch 28/100, Training Loss: 0.2038, Validation Loss: 5.6830
  Epoch 29/100, Training Loss: 0.4947, Validation Loss: 5.4335
  Epoch 30/100, Training Loss: 0.2473, Validation Loss: 4.9561
  Epoch 31/100, Training Loss: 0.2920, Validation Loss: 4.9787
  Epoch 32/100, Training Loss: 0.3916, Validation Loss: 4.9999
  Epoch 33/100, Training Loss: 0.3838, Validation Loss: 5.0259
  Epoch 34/100, Training Loss: 0.5256, Validation Loss: 5.0830
  Epoch 35/100, Training Loss: 0.3948, Validation Loss: 5.1200
  Epoch 36/100, Training Loss: 0.1996, Validation Loss: 5.1331
  Epoch 37/100, Training Loss: 0.1909, Validation Loss: 5.1583
  Epoch 38/100, Training Loss: 0.3810, Validation Loss: 5.1760
  Epoch 39/100, Training Loss: 0.2505, Validation Loss: 5.1540
  Epoch 40/100, Training Loss: 0.5505, Validation Loss: 5.1259
  Epoch 41/100, Training Loss: 0.6509, Validation Loss: 5.0916
  Epoch 42/100, Training Loss: 0.4387, Validation Loss: 5.0885
  Epoch 43/100, Training Loss: 0.5421, Validation Loss: 5.0892
  Epoch 44/100, Training Loss: 0.1832, Validation Loss: 5.0830
  Epoch 45/100, Training Loss: 0.6178, Validation Loss: 5.0846
  Epoch 46/100, Training Loss: 0.2570, Validation Loss: 5.0802
  Epoch 47/100, Training Loss: 0.3158, Validation Loss: 5.0749
  Epoch 48/100, Training Loss: 0.2662, Validation Loss: 5.0709
  Epoch 49/100, Training Loss: 0.3737, Validation Loss: 5.0703
  Epoch 50/100, Training Loss: 0.3539, Validation Loss: 5.0812
  Epoch 51/100, Training Loss: 0.4402, Validation Loss: 5.0841
  Epoch 52/100, Training Loss: 0.5032, Validation Loss: 5.0904
  Epoch 53/100, Training Loss: 0.2284, Validation Loss: 5.0837
  Epoch 54/100, Training Loss: 0.2862, Validation Loss: 5.0869
  Epoch 55/100, Training Loss: 0.3713, Validation Loss: 5.0870
  Epoch 56/100, Training Loss: 0.2048, Validation Loss: 5.0865
  Epoch 57/100, Training Loss: 0.2163, Validation Loss: 5.0872
  Epoch 58/100, Training Loss: 0.2531, Validation Loss: 5.0906
  Epoch 59/100, Training Loss: 0.3063, Validation Loss: 5.0888
  Epoch 60/100, Training Loss: 0.2845, Validation Loss: 5.0887
  Epoch 61/100, Training Loss: 0.3161, Validation Loss: 5.0884
  Epoch 62/100, Training Loss: 0.4563, Validation Loss: 5.0901
  Epoch 63/100, Training Loss: 0.4170, Validation Loss: 5.0906
  Epoch 64/100, Training Loss: 0.2673, Validation Loss: 5.0919
  Epoch 65/100, Training Loss: 0.3730, Validation Loss: 5.0932
  Epoch 66/100, Training Loss: 0.3264, Validation Loss: 5.0931
  Epoch 67/100, Training Loss: 0.2079, Validation Loss: 5.0886
  Epoch 68/100, Training Loss: 0.5881, Validation Loss: 5.0931
  Epoch 69/100, Training Loss: 0.5774, Validation Loss: 5.0938
  Epoch 70/100, Training Loss: 0.5023, Validation Loss: 5.0912
  Epoch 71/100, Training Loss: 0.2867, Validation Loss: 5.0889
  Epoch 72/100, Training Loss: 0.3650, Validation Loss: 5.0922
  Epoch 73/100, Training Loss: 0.3014, Validation Loss: 5.0947
  Epoch 74/100, Training Loss: 0.4035, Validation Loss: 5.0953
  Epoch 75/100, Training Loss: 0.1987, Validation Loss: 5.0932
  Epoch 76/100, Training Loss: 0.2490, Validation Loss: 5.0920
  Epoch 77/100, Training Loss: 0.0913, Validation Loss: 5.0969
  Epoch 78/100, Training Loss: 0.2121, Validation Loss: 5.0906
  Epoch 79/100, Training Loss: 0.3351, Validation Loss: 5.0932
  Epoch 80/100, Training Loss: 0.2238, Validation Loss: 5.0896
  Epoch 81/100, Training Loss: 0.3651, Validation Loss: 5.0895
  Epoch 82/100, Training Loss: 0.3113, Validation Loss: 5.0933
  Epoch 83/100, Training Loss: 0.5586, Validation Loss: 5.0928
  Epoch 84/100, Training Loss: 0.1734, Validation Loss: 5.0959
  Epoch 85/100, Training Loss: 0.1751, Validation Loss: 5.0894
  Epoch 86/100, Training Loss: 0.2355, Validation Loss: 5.0933
  Epoch 87/100, Training Loss: 0.1991, Validation Loss: 5.0956
  Epoch 88/100, Training Loss: 0.2711, Validation Loss: 5.0892
  Epoch 89/100, Training Loss: 0.3770, Validation Loss: 5.0899
  Epoch 90/100, Training Loss: 0.5681, Validation Loss: 5.0879
  Epoch 91/100, Training Loss: 0.5121, Validation Loss: 5.0930
  Epoch 92/100, Training Loss: 0.4834, Validation Loss: 5.0903
  Epoch 93/100, Training Loss: 0.2199, Validation Loss: 5.0942
  Epoch 94/100, Training Loss: 0.4171, Validation Loss: 5.0860
  Epoch 95/100, Training Loss: 0.3148, Validation Loss: 5.0929
  Epoch 96/100, Training Loss: 0.2730, Validation Loss: 5.0918
  Epoch 97/100, Training Loss: 0.2172, Validation Loss: 5.0887
  Epoch 98/100, Training Loss: 0.2137, Validation Loss: 5.0931
  Epoch 99/100, Training Loss: 0.3493, Validation Loss: 5.0915
  Epoch 100/100, Training Loss: 0.3234, Validation Loss: 5.0888
#+end_example

#+begin_src ipython
  plt.plot(loss)
  plt.plot(val_loss)
  plt.xlabel('epochs')
  plt.ylabel('Loss')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/b77df341ba40c82ed23b8d7f69855862016ba983.png]]

#+begin_src ipython
  Wij = model.Wab_T.clone()
#+end_src

#+RESULTS:

#+begin_src ipython
  model.eval()

  # lr = (1.0 + model.lr_mask * (model.U @ model.V.T))
  # model.Wab_T = model.Wab_T * lr.T
  # lr = model.lr_mask * (model.U @ model.V.T) / (1.0 * model.Na[0])
  lr = model.lr_kappa * model.lr_mask * (model.U @ model.V.T) / (1.0 * model.Na[0])
  model.Wab_T = Wij + lr.T

  model.N_BATCH = 1
  model.VERBOSE=1
  model.LR_TRAIN=0
#+end_src

#+RESULTS:

* Results

#+begin_src ipython
  model.N_BATCH = 1
  model.DURATION = 5
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = 1
  model.I0[1] = 1

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = -1

  AD_pair = model.init_ff_input()

  # ff_input = torch.cat((AC_pair, AD_pair))

  model.I0[0] = -1
  model.I0[1] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = -1

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 122, 1000])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input, RET_FF=1).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
#+begin_example
  times (s) 0.0 rates (Hz) [0.69, 2.32]
  times (s) 0.08 rates (Hz) [0.61, 2.03]
  times (s) 0.16 rates (Hz) [0.6, 2.27]
  times (s) 0.25 rates (Hz) [0.54, 2.15]
  times (s) 0.33 rates (Hz) [0.6, 2.16]
  times (s) 0.41 rates (Hz) [0.57, 2.0]
  times (s) 0.49 rates (Hz) [0.57, 2.06]
  times (s) 0.57 rates (Hz) [0.62, 2.04]
  times (s) 0.66 rates (Hz) [0.61, 1.93]
  times (s) 0.74 rates (Hz) [0.64, 1.99]
  times (s) 0.82 rates (Hz) [0.71, 1.96]
  times (s) 0.9 rates (Hz) [0.75, 2.0]
  times (s) 0.98 rates (Hz) [0.72, 1.96]
  times (s) 1.07 rates (Hz) [0.74, 1.99]
  times (s) 1.15 rates (Hz) [0.75, 2.13]
  times (s) 1.23 rates (Hz) [0.74, 2.09]
  times (s) 1.31 rates (Hz) [0.7, 1.98]
  times (s) 1.39 rates (Hz) [0.73, 2.01]
  times (s) 1.48 rates (Hz) [0.73, 1.86]
  times (s) 1.56 rates (Hz) [0.73, 2.03]
  times (s) 1.64 rates (Hz) [0.57, 1.94]
  times (s) 1.72 rates (Hz) [0.52, 1.95]
  times (s) 1.8 rates (Hz) [0.52, 1.98]
  times (s) 1.89 rates (Hz) [0.51, 1.95]
  times (s) 1.97 rates (Hz) [0.56, 1.95]
  times (s) 2.05 rates (Hz) [0.58, 1.9]
  times (s) 2.13 rates (Hz) [0.57, 1.91]
  times (s) 2.21 rates (Hz) [0.6, 1.79]
  times (s) 2.3 rates (Hz) [0.64, 1.91]
  times (s) 2.38 rates (Hz) [0.59, 1.84]
  times (s) 2.46 rates (Hz) [0.73, 1.86]
  times (s) 2.54 rates (Hz) [0.68, 2.0]
  times (s) 2.62 rates (Hz) [0.73, 1.94]
  times (s) 2.7 rates (Hz) [0.74, 1.99]
  times (s) 2.79 rates (Hz) [0.71, 1.91]
  times (s) 2.87 rates (Hz) [0.69, 1.91]
  times (s) 2.95 rates (Hz) [0.66, 1.95]
  times (s) 3.03 rates (Hz) [0.65, 1.94]
  times (s) 3.11 rates (Hz) [0.65, 1.85]
  times (s) 3.2 rates (Hz) [0.7, 1.86]
  times (s) 3.28 rates (Hz) [0.56, 1.92]
  times (s) 3.36 rates (Hz) [0.59, 1.84]
  times (s) 3.44 rates (Hz) [0.59, 2.0]
  times (s) 3.52 rates (Hz) [0.55, 2.04]
  times (s) 3.61 rates (Hz) [0.56, 1.95]
  times (s) 3.69 rates (Hz) [0.59, 1.94]
  times (s) 3.77 rates (Hz) [0.64, 1.83]
  times (s) 3.85 rates (Hz) [0.6, 2.02]
  times (s) 3.93 rates (Hz) [0.58, 1.91]
  times (s) 4.02 rates (Hz) [0.59, 2.0]
  times (s) 4.1 rates (Hz) [0.62, 1.91]
  (4, 51, 800)
#+end_example

#+begin_src ipython
  plt.plot(model.ff_input.cpu().detach().numpy()[0,:, :10])
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/5cddac4c5e75a1c619ecfe1d568343964c338aa4.png]]

#+begin_src ipython
  r_max = 1.25 * np.max(rates)
  plt.imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
  plt.vlines((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  plt.vlines((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  plt.ylabel('Neuron #')
  plt.xlabel('Step')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/92da07736ff93f82f0cd6db28ee155ac6452fda4.png]]

#+begin_src ipython
  idx = get_idx(model, 2)
  ordered = rates[..., idx]
  print(ordered.shape)
#+end_src

#+RESULTS:
: torch.Size([1000, 2])
: ksi torch.Size([4, 1000])
: (4, 1000)
: (4, 51, 800)

#+begin_src ipython
  plt.imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
  plt.yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))
  plt.vlines((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  plt.vlines((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  plt.ylabel('Pref. Location (°)')
  plt.xlabel('Step')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/0025cf3f9f484fd143768214a6bc28d7d7b3f5a8.png]]

#+begin_src ipython
  readout = model.linear.weight.data.cpu().detach().numpy()[0]
  overlap = (rates @ readout) / rates.shape[-1]
  print(overlap.shape)

  plt.plot(overlap.T[..., :2], label='pair')
  plt.plot(overlap.T[..., 2:], '--', label='unpair')
  plt.legend(fontsize=10)
  plt.xlabel('Step')
  plt.ylabel('Overlap')

  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (4, 51)
[[file:./.ob-jupyter/e0e08ec6964f2e027972306094b674e82f6c81af.png]]
:END:

#+begin_src ipython
  m0, m1, phi = decode_bump(ordered, axis=-1)
#+end_src

#+RESULTS:

#+begin_src ipython
  fig, ax = plt.subplots(1, 3, figsize=[2*width, height])
  
  ax[0].plot(m0.T)
  #ax[0].set_ylim([0, 360])
  #ax[0].set_yticks([0, 90, 180, 270, 360])
  ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
  ax[0].set_xlabel('Step')

  ax[1].plot(m1.T)
  # ax[1].set_ylim([0, 360])
  # ax[1].set_yticks([0, 90, 180, 270, 360])
  ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
  ax[1].set_xlabel('Step')

  ax[2].plot(phi.T * 180 / np.pi)
  ax[2].set_ylim([0, 360])
  ax[2].set_yticks([0, 90, 180, 270, 360])
  ax[2].set_ylabel('Phase (°)')
  ax[2].set_xlabel('Step')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/f50152fdc6901fd152ab2c5b0426971374febbe3.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
