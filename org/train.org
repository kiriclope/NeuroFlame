#+STARTUP: fold
#+TITLE: Training Low Rank RNNs
#+PROPERTY: header-args:ipython :var B0="0.0" :results both :exports both :async yes :session dual :kernel torch :tangle ./train.py

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
    %reload_ext autoreload
  Python exe
  /home/leon/mambaforge/envs/torch/bin/python
  <Figure size 600x370.82 with 0 Axes>The autoreload extension is already loaded. To reload it, use:
    %reload_ext autoreload
  Python exe
  /home/leon/mambaforge/envs/torch/bin/python
  <Figure size 600x370.82 with 0 Axes>The autoreload extension is already loaded. To reload it, use:
    %reload_ext autoreload
  Python exe
  /home/leon/mambaforge/envs/torch/bin/python
#+end_example
: <Figure size 600x370.82 with 0 Axes>The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python
: <Figure size 600x370.82 with 0 Axes>The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python
: <Figure size 600x370.82 with 0 Axes>
:END:

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  import torchmetrics
  from torch.utils.data import Dataset, TensorDataset, DataLoader

  DEVICE = 'cuda:1'
#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

* Helpers
** Data Split

#+begin_src ipython
  from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

  def split_data(X, Y, train_perc=0.8, batch_size=32):

    if Y.ndim==3:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0, 0].cpu().numpy(),
                                                          shuffle=True)
    else:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0].cpu().numpy(),
                                                          shuffle=True)
    print(X_train.shape, X_test.shape)
    print(Y_train.shape, Y_test.shape)

    train_dataset = TensorDataset(X_train, Y_train)
    val_dataset = TensorDataset(X_test, Y_test)

    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
  def accuracy_score(y_pred, labels):
    probs = torch.sigmoid(y_pred)
    # Assuming 'outputs' are logits from your model (raw scores before sigmoid)
    predicted = (probs > 0.5).float()  # Convert to 0 or 1 based on comparison with 0
    # 'labels' should be your ground truth labels for the binary classification, also in 0 or 1
    correct = (predicted == labels).sum()
    accuracy = correct / labels.size(0) / labels.size(-1)

    return accuracy
#+end_src

#+RESULTS:

#+begin_src ipython
  def torch_angle_AB(U, V):
      # Calculate the dot product
      dot_product = torch.dot(U, V)

      # Calculate the magnitudes of U and V
      magnitude_U = torch.linalg.norm(U)
      magnitude_V = torch.linalg.norm(V)

      # Compute the cosine of the angle
      cos_theta = dot_product / (magnitude_U * magnitude_V)

      # Calculate the angle in radians, then convert to degrees
      angle_radians = torch.acos(cos_theta)
      return torch.round(torch.rad2deg(angle_radians))
#+end_src

#+RESULTS:

#+begin_src ipython
  def training_step(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1, clip_grad=0, zero_grad=0, read_idx=1):
      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          X, y = X.to(device), y.to(device)

          rates = model(X)

          if read_idx < 0:
              y_pred = model.low_rank.linear(model.low_rank.dropout(rates)).squeeze(-1)
          else:
              y_pred = rates @ model.low_rank.U[model.slices[0], read_idx]

          # if zero_grad == 0:
          # overlap = rates @ model.low_rank.U[model.slices[0]] / model.Na[0]
          # elif zero_grad == 1:
          overlap = rates @ model.low_rank.U[model.slices[0], 0] / model.Na[0]
          # elif zero_grad == 2:
          #     overlap = rates @ model.low_rank.U[model.slices[0], 1] / model.Na[0]

          loss = loss_fn(y_pred, y) + F.relu(overlap[..., :9].abs()-0.1).mean()

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()

          if zero_grad > 0:
              try:
                  model.low_rank.U.grad[:, zero_grad-1] = 0
                  model.low_rank.V.grad[:, zero_grad-1] = 0
              except:
                  pass

          # Clip gradients
          if clip_grad:
              torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
              #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)

          optimizer.step()
          optimizer.zero_grad()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def validation_step(dataloader, model, loss_fn, zero_grad=0, read_idx=1):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")
      # metric = torchmetrics.classification.Accuracy(task="binary")

      # Validation loop.
      model.eval()
      val_loss = 0.0

      with torch.no_grad():
          for X, y in dataloader:
              X, y = X.to(device), y.to(device)

              rates = model(X)

              if read_idx < 0:
                  y_pred = model.low_rank.linear(model.low_rank.dropout(rates)).squeeze(-1)
              else:
                  y_pred = rates @ model.low_rank.U[model.slices[0], read_idx]

              # if zero_grad == 0:
              #     overlap = rates @ model.low_rank.U[model.slices[0]] / model.Na[0]
              # elif zero_grad == 1:
              overlap = rates @ model.low_rank.U[model.slices[0], 0] / model.Na[0]
              # elif zero_grad == 2:
              #     overlap = rates @ model.low_rank.U[model.slices[0], 1] / model.Na[0]

              loss = loss_fn(y_pred, y) + F.relu(overlap[..., :9].abs()-0.1).mean()

              # acc = metric(y_pred, y)

              val_loss += loss.item() * X.size(0)

          val_loss /= size
          # acc = metric.compute()
          # print(f"Accuracy: {acc}")
          # metric.reset()
      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def optimization(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=.005, zero_grad=0, read_idx=1):
      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')
      model.to(device)

      loss_list = []
      val_loss_list = []
      accuracies = []
      angle_list = []

      for epoch in range(num_epochs):
          loss = training_step(train_loader, model, loss_fn, optimizer, penalty, lbd, zero_grad=zero_grad, read_idx=read_idx)
          val_loss = validation_step(val_loader, model, loss_fn, zero_grad, read_idx=read_idx)

          scheduler.step(val_loss)

          loss_list.append(loss.item())
          val_loss_list.append(val_loss)

          memory = model.low_rank.U[model.slices[0], 0]

          if read_idx <0:
              readout = model.low_rank.linear.weight.data[0]
          else:
              readout = model.low_rank.U[model.slices[0], read_idx]

          angle = torch_angle_AB(memory, readout).item()
          angle_list.append(angle)

          # if epoch % int(num_epochs  / 10) == 0:
          print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}, Angle(U, W) : {angle} °')

          if val_loss < thresh and loss < thresh:
              print(f'Stopping training as loss has fallen below the threshold: {loss}, {val_loss}')
              break

          if val_loss > 300:
              print(f'Stopping training as loss is too high: {val_loss}')
              break

          if torch.isnan(loss):
              print(f'Stopping training as loss is NaN.')
              break

      return loss_list, val_loss_list
#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
  def performance_score(model, rates, labels):
      print(rates.shape)
      y_pred = model.low_rank.linear(rates[:, -2:]).squeeze(-1)
      accuracy = accuracy_score(y_pred, labels)
      return accuracy
#+end_src

#+RESULTS:

#+begin_src ipython
  def imbalance_func(target, imbalance):
    output = torch.zeros_like(target)

    # Update values
    output[target == 1] = 1
    output[target == 0] = imbalance

    return output
#+end_src

#+RESULTS:


#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.nn.functional as F

  class SignBCELoss(nn.Module):
      def __init__(self, alpha=1.0, thresh=4.0, N=1000, imbalance=0):
          super(SignBCELoss, self).__init__()
          self.alpha = alpha
          self.thresh = thresh
          self.N = N
          self.imbalance = imbalance
          self.bce_with_logits = nn.BCEWithLogitsLoss()

      def forward(self, readout, targets):
          if self.alpha != 1.0:
              bce_loss = self.bce_with_logits(readout, targets)
          else:
              bce_loss = 0.0

          mean_activation = readout.mean(dim=1).unsqueeze(-1)

          # if self.type == 'DPA':
          #     sign_overlap = torch.sign(2 * targets - 1) * mean_activation / (1.0 * self.N)
          #     sign_loss = F.relu(self.thresh - sign_overlap).mean()
          # else:
          #     sign_overlap = torch.sign(targets) * mean_activation / (1.0 * self.N)
          #     sign_loss = F.relu((sign_overlap>0) * self.thresh - sign_overlap).mean()

          # sign_loss = F.relu(self.thresh - sign_overlap).mean()

          # Let's penalize more the wrong licks
          sign_overlap = torch.sign(2 * targets - 1) * mean_activation / (1.0 * self.N)
          if self.imbalance !=1 :
              sign_loss = F.relu(imbalance_func(targets, self.imbalance) * self.thresh - sign_overlap).mean()
          else:
              sign_loss = F.relu(self.thresh - sign_overlap).mean()

          combined_loss = (1-self.alpha) * bce_loss + self.alpha * sign_loss
          return combined_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  class DualLoss(nn.Module):
      def __init__(self, alpha=1.0, thresh=4.0, N=1000, cue_idx=[], rwd_idx=-1, zero_idx=[], imbalance=0):
          super(DualLoss, self).__init__()
          self.alpha = alpha
          self.thresh = thresh
          self.N = N
          self.imbalance = imbalance

          self.zero_idx = zero_idx
          self.cue_idx = torch.tensor(cue_idx, dtype=torch.int, device=DEVICE)
          self.rwd_idx = torch.tensor(rwd_idx, dtype=torch.int, device=DEVICE)

          self.loss = SignBCELoss(self.alpha, self.thresh, self.N, self.imbalance)

      def forward(self, readout, targets):

          # ensuring zero bl overlap
          bl_loss = F.relu((readout[:, self.zero_idx] / self.N).abs() -1.0).mean()

          is_empty = self.cue_idx.numel() == 0
          if is_empty:
              self.DPA_loss = self.loss(readout[:, self.rwd_idx], targets)
              return (self.DPA_loss + bl_loss)
          else:
              self.loss.imbalance = self.imbalance[0]
              self.DPA_loss = self.loss(readout[:, self.rwd_idx], targets[:, 0, :self.rwd_idx.shape[0]])

              self.loss.imbalance = self.imbalance[1]
              self.DRT_loss = self.loss(readout[:, self.cue_idx], targets[:, 1, :self.cue_idx.shape[0]])

              return (0.5 * self.DPA_loss + 0.5 * self.DRT_loss) + bl_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  class AccuracyLoss(nn.Module):
      def __init__(self, N=1000, cue_idx=[], rwd_idx=-1):
          super(AccuracyLoss, self).__init__()
          self.N = N

          # self.loss = nn.BCEWithLogitsLoss()
          self.cue_idx = torch.tensor(cue_idx, dtype=torch.int, device=DEVICE)
          self.rwd_idx = torch.tensor(rwd_idx, dtype=torch.int, device=DEVICE)

      def forward(self, readout, targets):

          is_empty = self.cue_idx.numel() == 0
          if is_empty:
              self.DPA_loss = accuracy_score(readout[:, self.rwd_idx], targets)
              return self.DPA_loss
          else:
              self.DPA_loss = accuracy_score(readout[:, self.rwd_idx], targets[:, 0, :self.rwd_idx.shape[0]])
              self.DRT_loss = accuracy_score(readout[:, self.cue_idx], targets[:, 1, :self.cue_idx.shape[0]])
              return (self.DPA_loss + self.DRT_loss) / 2.0
#+end_src

#+RESULTS:

** Other

#+begin_src ipython
  def angle_AB(A, B):
      A_norm = A / (np.linalg.norm(A) + 1e-5)
      B_norm = B / (np.linalg.norm(B) + 1e-5)

      return int(np.arccos(A_norm @ B_norm) * 180 / np.pi)
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      u, v = a, b

      if GM:
          v = b - np.dot(b, a) / np.dot(a, a) * a

      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)

      return np.arctan2(v, u) % (2.0 * np.pi)
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_idx(model, rank=2):
      ksi = torch.hstack((model.low_rank.U, model.low_rank.V)).T
      ksi = ksi[:, :model.Na[0]]

      readout = model.low_rank.linear.weight.data
      ksi = torch.vstack((ksi, readout))

      print('ksi', ksi.shape)

      ksi = ksi.cpu().detach().numpy()
      theta = get_theta(ksi[0], ksi[rank])

      return theta.argsort()
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_overlap(model, rates):
      ksi = model.odors.cpu().detach().numpy()
      return rates @ ksi.T / rates.shape[-1]
#+end_src

#+RESULTS:

#+begin_src ipython
  import scipy.stats as stats

  def plot_smooth(data, ax, color):
      mean = data.mean(axis=0)
      ci = smooth.std(axis=0, ddof=1) * 1.96

      # Plot
      ax.plot(mean, color=color)
      ax.fill_between(range(data.shape[1]), mean - ci, mean + ci, alpha=0.25, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

** plots

#+begin_src ipython
  def plot_rates_selec(rates, idx, thresh=0.5, figname='fig.svg'):
        ordered = rates[..., idx]
        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
        r_max = thresh * np.max(rates[0])

        ax[0].imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[0].set_ylabel('Neuron #')
        ax[0].set_xlabel('Step')

        ax[1].imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[1].set_yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))
        ax[1].set_ylabel('Pref. Location (°)')
        ax[1].set_xlabel('Step')
        plt.savefig(figname, dpi=300)
        plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_overlap(rates, memory, readout, labels=['A', 'B'], figname='fig.svg'):
      fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
      overlap =(rates @ memory) / rates.shape[-1]

      if overlap.shape[0]>2:
          ax[0].plot(overlap.T[..., :2], label=labels[0])
          ax[0].plot(overlap.T[..., 2:], '--', label=labels[1])
      else:
          ax[0].plot(overlap.T[..., 0], label=labels[0])
          ax[0].plot(overlap.T[..., 1], '--', label=labels[1])

      ax[0].set_xlabel('Step')
      ax[0].set_ylabel('Overlap')
      ax[0].set_title('Memory')

      overlap =(rates @ readout) / rates.shape[-1]

      if overlap.shape[0]>2:
          ax[1].plot(overlap.T[..., :2], label=labels[0])
          ax[1].plot(overlap.T[..., 2:], '--', label=labels[1])
      else:
          ax[1].plot(overlap.T[..., 0], label=labels[0])
          ax[1].plot(overlap.T[..., 1], '--', label=labels[1])

      ax[1].set_xlabel('Step')
      ax[1].set_ylabel('Overlap')
      ax[1].set_title('Readout')

      # plt.legend(fontsize=10, frameon=False)
      plt.savefig(figname, dpi=300)
      plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_m0_m1_phi(rates, idx, figname='fig.svg'):

      m0, m1, phi = decode_bump(rates[..., idx], axis=-1)
      fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

      ax[0].plot(m0[:2].T)
      ax[0].plot(m0[2:].T, '--')
      #ax[0].set_ylim([0, 360])
      #ax[0].set_yticks([0, 90, 180, 270, 360])
      ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
      ax[0].set_xlabel('Step')

      ax[1].plot(m1[:2].T)
      ax[1].plot(m1[2:].T, '--')
      # ax[1].set_ylim([0, 360])
      # ax[1].set_yticks([0, 90, 180, 270, 360])
      ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
      ax[1].set_xlabel('Step')

      ax[2].plot(phi[:2].T * 180 / np.pi)
      ax[2].plot(phi[2:].T * 180 / np.pi, '--')
      ax[2].set_ylim([0, 360])
      ax[2].set_yticks([0, 90, 180, 270, 360])
      ax[2].set_ylabel('Phase (°)')
      ax[2].set_xlabel('Step')

      plt.savefig(figname, dpi=300)
      plt.show()
    #+end_src

#+RESULTS:

* Model

#+begin_src ipython
        REPO_ROOT = "/home/leon/models/NeuroFlame"
        conf_name = "config_train.yml"
        DEVICE = 'cuda:1'
        seed = np.random.randint(0, 1e6)
        # seed = 21881
        print(seed)
        # 789395
        # 453642
        # : 577806

        A0 = 1.0
        B0 = 1.0
        C0 = 0.0
#+end_src

#+RESULTS:
:RESULTS:
:
: 791079218010
:
: 848895
: 152494
:END:

#+begin_src ipython
  model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=16)
#+end_src

#+RESULTS:

* Sample Classification
** Training
*** Parameters

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
#+begin_example
  low_rank.V torch.Size([2000, 2])
  low_rank.lr_kappa torch.Size([1])
  low_rank.U torch.Size([2000, 2])
  low_rank.V torch.Size([2000, 2])
  low_rank.lr_kappa torch.Size([1])
  low_rank.U torch.Size([2000, 2])
  low_rank.V torch.Size([2000, 2])
  low_rank.lr_kappa torch.Size([1])
  low_rank.U torch.Size([2000, 2])
  low_rank.V torch.Size([2000, 2])
  low_rank.lr_kappa torch.Size([1])
  low_rank.U torch.Size([2000, 2])
  low_rank.V torch.Size([2000, 2])
  low_rank.lr_kappa torch.Size([1])
#+end_example

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1
  model.IF_RL = 0
#+end_src

#+RESULTS:

Testing the network on steps from sample odor offset to test odor onset

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

  mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  rwd_idx = np.where(mask)[0]
  print('rwd', rwd_idx)

  model.lr_eval_win = rwd_idx.shape[0]

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))

  zero_idx = np.where(~mask & ~stim_mask )[0]
  print('zero', zero_idx)
#+end_src

#+RESULTS:
#+begin_example
   44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
   68 69 70 71 72 73 74 75 76 77 78 79 80]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
   44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
   68 69 70 71 72 73 74 75 76 77 78 79 80]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
   44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
   68 69 70 71 72 73 74 75 76 77 78 79 80]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
   44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
   68 69 70 71 72 73 74 75 76 77 78 79 80]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
   44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
   68 69 70 71 72 73 74 75 76 77 78 79 80]
  zero [0 1 2 3 4 5 6 7 8 9]
#+end_example

*** Inputs and Labels

#+begin_src ipython
  model.N_BATCH = 80

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  A = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print(ff_input.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: torch.Size([160, 455, 2000])torch.Size([160, 455, 2000])
:
: torch.Size([160, 455, 2000])
: torch.Size([160, 455, 2000])
:END:

#+begin_src ipython
  labels_A = torch.ones((model.N_BATCH, rwd_idx.shape[0]))
  labels_B = torch.zeros((model.N_BATCH, rwd_idx.shape[0]))
  labels = torch.cat((labels_A, labels_B))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: labels torch.Size([160, 61])labels torch.Size([160, 61])
:
: labels torch.Size([160, 61])
: labels torch.Size([160, 61])
:END:

*** Run

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([128, 61]) torch.Size([32, 61])
: torch.Size([128, 455, 2000]) torch.Size([32, 455, 2000])
: torch.Size([128, 61]) torch.Size([32, 61])
: torch.Size([128, 455, 2000]) torch.Size([32, 455, 2000])
: torch.Size([128, 61]) torch.Size([32, 61])
: torch.Size([128, 455, 2000]) torch.Size([32, 455, 2000])
: torch.Size([128, 61]) torch.Size([32, 61])
: torch.Size([128, 455, 2000]) torch.Size([32, 455, 2000])
: torch.Size([128, 61]) torch.Size([32, 61])

#+begin_src ipython
  criterion = DualLoss(alpha=1.0, thresh=5.0, N=model.Na[0], rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=1)
  # SGD, Adam, Adam
  learning_rate = 0.05
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 15
  start = perf_counter()
  loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=2, read_idx=0)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example

  Epoch 2/15, Training Loss: 4.9907, Validation Loss: 4.9838, Angle(U, W) : 0.0 °Epoch 3/15, Training Loss: 4.9758, Validation Loss: 4.9750, Angle(U, W) : nan °

  Epoch 4/15, Training Loss: 4.9746, Validation Loss: 4.9623, Angle(U, W) : 0.0 °
  Epoch 5/15, Training Loss: 4.9798, Validation Loss: 4.9383, Angle(U, W) : nan °
  Epoch 6/15, Training Loss: 4.8893, Validation Loss: 4.8783, Angle(U, W) : 0.0 °
  Epoch 7/15, Training Loss: 4.6415, Validation Loss: 4.5904, Angle(U, W) : 0.0 °
  Epoch 8/15, Training Loss: 0.0008, Validation Loss: 0.0011, Angle(U, W) : nan °
  Stopping training as loss has fallen below the threshold: 0.0008066672016866505, 0.0010578491783235222
  Elapsed (with compilation) = 0h 0m 47s
  Epoch 1/15, Training Loss: 4.9863, Validation Loss: 4.9890, Angle(U, W) : 0.0 °
  Epoch 2/15, Training Loss: 4.9811, Validation Loss: 4.9817, Angle(U, W) : 0.0 °
  Epoch 3/15, Training Loss: 4.9757, Validation Loss: 4.9720, Angle(U, W) : 0.0 °
  Epoch 4/15, Training Loss: 4.9598, Validation Loss: 4.9580, Angle(U, W) : 0.0 °
  Epoch 5/15, Training Loss: 4.9330, Validation Loss: 4.9322, Angle(U, W) : 0.0 °
  Epoch 6/15, Training Loss: 4.8854, Validation Loss: 4.8637, Angle(U, W) : 0.0 °
  Epoch 7/15, Training Loss: 4.6239, Validation Loss: 4.5127, Angle(U, W) : 0.0 °
  Epoch 8/15, Training Loss: 0.0035, Validation Loss: 0.0047, Angle(U, W) : 0.0 °
  Stopping training as loss has fallen below the threshold: 0.0035130572505295277, 0.0047433641739189625
  Elapsed (with compilation) = 0h 0m 49s
  Epoch 1/15, Training Loss: 4.9930, Validation Loss: 4.9890, Angle(U, W) : nan °
  Epoch 2/15, Training Loss: 4.9811, Validation Loss: 4.9814, Angle(U, W) : nan °
  Epoch 3/15, Training Loss: 4.9770, Validation Loss: 4.9720, Angle(U, W) : 0.0 °
  Epoch 4/15, Training Loss: 4.9658, Validation Loss: 4.9590, Angle(U, W) : nan °
  Epoch 5/15, Training Loss: 4.9437, Validation Loss: 4.9354, Angle(U, W) : 0.0 °
  Epoch 6/15, Training Loss: 4.8880, Validation Loss: 4.8769, Angle(U, W) : 0.0 °
  Epoch 7/15, Training Loss: 4.6748, Validation Loss: 4.6022, Angle(U, W) : 0.0 °
  Epoch 8/15, Training Loss: 0.0205, Validation Loss: 0.0000, Angle(U, W) : 0.0 °
  Epoch 9/15, Training Loss: 0.0010, Validation Loss: 0.0089, Angle(U, W) : 0.0 °
  Epoch 10/15, Training Loss: 0.0428, Validation Loss: 0.0184, Angle(U, W) : nan °
  Epoch 11/15, Training Loss: 0.0222, Validation Loss: 0.0067, Angle(U, W) : 0.0 °
  Epoch 12/15, Training Loss: 0.0015, Validation Loss: 0.0040, Angle(U, W) : 0.0 °
  Stopping training as loss has fallen below the threshold: 0.0015154181746765971, 0.004027549177408218
  Elapsed (with compilation) = 0h 1m 9s
  Epoch 1/15, Training Loss: 4.9934, Validation Loss: 4.9872, Angle(U, W) : 0.0 °
  Epoch 2/15, Training Loss: 4.9760, Validation Loss: 4.9793, Angle(U, W) : nan °
  Epoch 3/15, Training Loss: 4.9873, Validation Loss: 4.9700, Angle(U, W) : nan °
  Epoch 4/15, Training Loss: 4.9803, Validation Loss: 4.9565, Angle(U, W) : 0.0 °
  Epoch 5/15, Training Loss: 4.9252, Validation Loss: 4.9346, Angle(U, W) : 0.0 °
  Epoch 6/15, Training Loss: 4.8897, Validation Loss: 4.8834, Angle(U, W) : 0.0 °
  Epoch 7/15, Training Loss: 4.7298, Validation Loss: 4.6787, Angle(U, W) : 0.0 °
  Epoch 8/15, Training Loss: 2.5163, Validation Loss: 1.4606, Angle(U, W) : 0.0 °
  Epoch 9/15, Training Loss: 0.0306, Validation Loss: 0.0012, Angle(U, W) : 0.0 °
  Epoch 10/15, Training Loss: 0.0640, Validation Loss: 0.0684, Angle(U, W) : 0.0 °
  Epoch 11/15, Training Loss: 0.0617, Validation Loss: 0.0188, Angle(U, W) : nan °
  Epoch 12/15, Training Loss: 0.0446, Validation Loss: 0.0130, Angle(U, W) : 0.0 °
  Epoch 13/15, Training Loss: 0.0090, Validation Loss: 0.0078, Angle(U, W) : nan °
  Epoch 14/15, Training Loss: 0.0018, Validation Loss: 0.0020, Angle(U, W) : 0.0 °
  Stopping training as loss has fallen below the threshold: 0.001777369761839509, 0.0019870841642841697
  Elapsed (with compilation) = 0h 1m 21s
  Epoch 1/15, Training Loss: 5.0024, Validation Loss: 4.9929, Angle(U, W) : nan °
  Epoch 2/15, Training Loss: 5.0039, Validation Loss: 4.9883, Angle(U, W) : nan °
  Epoch 3/15, Training Loss: 4.9741, Validation Loss: 4.9825, Angle(U, W) : nan °
  Epoch 4/15, Training Loss: 4.9872, Validation Loss: 4.9754, Angle(U, W) : nan °
  Epoch 5/15, Training Loss: 4.9668, Validation Loss: 4.9652, Angle(U, W) : nan °
  Epoch 6/15, Training Loss: 4.9802, Validation Loss: 4.9468, Angle(U, W) : nan °
  Epoch 7/15, Training Loss: 4.9034, Validation Loss: 4.9023, Angle(U, W) : 0.0 °
  Epoch 8/15, Training Loss: 4.7554, Validation Loss: 4.7173, Angle(U, W) : 0.0 °
  Epoch 9/15, Training Loss: 1.5732, Validation Loss: 0.3526, Angle(U, W) : 0.0 °
  Epoch 10/15, Training Loss: 0.0005, Validation Loss: 0.0000, Angle(U, W) : nan °
  Stopping training as loss has fallen below the threshold: 0.0005130159552209079, 1.7415732145309448e-06
  Elapsed (with compilation) = 0h 1m 1s
#+end_example
:END:

** Testing

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
:RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
:END:

#+begin_src ipython
  model.N_BATCH = 10

  model.I0[0] = 2
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = -2
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: ff_input torch.Size([20, 455, 2000])ff_input torch.Size([20, 455, 2000])
:
: ff_input torch.Size([20, 455, 2000])
: ff_input torch.Size([20, 455, 2000])
:END:

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print('rates', rates.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: rates (20, 81, 1000)rates (20, 81, 1000)
:
: rates (20, 81, 1000)
: rates (20, 81, 1000)
:END:

#+begin_src ipython
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
  # readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
  plot_overlap(rates, memory, readout, labels=['A', 'B'])
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/d7a06f104ce2b48d7377440412dd3cd51529597f.png]]
[[file:./.ob-jupyter/51e1d5e7f4667e093e92b04b212f21dcd5cb5758.png]]
[[file:./.ob-jupyter/6be21d9bcc25f1d3c98785fff658d1ceea0b860e.png]]
[[file:./.ob-jupyter/94a128eaf5c81f0a481c299b289b37f01e6c218e.png]]
[[file:./.ob-jupyter/1b82d50696ddc0d5692a9308794053ae36061958.png]]
:END:

#+begin_src ipython
  idx = get_idx(model, -1)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/246d14acf715deb4100701dffbcc1fbb7fb8371b.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/cdc4cdcf5415ac482d89c3cc92b74ddd3e906f95.png]]
:END:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/32e699eb82e92e77df383538115612108c76e60b.png]]
:END:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/80b78ff530aae868e6a367f388d3935b8ed6a252.png]]
:END:
:RESULTS:
:
[[file:./.ob-jupyter/91eb541d52f4a9a6947e05730b47d5c6bb9892a8.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/80f34ffedc45952be4bd2f4948e5074892f09b51.png]]
[[file:./.ob-jupyter/16ac5739a9737aa4925d8bd815777734f98a9c58.png]]
[[file:./.ob-jupyter/c4a4803fa0cf07c5543fdbe0b54263fd258080a8.png]]
[[file:./.ob-jupyter/9abb022b94594af19d727ebfe836d909053c8604.png]]
[[file:./.ob-jupyter/5a72e1e0edafe3cbb90e7c10ff567a520ec02b38.png]]
:END:

* DPA
** Training
*** Parameters

#+begin_src ipython
  model.low_rank.lr_kappa.requires_grad = False
  model.low_rank.U.data[:, 1] = torch.randn(model.low_rank.U.T.data[1].shape) * 0.01
  model.low_rank.V.data[:, 1] = torch.randn(model.low_rank.U.T.data[1].shape) * 0.01

  import torch.nn.init as init

  if model.LR_FIX_READ==0:
      init.xavier_uniform_(model.low_rank.linear.weight)
      if model.low_rank.linear.bias is not None:
          model.low_rank.linear.bias.data.zero_()  # Common practice is to set biases to zero
#+end_src

#+RESULTS:

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1
  model.IF_RL = 0
#+end_src

#+RESULTS:

Here we only evaluate performance from test onset to test offset

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
  # mask = (steps >= (model.N_STIM_OFF[2] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  mask = (steps >= (model.N_STIM_ON[4] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  rwd_idx = np.where(mask)[0]
  print('rwd', rwd_idx)

  model.lr_eval_win = rwd_idx.shape[0]

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))

  stim_mask1 = (steps >= (model.N_STIM_ON[4] - model.N_STEADY)) # & (steps < (model.N_STIM_OFF[3] - model.N_STEADY))

  mask_zero = ~mask & ~stim_mask & ~stim_mask1
  zero_idx = np.where(mask_zero)[0]
  print('zero', zero_idx)
#+end_src

#+RESULTS:
#+begin_example
  zero [ 0  1  2  3  4  5  6  7  8  9 20 21 22 23 24 25 26 27 28 29 30 31 32 33
   34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
   58 59 60 61 62 63 64 65 66 67 68 69]
  rwd [70 71 72 73 74 75 76 77 78 79 80]
  zero [ 0  1  2  3  4  5  6  7  8  9 20 21 22 23 24 25 26 27 28 29 30 31 32 33
   34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
   58 59 60 61 62 63 64 65 66 67 68 69]
  rwd [70 71 72 73 74 75 76 77 78 79 80]
  zero [ 0  1  2  3  4  5  6  7  8  9 20 21 22 23 24 25 26 27 28 29 30 31 32 33
   34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
   58 59 60 61 62 63 64 65 66 67 68 69]
  rwd [70 71 72 73 74 75 76 77 78 79 80]
  zero [ 0  1  2  3  4  5  6  7  8  9 20 21 22 23 24 25 26 27 28 29 30 31 32 33
   34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
   58 59 60 61 62 63 64 65 66 67 68 69]
  rwd [70 71 72 73 74 75 76 77 78 79 80]
  zero [ 0  1  2  3  4  5  6  7  8  9 20 21 22 23 24 25 26 27 28 29 30 31 32 33
   34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57
   58 59 60 61 62 63 64 65 66 67 68 69]
#+end_example

*** Inputs and Labels

#+begin_src ipython
  model.N_BATCH = 80

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = A0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = -A0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = A0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = -A0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: ff_input torch.Size([320, 455, 2000])ff_input torch.Size([320, 455, 2000])
:
: ff_input torch.Size([320, 455, 2000])
: ff_input torch.Size([320, 455, 2000])
:END:

 #+begin_src ipython
  labels_pair = torch.ones((2 * model.N_BATCH, model.lr_eval_win))
  labels_unpair = torch.zeros((2 * model.N_BATCH, model.lr_eval_win))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: labels torch.Size([320, 11])labels torch.Size([320, 11])
:
: labels torch.Size([320, 11])
: labels torch.Size([320, 11])
:END:

#+RESULTS:

*** Run

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([256, 11]) torch.Size([64, 11])
: torch.Size([256, 455, 2000]) torch.Size([64, 455, 2000])
: torch.Size([256, 11]) torch.Size([64, 11])
: torch.Size([256, 455, 2000]) torch.Size([64, 455, 2000])
: torch.Size([256, 11]) torch.Size([64, 11])
: torch.Size([256, 455, 2000]) torch.Size([64, 455, 2000])
: torch.Size([256, 11]) torch.Size([64, 11])
: torch.Size([256, 455, 2000]) torch.Size([64, 455, 2000])
: torch.Size([256, 11]) torch.Size([64, 11])

#+begin_src ipython
  # Loss
  criterion = DualLoss(alpha=1.0, thresh=5.0, N=model.Na[0], rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=0.0)

  # Optimizer: SGD, Adam, Adam
  learning_rate = 0.05
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 30
  start = perf_counter()
  loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=1, read_idx=1)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example

  Epoch 2/30, Training Loss: 0.9218, Validation Loss: 0.8558, Angle(U, W) : 92.0 °Epoch 3/30, Training Loss: 0.0100, Validation Loss: 0.0066, Angle(U, W) : 91.0 °

  Epoch 4/30, Training Loss: 0.0000, Validation Loss: 0.0001, Angle(U, W) : 91.0 °
  Stopping training as loss has fallen below the threshold: 0.0, 5.0550754735922965e-05
  Elapsed (with compilation) = 0h 1m 1s
  Epoch 1/30, Training Loss: 1.0939, Validation Loss: 1.7040, Angle(U, W) : 91.0 °
  Epoch 2/30, Training Loss: 1.2545, Validation Loss: 0.9518, Angle(U, W) : 90.0 °
  Epoch 3/30, Training Loss: 0.0002, Validation Loss: 0.0002, Angle(U, W) : 90.0 °
  Stopping training as loss has fallen below the threshold: 0.0002491758204996586, 0.00022042162117941189
  Elapsed (with compilation) = 0h 0m 36s
  Epoch 1/30, Training Loss: 2.6778, Validation Loss: 1.8982, Angle(U, W) : 90.0 °
  Epoch 2/30, Training Loss: 1.3702, Validation Loss: 1.3667, Angle(U, W) : 89.0 °
  Epoch 3/30, Training Loss: 1.0116, Validation Loss: 0.9595, Angle(U, W) : 89.0 °
  Epoch 4/30, Training Loss: 0.1023, Validation Loss: 0.1697, Angle(U, W) : 89.0 °
  Epoch 5/30, Training Loss: 0.0002, Validation Loss: 0.0007, Angle(U, W) : 90.0 °
  Stopping training as loss has fallen below the threshold: 0.00016545411199331284, 0.0007227715395856649
  Elapsed (with compilation) = 0h 0m 58s
  Epoch 1/30, Training Loss: 2.4670, Validation Loss: 1.8430, Angle(U, W) : 91.0 °
  Epoch 2/30, Training Loss: 1.1388, Validation Loss: 1.2944, Angle(U, W) : 89.0 °
  Epoch 3/30, Training Loss: 0.5733, Validation Loss: 0.6182, Angle(U, W) : 88.0 °
  Epoch 4/30, Training Loss: 0.0001, Validation Loss: 0.0011, Angle(U, W) : 87.0 °
  Stopping training as loss has fallen below the threshold: 0.00011346597602823749, 0.0010552255407674238
  Elapsed (with compilation) = 0h 0m 49s
  Epoch 1/30, Training Loss: 2.1659, Validation Loss: 1.8628, Angle(U, W) : 90.0 °
  Epoch 2/30, Training Loss: 0.8283, Validation Loss: 1.2789, Angle(U, W) : 88.0 °
  Epoch 3/30, Training Loss: 0.1577, Validation Loss: 0.2355, Angle(U, W) : 89.0 °
  Epoch 4/30, Training Loss: 0.0008, Validation Loss: 0.0001, Angle(U, W) : 89.0 °
  Stopping training as loss has fallen below the threshold: 0.0008350101998075843, 0.00012489563914641622
  Elapsed (with compilation) = 0h 0m 47s
#+end_example
:END:

#+begin_src ipython
    torch.save(model.state_dict(), 'models/dpa_%d.pth' % seed)
#+end_src

#+RESULTS:

#+begin_src ipython
    plt.plot(loss)
    plt.plot(val_loss)
    plt.xlabel('epochs')
    plt.ylabel('Loss')
    plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/fd2807a0aff3225fe28f602bdd52df2a6d12dd47.png]]
[[file:./.ob-jupyter/cfceed46917d0f2b99595251fe260bd6b2615de2.png]]
[[file:./.ob-jupyter/79bc9508333b0331b5501c3174f0e6836a7f6831.png]]
[[file:./.ob-jupyter/f4fc9ad4a1472a2a0ad0a112aa2469fb305be237.png]]
[[file:./.ob-jupyter/fd2b088d9ab0283893b7c8a74936fd238306d31c.png]]
:END:

#+begin_src ipython
  odors = model.odors.cpu().numpy()
  U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]
  W = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]

  print('   U  V  W  S  D')
  print('U ', angle_AB(U, U), angle_AB(U, V), angle_AB(U, W), angle_AB(U, odors[0]), angle_AB(U, odors[1]))
  print('V ', 'XXX', angle_AB(V, V), angle_AB(V, W), angle_AB(V, odors[0]), angle_AB(V, odors[1]))
  print('W ', 'XXX', 'XXX', angle_AB(W, W), angle_AB(W, odors[0]), angle_AB(W, odors[1]))
  print('S ', 'XXX', 'XXX', 'XXX', angle_AB(odors[0], odors[0]), angle_AB(odors[0], odors[1]))
  print('D ', 'XXX', 'XXX', 'XXX', 'XXX', angle_AB(odors[1], odors[1]))

#+end_src

#+RESULTS:
#+begin_example
  U  0 28 92 71 92
  V  XXX 0 92 64 92
  W  XXX XXX 0 90 88
  S  XXX XXX XXX 0 90
  D  XXX XXX XXX XXX 0
     U  V  W  S  D
  U  0 27 92 73 86
  V  XXX 0 92 67 85
  W  XXX XXX 0 90 92
  S  XXX XXX XXX 0 89
  D  XXX XXX XXX XXX 0
     U  V  W  S  D
  U  0 36 90 74 93
  V  XXX 0 90 66 92
  W  XXX XXX 0 94 88
  S  XXX XXX XXX 0 91
  D  XXX XXX XXX XXX 0
     U  V  W  S  D
  U  0 37 90 73 89
  V  XXX 0 90 67 90
  W  XXX XXX 0 89 89
  S  XXX XXX XXX 0 90
  D  XXX XXX XXX XXX 0
     U  V  W  S  D
  U  0 34 87 71 92
  V  XXX 0 88 64 90
  W  XXX XXX 0 91 92
  S  XXX XXX XXX 0 89
  D  XXX XXX XXX XXX 0
#+end_example

** Testing

#+begin_src ipython
  model.DURATION = 8
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW

  model.eval()
#+end_src

#+RESULTS:
:RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
:END:

#+begin_src ipython
  model.N_BATCH = 1
  A0 = 1

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = A0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = -A0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = A0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = -A0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: ff_input torch.Size([4, 455, 2000])ff_input torch.Size([4, 455, 2000])
:
: ff_input torch.Size([4, 455, 2000])
: ff_input torch.Size([4, 455, 2000])
:END:

 #+begin_src ipython
  labels_pair = torch.ones((2 * model.N_BATCH, 2))
  labels_unpair = torch.zeros((2 * model.N_BATCH, 2))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: labels torch.Size([4, 2])labels torch.Size([4, 2])
:
: labels torch.Size([4, 2])
: labels torch.Size([4, 2])
:END:

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).detach().cpu().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: (4, 81, 1000)(4, 81, 1000)
:
: (4, 81, 1000)
: (4, 81, 1000)
:END:

#+begin_src ipython
  print(rates.shape)
  print(labels.shape)
#+end_src

#+RESULTS:
: torch.Size([4, 2])
: (4, 81, 1000)
: torch.Size([4, 2])
: (4, 81, 1000)
: torch.Size([4, 2])
: (4, 81, 1000)
: torch.Size([4, 2])
: (4, 81, 1000)
: torch.Size([4, 2])

#+begin_src ipython
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
  # readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
  plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dpa_overlap.svg')
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/68f442ff60a350f9b716539cff9063d9541c64cc.png]]
[[file:./.ob-jupyter/e8359dd617e824f8183008e19ca8b0983cd0a627.png]]
[[file:./.ob-jupyter/731d3eb08c0a297ccf22b6abe7c29e5bf2b8c7b9.png]]
[[file:./.ob-jupyter/9b7b9e56ffc4a013ab652c1f5ac998cfaed08158.png]]
[[file:./.ob-jupyter/084fd24364c4006de1d3628d69dde251da1f9d92.png]]
:END:

#+begin_src ipython
  idx = get_idx(model, 1)
  plot_rates_selec(rates, idx, figname='dpa_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/1ad2d12f83ba77250e0cd26e25a7aa1a971b85d6.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/1a612e274f9cd0329cfe4512d7a86c86b075f7af.png]]
:END:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/ab6f04d4baa6e334e2f5346bcad4438b01bc9a98.png]]
:END:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/fa82332db0d361bb21df259ece45878560853e1e.png]]
:END:
:RESULTS:
:
[[file:./.ob-jupyter/735d2c93d22bd77e353804ba66e022bf22add3df.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx, figname='dpa_fourier.svg')
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/fe8b7682c0399a4d656d1a2660022bbdfd40a9a6.png]]
[[file:./.ob-jupyter/4f6239e78e4cb041b9f0330e11ce8df771e12718.png]]
[[file:./.ob-jupyter/06f1e2c33a8785ddb50521db0e6845fed8403279.png]]
[[file:./.ob-jupyter/905fb88fa82a44be1b7e6152db9d8c71918fda6e.png]]
[[file:./.ob-jupyter/49568137f7d47df8c4847b050191ced8dcda3675.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

** Fixed points

#+begin_src ipython
  model.DURATION = 20
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
  model.IF_RL = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
:RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
:END:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape, ff_input[0, 0, :4])
#+end_src

#+RESULTS:
:RESULTS:
:
: ff_input torch.Size([4, 1055, 2000]) tensor([28.7128, 28.0022, 28.6979, 28.9964], device='cuda:1')ff_input torch.Size([4, 1055, 2000]) tensor([29.7876, 29.9256, 28.3764, 28.4222], device='cuda:1')
:
: ff_input torch.Size([4, 1055, 2000]) tensor([29.3741, 27.4171, 29.3671, 27.0026], device='cuda:1')
: ff_input torch.Size([4, 1055, 2000]) tensor([28.6524, 29.0090, 28.0280, 28.3500], device='cuda:1')
:END:

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: (4, 201, 1000)(4, 201, 1000)
:
: (4, 201, 1000)
: (4, 201, 1000)
:END:

#+begin_src ipython
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
  # readout = model.low_rank.linear.weight.data[0].cpu().detach().numpy()
  plot_overlap(rates, memory, readout, labels=['pair', 'unpair'])
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/78866a64ab70a7b5354837e971570f5ca98d2203.png]]
[[file:./.ob-jupyter/4feb64a560d7b50e0edc5a769af7e2e786560c5e.png]]
[[file:./.ob-jupyter/feee5801a0870bfe510eb2727da042460cbc571e.png]]
[[file:./.ob-jupyter/60e20927303facae14813654e384ce2069413a00.png]]
[[file:./.ob-jupyter/f1712db5b50738c6148736a48c27ed97164ab3d7.png]]
:END:

#+begin_src ipython
  idx = get_idx(model, 1)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/8ff85cd05a507eeeb94c379f7ba7f86bddd01d8d.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/55a31a76895bb53c36f2e68971ced7e3a843b5ff.png]]
:END:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/a194e59c55dfd7c6acfdbdc30f71ece267122b27.png]]
:END:
:RESULTS:
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/b5bddf249452c3216e7926abb0233886801ce2dd.png]]
:END:
:RESULTS:
:
[[file:./.ob-jupyter/b1c12cd1b154d6ceafe51ee0e0655a390a83b60b.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/14696bace127ec2185cb1b8516f186f4f62a7088.png]]
[[file:./.ob-jupyter/1530a44abe63d11b48b6f16c7f29c6686d6b3bfb.png]]
[[file:./.ob-jupyter/dd31aa9e9034a260c005ec4e73a2ed0efc677189.png]]
[[file:./.ob-jupyter/d285f64950eecdfb0f1c104d0699288a155efc40.png]]
[[file:./.ob-jupyter/3103d43c6a4892ad449757556fbad363bffa2cc1.png]]
:END:

    #+begin_src ipython
  print(rates.shape)
#+end_src

#+RESULTS:
: (4, 201, 1000)
: (4, 201, 1000)
: (4, 201, 1000)
:RESULTS:
:
: (4, 201, 1000)
:END:

#+RESULTS:

#+begin_src ipython
  from matplotlib.patches import Circle
  m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

  x = m1 / m0 * np.cos(phi)
  y = m1 / m0 * np.sin(phi)

  xA = x
  yA = y

  fig, ax = plt.subplots(1, 1, figsize=[height, height])

  # ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
  # ax.plot(xA.T, yA.T, '-', alpha=.5)
  ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=20)
  # ax.set_xlim([-.9, .9])
  # ax.set_ylim([-.9, .9])
  circle = Circle((0., 0.), 1.8, fill=False, edgecolor='k')
  ax.add_patch(circle)

  # Set the aspect of the plot to equal to make the circle circular
  ax.set_aspect('equal')
  plt.savefig('fp_dpa.svg', dpi=300)
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/f089b84a3ae3af7511242f2b1a381fef224f3dc1.png]]
[[file:./.ob-jupyter/40158cc6e1bbb9d487fd61eb000c7a20021751d6.png]]
[[file:./.ob-jupyter/5cb05b891b2770ae588d92a266d9a250101ba034.png]]
[[file:./.ob-jupyter/5e9c61b069bad603c64e7c269b749442833c1863.png]]
[[file:./.ob-jupyter/4845190be3ed5292f36dca66c9ad66a4a0537d79.png]]
:END:

#+RESULTS:

#+begin_src ipython

#+end_src

#+RESULTS:

* Go/NoGo
** Training

#+begin_src ipython
  model.low_rank.lr_kappa.requires_grad = True

  # readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
  # idx = readout.argsort()[:250]
  # model.low_rank.lr_mask[idx, :1000] = 0

  # for param in model.low_rank.linear.parameters():
  #     param.requires_grad = True

  # model.low_rank.linear.bias.requires_grad = True
  # model.low_rank.linear.bias.data.zero_()  # Common practice is to set biases to zero

  # model.low_rank.U.requires_grad = False
  # model.low_rank.V.requires_grad = False

#+end_src

#+RESULTS:

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
#+begin_example
  low_rank.V torch.Size([2000, 2])
  low_rank.lr_kappa torch.Size([1])
  low_rank.U torch.Size([2000, 2])
  low_rank.V torch.Size([2000, 2])
  low_rank.lr_kappa torch.Size([1])
  low_rank.U torch.Size([2000, 2])
  low_rank.V torch.Size([2000, 2])
  low_rank.lr_kappa torch.Size([1])
  low_rank.U torch.Size([2000, 2])
  low_rank.V torch.Size([2000, 2])
  low_rank.lr_kappa torch.Size([1])
  low_rank.U torch.Size([2000, 2])
  low_rank.V torch.Size([2000, 2])
  low_rank.lr_kappa torch.Size([1])
#+end_example

#+begin_src ipython
  model.DURATION = 4.0
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW

  model.T_STIM_ON =  [1.0, 3.0]
  model.T_STIM_OFF =  [2.0, 4.0]

  # model.T_STIM_ON =  [1.0, 3.0, 3.5]
  # model.T_STIM_OFF =  [2.0, 3.5, 4.0]

  model.N_STIM_ON = np.array(
        [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_ON]
    )

  model.N_STIM_OFF = [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_OFF]
#+end_src

#+RESULTS:

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1
  model.IF_RL = 0 # 1
  model.RWD = 1 # 1/2
#+end_src

#+RESULTS:

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
  # mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[1] - model.N_STEADY))
  mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps <= (model.N_STIM_OFF[0] - model.N_STEADY))
  # mask = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))

  rwd_idx = np.where(mask)[0]
  print('rwd', rwd_idx)

  mask_cue = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))
  # mask_cue = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY))  & (steps < (model.N_STIM_ON[1] - model.N_STEADY))
  cue_idx = np.where(mask_cue)[0]

  # cue_idx = []

  print('cue', cue_idx)

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) # & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))

  mask_zero = ~mask & ~stim_mask
  zero_idx = np.where(mask_zero)[0]
  print('zero', zero_idx)

  # model.lr_eval_win = rwd_idx.shape[0]
  model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))
#+end_src

#+RESULTS:
#+begin_example
  cue [30 31 32 33 34 35 36 37 38 39 40]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [10 11 12 13 14 15 16 17 18 19 20]
  cue [30 31 32 33 34 35 36 37 38 39 40]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [10 11 12 13 14 15 16 17 18 19 20]
  cue [30 31 32 33 34 35 36 37 38 39 40]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [10 11 12 13 14 15 16 17 18 19 20]
  cue [30 31 32 33 34 35 36 37 38 39 40]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [10 11 12 13 14 15 16 17 18 19 20]
  cue [30 31 32 33 34 35 36 37 38 39 40]
  zero [0 1 2 3 4 5 6 7 8 9]
#+end_example

#+begin_src ipython
  # switching sample and distractor odors
  odors = model.odors.clone()
  model.odors[0] = odors[1] # distractor Go
  model.odors[5] = odors[5+1] # distractor NoGo

  model.odors[1] = odors[2] # cue
  model.odors[2] = odors[3] # rwd

  model.N_BATCH = 80

  if model.IF_RL == 0:
      B0 = 0

  model.I0[0] = A0
  model.I0[1] = float(B0) # cue
  model.I0[2] = 0.0 # float(C0) * model.IF_RL  # reward
  model.I0[3] = 0
  model.I0[4] = 0

  Go = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = float(B0) # cue
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  NoGo = model.init_ff_input()

  ff_input = torch.cat((Go, NoGo))
  print(ff_input.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: torch.Size([160, 255, 2000])torch.Size([160, 255, 2000])
:
: torch.Size([160, 255, 2000])
: torch.Size([160, 255, 2000])
:END:

#+begin_src ipython
  labels_Go = torch.ones((model.N_BATCH, model.lr_eval_win))
  labels_NoGo = torch.zeros((model.N_BATCH, model.lr_eval_win))
  labels = torch.cat((labels_Go, labels_NoGo))
  print(labels.shape)
  # print(labels)
  labels =  labels.repeat((2, 1, 1))
  labels = torch.transpose(labels, 0, 1)
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([160, 2, 11])
: torch.Size([160, 11])
: labels torch.Size([160, 2, 11])
: torch.Size([160, 11])
: labels torch.Size([160, 2, 11])
: torch.Size([160, 11])
: labels torch.Size([160, 2, 11])
: torch.Size([160, 11])
: labels torch.Size([160, 2, 11])

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([128, 2, 11]) torch.Size([32, 2, 11])
: torch.Size([128, 255, 2000]) torch.Size([32, 255, 2000])
: torch.Size([128, 2, 11]) torch.Size([32, 2, 11])
: torch.Size([128, 255, 2000]) torch.Size([32, 255, 2000])
: torch.Size([128, 2, 11]) torch.Size([32, 2, 11])
: torch.Size([128, 255, 2000]) torch.Size([32, 255, 2000])
: torch.Size([128, 2, 11]) torch.Size([32, 2, 11])
: torch.Size([128, 255, 2000]) torch.Size([32, 255, 2000])
: torch.Size([128, 2, 11]) torch.Size([32, 2, 11])

#+begin_src ipython
  criterion = DualLoss(alpha=1.0, thresh=5.0, N=model.Na[0], rwd_idx=rwd_idx, zero_idx=zero_idx, cue_idx=cue_idx, imbalance=[1.0, 0.0])

  # SGD, Adam, Adam
  learning_rate = 0.05
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 15
  start = perf_counter()
  loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=1, read_idx=1)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

  # switching back sample and distractor odors
  model.odors = odors
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example

  Epoch 2/15, Training Loss: 1.1081, Validation Loss: 1.0316, Angle(U, W) : 92.0 °Epoch 3/15, Training Loss: 0.3520, Validation Loss: 0.2140, Angle(U, W) : 91.0 °

  Epoch 4/15, Training Loss: 0.0013, Validation Loss: 0.0007, Angle(U, W) : 89.0 °
  Stopping training as loss has fallen below the threshold: 0.001347902463749051, 0.0007481974826077931
  Elapsed (with compilation) = 0h 0m 13s
  Epoch 1/15, Training Loss: 3.5397, Validation Loss: 3.1796, Angle(U, W) : 88.0 °
  Epoch 2/15, Training Loss: 2.6529, Validation Loss: 2.2998, Angle(U, W) : 87.0 °
  Epoch 3/15, Training Loss: 0.7798, Validation Loss: 0.6273, Angle(U, W) : 85.0 °
  Epoch 4/15, Training Loss: 0.1100, Validation Loss: 0.0588, Angle(U, W) : 84.0 °
  Epoch 5/15, Training Loss: 0.0011, Validation Loss: 0.0001, Angle(U, W) : 86.0 °
  Stopping training as loss has fallen below the threshold: 0.0011387089034542441, 0.00010730727262853179
  Elapsed (with compilation) = 0h 0m 17s
  Epoch 1/15, Training Loss: 1.7984, Validation Loss: 1.6811, Angle(U, W) : 91.0 °
  Epoch 2/15, Training Loss: 0.5791, Validation Loss: 0.5113, Angle(U, W) : 94.0 °
  Epoch 3/15, Training Loss: 0.0228, Validation Loss: 0.0110, Angle(U, W) : 95.0 °
  Epoch 4/15, Training Loss: 0.0058, Validation Loss: 0.0171, Angle(U, W) : 96.0 °
  Epoch 5/15, Training Loss: 0.0175, Validation Loss: 0.0435, Angle(U, W) : 96.0 °
  Epoch 6/15, Training Loss: 0.0080, Validation Loss: 0.0081, Angle(U, W) : 96.0 °
  Epoch 7/15, Training Loss: 0.0027, Validation Loss: 0.0067, Angle(U, W) : 96.0 °
  Epoch 8/15, Training Loss: 0.0079, Validation Loss: 0.0044, Angle(U, W) : 96.0 °
  Epoch 9/15, Training Loss: 0.0020, Validation Loss: 0.0024, Angle(U, W) : 96.0 °
  Stopping training as loss has fallen below the threshold: 0.002004601527005434, 0.002377196855377406
  Elapsed (with compilation) = 0h 0m 29s
  Epoch 1/15, Training Loss: 3.2273, Validation Loss: 3.0326, Angle(U, W) : 88.0 °
  Epoch 2/15, Training Loss: 1.4223, Validation Loss: 1.3030, Angle(U, W) : 92.0 °
  Epoch 3/15, Training Loss: 0.3818, Validation Loss: 0.2661, Angle(U, W) : 91.0 °
  Epoch 4/15, Training Loss: 0.0024, Validation Loss: 0.0075, Angle(U, W) : 91.0 °
  Epoch 5/15, Training Loss: 0.0224, Validation Loss: 0.0087, Angle(U, W) : 91.0 °
  Epoch 6/15, Training Loss: 0.0097, Validation Loss: 0.0095, Angle(U, W) : 91.0 °
  Epoch 7/15, Training Loss: 0.0043, Validation Loss: 0.0034, Angle(U, W) : 91.0 °
  Stopping training as loss has fallen below the threshold: 0.004264381248503923, 0.0034437585854902864
  Elapsed (with compilation) = 0h 0m 23s
  Epoch 1/15, Training Loss: 3.7444, Validation Loss: 3.2543, Angle(U, W) : 90.0 °
  Epoch 2/15, Training Loss: 2.6950, Validation Loss: 2.5266, Angle(U, W) : 89.0 °
  Epoch 3/15, Training Loss: 1.3086, Validation Loss: 1.0785, Angle(U, W) : 89.0 °
  Epoch 4/15, Training Loss: 0.2502, Validation Loss: 0.2970, Angle(U, W) : 89.0 °
  Epoch 5/15, Training Loss: 0.0008, Validation Loss: 0.0000, Angle(U, W) : 89.0 °
  Stopping training as loss has fallen below the threshold: 0.0007635244983248413, 3.348733298480511e-05
  Elapsed (with compilation) = 0h 0m 17s
#+end_example
:END:

#+begin_src ipython
    torch.save(model.state_dict(), 'models/dual_naive_%d.pth' % seed)
#+end_src

#+RESULTS:

** Test

  #+begin_src ipython
    model.eval()
  #+end_src

  #+RESULTS:
  :RESULTS:
  : Network(
  :   (low_rank): LowRankWeights(
  :     (linear): Linear(in_features=1000, out_features=1, bias=True)
  :     (dropout): Dropout(p=0.0, inplace=False)
  :   )
  : )
  : Network(
  :   (low_rank): LowRankWeights(
  :     (linear): Linear(in_features=1000, out_features=1, bias=True)
  :     (dropout): Dropout(p=0.0, inplace=False)
  :   )
  : )
  : Network(
  :   (low_rank): LowRankWeights(
  :     (linear): Linear(in_features=1000, out_features=1, bias=True)
  :     (dropout): Dropout(p=0.0, inplace=False)
  :   )
  : )
  : Network(
  :   (low_rank): LowRankWeights(
  :     (linear): Linear(in_features=1000, out_features=1, bias=True)
  :     (dropout): Dropout(p=0.0, inplace=False)
  :   )
  : )
  : Network(
  :   (low_rank): LowRankWeights(
  :     (linear): Linear(in_features=1000, out_features=1, bias=True)
  :     (dropout): Dropout(p=0.0, inplace=False)
  :   )
  : )
  :END:

 #+begin_src ipython
   odors = model.odors.clone()
   model.odors[0] = odors[1] # distractor Go
   model.odors[5] = odors[5+1] # distractor NoGo

   model.odors[1] = odors[2] # cue
   model.odors[2] = odors[3] # rwd
  #+end_src

#+RESULTS:

  #+begin_src ipython
    model.N_BATCH = 1

    model.I0[0] = A0 # Go
    model.I0[1] = float(B0) # cue
    model.I0[2] = 0.0 # float(C0) * model.IF_RL # rwd
    model.I0[3] = 0.0
    model.I0[4] = 0.0

    A = model.init_ff_input()

    model.I0[0] = -A0 # NoGo
    model.I0[1] = float(B0) # cue
    model.I0[2] = 0.0 # rwd
    model.I0[3] = 0.0
    model.I0[4] = 0.0

    B = model.init_ff_input()

    ff_input = torch.cat((A, B))
    print('ff_input', ff_input.shape)
  #+end_src

#+RESULTS:
:RESULTS:
:
: ff_input torch.Size([2, 255, 2000])ff_input torch.Size([2, 255, 2000])
:
: ff_input torch.Size([2, 255, 2000])
: ff_input torch.Size([2, 255, 2000])
:END:

  #+begin_src ipython
      rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
      model.odors = odors
      print(rates.shape)
  #+end_src

#+RESULTS:
:RESULTS:
:
: (2, 41, 1000)(2, 41, 1000)
:
: (2, 41, 1000)
: (2, 41, 1000)
:END:

  #+begin_src ipython
    memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
    readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
    # readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
    plot_overlap(rates, memory, readout, labels=['Go', 'NoGo'])
  #+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/feea0fe109f4364ff837e4ca9a4687a7f10d5d64.png]]
[[file:./.ob-jupyter/9992952137b0cceb5c3e8336dac806474bb069f2.png]]
[[file:./.ob-jupyter/e9437cc134e696c426bc8293675eed60bb6c4ea9.png]]
[[file:./.ob-jupyter/03226879806372ce5c730c2cee846abcafe82e9d.png]]
[[file:./.ob-jupyter/b97b20f6644f69fe852d6b5f637619107996e4c2.png]]
:END:

  #+begin_src ipython
    memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
    # readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
    readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
    plot_overlap(rates, memory, readout, labels=['Go', 'NoGo'])
  #+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/aa9160b0a3f639b0682a3ee2adbac870c46495d8.png]]
[[file:./.ob-jupyter/e90496fad85cc55460fe3ab703927ac15d3a126f.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/d034235ba5846f19f3698426eca8001d0e6bd586.png]]
[[file:./.ob-jupyter/6d708ae180fb611cd3c68e2745f7faf64a1f30ca.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/6a1f2a0c54b141cf6c15a0bbda6b54f026afd5d7.png]]
:END:

  #+begin_src ipython
    idx = get_idx(model, 1)
    plot_rates_selec(rates, idx)
  #+end_src

#+RESULTS:
:RESULTS:
:
[[file:./.ob-jupyter/1c449983eb20de223ad2fa406cebf4d38f92697e.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/f2012e98cff0f043e25871b0cbaf1d6c23905662.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/70b6ea819b29df1a169af7c6d32fe467fbfd4bd8.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/0ce558b0a9e4f80bd364864b0147b41d21265764.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/a99ab9238ce0a06899d30a71d561c9c31f98999b.png]]
:END:

#+begin_src ipython
    plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/1cd3aba9e0ba4a52b38355cebcd80716d6bdd731.png]]
[[file:./.ob-jupyter/9fe3be6f8cd0735a510cf34c50ee24172c5061c0.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/78236f9fb6bed1efc6c2f28068ca284e7db8f725.png]]
[[file:./.ob-jupyter/4ee4135c1d5911b5deebc02f4bca99f48989d6eb.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/3955461d7d93c7ad89ab5424fa8c514aa5fe65c4.png]]
:END:

* Dual
** Parameters
#+begin_src ipython
  model.DURATION = 8
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
  model.IF_RL = 0 # 1
  model.RWD = 22 # 2/3
#+end_src

#+RESULTS:

#+begin_src ipython
  model.T_STIM_ON = [1.0, 3.0, 5.0, 5.5, 7.0]
  model.T_STIM_OFF = [2.0, 4.0, 5.5, 6.0, 8.0]

  model.N_STIM_ON = np.array(
      [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_ON]
  )

  model.N_STIM_OFF = [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_OFF]
#+end_src

#+RESULTS:

** Testing

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
:RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
:END:

#+begin_src ipython
  B0 = 0
  model.N_BATCH = 1

  model.I0[0] = A0 # sample A
  model.I0[1] = A0 # distractor Go
  model.I0[2] = float(B0) # cue
  model.I0[3] = 0.0 # float(C0) * model.IF_RL # rwd
  model.I0[4] = A0 # test

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = -A0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = A0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = -A0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: ff_input torch.Size([4, 455, 2000])ff_input torch.Size([4, 455, 2000])
:
: ff_input torch.Size([4, 455, 2000])
: ff_input torch.Size([4, 455, 2000])
:END:

#+begin_src ipython
  labels_pair = torch.ones((2 * model.N_BATCH, 2))
  labels_unpair = torch.zeros((2 * model.N_BATCH, 2))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: labels torch.Size([4, 2])labels torch.Size([4, 2])
:
: labels torch.Size([4, 2])
: labels torch.Size([4, 2])
:END:

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).detach()
  print(rates.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: torch.Size([4, 81, 1000])torch.Size([4, 81, 1000])
:
: torch.Size([4, 81, 1000])
: torch.Size([4, 81, 1000])
:END:

#+begin_src ipython
  rates = rates.cpu().numpy()
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
  plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_naive_overlap.svg')
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/2eaf3daf20c88f4d61d9472b0f11281ff14095d1.png]]
[[file:./.ob-jupyter/26870f8a064e674e9f4d5ef7cb4f66dc5aa4ac48.png]]
[[file:./.ob-jupyter/6e964d1f098a721a1e4b9c755a595263022f11fa.png]]
[[file:./.ob-jupyter/7483313477a92b7c390d48de26c6951ea5177ab2.png]]
[[file:./.ob-jupyter/973add906967645336496842fbef3901f81c1cda.png]]
:END:

#+begin_src ipython
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
  plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_naive_overlap.svg')
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/e9448a87fb8b7c69118b85183b8d7ec837de0f19.png]]
[[file:./.ob-jupyter/62c877d1cf3c507d927a7553db45614519355f53.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/2da515204268d9803cac70489408cab84d2b9b73.png]]
[[file:./.ob-jupyter/d76fb01a6edf5deee23532c7871489a47afebb0b.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/9be48070756715be4f0387e05f42e34b079ff4a8.png]]
:END:

#+begin_src ipython
  idx = get_idx(model, 1)
  plot_rates_selec(rates, idx, figname='dual_naive_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
:
[[file:./.ob-jupyter/0a2f929b4dd3c0d849ab93d5da2f8f3e997d6262.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/bc06664faec5bb35c8ed8a6761c6f976ecf645cf.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/0bf0c52c4dc206219e4c9c4d396b8fd41e90a2f9.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/4c7ded8a127fedfa5aa8530f37028f464022b865.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/69fd52211b59369b65f673c08be8c7c95d927aba.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx, figname='dual_naive_fourier.svg')
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/e34eae1db983583f2f6fa367857ccd0a214e82f8.png]]
[[file:./.ob-jupyter/104b52ea86595fa1ce03980419308202b70bb6c5.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/2616ac3e3d9d0d14d59ae67568c27f757d967dda.png]]
[[file:./.ob-jupyter/47845b1e8bb76f9e799154f0abede67f624ee706.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/5a9a8b6beaeab340f1727244b5b1db335c57f140.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

** Fixed points

#+begin_src ipython
  model.DURATION = 20
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
  model.IF_RL = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
:RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
:END:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape, ff_input[0, 0, :4])
#+end_src

#+RESULTS:
:RESULTS:
:
: ff_input torch.Size([4, 1055, 2000]) tensor([29.8786, 29.0055, 26.9757, 28.4254], device='cuda:1')ff_input torch.Size([4, 1055, 2000]) tensor([30.5198, 27.9905, 31.0362, 23.7194], device='cuda:1')
:
: ff_input torch.Size([4, 1055, 2000]) tensor([26.3177, 26.4306, 29.2753, 27.2782], device='cuda:1')
: ff_input torch.Size([4, 1055, 2000]) tensor([27.7583, 27.7955, 28.8219, 25.1338], device='cuda:1')
:END:

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: (4, 201, 1000)(4, 201, 1000)
:
: (4, 201, 1000)
: (4, 201, 1000)
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/ceeebb13b0374dc18cb4a0a0d70438265c525e10.png]]
[[file:./.ob-jupyter/4a0f3d41744bfc1a5557d684361addd5666a96e0.png]]
[[file:./.ob-jupyter/62200ffcb2aefe511448ba102dc5be1a6fb6c660.png]]
[[file:./.ob-jupyter/826efc8c499045512cbe0e4e69e8350222cb26a6.png]]
[[file:./.ob-jupyter/88557e71455ba25ee2248ac8311776a027af4027.png]]
:END:


#+begin_src ipython
  from matplotlib.patches import Circle
  m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

  x = m1 / m0 * np.cos(phi)
  y = m1 / m0 * np.sin(phi)

  xA = x
  yA = y

  fig, ax = plt.subplots(1, 1, figsize=[height, height])

  # ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
  # ax.plot(xA.T, yA.T, '-', alpha=.5)
  ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=20)
  # ax.set_xlim([-.9, .9])
  # ax.set_ylim([-.9, .9])
  circle = Circle((0., 0.), 1.8, fill=False, edgecolor='k')
  ax.add_patch(circle)

  # Set the aspect of the plot to equal to make the circle circular
  ax.set_aspect('equal')
  plt.savefig('fp_dual_naive.svg', dpi=300)
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/0e3b1a4e6fed0260f1a25b5be7f8f49a8a5cd4e9.png]]
[[file:./.ob-jupyter/458b745f1fe0bc6bb4e4b7531e046ce77027c8cc.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/23cbac6b57cd9ff7428a7b0eaf078a723cc7c36a.png]]
[[file:./.ob-jupyter/a73a441ae1ea0f2da80607cccaeecd30471c1278.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/28fb0eb12171ebffa95128871bb02dfc5d33ada0.png]]
:END:

#+RESULTS:

#+begin_src ipython

#+end_src

#+RESULTS:

** Training

#+begin_src ipython
  # for param in model.low_rank.linear.parameters():
  #     param.requires_grad = False

  model.low_rank.U.requires_grad = True
  model.low_rank.V.requires_grad = True

  # init.xavier_uniform_(model.low_rank.linear.weight)
  # if model.low_rank.linear.bias is not None:
  #     model.low_rank.linear.bias.data.zero_()  # Common practice is to set biases to zero
  #+end_src

#+RESULTS:

#+begin_src ipython
  model.DURATION = 8
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
  model.IF_RL = 0 # 1

  model.LR_TRAIN = 1
  model.LR_READOUT = 1
  model.RWD = 2 # 2/3
#+end_src

#+RESULTS:

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

  mask_rwd = (steps >= (model.N_STIM_ON[-1] - model.N_STEADY))
  rwd_idx = np.where(mask_rwd)[0]
  print('rwd', rwd_idx)

  # mask_dist = (steps >= (model.N_STIM_ON[1] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[-1] - model.N_STEADY))
  # # mask_dist = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))
  # dist_idx = np.where(mask_dist)[0]
  # print('dist', dist_idx)

  mask_cue = (steps >= (model.N_STIM_ON[2] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[-1] - model.N_STEADY))
  # mask_cue = (steps >= (model.N_STIM_ON[1] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[-1] - model.N_STEADY))
  # mask_cue = (steps >= (model.N_STIM_ON[1] - model.N_STEADY))
  cue_idx = np.where(mask_cue)[0]
  print('cue', cue_idx)

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY))

  mask_zero = ~mask_rwd & ~mask_cue & ~stim_mask
  zero_idx = np.where(mask_zero)[0]
  print('zero', zero_idx)
#+end_src

#+RESULTS:
#+begin_example
  cue [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [70 71 72 73 74 75 76 77 78 79 80]
  cue [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [70 71 72 73 74 75 76 77 78 79 80]
  cue [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [70 71 72 73 74 75 76 77 78 79 80]
  cue [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]
  zero [0 1 2 3 4 5 6 7 8 9]
  rwd [70 71 72 73 74 75 76 77 78 79 80]
  cue [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]
  zero [0 1 2 3 4 5 6 7 8 9]
#+end_example

#+begin_src ipython
  model.N_BATCH = 80

  model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))
  # model.lr_eval_win = np.max( (rwd_idx.shape[0], dist_idx.shape[0], cue_idx.shape[0]))

  ff_input = []
  labels = np.zeros((2, 12, model.N_BATCH, model.lr_eval_win))
  # labels = np.zeros((3, 12, model.N_BATCH, model.lr_eval_win))

  if model.IF_RL==0:
      B0 = 0

  print(float(B0), float(C0))

  l=0
  for i in [-1, 1]:
      for j in [-1, 0, 1]:
          for k in [-1, 1]:

              model.I0[0] = i # sample
              model.I0[1] = j # distractor
              model.I0[4] = k # test

              if i==k: # Pair Trials
                  labels[0, l] = np.ones((model.N_BATCH, model.lr_eval_win))

              if j==1: # Go
                  model.I0[2] = float(B0) # cue
                  model.I0[3] = float(C0) * model.IF_RL # rwd

                  labels[1, l] = np.ones((model.N_BATCH, model.lr_eval_win))
              elif j==-1: # NoGo
                  model.I0[2] = float(B0) # cue
                  model.I0[3] = 0.0 # rwd
              else: # DPA
                  model.I0[2] = 0 # cue
                  model.I0[3] = 0 # rwd

              l+=1

              ff_input.append(model.init_ff_input())

  labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(2, -1, model.lr_eval_win).transpose(0, 1)
  # labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(3, -1, model.lr_eval_win).transpose(0, 1)
  ff_input = torch.vstack(ff_input)
  print('ff_input', ff_input.shape, 'labels', labels.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([960, 455, 2000]) labels torch.Size([960, 2, 21])
: 0.0 0.0
: ff_input torch.Size([960, 455, 2000]) labels torch.Size([960, 2, 21])
: 0.0 0.0
: ff_input torch.Size([960, 455, 2000]) labels torch.Size([960, 2, 21])
: 0.0 0.0
: ff_input torch.Size([960, 455, 2000]) labels torch.Size([960, 2, 21])
: 0.0 0.0
: ff_input torch.Size([960, 455, 2000]) labels torch.Size([960, 2, 21])

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([768, 2, 21]) torch.Size([192, 2, 21])
: torch.Size([768, 455, 2000]) torch.Size([192, 455, 2000])
: torch.Size([768, 2, 21]) torch.Size([192, 2, 21])
: torch.Size([768, 455, 2000]) torch.Size([192, 455, 2000])
: torch.Size([768, 2, 21]) torch.Size([192, 2, 21])
: torch.Size([768, 455, 2000]) torch.Size([192, 455, 2000])
: torch.Size([768, 2, 21]) torch.Size([192, 2, 21])
: torch.Size([768, 455, 2000]) torch.Size([192, 455, 2000])
: torch.Size([768, 2, 21]) torch.Size([192, 2, 21])

#+begin_src ipython
  criterion = DualLoss(alpha=1.0, thresh=5.0, N=model.Na[0], cue_idx=cue_idx, rwd_idx=rwd_idx, zero_idx=zero_idx, imbalance=[0.0, 0.0])

  # SGD, Adam, AdamW
  learning_rate = 0.05
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 15
  start = perf_counter()
  loss, val_loss = optimization(model, train_loader, val_loader, criterion, optimizer, num_epochs, zero_grad=0, read_idx=1)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example

  Epoch 2/15, Training Loss: 0.4936, Validation Loss: 0.4046, Angle(U, W) : 87.0 °Epoch 3/15, Training Loss: 0.0007, Validation Loss: 0.0492, Angle(U, W) : 86.0 °

  Epoch 4/15, Training Loss: 0.8381, Validation Loss: 0.4423, Angle(U, W) : 93.0 °
  Epoch 5/15, Training Loss: 0.0000, Validation Loss: 0.0003, Angle(U, W) : 95.0 °
  Stopping training as loss has fallen below the threshold: 3.48795838363003e-05, 0.0002507442544204726
  Elapsed (with compilation) = 0h 2m 59s
  Epoch 1/15, Training Loss: 0.1418, Validation Loss: 0.3893, Angle(U, W) : 88.0 °
  Epoch 2/15, Training Loss: 0.0001, Validation Loss: 0.0010, Angle(U, W) : 89.0 °
  Stopping training as loss has fallen below the threshold: 8.502970013068989e-05, 0.0010245942115337432
  Elapsed (with compilation) = 0h 1m 31s
  Epoch 1/15, Training Loss: 0.8418, Validation Loss: 0.7893, Angle(U, W) : 89.0 °
  Epoch 2/15, Training Loss: 0.0311, Validation Loss: 0.0047, Angle(U, W) : 89.0 °
  Epoch 3/15, Training Loss: 0.0003, Validation Loss: 0.0007, Angle(U, W) : 88.0 °
  Stopping training as loss has fallen below the threshold: 0.00025136335170827806, 0.0007382531985058449
  Elapsed (with compilation) = 0h 2m 8s
  Epoch 1/15, Training Loss: 0.2941, Validation Loss: 0.2416, Angle(U, W) : 87.0 °
  Epoch 2/15, Training Loss: 0.0003, Validation Loss: 0.0016, Angle(U, W) : 89.0 °
  Stopping training as loss has fallen below the threshold: 0.0003162506618537009, 0.0015799709743381147
  Elapsed (with compilation) = 0h 1m 13s
  Epoch 1/15, Training Loss: 1.0045, Validation Loss: 0.9010, Angle(U, W) : 85.0 °
  Epoch 2/15, Training Loss: 0.1937, Validation Loss: 0.1304, Angle(U, W) : 89.0 °
  Epoch 3/15, Training Loss: 0.0002, Validation Loss: 0.0014, Angle(U, W) : 87.0 °
  Stopping training as loss has fallen below the threshold: 0.0001569792366353795, 0.0014423090557329488
  Elapsed (with compilation) = 0h 1m 49s
#+end_example
:END:

#+begin_src ipython
    torch.save(model.state_dict(), 'models/dual_train_%d.pth' % seed)
#+end_src

#+RESULTS:

#+begin_src ipython
  odors = model.odors.cpu().numpy()
  U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]
  W = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]

  print('   U  V  W  S  D')
  print('U ', angle_AB(U, U), angle_AB(U, V), angle_AB(U, W), angle_AB(U, odors[0]), angle_AB(U, odors[1]))
  print('V ', 'XXX', angle_AB(V, V), angle_AB(V, W), angle_AB(V, odors[0]), angle_AB(V, odors[1]))
  print('W ', 'XXX', 'XXX', angle_AB(W, W), angle_AB(W, odors[0]), angle_AB(W, odors[1]))
  print('S ', 'XXX', 'XXX', 'XXX', angle_AB(odors[0], odors[0]), angle_AB(odors[0], odors[1]))
  print('D ', 'XXX', 'XXX', 'XXX', 'XXX', angle_AB(odors[1], odors[1]))

#+end_src

#+RESULTS:
#+begin_example
  U  0 35 91 73 93
  V  XXX 0 91 69 88
  W  XXX XXX 0 90 88
  S  XXX XXX XXX 0 90
  D  XXX XXX XXX XXX 0
     U  V  W  S  D
  U  0 33 93 76 88
  V  XXX 0 92 71 85
  W  XXX XXX 0 90 92
  S  XXX XXX XXX 0 89
  D  XXX XXX XXX XXX 0
     U  V  W  S  D
  U  0 48 90 77 92
  V  XXX 0 90 66 93
  W  XXX XXX 0 94 88
  S  XXX XXX XXX 0 91
  D  XXX XXX XXX XXX 0
     U  V  W  S  D
  U  0 46 89 76 89
  V  XXX 0 90 67 92
  W  XXX XXX 0 89 89
  S  XXX XXX XXX 0 90
  D  XXX XXX XXX XXX 0
     U  V  W  S  D
  U  0 42 88 71 92
  V  XXX 0 87 67 94
  W  XXX XXX 0 91 92
  S  XXX XXX XXX 0 89
  D  XXX XXX XXX XXX 0
#+end_example

** Re-Testing

#+begin_src ipython
  model.DURATION = 8
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

    #+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
:RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
:END:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = A0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = -A0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = A0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = -A0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: ff_input torch.Size([4, 455, 2000])ff_input torch.Size([4, 455, 2000])
:
: ff_input torch.Size([4, 455, 2000])
: ff_input torch.Size([4, 455, 2000])
:END:

#+begin_src ipython
  labels_A = torch.ones((2*model.N_BATCH, 2))
  labels_B = torch.zeros((2*model.N_BATCH, 2))
  labels = torch.cat((labels_A, labels_B))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: labels torch.Size([4, 2])labels torch.Size([4, 2])
:
: labels torch.Size([4, 2])
: labels torch.Size([4, 2])
:END:

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).detach()
  print(rates.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: torch.Size([4, 81, 1000])torch.Size([4, 81, 1000])
:
: torch.Size([4, 81, 1000])
: torch.Size([4, 81, 1000])
:END:

 #+begin_src ipython
   rates = rates.cpu().detach().numpy()
   memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
   readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
   plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_train_overlap.svg')
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/fbd6e04dae1d6bd1afc9d6bfe8e8114085144758.png]]
[[file:./.ob-jupyter/aaa724a0854351a3b5a3eb66e95e5a6075b23186.png]]
[[file:./.ob-jupyter/a047c53193cac4e89de12b19463f9c5209663b35.png]]
[[file:./.ob-jupyter/6222fba9adff2e355486e40e5a61bdfbd481e9e3.png]]
[[file:./.ob-jupyter/7cd96404d5f13059b59d45f38fb2a9fb28712331.png]]
:END:

 #+begin_src ipython
   memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
   # readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
   readout = model.low_rank.linear.weight.data[0].cpu().detach().numpy()
   plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_train_overlap.svg')
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/f1ec209f6cd7aefa9ab26bffbd7a8138ba1d8fef.png]]
[[file:./.ob-jupyter/667bd15bad469b4823aacbde8c509635a474bf48.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/d4429474760db7644cf737c7609d9af88ad6d08e.png]]
[[file:./.ob-jupyter/7b168aece107de7ca4c047dd43f7ee3d6690c529.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/c075ccfdb459ea62f7630e7b45431ea318bd5b23.png]]
:END:

#+begin_src ipython
  idx = get_idx(model, 1)
  plot_rates_selec(rates, idx, figname='dual_train_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
:
[[file:./.ob-jupyter/d75cf7b0988c2cf6bee568c85a9378e3525a4027.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/765d7772be837055cddd5653d54ab9f28cdc33ce.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/2bf8f08dde50a0226f7cdb7352147b23bb0d4215.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/566b8b6082e53f9e553258bd87d88d9194d93dd6.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/372b63bd05a7245aa101f53afc14007878d2c02f.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx, figname='dual_train_fourier.svg')
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/631593e6c8d2347d620ac6af4a8c38378aa1aabb.png]]
[[file:./.ob-jupyter/4a47e79bd76c228b27affdd6c3dbdf1d145adad9.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/3ee23b2688896132f4a93cf260ad61a7f4792d99.png]]
[[file:./.ob-jupyter/00f0cb560dba6a72515c8153e690d1edd18e7887.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/c7eb3e4dfe5c78d949ed86cea768f390969116f5.png]]
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

** Fixed points

#+begin_src ipython
  model.DURATION = 20
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
  model.IF_RL = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
:RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
:END:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0
  model.I0[3] = 0
  model.I0[4] = 0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape, ff_input[0, 0, :4])
#+end_src

#+RESULTS:
:RESULTS:
:
: ff_input torch.Size([4, 1055, 2000]) tensor([26.4747, 27.8523, 28.0725, 24.2506], device='cuda:1')ff_input torch.Size([4, 1055, 2000]) tensor([29.9058, 29.3866, 29.5339, 26.2023], device='cuda:1')
:
: ff_input torch.Size([4, 1055, 2000]) tensor([29.6336, 29.1078, 27.0581, 26.5915], device='cuda:1')
: ff_input torch.Size([4, 1055, 2000]) tensor([29.1685, 28.0881, 29.7567, 29.6693], device='cuda:1')
:END:

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: (4, 201, 1000)(4, 201, 1000)
:
: (4, 201, 1000)
: (4, 201, 1000)
:END:

#+begin_src ipython
  idx = get_idx(model, 1)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
:
[[file:./.ob-jupyter/85e94f4096b8b7067e9c133093dc9ff88307e154.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/38fcd918b2883449bec246ae6b4fe511bc5284f5.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/5be30fb5981786208606f0e507ffacc9e144f3ae.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/e6d385e26eaf5b606088c2d37fd74a919ca0ea7d.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/bf5f1066121f04cca360fb9fb6a0974ad5656d6e.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/b6177514ce7c1c73422073388e29f0ec71533e8b.png]]
[[file:./.ob-jupyter/54e1f4a7bdbb2cf61da0486284e8a8a4aee26478.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/41f9be87d587a05991ccda4dd2a8b9dfc5ca90b0.png]]
[[file:./.ob-jupyter/1f277dd0e070e59839f0499e0827c2ba8537f07c.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/9522cbaffc42862d257abeb13684ae70ad505b54.png]]
:END:

#+begin_src ipython
  from matplotlib.patches import Circle
  m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

  x = m1 / m0 * np.cos(phi)
  y = m1 / m0 * np.sin(phi)

  xA = x
  yA = y

  fig, ax = plt.subplots(1, 1, figsize=[height, height])

  # ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
  # ax.plot(xA.T, yA.T, '-', alpha=.5)
  ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=20)
  # ax.set_xlim([-.9, .9])
  # ax.set_ylim([-.9, .9])
  circle = Circle((0., 0.), 1.7, fill=False, edgecolor='k')
  ax.add_patch(circle)

  # Set the aspect of the plot to equal to make the circle circular
  ax.set_aspect('equal')
  plt.savefig('fp_dual_train.svg', dpi=300)
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/4a6ed0ff943ab48d7db52fbcd045ce348a8d2036.png]]
[[file:./.ob-jupyter/1197793e7fa972dbf89cf04490497c9cbfd887f9.png]]
[[file:./.ob-jupyter/40d4a0ae01336c9bfeb9e63309dd67229891859b.png]]
[[file:./.ob-jupyter/e4982a3b4dd9b693dd2529b34e703bdac776e091.png]]
[[file:./.ob-jupyter/314bb706d3e49e9acaf5c48b2f428be11e3c3cd6.png]]
:END:

#+RESULTS:

    #+begin_src ipython

  #+end_src

#+RESULTS:

** Load models

#+begin_src emacs-lisp
  (defun lc/org-reevaluate-buffer-n-times (n)
    "Reevaluate the current Org buffer N times."
    (interactive "nHow many times to reevaluate the buffer? ")
    (dotimes (_ n)
      (org-babel-execute-buffer)))
#+end_src

#+RESULTS:
: lc/org-reevaluate-buffer-n-times


#+begin_src ipython
  import os

  model_directory = "./models/"
  model_files = [f for f in os.listdir(model_directory) if f.startswith("dual_train_") and f.endswith(".pth")]

  model.DURATION = 20
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  def create_input(model):
      model.N_BATCH = 1

      model.I0[0] = A0
      model.I0[1] = 0
      model.I0[2] = 0
      model.I0[3] = 0
      model.I0[4] = 0

      AC_pair = model.init_ff_input()

      model.I0[0] = -A0
      model.I0[1] = 0
      model.I0[2] = 0
      model.I0[3] = 0
      model.I0[4] = 0

      AD_pair = model.init_ff_input()

      return torch.cat((AC_pair, AD_pair))
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_circle(rates, idx, ax):
      m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

      x = m1 / m0 * np.cos(phi)
      y = m1 / m0 * np.sin(phi)

      ax.plot(x.T[-1], y.T[-1], 'o', alpha=.5, ms=20)

#+end_src

#+RESULTS:

#+begin_src ipython
  fig, ax = plt.subplots(1, 1, figsize=[height, height])

  rates_list = []
  idx_list = []

  for model_file in model_files:
      model_path = os.path.join(model_directory, model_file)
      model_state_dict = torch.load(model_path)

      seed_str = model_file.split('_')[2].split('.')[0]  # Assumes format dual_train_XXXX.pth
      seed = int(seed_str)
      # print(model_file)
      # print(seed)

      model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=4)
      model.load_state_dict(model_state_dict)
      model.eval()  # Set to evaluation mode


      model.DURATION = 20
      model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW

      ff_input = create_input(model)

      rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
      rates_list.append(rates)
      # plot_m0_m1_phi(rates, idx)

      idx = get_idx(model, 1)
      idx_list.append(idx)

      plot_circle(rates, idx, ax)

  circle = Circle((0., 0.), 1.7, fill=False, edgecolor='k')
  ax.add_patch(circle)
  ax.set_aspect('equal')
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1000])
: ksi torch.Size([5, 1000])
: ksi torch.Size([5, 1000])
: ksi torch.Size([5, 1000])
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/ca380efcd63ac35d128e312f9726e7c38df05eea.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates_list[1], idx_list[1])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/a2110cae4327745e8365ef5302c90c7102fb51d0.png]]

** Opto


#+begin_src ipython
  model.DURATION = 8
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
  model.IF_RL = 0
  model.RWD = 5
#+end_src

#+RESULTS:

    #+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
:RESULTS:
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
: Network(
:   (low_rank): LowRankWeights(
:     (linear): Linear(in_features=1000, out_features=1, bias=True)
:     (dropout): Dropout(p=0.0, inplace=False)
:   )
: )
:END:

#+begin_src ipython
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]

  plt.hist(memory, bins='auto');
  # plt.hist(readout, bins='auto');
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/6f316e5a69a832f5fa059b82bb5fff50797b32c6.png]]
[[file:./.ob-jupyter/5e09e29db83f143d93154d0637faeeb864e21414.png]]
[[file:./.ob-jupyter/5e09e29db83f143d93154d0637faeeb864e21414.png]]
[[file:./.ob-jupyter/5e09e29db83f143d93154d0637faeeb864e21414.png]]
[[file:./.ob-jupyter/5e09e29db83f143d93154d0637faeeb864e21414.png]]
:END:


#+begin_src ipython
  N_OPTO = 250
  readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
  # idx = np.random.choice(range(1000), N_OPTO, replace=False)
  idx = readout.argsort()[:N_OPTO]
  # idx = []
  # idx = np.flip(readout.argsort())[:N_OPTO]
  # print(idx)
#+end_src

#+RESULTS:

#+begin_src ipython
  Wab_T = model.Wab_T.clone()
  W_stp_T = model.W_stp_T.clone()

  # model.Wab_T[idx, :1000] = 0
  model.W_stp_T[idx, :1000] = 0
  model.low_rank.lr_mask[:1000, idx] = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = A0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = -A0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = A0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = A0
  model.I0[2] = float(B0)
  model.I0[3] = float(C0) * model.IF_RL # rwd
  model.I0[4] = -A0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 455, 2000])
: ff_input torch.Size([4, 455, 2000])
: ff_input torch.Size([4, 455, 2000])
:RESULTS:
:
: ff_input torch.Size([4, 455, 2000])
:END:

#+begin_src ipython
  labels_A = torch.ones((2*model.N_BATCH, 2))
  labels_B = torch.zeros((2*model.N_BATCH, 2))
  labels = torch.cat((labels_A, labels_B))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: labels torch.Size([4, 2])labels torch.Size([4, 2])
:
: labels torch.Size([4, 2])
: labels torch.Size([4, 2])
:END:

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).detach()
  model.Wab_T = Wab_T.clone()
  model.W_stp_T = W_stp_T.clone()
  model.low_rank.lr_mask[:1000, idx] = 1
  print(rates.shape)
#+end_src

#+RESULTS:
:RESULTS:
:
: torch.Size([4, 81, 1000])torch.Size([4, 81, 1000])
:
: torch.Size([4, 81, 1000])
: torch.Size([4, 81, 1000])
:END:

 #+begin_src ipython
   rates = rates.cpu().detach().numpy()
   memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
   readout = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 1]
   # readout = model.low_rank.linear.weight.data[0].cpu().detach().numpy()
   plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_opto_overlap.svg')
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/ada797b2d1de41a967eb2d3ed609791b25fd6851.png]]
[[file:./.ob-jupyter/2347f87fb124b54e2290fd28cc02c2d228e39aab.png]]
[[file:./.ob-jupyter/373fa183c21d9d1340d8d2833391bdf1b1ec9096.png]]
[[file:./.ob-jupyter/5b1e45b691297ae3c2e1b9ffbd10bf4d48951369.png]]
[[file:./.ob-jupyter/69bdf02a288d14ae62d1dce86b787a2ce0ff8ccb.png]]
:END:

 #+begin_src ipython
   memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
   readout = model.low_rank.linear.weight.data[0].cpu().detach().numpy()
   plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_opto_overlap.svg')
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/70f1ab41145d5293ee321714534ee0b664b470ca.png]]
[[file:./.ob-jupyter/9b10297d3d0c83919e67e492dc6b54708f5671cc.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/8ed1e8cfb2c5cf35aa8bde3dad6f8ed84c275176.png]]
[[file:./.ob-jupyter/030c1c693655b90a9e00f448c1deae3f51491910.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/c675fa73f2e8f29eba4b0e635f4e7127af55525b.png]]
:END:

#+begin_src ipython
  idx = get_idx(model, 1)
  plot_rates_selec(rates, idx, figname='dual_opto_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
:
[[file:./.ob-jupyter/aae16aa46614a806fd5a7753a06b394ecd036219.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/23009012b632a8a7fa34d1fbe40af772d5e8e4a5.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/250e6c925173773d6dc8ddea8f97e1c3f0bc792b.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/2ffaa168f7e94cc4d36ae4b8493ab87a28167711.png]]
: ksi torch.Size([5, 1000])
[[file:./.ob-jupyter/6cd186829bc02fdb8d64d9b90b72fc0a01ef1ca5.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx, figname='dual_opto_fourier.svg')
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/aa7b92a15eb0031c424daef8e2cd4217eadaa127.png]]
[[file:./.ob-jupyter/c435d70ea48b6b0507c7a316434212f969539224.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/65600199ee173d3016e5e8b36b7f24b5a368dd26.png]]
[[file:./.ob-jupyter/6e4092a432375b190599071675f673de9a6c0191.png]]
:END:
:RESULTS:
[[file:./.ob-jupyter/0e2285faf010ec25e83fad7bb9048903ae25bc09.png]]
:END:
