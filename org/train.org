#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session dual :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroTorch"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Helpers
** Training
*** split data

#+begin_src ipython
  def split_data(X, Y, train_perc=0.8, batch_size=32):

    # Split the dataset into training and validation sets
    train_size = int(train_perc * X.shape[0])

    X_train = X[:train_size]
    X_test = X[train_size:]

    # X_train, X_mean, X_std = standard_scaler(X_train, IF_RETURN=1)
    # X_test = (X_test - X_mean) / X_std

    Y_train = Y[:train_size]    
    Y_test = Y[train_size:]

    # Y_train, Y_mean, Y_std = standard_scaler(Y_train, IF_RETURN=1)
    # Y_test = (Y_test - Y_mean) / Y_std

    # Create data sets
    # train_dataset = TensorDataset(X_train_scaled, Y_train_scaled)
    # val_dataset = TensorDataset(X_test_scaled, Y_test_scaled)

    # print('X_train', X_train.shape, 'y_train', Y_train.shape)
    train_dataset = TensorDataset(X_train, Y_train)

    # print('X_test', X_test.shape, 'y_test', Y_test.shape)
    val_dataset = TensorDataset(X_test, Y_test)
    
    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    # sequence_length = 14  # or any other sequence length you want
    # stride = 1  # or any other stride you want

    # sliding_window_dataset = SlidingWindowDataset(X, sequence_length, stride)
    # train_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)
    # val_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)

    return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
  def train(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1):
      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          optimizer.zero_grad()

          X, y = X.to(device), y.to(device)
          # Compute prediction error
          y_pred = model(X)
          loss = loss_fn(y_pred, y)

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()
          optimizer.step()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def test(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0
      with torch.no_grad():
          for data, targets in dataloader:
              data, targets = data.to(device), targets.to(device)
              
              outputs = model(data)
              loss = loss_fn(outputs, targets)
              val_loss += loss.item() * data.size(0)
          val_loss /= size

      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def run_optim(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1):

    # scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)

    loss_list = []
    val_loss_list = []

    # Training loop.
    for epoch in range(num_epochs):
        loss = train(train_loader, model, loss_fn, optimizer, penalty, lbd)
        val_loss = test(val_loader, model, loss_fn)
        scheduler.step(val_loss)

        loss_list.append(loss.item())
        val_loss_list.append(val_loss)

        # if epoch % int(num_epochs  / 10) == 0:
        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

    return loss_list, val_loss_list
#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
  def correlation_loss(output, target):
      # Subtract the mean of each vector
      output_mean = output - torch.mean(output)
      target_mean = target - torch.mean(target)
    
      # Compute the covariance between output and target
      covariance = torch.mean(output_mean * target_mean)
      
      # Compute the standard deviations of the vectors
      output_std = torch.std(output)
      target_std = torch.std(target)
    
      # Calculate the Pearson correlation coefficient
      correlation = covariance / (output_std * target_std)
    
      # Since we want to increase the correlation, we minimize its negative
      loss = -correlation  # Maximizing correlation by minimizing its negative
    
      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
    import torch
    import torch.nn as nn

    def sign_constrained_loss(output, xi, target_sign):
        dot_product = torch.dot(output.flatten(), xi.flatten())
        if target_sign > 0:
            loss = torch.relu(-dot_product)  # Encourages positive dot product
        else:
            loss = torch.relu(dot_product)   # Encourages negative dot product
        return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  class CosineLoss(nn.Module):
      def __init__(self):
          super(CosineLoss, self).__init__()
          self.cosine_similarity = nn.CosineSimilarity(dim=-1)
          
      def forward(self, input1, input2):
          # Calculate cosine similarity
          cosine_sim = self.cosine_similarity(input1, input2)
          # Calculate the loss as 1 - cosine_similarity
          loss = 1 - cosine_sim
          # Return the mean loss over the batch
          return loss.mean()
#+end_src

#+RESULTS:


#+RESULTS:

** Other

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      u, v = a, b

      if GM:          
          v = b - np.dot(b, a) / np.dot(a, a) * a
          
      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)

      return np.arctan2(v, u)
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_idx(model):
      ksi = model.U.cpu().detach().numpy().T
      # ksi = model.PHI0.cpu().detach().numpy()

      print(ksi.shape)
      
      theta = get_theta(ksi[0], ksi[1], GM=0, IF_NORM=0)
      theta = get_theta(ksi[0][:model.Na[0]], ksi[1][:model.Na[0]], GM=0, IF_NORM=0)

      return theta.argsort()
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_overlap(model, rates):
      ksi = model.PHI0.cpu().detach().numpy()
      return rates @ ksi.T / rates.shape[-1]
  
#+end_src

#+RESULTS:

#+begin_src ipython
  import scipy.stats as stats

  def plot_smooth(data, ax, color):
      mean = data.mean(axis=0)  
      ci = smooth.std(axis=0, ddof=1) * 1.96
      
      # Plot
      ax.plot(mean, color=color)
      ax.fill_between(range(data.shape[1]), mean - ci, mean + ci, alpha=0.25, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter  
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl
#+end_src

#+RESULTS:

* Train RNN
** Parameters

#+Begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroTorch"
  conf_name = "config_train.yml"
#+end_src

#+RESULTS:

** Model

#+begin_src ipython
  start = perf_counter()
  model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE='cuda', SEED=0)
#+end_src

#+RESULTS:

#+begin_src ipython
for name, param in model.named_parameters():
    if param.requires_grad:
        print(name, param.data)
#+end_src

#+RESULTS:
#+begin_example
  U tensor([[ 0.2977,  0.5942],
          [-0.4112, -0.6682],
          [-0.2976, -1.4120],
          ...,
          [ 1.3492,  1.0612],
          [ 0.4737,  0.0444],
          [ 0.8238,  1.1250]], device='cuda:0')
  lr_kappa tensor([1.2297], device='cuda:0')
  linear.weight tensor([[-3.1109e-03, -3.4396e-02, -2.5732e-02, -2.2767e-02,  6.7266e-03,
           -1.5868e-02,  2.3995e-02, -4.0456e-02,  3.2401e-02,  2.5510e-02,
           -3.1514e-02, -9.5425e-03, -1.1611e-02, -2.3405e-02, -2.3165e-02,
            1.7676e-02, -3.3339e-02,  3.0477e-02, -2.6717e-02,  3.4337e-02,
            1.2143e-02,  2.5977e-02,  1.4700e-02, -3.4412e-02, -4.3256e-02,
            4.3283e-02,  1.0186e-02, -3.0978e-02,  3.0077e-02,  3.4422e-02,
            2.4860e-02,  3.9334e-02,  2.7227e-02, -1.1319e-02, -3.4972e-02,
            4.4301e-02,  6.3631e-03,  3.9933e-02,  2.5942e-03, -7.5359e-03,
            3.8421e-02, -1.7824e-02,  1.1587e-02,  2.5796e-02,  2.8886e-02,
           -1.1315e-03,  3.9511e-02,  3.5819e-02, -3.6065e-03,  3.4422e-02,
           -7.9159e-03,  2.1247e-02,  2.6675e-02, -3.4427e-02,  3.3631e-02,
           -3.9805e-02,  1.0964e-02,  3.6599e-02,  3.5241e-02,  3.1509e-02,
            3.8964e-02,  1.0944e-02, -3.2410e-02,  5.3459e-03,  1.2457e-02,
            4.2103e-02, -5.6034e-03, -1.2852e-02,  2.9877e-02, -2.6293e-02,
           -3.5450e-02, -1.7979e-02, -3.8420e-02, -9.4088e-03,  1.8826e-02,
           -4.3168e-03, -2.1801e-03, -3.2314e-02,  3.0339e-02, -1.7691e-02,
           -3.2427e-02, -5.6584e-03, -4.2861e-03,  3.4492e-02,  1.2335e-02,
            2.0837e-02,  1.1738e-02,  1.0714e-02, -1.9655e-02,  2.7642e-02,
            3.8008e-02,  4.2055e-02, -4.8671e-03, -2.0728e-02, -1.9289e-02,
           -4.0297e-02, -2.6153e-02,  2.6294e-02, -1.0171e-02,  5.6483e-03,
           -1.5890e-02,  1.0694e-02, -1.3883e-02,  7.2346e-03,  1.0904e-04,
           -1.2608e-03,  2.1107e-02, -1.7534e-02,  1.9312e-02,  1.2001e-02,
            3.6134e-02, -1.5614e-02,  3.9058e-02, -1.9808e-02, -4.2253e-02,
           -8.1481e-03, -1.9353e-02,  2.5420e-02,  1.2973e-02,  2.0207e-02,
            3.5299e-02, -1.7155e-02, -4.2235e-02,  4.3781e-02, -2.9859e-02,
           -5.3226e-04,  1.2711e-02,  3.8773e-02, -4.7992e-03, -9.1565e-03,
           -2.8612e-02,  4.7854e-03, -6.6057e-03,  1.5289e-02, -5.8390e-04,
           -4.3823e-02, -1.6622e-02,  2.0711e-02, -1.9079e-02, -3.1929e-02,
           -2.1831e-02, -3.7239e-02, -2.6618e-02,  4.3614e-02, -1.9764e-02,
           -1.7396e-02, -9.5674e-03,  1.5487e-02,  2.6653e-02,  4.3430e-02,
           -2.4345e-02, -1.8742e-02,  2.3860e-02,  2.5893e-02,  7.1022e-03,
           -7.0638e-07,  4.2783e-02, -7.9059e-03,  2.5175e-02, -3.1760e-02,
           -2.3349e-02,  7.1883e-03, -5.6934e-03, -1.8279e-02,  2.0515e-02,
            2.0768e-03,  1.3729e-02,  4.4014e-02, -5.6042e-03, -3.3291e-02,
           -1.1257e-02, -3.2675e-03, -3.1741e-02, -7.2530e-03,  2.2922e-02,
           -4.1396e-02,  3.2534e-02,  5.8436e-03,  1.2483e-02, -2.6934e-02,
           -3.4476e-02,  3.9452e-02,  1.5173e-02,  1.9482e-02,  3.7145e-02,
            4.1685e-02, -2.9711e-02,  3.3594e-02, -1.3119e-02,  2.0353e-03,
           -1.9268e-02, -4.2193e-02,  8.6535e-03, -1.1738e-02, -1.5999e-02,
            4.2795e-02,  9.8794e-03, -1.4576e-02, -3.2296e-02, -1.5814e-02,
            3.8083e-02, -1.9685e-02,  1.3351e-03, -4.0986e-02,  3.2264e-02,
            1.6839e-03, -2.6932e-02,  8.1520e-03,  3.1026e-02,  3.4447e-02,
            3.7456e-02,  5.9219e-03, -2.9363e-02,  8.0805e-04,  3.7732e-03,
            2.1809e-02, -2.9398e-04, -5.1553e-03, -2.5436e-02, -8.4269e-03,
            1.1506e-02,  1.8849e-02, -1.3123e-02,  2.7259e-02,  9.7478e-03,
            1.7135e-02, -8.3546e-03,  3.3733e-03,  2.2017e-02, -2.5246e-02,
            2.5938e-02, -4.4711e-02, -4.3730e-02, -3.8831e-02,  4.0565e-02,
            2.2539e-02,  1.2948e-02, -3.3747e-02, -3.2489e-02, -1.1681e-02,
           -2.4601e-02, -1.4774e-02,  8.9946e-03, -2.3559e-02, -3.0495e-02,
           -2.5413e-02,  3.2582e-02,  9.6996e-03,  5.9120e-03,  2.9997e-02,
           -3.5469e-02,  3.0834e-02, -4.2325e-02,  4.1609e-02,  6.1816e-03,
           -3.9704e-02,  1.5443e-02, -1.7003e-02, -3.6354e-02,  2.2816e-02,
            3.8443e-02,  1.3477e-02,  2.8949e-02,  6.4904e-03,  4.1951e-02,
           -2.9219e-02, -3.6801e-02,  2.0571e-02,  4.2621e-02, -2.0991e-02,
            4.0333e-02, -4.1121e-02,  2.0255e-02, -1.5394e-02,  3.3942e-02,
            4.7751e-03,  2.0607e-02, -1.0114e-02,  2.9099e-02,  1.1924e-03,
           -1.4546e-02,  1.4216e-02, -2.0131e-02,  3.1790e-02,  4.1033e-02,
            3.4374e-02, -2.0687e-02,  3.0299e-02, -5.6145e-04,  3.7031e-02,
            2.8111e-02, -1.4274e-02,  3.9585e-02, -1.2333e-02, -2.3264e-02,
           -3.6607e-02,  5.7014e-03,  4.2453e-02,  3.9873e-02, -2.4969e-02,
            3.5384e-02,  1.7772e-02, -2.7344e-02,  2.1581e-02, -3.5034e-02,
            2.2069e-02, -9.5902e-03,  1.5405e-02, -3.0839e-02,  3.6529e-02,
           -2.7866e-02, -2.2285e-02,  2.6759e-03,  2.4500e-02,  3.8289e-02,
            2.7548e-02, -2.1370e-02, -6.8878e-04,  2.2297e-02,  1.3590e-02,
            3.6457e-02, -8.3061e-04, -4.1981e-02,  4.2522e-03, -1.7489e-02,
           -5.7668e-03, -4.6883e-03,  2.2634e-02, -2.7702e-02,  2.1065e-02,
           -4.1537e-02,  2.8343e-02,  1.6376e-02, -1.7837e-02, -3.3440e-02,
            1.4760e-02, -1.3693e-02, -1.6741e-02, -3.1896e-02, -8.8663e-04,
            1.7179e-02, -2.9593e-02, -1.9872e-02, -2.0368e-02, -6.8316e-03,
            2.3104e-03,  8.6347e-03, -2.7850e-02,  6.9992e-03, -2.4443e-02,
            3.2852e-02,  8.6647e-03, -2.2279e-03,  1.4064e-02, -2.4061e-02,
            2.0431e-02,  3.7490e-02, -2.1713e-02,  6.2708e-03,  1.5459e-02,
            3.4641e-02, -2.9314e-02,  2.5723e-02,  2.9851e-02,  3.6708e-02,
            2.4259e-02,  1.1685e-02, -7.3292e-03,  2.4812e-02,  2.4804e-02,
            9.3713e-03, -3.4392e-02, -4.1620e-02, -1.5304e-02, -1.7071e-02,
            3.2395e-02, -2.5148e-02, -4.4422e-02, -4.3584e-02, -1.4036e-02,
            3.7153e-02,  2.8900e-02, -1.1906e-02, -3.9335e-02,  3.9390e-03,
           -1.1415e-02, -1.3908e-02,  3.7849e-03,  3.8642e-02,  8.1470e-03,
           -1.9263e-02,  1.3716e-02, -1.5996e-02,  2.3656e-02, -3.0961e-02,
           -3.3437e-02, -5.9996e-03, -3.5782e-02,  3.4102e-02,  1.1894e-03,
            2.3032e-02, -1.7130e-02, -3.4730e-02,  2.9674e-02,  1.7247e-02,
            2.4224e-02, -8.9046e-03, -5.0372e-04, -3.6759e-02, -2.2392e-02,
           -3.8642e-02,  3.6911e-02,  3.8047e-02,  2.7605e-02, -1.3211e-02,
            1.6702e-02,  1.2099e-02,  4.5438e-03, -1.4892e-03, -3.5084e-02,
           -3.1003e-02,  2.9539e-02, -6.5009e-03,  4.1881e-03,  7.8922e-03,
            4.2246e-02, -4.2929e-02, -2.8917e-02,  9.7259e-04,  3.0485e-02,
           -1.3063e-02, -4.4163e-02, -4.3819e-02, -3.7422e-02, -2.0687e-03,
           -2.8172e-02,  2.9118e-03, -1.7128e-02, -1.7965e-02, -4.1408e-02,
           -3.4438e-02, -3.1606e-02, -1.3605e-02,  3.1203e-02,  3.1148e-02,
           -1.5195e-02, -7.1566e-03,  3.8548e-02,  1.1666e-02,  6.0899e-03,
           -5.4576e-03, -2.7121e-02,  3.6052e-02, -3.3468e-02,  3.9629e-03,
           -3.8267e-02,  3.8597e-02,  1.5494e-02, -2.2654e-02,  3.9652e-02,
           -1.4014e-02,  2.0798e-02, -2.7300e-02, -3.9297e-02, -2.8413e-02,
           -2.1422e-02,  2.6151e-02, -1.9526e-02,  3.6530e-02, -1.7642e-02,
            1.5532e-02, -3.0658e-02, -3.1045e-02, -3.7597e-02, -3.3580e-02,
            3.3648e-02, -3.3443e-02, -4.4190e-02,  1.1669e-02, -3.7539e-02,
           -3.9321e-02,  2.6253e-02, -8.1988e-03, -1.0469e-02,  4.3888e-02,
            6.2491e-03, -2.1774e-02,  3.5552e-02,  2.7851e-02, -3.1863e-02,
            3.6139e-02,  2.1169e-02,  2.6071e-02,  3.8488e-02, -1.5099e-02,
           -2.7607e-02, -7.5970e-03,  2.9537e-02,  2.2346e-03, -2.4155e-02]],
         device='cuda:0')
#+end_example

** Inputs and labels

#+begin_src ipython
  model.N_BATCH = 16

  model.I0[0] = 1
  model.I0[1] = 0 # 1 

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 0 # -1

  AD_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0 # 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0 #-1

  BD_pair = model.init_ff_input()
  
  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([64, 1220, 1000])

#+begin_src ipython
  labels_pair = torch.zeros((2 * model.N_BATCH, model.lr_eval_win))
  labels_unpair = torch.ones((2 * model.N_BATCH, model.lr_eval_win))
  
  labels = torch.cat((labels_pair, labels_unpair))
  print(ff_input.shape, labels.shape)
#+end_src

#+RESULTS:
: torch.Size([64, 1220, 1000]) torch.Size([64, 10])

#+begin_src ipython
  # plt.imshow(ff_input[0].T.cpu().detach().numpy(), cmap='jet', aspect='auto')
#+end_src

#+RESULTS:

** Train

#+begin_src ipython
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  batch_size = 32
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)

  learning_rate = 0.01

  # CosineLoss, BCELoss, BCEWithLogitLoss
  criterion = nn.BCEWithLogitsLoss()

  # SGD, Adam, AdamW
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
  
  num_epochs = 30
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
#+End_src

#+RESULTS:
#+begin_example
  Epoch 1/30, Training Loss: 4.0994, Validation Loss: 5.8809
  Epoch 2/30, Training Loss: 0.9136, Validation Loss: 0.0135
  Epoch 3/30, Training Loss: 1.6247, Validation Loss: 0.1432
  Epoch 4/30, Training Loss: 0.7629, Validation Loss: 3.4055
  Epoch 5/30, Training Loss: 1.1101, Validation Loss: 1.9943
  Epoch 6/30, Training Loss: 0.9773, Validation Loss: 0.8513
  Epoch 7/30, Training Loss: 0.7978, Validation Loss: 2.7192
  Epoch 8/30, Training Loss: 0.7426, Validation Loss: 0.4892
  Epoch 9/30, Training Loss: 0.5730, Validation Loss: 2.8649
  Epoch 10/30, Training Loss: 0.5611, Validation Loss: 1.7771
  Epoch 11/30, Training Loss: 0.6323, Validation Loss: 0.5949
  Epoch 12/30, Training Loss: 0.7374, Validation Loss: 2.0069
  Epoch 13/30, Training Loss: 1.0896, Validation Loss: 2.1670
  Epoch 14/30, Training Loss: 0.6998, Validation Loss: 1.8329
  Epoch 15/30, Training Loss: 0.7409, Validation Loss: 1.4155
  Epoch 16/30, Training Loss: 0.5580, Validation Loss: 1.0463
  Epoch 17/30, Training Loss: 0.6240, Validation Loss: 0.9346
  Epoch 18/30, Training Loss: 0.6564, Validation Loss: 1.0400
  Epoch 19/30, Training Loss: 0.6361, Validation Loss: 1.2855
  Epoch 20/30, Training Loss: 0.6466, Validation Loss: 1.5466
  Epoch 21/30, Training Loss: 0.5096, Validation Loss: 1.8129
  Epoch 22/30, Training Loss: 0.5849, Validation Loss: 2.0269
  Epoch 23/30, Training Loss: 0.6594, Validation Loss: 2.1324
  Epoch 24/30, Training Loss: 0.6791, Validation Loss: 2.0931
  Epoch 25/30, Training Loss: 0.5914, Validation Loss: 2.0829
  Epoch 26/30, Training Loss: 0.6047, Validation Loss: 2.0476
  Epoch 27/30, Training Loss: 0.6559, Validation Loss: 2.0266
  Epoch 28/30, Training Loss: 0.5619, Validation Loss: 1.9951
  Epoch 29/30, Training Loss: 0.5650, Validation Loss: 1.9762
  Epoch 30/30, Training Loss: 0.5253, Validation Loss: 1.9422
#+end_example

#+begin_src ipython
  model.eval()
#+end_src

#+RESULTS:
: Network(
:   (linear): Linear(in_features=500, out_features=1, bias=False)
: )

#+begin_src ipython
  plt.plot(loss[:10])
  plt.plot(val_loss[:10])
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/38f97d9f18b50d20cd4b4bf9a5bee33f140a33c4.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* Results

#+begin_src ipython
  ksi = model.U.T
  # ksi = torch.stack((model.U.T[0], model.V.T[0]))
  print(ksi.shape)
  
  print('kappa', model.lr_kappa.cpu().detach())

  angle = torch.arccos(nn.CosineSimilarity(dim=0)(ksi[0], ksi[1])) * 180 / torch.pi
  print('angle ksi1 vs ksi2', angle.cpu().detach())

  var = torch.var(ksi, axis=-1)
  print('variances', var.cpu().detach())
#+end_src

#+RESULTS:
: torch.Size([2, 1000])
: kappa tensor([1.2297])
: angle ksi1 vs ksi2 tensor(90.4251)
: variances tensor([1.0075, 1.0051])

#+begin_src ipython
  lr = (1.0 + model.U @ model.U.T / torch.sqrt(model.Ka[0]))
  weights = model.Wab_T * lr
  weights = weights.cpu().detach().numpy()
#+end_src

#+RESULTS:

#+begin_src ipython  
  plot_con(weights)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/f098580a78563d2195853fde63c88b061bc8bcb7.png]]

#+begin_src ipython
  readout = model.linear.weight.data[0]
  print(readout.shape)
#+end_src

#+RESULTS:
: torch.Size([500])

#+begin_src ipython
  read0 = nn.CosineSimilarity(dim=0)(model.U[:model.Na[0],0], readout).cpu().detach().numpy()
  read1 = nn.CosineSimilarity(dim=0)(model.U[:model.Na[0],1], readout).cpu().detach().numpy()

  print('angle readout vs ksis', np.arccos(read0)*180/np.pi, np.arccos(read1)*180/np.pi)
#+end_src

#+RESULTS:
: angle readout vs ksis 93.46348897975409 115.27968692466509

** Eval

#+begin_src ipython
  model.eval()

  lr = (1.0 + model.mask * (model.U @ model.U.T))  
  model.Wab_T = model.Wab_T * lr.T

  model.N_BATCH = 1
  model.VERBOSE=1
  model.LR_TRAIN=0
  # print(model.ff_input.shape)
  # print(ff_input.shape)
#+end_src

#+RESULTS:

#+begin_src ipython
  rates = model.forward(RET_FF=1).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
#+begin_example
  Generating ff input
  times (s) 0.0 rates (Hz) [1.69, 1.36]
  times (s) 0.08 rates (Hz) [1.69, 1.36]
  times (s) 0.16 rates (Hz) [1.69, 1.37]
  times (s) 0.25 rates (Hz) [1.69, 1.37]
  times (s) 0.33 rates (Hz) [1.69, 1.37]
  times (s) 0.41 rates (Hz) [1.69, 1.37]
  times (s) 0.49 rates (Hz) [1.69, 1.37]
  times (s) 0.57 rates (Hz) [1.69, 1.37]
  times (s) 0.66 rates (Hz) [1.69, 1.37]
  times (s) 0.74 rates (Hz) [1.69, 1.37]
  times (s) 0.82 rates (Hz) [1.73, 1.37]
  times (s) 0.9 rates (Hz) [1.7, 1.37]
  times (s) 0.98 rates (Hz) [1.67, 1.36]
  times (s) 1.07 rates (Hz) [1.66, 1.35]
  times (s) 1.15 rates (Hz) [1.65, 1.35]
  times (s) 1.23 rates (Hz) [1.65, 1.34]
  times (s) 1.31 rates (Hz) [1.65, 1.34]
  times (s) 1.39 rates (Hz) [1.64, 1.34]
  times (s) 1.48 rates (Hz) [1.64, 1.34]
  times (s) 1.56 rates (Hz) [1.65, 1.34]
  times (s) 1.64 rates (Hz) [1.62, 1.34]
  times (s) 1.72 rates (Hz) [1.62, 1.33]
  times (s) 1.8 rates (Hz) [1.63, 1.33]
  times (s) 1.89 rates (Hz) [1.64, 1.34]
  times (s) 1.97 rates (Hz) [1.64, 1.34]
  times (s) 2.05 rates (Hz) [1.65, 1.34]
  times (s) 2.13 rates (Hz) [1.66, 1.35]
  times (s) 2.21 rates (Hz) [1.66, 1.35]
  times (s) 2.3 rates (Hz) [1.67, 1.35]
  times (s) 2.38 rates (Hz) [1.67, 1.36]
  times (s) 2.46 rates (Hz) [1.67, 1.36]
  times (s) 2.54 rates (Hz) [1.68, 1.36]
  times (s) 2.62 rates (Hz) [1.68, 1.36]
  times (s) 2.7 rates (Hz) [1.68, 1.36]
  times (s) 2.79 rates (Hz) [1.68, 1.36]
  times (s) 2.87 rates (Hz) [1.68, 1.36]
  times (s) 2.95 rates (Hz) [1.68, 1.36]
  times (s) 3.03 rates (Hz) [1.68, 1.36]
  times (s) 3.11 rates (Hz) [1.69, 1.36]
  times (s) 3.2 rates (Hz) [1.69, 1.36]
  times (s) 3.28 rates (Hz) [1.69, 1.36]
  times (s) 3.36 rates (Hz) [1.69, 1.36]
  times (s) 3.44 rates (Hz) [1.69, 1.36]
  times (s) 3.52 rates (Hz) [1.69, 1.37]
  times (s) 3.61 rates (Hz) [1.69, 1.37]
  times (s) 3.69 rates (Hz) [1.69, 1.37]
  times (s) 3.77 rates (Hz) [1.69, 1.37]
  times (s) 3.85 rates (Hz) [1.69, 1.37]
  times (s) 3.93 rates (Hz) [1.69, 1.37]
  times (s) 4.02 rates (Hz) [1.69, 1.37]
  times (s) 4.1 rates (Hz) [1.69, 1.37]
  (1, 51, 500)
#+end_example

#+begin_src ipython
  plt.plot(model.ff_input.cpu().detach().numpy()[0,:, :10])
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/e91f0e7308afc5ef30e73b104da102e967df8b36.png]]

#+begin_src ipython
  plt.imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=30)
  plt.vlines((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  plt.vlines((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  plt.ylabel('Neuron #')
  plt.xlabel('Step')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/28e77612398c2537f0fe3542d58e53be4df3d3ae.png]]

#+begin_src ipython
  idx = get_idx(model)
  ordered = rates[..., idx]
  print(ordered.shape)
#+end_src

#+RESULTS:
: (2, 1000)
: (1, 51, 500)

#+begin_src ipython
  plt.imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=30.0)
  plt.yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))
  plt.vlines((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  plt.vlines((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
  plt.ylabel('Pref. Location (°)')
  plt.xlabel('Step')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/2e9fa73edb22df6666a117d603f8566e65d1ff2b.png]]

#+begin_src ipython
  print(model.N_STIM_ON)
#+end_src

#+RESULTS:
: [400 800]

#+begin_src ipython
  y_pred = model.linear.weight.data.cpu().detach().numpy()[0]
  print(y_pred.shape)

  overlap = (rates @ y_pred) / rates.shape[-1]
  print(overlap.shape)
  plt.plot(overlap.T)
  plt.xlabel('Step')
  plt.ylabel('Overlap')
  
  plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: (500,)
: (1, 51)
[[file:./.ob-jupyter/4f7a86ccc95745e0171d68eebb163c296f0c78b7.png]]
:END:

#+begin_src ipython
  m0, m1, phi = decode_bump(ordered, axis=-1)
#+end_src

#+RESULTS:

#+begin_src ipython
  fig, ax = plt.subplots(1, 3, figsize=[2*width, height])
  
  ax[0].plot(m0.T)
  #ax[0].set_ylim([0, 360])
  #ax[0].set_yticks([0, 90, 180, 270, 360])
  ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
  ax[0].set_xlabel('Step')

  ax[1].plot(m1.T)
  # ax[1].set_ylim([0, 360])
  # ax[1].set_yticks([0, 90, 180, 270, 360])
  ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
  ax[1].set_xlabel('Step')

  ax[2].plot(phi.T * 180 / np.pi)
  ax[2].set_ylim([0, 360])
  ax[2].set_yticks([0, 90, 180, 270, 360])
  ax[2].set_ylabel('Phase (°)')
  ax[2].set_xlabel('Step')

  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/5ee491f4846a9990984ffab4be9fd32f25b1781d.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
