#+STARTUP: fold
#+TITLE: Training Low Rank RNNs
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session dual :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

* Helpers
** Data Split

#+begin_src ipython
  from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

  def split_data(X, Y, train_perc=0.8, batch_size=32):

    if Y.ndim==3:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0, 0].cpu().numpy(),
                                                          shuffle=True)
    else:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0].cpu().numpy(),
                                                          shuffle=True)
    print(X_train.shape, X_test.shape)
    print(Y_train.shape, Y_test.shape)

    train_dataset = TensorDataset(X_train, Y_train)
    val_dataset = TensorDataset(X_test, Y_test)

    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
  def train(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1):
      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          X, y = X.to(device), y.to(device)
          # Compute prediction error
          y_pred = model(X)

          # if y.ndim==y_pred.ndim:
          loss = loss_fn(y_pred, y)

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()
          # Clip gradients (norm)
          # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

          # Or clip gradients (value)
          #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)

          optimizer.step()
          optimizer.zero_grad()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def test(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0
      with torch.no_grad():
          for data, targets in dataloader:
              data, targets = data.to(device), targets.to(device)

              outputs = model(data)
              loss = loss_fn(outputs, targets)
              val_loss += loss.item() * data.size(0)

          val_loss /= size

      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def run_optim(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=.005):
      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')
      model.to(device)

      loss_list = []
      val_loss_list = []

      # Training loop.
      for epoch in range(num_epochs):
          loss = train(train_loader, model, loss_fn, optimizer, penalty, lbd)
          val_loss = test(val_loader, model, loss_fn)
          scheduler.step(val_loss)

          loss_list.append(loss.item())
          val_loss_list.append(val_loss)

          # if epoch % int(num_epochs  / 10) == 0:
          print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

          if val_loss < thresh:
              print(f'Stopping training as loss has fallen below the threshold: {val_loss}')
              break

          if val_loss > 300:
              print(f'Stopping training as loss is too high: {val_loss}')
              break

          if torch.isnan(loss):
              print(f'Stopping training as loss is NaN.')
              break

      return loss_list, val_loss_list
#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
  def accuracy(y_pred, labels):
    # Assuming 'outputs' are logits from your model (raw scores before sigmoid)
    predicted = (y_pred > 0).float()  # Convert to 0 or 1 based on comparison with 0
    # 'labels' should be your ground truth labels for the binary classification, also in 0 or 1
    correct = (predicted == labels).sum().item()
    accuracy = correct / labels.size(0)
    return accuracy
#+end_src

#+RESULTS:

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.nn.functional as F

  class SignBCELoss(nn.Module):
      def __init__(self, alpha=0.1, thresh=1.0, N=1000):
          super(SignBCELoss, self).__init__()
          self.alpha = alpha
          self.thresh = thresh
          self.N = N

          self.bce_with_logits = nn.BCEWithLogitsLoss()

      def forward(self, readout, targets):
          bce_loss = self.bce_with_logits(readout, targets)

          # sign_overlap = torch.sign(2 * targets - 1) * readout / (1.0 * self.N)

          mean_activation = readout.mean(dim=1).unsqueeze(-1)
          sign_overlap = torch.sign(2 * targets - 1) * mean_activation / (1.0 * self.N)

          sign_loss = F.relu(self.thresh - sign_overlap).mean()
          # sign_loss = torch.sigmoid(self.thresh -sign_overlap).mean()

          combined_loss = (1-self.alpha) * bce_loss + self.alpha * sign_loss
          return combined_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  class CosineLoss(nn.Module):
      def __init__(self, readout):
          super(CosineLoss, self).__init__()
          self.cosine_similarity = nn.CosineSimilarity(dim=-1)
          self.readout = readout

      def forward(self, rates, target):
          # Calculate cosine similarity
          cosine_sim = self.cosine_similarity(torch.sign(target) * rates, readout)
          # Calculate the loss as 1 - cosine_similarity
          loss = 1 - cosine_sim
          # Return the mean loss over the batch
          return loss.mean()
#+end_src

#+RESULTS:

#+begin_src ipython
  class DualLoss(nn.Module):
      def __init__(self, alpha=0.1, thresh=1.0, N=1000, cue_idx=[], rwd_idx=-1):
          super(DualLoss, self).__init__()
          self.alpha = alpha
          self.thresh = thresh
          self.N = N

          self.cue_idx = torch.tensor(cue_idx, dtype=torch.int, device=DEVICE)
          self.rwd_idx = torch.tensor(rwd_idx, dtype=torch.int, device=DEVICE)

          self.loss = SignBCELoss(self.alpha, self.thresh, self.N)

      def forward(self, readout, targets):

          is_empty = self.cue_idx.numel() == 0
          if is_empty:
              self.DPA_loss = self.loss(readout[:, self.rwd_idx], targets)
              return self.DPA_loss
          else:
              self.DPA_loss = self.loss(readout[:, self.rwd_idx], targets[:, 0, :self.rwd_idx.shape[0]])
              self.DRT_loss = self.loss(readout[:, self.cue_idx], targets[:, 1, :self.cue_idx.shape[0]])
              return (self.DPA_loss + self.DRT_loss) / 2.0
#+end_src

#+RESULTS:

** Other

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      u, v = a, b

      if GM:
          v = b - np.dot(b, a) / np.dot(a, a) * a

      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)

      return np.arctan2(v, u)
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_idx(model, rank=2):
      ksi = torch.hstack((model.U, model.V)).T
      ksi = ksi[:, :model.Na[0]]

      readout = model.linear.weight.data
      ksi = torch.vstack((ksi, readout))

      print('ksi', ksi.shape)

      ksi = ksi.cpu().detach().numpy()
      theta = get_theta(ksi[0], ksi[rank])

      return theta.argsort()
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_overlap(model, rates):
      ksi = model.odors.cpu().detach().numpy()
      return rates @ ksi.T / rates.shape[-1]

#+end_src

#+RESULTS:

#+begin_src ipython
  import scipy.stats as stats

  def plot_smooth(data, ax, color):
      mean = data.mean(axis=0)
      ci = smooth.std(axis=0, ddof=1) * 1.96

      # Plot
      ax.plot(mean, color=color)
      ax.fill_between(range(data.shape[1]), mean - ci, mean + ci, alpha=0.25, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:
** plots

#+begin_src ipython
  def plot_rates_selec(rates, idx):
        ordered = rates[..., idx]
        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
        r_max = 0.2 * np.max(rates[0])

        ax[0].imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        # ax[0].axvline((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, color='w', ls='--')
        # ax[0].axvline((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, color='w', ls='--')
        ax[0].set_ylabel('Neuron #')
        ax[0].set_xlabel('Step')

        ax[1].imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[1].set_yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))
        # ax[1].axvline((np.array(model.N_STIM_ON) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
        # ax[1].axvline((np.array(model.N_STIM_OFF) - model.N_STEADY) / model.N_WINDOW, 0, 360, 'w', '--')
        ax[1].set_ylabel('Pref. Location (°)')
        ax[1].set_xlabel('Step')

        plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_overlap(rates, readout, labels=['A', 'B']):
      overlap =(rates @ readout) / rates.shape[-1]
      print(overlap.shape)

      plt.plot(overlap.T[..., :2], label=labels[0])
      plt.plot(overlap.T[..., 2:], '--', label=labels[1])

      plt.legend(fontsize=10)
      plt.xlabel('Step')
      plt.ylabel('Overlap')

      plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_m0_m1_phi(rates, idx):

      m0, m1, phi = decode_bump(rates[..., idx], axis=-1)
      fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

      ax[0].plot(m0[:2].T)
      ax[0].plot(m0[2:].T, '--')
      #ax[0].set_ylim([0, 360])
      #ax[0].set_yticks([0, 90, 180, 270, 360])
      ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
      ax[0].set_xlabel('Step')

      ax[1].plot(m1[:2].T)
      ax[1].plot(m1[2:].T, '--')
      # ax[1].set_ylim([0, 360])
      # ax[1].set_yticks([0, 90, 180, 270, 360])
      ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
      ax[1].set_xlabel('Step')

      ax[2].plot(phi[:2].T * 180 / np.pi)
      ax[2].plot(phi[2:].T * 180 / np.pi, '--')
      ax[2].set_ylim([0, 360])
      ax[2].set_yticks([0, 90, 180, 270, 360])
      ax[2].set_ylabel('Phase (°)')
      ax[2].set_xlabel('Step')

      plt.show()
    #+end_src

#+RESULTS:

* Model

#+begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroFlame"
  conf_name = "config_train.yml"
  DEVICE = 'cuda'
  seed = np.random.randint(0, 1e6)
  print(seed)
#+end_src

#+RESULTS:
: 995054

#+begin_src ipython
  start = perf_counter()
  model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=16)
#+end_src

#+RESULTS:

* Sample Classification
** Training
*** Parameters

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: U torch.Size([1000, 2])
: V torch.Size([1000, 2])
: linear.weight torch.Size([1, 500])
: linear.bias torch.Size([1])

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT=1

  model.LR_EVAL_WIN = model.T_STIM_OFF[2] - model.T_STIM_ON[0]
  model.lr_eval_win = int(model.LR_EVAL_WIN / model.DT / model.N_WINDOW)
  print(model.lr_eval_win)

  model.DURATION = 6.0
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:
: 50

Testing the network on steps from sample odor offset to test odor onset

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
  mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[2] - model.N_STEADY))
  rwd_idx = np.where(mask)[0]
  print(rwd_idx.shape)
#+end_src

#+RESULTS:
: (31,)

*** Inputs and Labels

#+begin_src ipython
  model.N_BATCH = 64

  model.I0[0] = 1.0
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = -1.0
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([128, 710, 1000])

#+begin_src ipython
  labels_A = torch.ones((model.N_BATCH, rwd_idx.shape[0]))
  labels_B = torch.zeros((model.N_BATCH, rwd_idx.shape[0]))
  labels = torch.cat((labels_A, labels_B))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([128, 31])

*** Run

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([102, 710, 1000]) torch.Size([26, 710, 1000])
: torch.Size([102, 31]) torch.Size([26, 31])

#+begin_src ipython
  criterion = DualLoss(alpha=0.5, thresh=1.0, N=model.Na[0], rwd_idx=rwd_idx)

  # SGD, Adam, AdamW
  learning_rate = 0.1
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)

  num_epochs = 30
  loss, val_loss = 0, 0
#+end_src

#+RESULTS:

#+begin_src ipython
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
#+end_src

#+RESULTS:
#+begin_example
  Epoch 1/30, Training Loss: 0.8195, Validation Loss: 0.5730
  Epoch 2/30, Training Loss: 0.5088, Validation Loss: 0.4928
  Epoch 3/30, Training Loss: 0.4759, Validation Loss: 0.4737
  Epoch 4/30, Training Loss: 0.4665, Validation Loss: 0.4631
  Epoch 5/30, Training Loss: 0.4506, Validation Loss: 0.4501
  Epoch 6/30, Training Loss: 0.4275, Validation Loss: 0.4202
  Epoch 7/30, Training Loss: 0.2160, Validation Loss: 0.2476
  Epoch 8/30, Training Loss: 0.1082, Validation Loss: 0.1501
  Epoch 9/30, Training Loss: 0.0000, Validation Loss: 0.0000
  Stopping training as loss has fallen below the threshold: 0.0
#+end_example

#+begin_src ipython
  torch.save(model.state_dict(), 'sample_%d.pth' % seed)
#+end_src

#+RESULTS:

** Testing

#+begin_src ipython
  model.LR_READOUT = 0
  model.eval()
#+end_src

#+RESULTS:
: Network(
:   (linear): Linear(in_features=500, out_features=1, bias=True)
:   (dropout): Dropout(p=0.0, inplace=False)
: )

#+begin_src ipython
  model.DURATION = 6
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([2, 710, 1000])

#+begin_src ipython
  model.VERBOSE = 0
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print('rates', rates.shape)
#+end_src

#+RESULTS:
: rates (2, 61, 500)

#+begin_src ipython
  idx = get_idx(model, 2)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 500])
[[file:./.ob-jupyter/17c331c063af0062370d9c20b545ee64b6cdbfc3.png]]
:END:

#+begin_src ipython
    readout = model.linear.weight.data.cpu().detach().numpy()[0]
    plot_overlap(rates, readout, labels=['A', 'B'])
#+end_src

#+RESULTS:
:RESULTS:
: (2, 61)
[[file:./.ob-jupyter/6f99449fbf48b44d3c37e3fb2480c29c4ea98273.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/0e32d7e2002fad5ada8ce0a9f7a2d1d5782ce0b1.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* DPA
** Training
*** Parameters

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: U torch.Size([1000, 2])
: V torch.Size([1000, 2])
: linear.weight torch.Size([1, 500])
: linear.bias torch.Size([1])

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1

  model.LR_EVAL_WIN = model.T_STIM_OFF[2] - model.T_STIM_ON[2]
  model.lr_eval_win = int(model.LR_EVAL_WIN / model.DT / model.N_WINDOW)

  model.DURATION = 6.0
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

Here we only evaluate performance from test onset to test offset

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
  mask = (steps >= (model.N_STIM_ON[2] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[2] - model.N_STEADY))
  rwd_idx = np.where(mask)[0]
#+end_src

#+RESULTS:

*** Inputs and Labels

#+begin_src ipython
  model.N_BATCH = 64

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 1

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = -1

  AD_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = -1

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([256, 710, 1000])

 #+begin_src ipython
  labels_pair = torch.ones((2 * model.N_BATCH, model.lr_eval_win))
  labels_unpair = torch.zeros((2 * model.N_BATCH, model.lr_eval_win))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([256, 10])

#+RESULTS:

*** Run

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([204, 710, 1000]) torch.Size([52, 710, 1000])
: torch.Size([204, 10]) torch.Size([52, 10])

#+begin_src ipython
  # Loss
  criterion = DualLoss(alpha=0.5, thresh=1.0, N=model.Na[0], rwd_idx=rwd_idx)

  # Optimizer: SGD, Adam, AdamW
  learning_rate = 0.1
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 30
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
#+End_src

#+RESULTS:
#+begin_example
  Epoch 1/30, Training Loss: 1.6835, Validation Loss: 2.3240
  Epoch 2/30, Training Loss: 0.3880, Validation Loss: 0.3742
  Epoch 3/30, Training Loss: 0.3903, Validation Loss: 0.3296
  Epoch 4/30, Training Loss: 0.3070, Validation Loss: 0.2988
  Epoch 5/30, Training Loss: 0.3535, Validation Loss: 0.2665
  Epoch 6/30, Training Loss: 0.2945, Validation Loss: 0.2353
  Epoch 7/30, Training Loss: 0.2668, Validation Loss: 0.2057
  Epoch 8/30, Training Loss: 0.1402, Validation Loss: 0.1568
  Epoch 9/30, Training Loss: 0.2611, Validation Loss: 0.1558
  Epoch 10/30, Training Loss: 0.1479, Validation Loss: 0.1503
  Epoch 11/30, Training Loss: 0.1840, Validation Loss: 0.1439
  Epoch 12/30, Training Loss: 0.1061, Validation Loss: 0.1305
  Epoch 13/30, Training Loss: 0.1960, Validation Loss: 0.4364
  Epoch 14/30, Training Loss: 0.2182, Validation Loss: 0.1330
  Epoch 15/30, Training Loss: 0.2165, Validation Loss: 0.1313
  Epoch 16/30, Training Loss: 0.1930, Validation Loss: 0.1441
  Epoch 17/30, Training Loss: 0.2374, Validation Loss: 0.1345
  Epoch 18/30, Training Loss: 0.1169, Validation Loss: 0.1241
  Epoch 19/30, Training Loss: 0.1660, Validation Loss: 0.1090
  Epoch 20/30, Training Loss: 0.1533, Validation Loss: 0.0808
  Epoch 21/30, Training Loss: 0.0447, Validation Loss: 0.0503
  Epoch 22/30, Training Loss: 0.1276, Validation Loss: 0.0813
  Epoch 23/30, Training Loss: 0.0635, Validation Loss: 0.0802
  Epoch 24/30, Training Loss: 0.0884, Validation Loss: 0.0744
  Epoch 25/30, Training Loss: 0.0820, Validation Loss: 0.0690
  Epoch 26/30, Training Loss: 0.1510, Validation Loss: 0.0634
  Epoch 27/30, Training Loss: 0.1377, Validation Loss: 0.0578
  Epoch 28/30, Training Loss: 0.1231, Validation Loss: 0.0515
  Epoch 29/30, Training Loss: 0.0877, Validation Loss: 0.0438
  Epoch 30/30, Training Loss: 0.0272, Validation Loss: 0.0337
#+end_example

    #+begin_src ipython
  plt.plot(loss)
  plt.plot(val_loss)
  plt.xlabel('epochs')
  plt.ylabel('Loss')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/006e702652a349caeac634457700ea645e9fad8b.png]]

#+begin_src ipython
  torch.save(model.state_dict(), 'dpa_%d.pth' % seed)
#+end_src

#+RESULTS:

** Testing

#+begin_src ipython
  model.eval()
  model.LR_READOUT = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.DURATION = 6
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 1

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = -1

  AD_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = -1

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 710, 1000])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
: (4, 61, 500)

#+begin_src ipython
  idx = get_idx(model, 2)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 500])
[[file:./.ob-jupyter/c0563a88b60efeb22aaabf8e291a327d0fa68f70.png]]
:END:

#+begin_src ipython
    readout = model.linear.weight.data.cpu().detach().numpy()[0]
    plot_overlap(rates, readout, labels=['pair', 'unpair'])
#+end_src

#+RESULTS:
:RESULTS:
: (4, 61)
[[file:./.ob-jupyter/cf659348e2e54456ad76a7b51163e440bb4699a6.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/ec4556519972d4f072c7f30582133f386f2b0328.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

* Go/NoGo
** Training

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1

  model.LR_EVAL_WIN = 1
  model.lr_eval_win = int(model.LR_EVAL_WIN / model.DT / model.N_WINDOW+1)
  print(model.lr_eval_win)

  model.DURATION = 6
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:
: 11

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
  mask = (steps >= (model.N_STIM_OFF[1] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[2] - model.N_STEADY))

  rwd_idx = np.where(mask)[0]
  model.lr_eval_win = rwd_idx.shape[0]
#+end_src

#+RESULTS:

#+begin_src ipython
  # for param in model.linear.parameters():
  #     param.requires_grad = False
#+end_src

#+RESULTS:

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: U torch.Size([1000, 2])
: V torch.Size([1000, 2])
: linear.weight torch.Size([1, 500])
: linear.bias torch.Size([1])

#+begin_src ipython
  # switching sample and distractor odors
  odors = model.odors.clone()
  model.odors[0] = odors[1]

  model.N_BATCH = 64

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 0

  Go = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 0

  NoGo = model.init_ff_input()

  ff_input = torch.cat((Go, NoGo))
  print(ff_input.shape)
  model.odors[0] = odors[0]
#+end_src

#+RESULTS:
: torch.Size([128, 710, 1000])

#+begin_src ipython
  labels_Go = torch.ones((model.N_BATCH, model.lr_eval_win))
  labels_NoGo = torch.zeros((model.N_BATCH, model.lr_eval_win))
  labels = torch.cat((labels_Go, labels_NoGo))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([128, 11])

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([102, 710, 1000]) torch.Size([26, 710, 1000])
: torch.Size([102, 11]) torch.Size([26, 11])

#+begin_src ipython
  # criterion = nn.BCEWithLogitsLoss()
  criterion = DualLoss(alpha=0.5, thresh=1.0, N=model.Na[0], rwd_idx=rwd_idx)

  # SGD, Adam, AdamW
  learning_rate = 0.1
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 30
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
  # switching back sample and distractor odors
  model.odors[0] = odors[0]
#+end_src
#+RESULTS:
#+begin_example
  Epoch 1/30, Training Loss: 1.3179, Validation Loss: 1.9098
  Epoch 2/30, Training Loss: 0.4827, Validation Loss: 0.4829
  Epoch 3/30, Training Loss: 0.4818, Validation Loss: 0.4819
  Epoch 4/30, Training Loss: 0.4827, Validation Loss: 0.4830
  Epoch 5/30, Training Loss: 0.4835, Validation Loss: 0.4811
  Epoch 6/30, Training Loss: 0.4794, Validation Loss: 0.4792
  Epoch 7/30, Training Loss: 0.4774, Validation Loss: 0.4771
  Epoch 8/30, Training Loss: 0.4749, Validation Loss: 0.4746
  Epoch 9/30, Training Loss: 0.4712, Validation Loss: 0.4717
  Epoch 10/30, Training Loss: 0.4688, Validation Loss: 0.4682
  Epoch 11/30, Training Loss: 0.4648, Validation Loss: 0.4641
  Epoch 12/30, Training Loss: 0.4558, Validation Loss: 0.4603
  Epoch 13/30, Training Loss: 0.4640, Validation Loss: 0.4562
  Epoch 14/30, Training Loss: 0.4600, Validation Loss: 0.4511
  Epoch 15/30, Training Loss: 0.4364, Validation Loss: 0.4446
  Epoch 16/30, Training Loss: 0.4381, Validation Loss: 0.4368
  Epoch 17/30, Training Loss: 0.4506, Validation Loss: 0.4246
  Epoch 18/30, Training Loss: 0.3970, Validation Loss: 0.4064
  Epoch 19/30, Training Loss: 0.3842, Validation Loss: 0.3878
  Epoch 20/30, Training Loss: 0.3577, Validation Loss: 0.3611
  Epoch 21/30, Training Loss: 0.3301, Validation Loss: 0.3244
  Epoch 22/30, Training Loss: 0.2949, Validation Loss: 0.2817
  Epoch 23/30, Training Loss: 0.2277, Validation Loss: 0.2316
  Epoch 24/30, Training Loss: 0.1871, Validation Loss: 0.1653
  Epoch 25/30, Training Loss: 0.0949, Validation Loss: 0.0810
  Epoch 26/30, Training Loss: 0.0192, Validation Loss: 0.0000
  Stopping training as loss has fallen below the threshold: 0.0
#+end_example

#+begin_src ipython
  plt.plot(loss)
  plt.plot(val_loss)
  plt.xlabel('epochs')
  plt.ylabel('Loss')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/84de79d3f8f753aa2433e2c75a3b49d75f441d80.png]]

#+begin_src ipython
  torch.save(model.state_dict(), 'drt.pth')
#+end_src

#+RESULTS:

** Testing

#+begin_src ipython
  model.eval()
  model.LR_READOUT = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1
  model.DURATION = 3
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  odors = model.odors.clone()
  model.odors[0] = odors[1]
  model.N_BATCH = 1

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print('ff_input', ff_input.shape)
  model.odors[0] = odors[0]
#+end_src

#+RESULTS:
: ff_input torch.Size([2, 410, 1000])

#+begin_src ipython
  model.VERBOSE = 0
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
: (2, 31, 500)

#+begin_src ipython
  idx = get_idx(model, 2)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 500])
[[file:./.ob-jupyter/44e32926d075d2f1b0a05ab4b835364c435ebaeb.png]]
:END:

#+begin_src ipython
    readout = model.linear.weight.data.cpu().detach().numpy()[0]
    plot_overlap(rates, readout, labels=['Go', 'NoGo'])
#+end_src

#+RESULTS:
:RESULTS:
: (2, 31)
[[file:./.ob-jupyter/6a4f7ae3f035bf71bcdc2988959a04fb034696ad.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/2b230bdefaa7dd4b398641eb5b74a3f68fddf315.png]]

#+begin_src ipython
  torch.save(model.state_dict(), 'dual.pth')
#+end_src

#+RESULTS:

* Dual
** Testing

#+begin_src ipython
  model.eval()
  model.LR_READOUT = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1
  model.DURATION = 6
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 1

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = -1

  AD_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = -1

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 710, 2000])

#+begin_src ipython
  model.VERBOSE = 0
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
: (4, 61, 1600)

#+begin_src ipython
  idx = get_idx(model, 2)
  ordered = rates[..., idx]
  m0, m1, phi = decode_bump(ordered, axis=-1)
#+end_src

#+RESULTS:
: ksi torch.Size([5, 1600])

#+begin_src ipython
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/3b5e974d7cbbb43b38fef688092c7d3a6c1fbc9c.png]]

#+begin_src ipython
    readout = model.linear.weight.data.cpu().detach().numpy()[0]
    plot_overlap(rates, readout, labels=['pair', 'unpair'])
#+end_src

#+RESULTS:
:RESULTS:
: (4, 61)
[[file:./.ob-jupyter/80290ccb1a25114339da689f45c6648bf5fbd613.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/42be825b7a63c18c931370508c91dabfc7ad5250.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

** Training

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1

  model.LR_EVAL_WIN = 1
  model.lr_eval_win = int(model.LR_EVAL_WIN / model.DT / model.N_WINDOW)
  print(model.lr_eval_win)

  model.DURATION = 6.0
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:
: 10

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
  print(steps.shape)

  mask = (steps >= (model.N_STIM_ON[2] - model.N_STEADY)) & (steps <= (model.N_STIM_OFF[2] - model.N_STEADY))
  rwd_idx = np.where(mask)[0]
  print(rwd_idx)

  mask = (steps >= (model.N_STIM_OFF[1] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[2] - model.N_STEADY))
  cue_idx = np.where(mask)[0]
  print(cue_idx)
#+end_src

#+RESULTS:
: (61,)
: [50 51 52 53 54 55 56 57 58 59 60]
: [40 41 42 43 44 45 46 47 48 49 50]

#+begin_src ipython
  for param in model.linear.parameters():
       param.requires_grad = True
#+end_src

#+RESULTS:

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src
#+RESULTS:
: U torch.Size([2000, 2])
: V torch.Size([2000, 2])
: linear.weight torch.Size([1, 1600])
: linear.bias torch.Size([1])

#+begin_src ipython
  model.N_BATCH = 64

  model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))

  ff_input = []
  labels = np.zeros((2, 12, model.N_BATCH, model.lr_eval_win))
  l=0
  for i in [-1, 1]:
      for j in [-1, 0, 1]:
          for k in [1, -1]:

              model.I0[0] = i
              model.I0[1] = j
              model.I0[2] = k

              if i==k: # Pair Trials
                  labels[0, l] = np.ones((model.N_BATCH, model.lr_eval_win))
              # else: # Unpair Trials
              #     labels[0, l] = np.zeros((model.N_BATCH, model.lr_eval_win))

              if j==1: # Go
                  labels[1, l] = np.ones((model.N_BATCH, model.lr_eval_win))
              # if j==-1: # NoGo
              #     labels[1, l] = np.zeros((model.N_BATCH, model.lr_eval_win))

              l+=1

              ff_input.append(model.init_ff_input())

  labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(2, -1, model.lr_eval_win).transpose(0, 1)
  ff_input = torch.vstack(ff_input)
  print('ff_input', ff_input.shape, 'labels', labels.shape)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: ---------------------------------------------------------------------------
: OutOfMemoryError                          Traceback (most recent call last)
: Cell In[117], line 31
:      28             ff_input.append(model.init_ff_input())
:      30 labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(2, -1, model.lr_eval_win).transpose(0, 1)
: ---> 31 ff_input = torch.vstack(ff_input)
:      32 print('ff_input', ff_input.shape, 'labels', labels.shape)
:
: OutOfMemoryError: CUDA out of memory. Tried to allocate 8.13 GiB. GPU 0 has a total capacity of 23.50 GiB of which 3.88 GiB is free. Process 2596683 has 440.00 MiB memory in use. Process 2648748 has 410.00 MiB memory in use. Including non-PyTorch memory, this process has 18.75 GiB memory in use. Of the allocated memory 17.77 GiB is allocated by PyTorch, and 681.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
:END:

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
  ---------------------------------------------------------------------------
  ValueError                                Traceback (most recent call last)
  Cell In[118], line 2
        1 batch_size = 16
  ----> 2 train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)

  Cell In[5], line 6, in split_data(X, Y, train_perc, batch_size)
        3 def split_data(X, Y, train_perc=0.8, batch_size=32):
        5   if Y.ndim==3:
  ----> 6     X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
        7                                                         train_size=train_perc,
        8                                                         stratify=Y[:, 0, 0].cpu().numpy(),
        9                                                         shuffle=True)
       10   else:
       11     X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
       12                                                         train_size=train_perc,
       13                                                         stratify=Y[:, 0].cpu().numpy(),
       14                                                         shuffle=True)

  File ~/mambaforge/envs/torch/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214, in validate_params.<locals>.decorator.<locals>.wrapper(*args, **kwargs)
      208 try:
      209     with config_context(
      210         skip_parameter_validation=(
      211             prefer_skip_nested_validation or global_skip_validation
      212         )
      213     ):
  --> 214         return func(*args, **kwargs)
      215 except InvalidParameterError as e:
      216     # When the function is just a wrapper around an estimator, we allow
      217     # the function to delegate validation to the estimator, but we replace
      218     # the name of the estimator by the name of the function in the error
      219     # message to avoid confusion.
      220     msg = re.sub(
      221         r"parameter of \w+ must be",
      222         f"parameter of {func.__qualname__} must be",
      223         str(e),
      224     )

  File ~/mambaforge/envs/torch/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2646, in train_test_split(test_size, train_size, random_state, shuffle, stratify, *arrays)
     2643 if n_arrays == 0:
     2644     raise ValueError("At least one array required as input")
  -> 2646 arrays = indexable(*arrays)
     2648 n_samples = _num_samples(arrays[0])
     2649 n_train, n_test = _validate_shuffle_split(
     2650     n_samples, test_size, train_size, default_test_size=0.25
     2651 )

  File ~/mambaforge/envs/torch/lib/python3.10/site-packages/sklearn/utils/validation.py:453, in indexable(*iterables)
      434 """Make arrays indexable for cross-validation.
      435
      436 Checks consistent length, passes through None, and ensures that everything
     (...)
      449     sparse matrix, or dataframe) or `None`.
      450 """
      452 result = [_make_indexable(X) for X in iterables]
  --> 453 check_consistent_length(*result)
      454 return result

  File ~/mambaforge/envs/torch/lib/python3.10/site-packages/sklearn/utils/validation.py:407, in check_consistent_length(*arrays)
      405 uniques = np.unique(lengths)
      406 if len(uniques) > 1:
  --> 407     raise ValueError(
      408         "Found input variables with inconsistent numbers of samples: %r"
      409         % [int(l) for l in lengths]
      410     )

  ValueError: Found input variables with inconsistent numbers of samples: [12, 768]
#+end_example
:END:

#+begin_src ipython
  # criterion = nn.BCEWithLogitsLoss()
  criterion = DualLoss(alpha=0.5, thresh=1.0, N=model.Na[0], cue_idx=cue_idx, rwd_idx=rwd_idx)

  # SGD, Adam, AdamW
  learning_rate = 0.1
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 30
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
#+end_src
#+RESULTS:
: 971d8653-169f-4934-ac32-3eb050d14571

** Re-Testing

#+begin_src ipython
  model.eval()
  model.LR_READOUT = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1
  model.DURATION = 6
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 1

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 1

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = -1

  AD_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = -1

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([4, 710, 2000])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
: (4, 61, 1600)

#+begin_src ipython
  idx = get_idx(model, 2)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([5, 1600])
[[file:./.ob-jupyter/6d61db29b639e84c2d372b67bc2d5688e428c38a.png]]
:END:

#+begin_src ipython
    readout = model.linear.weight.data[0].cpu().detach().numpy()
    plot_overlap(rates, readout)
#+end_src

#+RESULTS:
:RESULTS:
: (4, 61)
[[file:./.ob-jupyter/ca38faca0c3a146addd4935a11d08a5f6e2bfe9b.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/414bc92961b30cbfaf129c016fe5844b46d6f48a.png]]

#+begin_src ipython

#+end_src

#+RESULTS:
