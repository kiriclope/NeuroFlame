#+STARTUP: fold
#+TITLE: Training Low Rank RNNs
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session dual :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroFlame"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python


* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  from torch.utils.data import Dataset, TensorDataset, DataLoader

  DEVICE = 'cuda:1'

#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl
  from src.lr_utils import masked_normalize, clamp_tensor, normalize_tensor
#+end_src

#+RESULTS:

* Helpers
** Data Split

#+begin_src ipython
  from sklearn.model_selection import train_test_split, StratifiedShuffleSplit

  def split_data(X, Y, train_perc=0.8, batch_size=32):

    if Y.ndim==3:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0, 0].cpu().numpy(),
                                                          shuffle=True)
    else:
      X_train, X_test, Y_train, Y_test = train_test_split(X, Y,
                                                          train_size=train_perc,
                                                          stratify=Y[:, 0].cpu().numpy(),
                                                          shuffle=True)
    print(X_train.shape, X_test.shape)
    print(Y_train.shape, Y_test.shape)

    train_dataset = TensorDataset(X_train, Y_train)
    val_dataset = TensorDataset(X_test, Y_test)

    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
  def torch_angle_AB(U, V):
      # Calculate the dot product
      dot_product = torch.dot(U, V)

      # Calculate the magnitudes of U and V
      magnitude_U = torch.linalg.norm(U)
      magnitude_V = torch.linalg.norm(V)

      # Compute the cosine of the angle
      cos_theta = dot_product / (magnitude_U * magnitude_V)

      # Calculate the angle in radians, then convert to degrees
      angle_radians = torch.acos(cos_theta)
      return torch.round(torch.rad2deg(angle_radians))
#+end_src

#+RESULTS:

#+begin_src ipython
  def train(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1, clip_grad=0):
      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          X, y = X.to(device), y.to(device)
          # Compute prediction error
          y_pred = model(X)

          # if y.ndim==y_pred.ndim:
          loss = loss_fn(y_pred, y)

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()

          # Clip gradients
          if clip_grad:
              torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
              #torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)

          optimizer.step()
          optimizer.zero_grad()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def test(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device(DEVICE if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0
      with torch.no_grad():
          for data, targets in dataloader:
              data, targets = data.to(device), targets.to(device)

              outputs = model(data)
              loss = loss_fn(outputs, targets)
              val_loss += loss.item() * data.size(0)

          val_loss /= size

      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def run_optim(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1, thresh=.005):
      scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
      # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
      # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

      device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')
      model.to(device)

      loss_list = []
      val_loss_list = []
      angle_list = []

      # Training loop.
      for epoch in range(num_epochs):
          loss = train(train_loader, model, loss_fn, optimizer, penalty, lbd)
          val_loss = test(val_loader, model, loss_fn)
          scheduler.step(val_loss)

          loss_list.append(loss.item())
          val_loss_list.append(val_loss)

          # if epoch % int(num_epochs  / 10) == 0:
          print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

          memory = model.low_rank.U[model.slices[0], 0]
          readout = model.low_rank.linear.weight.data[0]
          angle = torch_angle_AB(memory, readout).item()
          angle_list.append(angle)

          print(f'Angle(U, W) : {angle} Â°')

          if val_loss < thresh:
              print(f'Stopping training as loss has fallen below the threshold: {val_loss}')
              break

          if val_loss > 300:
              print(f'Stopping training as loss is too high: {val_loss}')
              break

          if torch.isnan(loss):
              print(f'Stopping training as loss is NaN.')
              break

      return loss_list, val_loss_list
#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
  def accuracy_score(y_pred, labels):
    # Assuming 'outputs' are logits from your model (raw scores before sigmoid)
    predicted = (y_pred > 0).float()  # Convert to 0 or 1 based on comparison with 0
    print(predicted.shape)
    # 'labels' should be your ground truth labels for the binary classification, also in 0 or 1
    correct = (predicted == labels).sum().item()
    accuracy = correct / labels.size(0) / labels.size(-1)
    return accuracy
#+end_src

#+RESULTS:

#+begin_src ipython
  def performance_score(model, rates, labels):
      print(rates.shape)
      y_pred = model.low_rank.linear(rates[:, -2:]).squeeze(-1)
      accuracy = accuracy_score(y_pred, labels)
      return accuracy
#+end_src

#+RESULTS:

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.nn.functional as F

  class SignBCELoss(nn.Module):
      def __init__(self, alpha=0.1, thresh=2.0, N=1000):
          super(SignBCELoss, self).__init__()
          self.alpha = alpha
          self.thresh = thresh
          self.N = N

          self.bce_with_logits = nn.BCEWithLogitsLoss()

      def forward(self, readout, targets):
          if self.alpha != 1.0:
              bce_loss = self.bce_with_logits(readout, targets)
          else:
              bce_loss = 0.0
          # sign_overlap = torch.sign(2 * targets - 1) * readout / (1.0 * self.N)

          mean_activation = readout.mean(dim=1).unsqueeze(-1)
          sign_overlap = torch.sign(2 * targets - 1) * mean_activation / (1.0 * self.N)

          sign_loss = F.relu(self.thresh - sign_overlap).mean()
          # sign_loss = torch.sigmoid(self.thresh -sign_overlap).mean()

          combined_loss = (1-self.alpha) * bce_loss + self.alpha * sign_loss
          return combined_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  class DualLoss(nn.Module):
      def __init__(self, alpha=0.1, thresh=2.0, N=1000, cue_idx=[], rwd_idx=-1, zero_idx=[]):
          super(DualLoss, self).__init__()
          self.alpha = alpha
          self.thresh = thresh
          self.N = N

          self.zero_idx = zero_idx
          self.cue_idx = torch.tensor(cue_idx, dtype=torch.int, device=DEVICE)
          self.rwd_idx = torch.tensor(rwd_idx, dtype=torch.int, device=DEVICE)

          self.loss = SignBCELoss(self.alpha, self.thresh, self.N)

      def forward(self, readout, targets):

          # ensuring zero bl overlap
          bl_loss = F.relu(readout[:, self.zero_idx].abs() / self.N - 0.1).mean()

          is_empty = self.cue_idx.numel() == 0
          if is_empty:
              self.DPA_loss = self.loss(readout[:, self.rwd_idx], targets)
              return (self.DPA_loss + bl_loss) / 2.0
          else:
              self.DPA_loss = self.loss(readout[:, self.rwd_idx], targets[:, 0, :self.rwd_idx.shape[0]])
              self.DRT_loss = self.loss(readout[:, self.cue_idx], targets[:, 1, :self.cue_idx.shape[0]])
              return (self.DPA_loss + self.DRT_loss + bl_loss ) / 3.0
#+end_src

#+RESULTS:

** Other

#+begin_src ipython
  def angle_AB(A, B):
      A_norm = A / (np.linalg.norm(A) + 1e-5)
      B_norm = B / (np.linalg.norm(B) + 1e-5)

      return int(np.arccos(A_norm @ B_norm) * 180 / np.pi)
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      u, v = a, b

      if GM:
          v = b - np.dot(b, a) / np.dot(a, a) * a

      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)

      return np.arctan2(v, u) % (2.0 * np.pi)
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_idx(model, rank=2):
      ksi = torch.hstack((model.low_rank.U, model.low_rank.V)).T
      ksi = ksi[:, :model.Na[0]]

      readout = model.low_rank.linear.weight.data
      ksi = torch.vstack((ksi, readout))

      print('ksi', ksi.shape)

      ksi = ksi.cpu().detach().numpy()
      theta = get_theta(ksi[0], ksi[rank])

      return theta.argsort()
#+end_src

#+RESULTS:

#+begin_src ipython
  def get_overlap(model, rates):
      ksi = model.odors.cpu().detach().numpy()
      return rates @ ksi.T / rates.shape[-1]

#+end_src

#+RESULTS:

#+begin_src ipython
  import scipy.stats as stats

  def plot_smooth(data, ax, color):
      mean = data.mean(axis=0)
      ci = smooth.std(axis=0, ddof=1) * 1.96

      # Plot
      ax.plot(mean, color=color)
      ax.fill_between(range(data.shape[1]), mean - ci, mean + ci, alpha=0.25, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

** plots

#+begin_src ipython
  def plot_rates_selec(rates, idx, thresh=0.5, figname='fig.svg'):
        ordered = rates[..., idx]
        fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
        r_max = thresh * np.max(rates[0])

        ax[0].imshow(rates[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[0].set_ylabel('Neuron #')
        ax[0].set_xlabel('Step')

        ax[1].imshow(ordered[0].T, aspect='auto', cmap='jet', vmin=0, vmax=r_max)
        ax[1].set_yticks(np.linspace(0, model.Na[0].cpu().detach(), 5), np.linspace(0, 360, 5).astype(int))
        ax[1].set_ylabel('Pref. Location (Â°)')
        ax[1].set_xlabel('Step')
        plt.savefig(figname, dpi=300)
        plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_overlap(rates, memory, readout, labels=['A', 'B'], figname='fig.svg'):
      fig, ax = plt.subplots(1, 2, figsize=[2*width, height])
      overlap =(rates @ memory) / rates.shape[-1]

      if overlap.shape[0]>2:
          ax[0].plot(overlap.T[..., :2], label=labels[0])
          ax[0].plot(overlap.T[..., 2:], '--', label=labels[1])
      else:
          ax[0].plot(overlap.T[..., 0], label=labels[0])
          ax[0].plot(overlap.T[..., 1], '--', label=labels[1])

      ax[0].set_xlabel('Step')
      ax[0].set_ylabel('Overlap')
      ax[0].set_title('Memory')

      overlap =(rates @ readout) / rates.shape[-1]

      if overlap.shape[0]>2:
          ax[1].plot(overlap.T[..., :2], label=labels[0])
          ax[1].plot(overlap.T[..., 2:], '--', label=labels[1])
      else:
          ax[1].plot(overlap.T[..., 0], label=labels[0])
          ax[1].plot(overlap.T[..., 1], '--', label=labels[1])

      ax[1].set_xlabel('Step')
      ax[1].set_ylabel('Overlap')
      ax[1].set_title('Readout')

      # plt.legend(fontsize=10, frameon=False)
      plt.savefig(figname, dpi=300)
      plt.show()
#+end_src

#+RESULTS:

#+begin_src ipython
  def plot_m0_m1_phi(rates, idx, figname='fig.svg'):

      m0, m1, phi = decode_bump(rates[..., idx], axis=-1)
      fig, ax = plt.subplots(1, 3, figsize=[2*width, height])

      ax[0].plot(m0[:2].T)
      ax[0].plot(m0[2:].T, '--')
      #ax[0].set_ylim([0, 360])
      #ax[0].set_yticks([0, 90, 180, 270, 360])
      ax[0].set_ylabel('$\mathcal{F}_0$ (Hz)')
      ax[0].set_xlabel('Step')

      ax[1].plot(m1[:2].T)
      ax[1].plot(m1[2:].T, '--')
      # ax[1].set_ylim([0, 360])
      # ax[1].set_yticks([0, 90, 180, 270, 360])
      ax[1].set_ylabel('$\mathcal{F}_1$ (Hz)')
      ax[1].set_xlabel('Step')

      ax[2].plot(phi[:2].T * 180 / np.pi)
      ax[2].plot(phi[2:].T * 180 / np.pi, '--')
      ax[2].set_ylim([0, 360])
      ax[2].set_yticks([0, 90, 180, 270, 360])
      ax[2].set_ylabel('Phase (Â°)')
      ax[2].set_xlabel('Step')

      plt.savefig(figname, dpi=300)
      plt.show()
    #+end_src

#+RESULTS:

* Model

#+begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroFlame"
  conf_name = "config_train.yml"
  DEVICE = 'cuda:1'
  seed = np.random.randint(0, 1e6)
  print(seed)
  #seed = 760946
#+end_src

#+RESULTS:
: 596535

#+begin_src ipython
  model = Network(conf_name, REPO_ROOT, VERBOSE=0, DEVICE=DEVICE, SEED=seed, N_BATCH=16)
#+end_src

#+RESULTS:

* Sample Classification
** Training
*** Parameters

#+begin_src ipython
  for name, param in model.named_parameters():
      if param.requires_grad:
          print(name, param.shape)
#+end_src

#+RESULTS:
: low_rank.U torch.Size([2000, 1])
: low_rank.V torch.Size([2000, 1])
: low_rank.lr_kappa torch.Size([1])
: low_rank.linear.weight torch.Size([1, 1000])
: low_rank.linear.bias torch.Size([1])

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT=1
#+end_src

#+RESULTS:

Testing the network on steps from sample odor offset to test odor onset

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

  mask = (steps >= (model.N_STIM_OFF[0] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  rwd_idx = np.where(mask)[0]
  print('rwd', rwd_idx)

  model.lr_eval_win = rwd_idx.shape[0]

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))

  zero_idx = np.where(~mask & ~stim_mask )[0]
  print('zero', zero_idx)
#+end_src

#+RESULTS:
: rwd [20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43
:  44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67
:  68 69 70]
: zero [0 1 2 3 4 5 6 7 8 9]

*** Inputs and Labels

#+begin_src ipython
  model.N_BATCH = 128

  model.I0[0] = 2.0
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = -2.0
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([256, 810, 2000])

#+begin_src ipython
  labels_A = torch.ones((model.N_BATCH, rwd_idx.shape[0]))
  labels_B = torch.zeros((model.N_BATCH, rwd_idx.shape[0]))
  labels = torch.cat((labels_A, labels_B))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([256, 51])

*** Run

#+begin_src ipython
  batch_size = 32
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([204, 810, 2000]) torch.Size([52, 810, 2000])
: torch.Size([204, 51]) torch.Size([52, 51])

#+begin_src ipython
  criterion = DualLoss(alpha=1.0, thresh=2.0, N=model.Na[0], rwd_idx=rwd_idx, zero_idx=zero_idx)

  # SGD, Adam, AdamW
  learning_rate = 0.05
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 30
  start = perf_counter()
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
  ---------------------------------------------------------------------------
  RuntimeError                              Traceback (most recent call last)
  Cell In[51], line 3
        1 num_epochs = 30
        2 start = perf_counter()
  ----> 3 loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
        4 end = perf_counter()
        5 print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))

  Cell In[8], line 15, in run_optim(model, train_loader, val_loader, loss_fn, optimizer, num_epochs, penalty, lbd, thresh)
       13 # Training loop.
       14 for epoch in range(num_epochs):
  ---> 15     loss = train(train_loader, model, loss_fn, optimizer, penalty, lbd)
       16     val_loss = test(val_loader, model, loss_fn)
       17     scheduler.step(val_loss)

  Cell In[6], line 24, in train(dataloader, model, loss_fn, optimizer, penalty, lbd, clip_grad)
       21         loss = loss + lbd * reg_loss
       23 # Backpropagation
  ---> 24 loss.backward()
       26 # Clip gradients
       27 if clip_grad:

  File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/_tensor.py:522, in Tensor.backward(self, gradient, retain_graph, create_graph, inputs)
      512 if has_torch_function_unary(self):
      513     return handle_torch_function(
      514         Tensor.backward,
      515         (self,),
     (...)
      520         inputs=inputs,
      521     )
  --> 522 torch.autograd.backward(
      523     self, gradient, retain_graph, create_graph, inputs=inputs
      524 )

  File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/autograd/__init__.py:266, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)
      261     retain_graph = create_graph
      263 # The reason we repeat the same comment below is that
      264 # some Python versions print out the first line of a multi-line function
      265 # calls in the traceback and some print out the last line
  --> 266 Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
      267     tensors,
      268     grad_tensors_,
      269     retain_graph,
      270     create_graph,
      271     inputs,
      272     allow_unreachable=True,
      273     accumulate_grad=True,
      274 )

  RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
#+end_example
:END:

** Testing

#+begin_src ipython
   from src.configuration import Configuration

   # model.DT = .001
   # model.RATE_NOISE=0
   # model.N_STEADY = int(model.T_STEADY / model.DT)
   # model.N_WINDOW = int(model.T_WINDOW / model.DT)
   # model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW

   # model.N_STIM_ON = np.array(
   #     [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_ON]
   # )
   # model.N_STIM_OFF = [int(i / model.DT) + model.N_STEADY for i in model.T_STIM_OFF]

   # # synaptic dynamics
   # model.TAU_SYN = torch.tensor([.004, .002], device=model.device)
   # model.EXP_DT_TAU_SYN = torch.ones(model.N_NEURON, device=model.device)
   # model.DT_TAU_SYN = torch.ones(model.N_NEURON, device=model.device)

   # for i_pop in range(model.N_POP):
   #       model.EXP_DT_TAU_SYN[model.slices[i_pop]] = torch.exp(
   #             -model.DT / model.TAU_SYN[i_pop]
   #       )
   #       model.DT_TAU_SYN[model.slices[i_pop]] = model.DT / model.TAU_SYN[i_pop]

   # config = Configuration(conf_name, REPO_ROOT)(DT=0.01, TAU_SYN=[.2, .1])
   # print(model.__dict__)
   # # model.__dict__.update(config.__dict__)
#+end_src

#+RESULTS:

#+begin_src ipython
  model.eval()
  model.LR_READOUT = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  # model.VAR_FF = model.VAR_FF * 0.75
  print(model.VAR_FF)
#+end_src

#+RESULTS:
: tensor([[[0.0707],
:          [0.0707]]], device='cuda:1')

#+begin_src ipython
  model.N_BATCH = 10

  model.I0[0] = 2
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = -2
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([20, 810, 2000])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print('rates', rates.shape)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
  [0;31m---------------------------------------------------------------------------[0m
  [0;31mRuntimeError[0m                              Traceback (most recent call last)
  Cell [0;32mIn[56], line 1[0m
  [0;32m----> 1[0m rates [38;5;241m=[39m [41mmodel[49m[38;5;241;41m.[39;49m[41mforward[49m[41m([49m[41mff_input[49m[38;5;241;41m=[39;49m[41mff_input[49m[41m)[49m[38;5;241m.[39mcpu()[38;5;241m.[39mdetach()[38;5;241m.[39mnumpy()
  [1;32m      2[0m [38;5;28mprint[39m([38;5;124m'[39m[38;5;124mrates[39m[38;5;124m'[39m, rates[38;5;241m.[39mshape)

  File [0;32m~/models/NeuroFlame/org/../src/network.py:258[0m, in [0;36mNetwork.forward[0;34m(self, ff_input, REC_LAST_ONLY, RET_FF, RET_STP)[0m
  [1;32m    247[0m [38;5;250m[39m[38;5;124;03m"""[39;00m
  [1;32m    248[0m [38;5;124;03mMain method of Network class, runs networks dynamics over set of timesteps[39;00m
  [1;32m    249[0m [38;5;124;03mand returns rates at each time point or just the last time point.[39;00m
  [0;32m   (...)[0m
  [1;32m    254[0m [38;5;124;03m:param rates_list: float (N_BATCH, N_STEP or 1, N_NEURONS), rates of the neurons.[39;00m
  [1;32m    255[0m [38;5;124;03m"""[39;00m
  [1;32m    257[0m [38;5;66;03m# Initialization (if  ff_input is None, ff_input is generated)[39;00m
  [0;32m--> 258[0m rates, ff_input, rec_input [38;5;241m=[39m [38;5;28;41mself[39;49m[38;5;241;41m.[39;49m[41minitRates[49m[41m([49m[41mff_input[49m[41m)[49m
  [1;32m    260[0m [38;5;66;03m# NEED .clone() here otherwise BAD THINGS HAPPEN[39;00m
  [1;32m    261[0m [38;5;28;01mif[39;00m [38;5;28mself[39m[38;5;241m.[39mIF_BATCH_J:

  File [0;32m~/models/NeuroFlame/org/../src/network.py:157[0m, in [0;36mNetwork.initRates[0;34m(self, ff_input)[0m
  [1;32m    153[0m     rates [38;5;241m=[39m Activation()(
  [1;32m    154[0m         ff_input [38;5;241m+[39m rec_input[[38;5;241m0[39m], func_name[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mTF_TYPE, thresh[38;5;241m=[39m[38;5;28mself[39m[38;5;241m.[39mthresh
  [1;32m    155[0m     )
  [1;32m    156[0m [38;5;28;01melse[39;00m:
  [0;32m--> 157[0m     rates [38;5;241m=[39m [41mActivation[49m[41m([49m[41m)[49m[41m([49m
  [1;32m    158[0m [41m        [49m[41mff_input[49m[41m[[49m[41m:[49m[41m,[49m[41m [49m[38;5;241;41m0[39;49m[41m][49m[41m [49m[38;5;241;41m+[39;49m[41m [49m[41mrec_input[49m[41m[[49m[38;5;241;41m0[39;49m[41m][49m[41m,[49m
  [1;32m    159[0m [41m        [49m[41mfunc_name[49m[38;5;241;41m=[39;49m[38;5;28;41mself[39;49m[38;5;241;41m.[39;49m[41mTF_TYPE[49m[41m,[49m
  [1;32m    160[0m [41m        [49m[41mthresh[49m[38;5;241;41m=[39;49m[38;5;28;41mself[39;49m[38;5;241;41m.[39;49m[41mthresh[49m[41m,[49m
  [1;32m    161[0m [41m    [49m[41m)[49m
  [1;32m    163[0m [38;5;28;01mreturn[39;00m rates, ff_input, rec_input

  File [0;32m~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1511[0m, in [0;36mModule._wrapped_call_impl[0;34m(self, *args, **kwargs)[0m
  [1;32m   1509[0m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m[38;5;241m.[39m_compiled_call_impl([38;5;241m*[39margs, [38;5;241m*[39m[38;5;241m*[39mkwargs)  [38;5;66;03m# type: ignore[misc][39;00m
  [1;32m   1510[0m [38;5;28;01melse[39;00m:
  [0;32m-> 1511[0m     [38;5;28;01mreturn[39;00m [38;5;28;41mself[39;49m[38;5;241;41m.[39;49m[41m_call_impl[49m[41m([49m[38;5;241;41m*[39;49m[41margs[49m[41m,[49m[41m [49m[38;5;241;41m*[39;49m[38;5;241;41m*[39;49m[41mkwargs[49m[41m)[49m

  File [0;32m~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1520[0m, in [0;36mModule._call_impl[0;34m(self, *args, **kwargs)[0m
  [1;32m   1515[0m [38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in[39;00m
  [1;32m   1516[0m [38;5;66;03m# this function, and just call forward.[39;00m
  [1;32m   1517[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m ([38;5;28mself[39m[38;5;241m.[39m_backward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_backward_pre_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_hooks [38;5;129;01mor[39;00m [38;5;28mself[39m[38;5;241m.[39m_forward_pre_hooks
  [1;32m   1518[0m         [38;5;129;01mor[39;00m _global_backward_pre_hooks [38;5;129;01mor[39;00m _global_backward_hooks
  [1;32m   1519[0m         [38;5;129;01mor[39;00m _global_forward_hooks [38;5;129;01mor[39;00m _global_forward_pre_hooks):
  [0;32m-> 1520[0m     [38;5;28;01mreturn[39;00m [41mforward_call[49m[41m([49m[38;5;241;41m*[39;49m[41margs[49m[41m,[49m[41m [49m[38;5;241;41m*[39;49m[38;5;241;41m*[39;49m[41mkwargs[49m[41m)[49m
  [1;32m   1522[0m [38;5;28;01mtry[39;00m:
  [1;32m   1523[0m     result [38;5;241m=[39m [38;5;28;01mNone[39;00m

  File [0;32m~/models/NeuroFlame/org/../src/activation.py:11[0m, in [0;36mActivation.forward[0;34m(self, x, func_name, thresh)[0m
  [1;32m      9[0m [38;5;28;01mdef[39;00m [38;5;21mforward[39m([38;5;28mself[39m, x, func_name[38;5;241m=[39m[38;5;124m"[39m[38;5;124mrelu[39m[38;5;124m"[39m, thresh[38;5;241m=[39m[38;5;241m15[39m):
  [1;32m     10[0m     [38;5;28;01mif[39;00m func_name [38;5;241m==[39m [38;5;124m"[39m[38;5;124mrelu[39m[38;5;124m"[39m:
  [0;32m---> 11[0m         [38;5;28;01mreturn[39;00m nn[38;5;241m.[39mReLU()([41mx[49m[41m [49m[38;5;241;41m-[39;49m[41m [49m[41mthresh[49m)
  [1;32m     12[0m     [38;5;28;01melif[39;00m func_name [38;5;241m==[39m [38;5;124m"[39m[38;5;124merf[39m[38;5;124m"[39m:
  [1;32m     13[0m         [38;5;28;01mreturn[39;00m torch[38;5;241m.[39merf(x [38;5;241m/[39m torch[38;5;241m.[39msqrt(torch[38;5;241m.[39mtensor([38;5;241m2.0[39m)))

  [0;31mRuntimeError[0m: The size of tensor a (20) must match the size of tensor b (32) at non-singleton dimension 0
#+end_example
:END:

#+begin_src ipython
  # memory = model.odors.cpu().detach().numpy()[0]
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
  plot_overlap(rates, memory, readout, labels=['A', 'B'])
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: [0;31m---------------------------------------------------------------------------[0m
: [0;31mNameError[0m                                 Traceback (most recent call last)
: Cell [0;32mIn[57], line 4[0m
: [1;32m      2[0m memory [38;5;241m=[39m model[38;5;241m.[39mlow_rank[38;5;241m.[39mU[38;5;241m.[39mcpu()[38;5;241m.[39mdetach()[38;5;241m.[39mnumpy()[model[38;5;241m.[39mslices[[38;5;241m0[39m], [38;5;241m0[39m]
: [1;32m      3[0m readout [38;5;241m=[39m model[38;5;241m.[39mlow_rank[38;5;241m.[39mlinear[38;5;241m.[39mweight[38;5;241m.[39mdata[38;5;241m.[39mcpu()[38;5;241m.[39mdetach()[38;5;241m.[39mnumpy()[[38;5;241m0[39m]
: [0;32m----> 4[0m plot_overlap([41mrates[49m, memory, readout, labels[38;5;241m=[39m[[38;5;124m'[39m[38;5;124mA[39m[38;5;124m'[39m, [38;5;124m'[39m[38;5;124mB[39m[38;5;124m'[39m])
:
: [0;31mNameError[0m: name 'rates' is not defined
:END:

#+begin_src ipython
  idx = get_idx(model, -1)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([3, 1000])
# [goto error]
: [0;31m---------------------------------------------------------------------------[0m
: [0;31mNameError[0m                                 Traceback (most recent call last)
: Cell [0;32mIn[58], line 2[0m
: [1;32m      1[0m idx [38;5;241m=[39m get_idx(model, [38;5;241m-[39m[38;5;241m1[39m)
: [0;32m----> 2[0m plot_rates_selec([41mrates[49m, idx)
:
: [0;31mNameError[0m: name 'rates' is not defined
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
: [0;31m---------------------------------------------------------------------------[0m
: [0;31mNameError[0m                                 Traceback (most recent call last)
: Cell [0;32mIn[59], line 1[0m
: [0;32m----> 1[0m plot_m0_m1_phi([41mrates[49m, idx)
:
: [0;31mNameError[0m: name 'rates' is not defined
:END:

#+begin_src ipython

#+end_src

#+RESULTS:

* DPA
** Training
*** Parameters

#+begin_src ipython
    model.low_rank.linear = nn.Linear(
        model.Na[0], model.low_rank.LR_CLASS, device=model.device, bias=model.low_rank.LR_BIAS
    )
#+end_src

#+RESULTS:

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1
#+end_src

#+RESULTS:

Here we only evaluate performance from test onset to test offset

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
  # mask = (steps >= (model.N_STIM_OFF[2] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  mask = (steps >= (model.N_STIM_ON[2] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  rwd_idx = np.where(mask)[0]
  print('rwd', rwd_idx)

  model.lr_eval_win = rwd_idx.shape[0]

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))
  stim_mask1 = (steps >= (model.N_STIM_ON[2] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[2] - model.N_STEADY))

  mask_zero = ~mask & ~stim_mask & ~stim_mask1
  zero_idx = np.where(mask_zero)[0]
  print('zero', zero_idx)
#+end_src

#+RESULTS:
: rwd [50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]
: zero [ 0  1  2  3  4  5  6  7  8  9 20 21 22 23 24 25 26 27 28 29 30 31 32 33
:  34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49]

*** Inputs and Labels

#+begin_src ipython
  model.N_BATCH = 64

  A0 = 1

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = A0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = -A0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = A0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = -A0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([256, 810, 2000])

 #+begin_src ipython
  labels_pair = torch.ones((2 * model.N_BATCH, model.lr_eval_win))
  labels_unpair = torch.zeros((2 * model.N_BATCH, model.lr_eval_win))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([256, 21])

#+RESULTS:

*** Run

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([204, 810, 2000]) torch.Size([52, 810, 2000])
: torch.Size([204, 21]) torch.Size([52, 21])

#+begin_src ipython
  # Loss
  criterion = DualLoss(alpha=1.0, thresh=2.0, N=model.Na[0], rwd_idx=rwd_idx, zero_idx=zero_idx)

  # Optimizer: SGD, Adam, AdamW
  learning_rate = 0.05
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 30
  start = perf_counter()
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src

#+RESULTS:
#+begin_example
  Epoch 1/30, Training Loss: 0.9223, Validation Loss: 0.9159
  Angle(U, W) : 89.0 Â°
  Epoch 2/30, Training Loss: 0.7941, Validation Loss: 0.8008
  Angle(U, W) : 89.0 Â°
  Epoch 3/30, Training Loss: 0.6516, Validation Loss: 0.6457
  Angle(U, W) : 89.0 Â°
  Epoch 4/30, Training Loss: 0.4892, Validation Loss: 0.4527
  Angle(U, W) : 90.0 Â°
  Epoch 5/30, Training Loss: 0.2433, Validation Loss: 0.2023
  Angle(U, W) : 89.0 Â°
  Epoch 6/30, Training Loss: 0.0220, Validation Loss: 0.0292
  Angle(U, W) : 90.0 Â°
  Epoch 7/30, Training Loss: 0.0112, Validation Loss: 0.0131
  Angle(U, W) : 89.0 Â°
  Epoch 8/30, Training Loss: 0.0136, Validation Loss: 0.0130
  Angle(U, W) : 89.0 Â°
  Epoch 9/30, Training Loss: 0.0068, Validation Loss: 0.0107
  Angle(U, W) : 89.0 Â°
  Epoch 10/30, Training Loss: 0.0086, Validation Loss: 0.0068
  Angle(U, W) : 89.0 Â°
  Epoch 11/30, Training Loss: 0.0061, Validation Loss: 0.0060
  Angle(U, W) : 89.0 Â°
  Epoch 12/30, Training Loss: 0.0019, Validation Loss: 0.0043
  Angle(U, W) : 89.0 Â°
  Stopping training as loss has fallen below the threshold: 0.0042504316303305905
  Elapsed (with compilation) = 0h 3m 18s
#+end_example

    #+begin_src ipython
  plt.plot(loss)
  plt.plot(val_loss)
  plt.xlabel('epochs')
  plt.ylabel('Loss')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/29d7faaea0fde49313d0b20d635daf9abcad0284.png]]

 #+begin_src ipython
  torch.save(model.state_dict(), 'models/dpa_%d.pth' % seed)
#+end_src

#+RESULTS:

#+begin_src ipython
  odors = model.odors.cpu().numpy()
  U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]
  W = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]

  print('   U  V  W  S  D')
  print('U ', angle_AB(U, U), angle_AB(U, V), angle_AB(U, W), angle_AB(U, odors[0]), angle_AB(U, odors[1]))
  print('V ', 'XXX', angle_AB(V, V), angle_AB(V, W), angle_AB(V, odors[0]), angle_AB(V, odors[1]))
  print('W ', 'XXX', 'XXX', angle_AB(W, W), angle_AB(W, odors[0]), angle_AB(W, odors[1]))
  print('S ', 'XXX', 'XXX', 'XXX', angle_AB(odors[0], odors[0]), angle_AB(odors[0], odors[1]))
  print('D ', 'XXX', 'XXX', 'XXX', 'XXX', angle_AB(odors[1], odors[1]))

#+end_src

#+RESULTS:
:    U  V  W  S  D
: U  0 80 88 87 90
: V  XXX 0 89 104 92
: W  XXX XXX 0 90 91
: S  XXX XXX XXX 0 88
: D  XXX XXX XXX XXX 0

** Testing

#+begin_src ipython
  model.eval()
  model.LR_READOUT = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 10
  A0 = 1

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = A0

  AC_pair = model.init_ff_input()

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = -A0

  AD_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = A0

  BC_pair = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = -A0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([40, 810, 2000])

 #+begin_src ipython
  labels_pair = torch.ones((2 * model.N_BATCH, 2))
  labels_unpair = torch.zeros((2 * model.N_BATCH, 2))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([40, 2])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input)
  print(rates.shape)
#+end_src

#+RESULTS:
: torch.Size([40, 71, 1000])

#+begin_src ipython
  print(rates.shape)
  print(labels.shape)
#+end_src

#+RESULTS:
: torch.Size([40, 71, 1000])
: torch.Size([40, 2])

#+begin_src ipython
  perf = performance_score(model, rates, labels.to('cuda:1'))
#+end_src

#+RESULTS:
: torch.Size([40, 71, 1000])
: torch.Size([40, 2])

#+begin_src ipython
  print(perf)
#+end_src

#+RESULTS:
: 1.0

#+begin_src ipython
  readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  plot_overlap(rates.detach().cpu().numpy(), memory, readout, labels=['pair', 'unpair'], figname='dpa_overlap.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/819d3bd83238fff6c304bf8b0dcac7c6ea614b62.png]]

#+begin_src ipython
  idx = get_idx(model, -1)
  plot_rates_selec(rates.detach().cpu().numpy(), idx, figname='dpa_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([3, 1000])
[[file:./.ob-jupyter/b62bb9899149cec9df96d10b1e6428a2faf1c05c.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates.detach().cpu().numpy(), idx, figname='dpa_fourier.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/bf9ac104d819b5d388b6db765b82ef51251170b6.png]]

#+begin_src ipython
  print(rates.shape)
#+end_src

#+RESULTS:
: torch.Size([40, 71, 1000])

#+begin_src ipython
    from matplotlib.patches import Circle
    m0, m1, phi = decode_bump(rates[..., idx].detach().cpu().numpy(), axis=-1)

    x = m1 / m0 * np.cos(phi)
    y = m1 / m0 * np.sin(phi)

    xA = x
    yA = y

    fig, ax = plt.subplots(1, 1, figsize=[height, height])

    ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
    ax.plot(xA.T, yA.T, '-', alpha=.5)
    ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=10)
    # ax.set_xlim([-.9, .9])
    # ax.set_ylim([-.9, .9])
    circle = Circle((0., 0.), 1, fill=False, edgecolor='k')
    ax.add_patch(circle)

    # Set the aspect of the plot to equal to make the circle circular
    ax.set_aspect('equal')

    plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/4697a78a0c673a953ebf5fc2b7b1643b32e11af0.png]]

* Go/NoGo
** Training

#+begin_src ipython
  model.DURATION = 3
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1
#+end_src

#+RESULTS:

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)
  mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))

  rwd_idx = np.where(mask)[0]
  print('rwd', rwd_idx)

  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))

  mask_zero = ~mask & ~stim_mask
  zero_idx = np.where(mask_zero)[0]
  print('zero', zero_idx)

  model.lr_eval_win = rwd_idx.shape[0]
#+end_src

#+RESULTS:
: rwd [10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30]
: zero [0 1 2 3 4 5 6 7 8 9]

#+begin_src ipython
  # switching sample and distractor odors
  odors = model.odors.clone()
  model.odors[0] = odors[1]

  model.N_BATCH = 64

  A0 = 1

  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0

  Go = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0

  NoGo = model.init_ff_input()

  ff_input = torch.cat((Go, NoGo))
  print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([128, 410, 2000])

#+begin_src ipython
  labels_Go = torch.ones((model.N_BATCH, model.lr_eval_win))
  labels_NoGo = torch.zeros((model.N_BATCH, model.lr_eval_win))
  labels = torch.cat((labels_Go, labels_NoGo))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([128, 21])

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([102, 410, 2000]) torch.Size([26, 410, 2000])
: torch.Size([102, 21]) torch.Size([26, 21])

#+begin_src ipython
  criterion = DualLoss(alpha=1.0, thresh=4.0, N=model.Na[0], rwd_idx=rwd_idx, zero_idx=zero_idx)

  # SGD, Adam, AdamW
  learning_rate = 0.05
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 30
  start = perf_counter()
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
  # switching back sample and distractor odors
  model.odors[0] = odors[0]
#+end_src
#+RESULTS:
#+begin_example
  Epoch 1/30, Training Loss: 1.7986, Validation Loss: 1.8449
  Angle(U, W) : 90.0 Â°
  Epoch 2/30, Training Loss: 1.6834, Validation Loss: 1.6049
  Angle(U, W) : 92.0 Â°
  Epoch 3/30, Training Loss: 1.2529, Validation Loss: 1.3164
  Angle(U, W) : 94.0 Â°
  Epoch 4/30, Training Loss: 0.8546, Validation Loss: 0.9205
  Angle(U, W) : 95.0 Â°
  Epoch 5/30, Training Loss: 0.3883, Validation Loss: 0.5576
  Angle(U, W) : 97.0 Â°
  Epoch 6/30, Training Loss: 0.4367, Validation Loss: 0.4340
  Angle(U, W) : 96.0 Â°
  Epoch 7/30, Training Loss: 0.1180, Validation Loss: 0.2558
  Angle(U, W) : 95.0 Â°
  Epoch 8/30, Training Loss: 0.0285, Validation Loss: 0.0350
  Angle(U, W) : 93.0 Â°
  Epoch 9/30, Training Loss: 0.0049, Validation Loss: 0.0066
  Angle(U, W) : 92.0 Â°
  Epoch 10/30, Training Loss: 0.0047, Validation Loss: 0.0055
  Angle(U, W) : 91.0 Â°
  Epoch 11/30, Training Loss: 0.0037, Validation Loss: 0.0058
  Angle(U, W) : 91.0 Â°
  Epoch 12/30, Training Loss: 0.0017, Validation Loss: 0.0030
  Angle(U, W) : 91.0 Â°
  Stopping training as loss has fallen below the threshold: 0.002964354012734615
  Elapsed (with compilation) = 0h 0m 53s
#+end_example

#+begin_src ipython
  plt.plot(loss)
  plt.plot(val_loss)
  plt.xlabel('epochs')
  plt.ylabel('Loss')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/f66bfc8ae6bf72f828b5968648cf635f037ac8cc.png]]

#+begin_src ipython
  odors = model.odors.cpu().numpy()
  U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]
  W = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]

  print('   U  V  W  S  D')
  print('U ', angle_AB(U, U), angle_AB(U, V), angle_AB(U, W), angle_AB(U, odors[0]), angle_AB(U, odors[1]))
  print('V ', 'XXX', angle_AB(V, V), angle_AB(V, W), angle_AB(V, odors[0]), angle_AB(V, odors[1]))
  print('W ', 'XXX', 'XXX', angle_AB(W, W), angle_AB(W, odors[0]), angle_AB(W, odors[1]))
  print('S ', 'XXX', 'XXX', 'XXX', angle_AB(odors[0], odors[0]), angle_AB(odors[0], odors[1]))
  print('D ', 'XXX', 'XXX', 'XXX', 'XXX', angle_AB(odors[1], odors[1]))

#+end_src

#+RESULTS:
:    U  V  W  S  D
: U  0 75 91 89 87
: V  XXX 0 96 99 94
: W  XXX XXX 0 91 67
: S  XXX XXX XXX 0 88
: D  XXX XXX XXX XXX 0

#+begin_src ipython
  torch.save(model.state_dict(), 'models/dual_naive_%d.pth' % seed)
#+end_src

#+RESULTS:

** Testing

#+begin_src ipython
  model.eval()
  model.LR_READOUT = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  odors = model.odors.clone()
  model.odors[0] = odors[1]
  model.N_BATCH = 1

  A0 = 1
  model.I0[0] = A0
  model.I0[1] = 0
  model.I0[2] = 0

  A = model.init_ff_input()

  model.I0[0] = -A0
  model.I0[1] = 0
  model.I0[2] = 0

  B = model.init_ff_input()

  ff_input = torch.cat((A, B))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([2, 410, 2000])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  model.odors[0] = odors[0]
  print(rates.shape)
#+end_src

#+RESULTS:
: (2, 31, 1000)

#+begin_src ipython
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
  plot_overlap(rates, memory, readout, labels=['Go', 'NoGo'])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/54a04120125fe1513667324a0b149f5f7b42d366.png]]

#+begin_src ipython
  idx = get_idx(model, -1)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([3, 1000])
[[file:./.ob-jupyter/446a98ec95d6352f1e2105edaedd625814cd4460.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/1d394076f525c2617fd7c46f80b874cd6536dbf3.png]]

* Dual

#+begin_src ipython
  model.DURATION = 7
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

** Testing

#+begin_src ipython
  model.eval()
  model.LR_READOUT = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 10

  model.I0[0] = 1
  model.I0[1] = 1
  model.I0[2] = 1

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 1
  model.I0[2] = -1

  AD_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 1
  model.I0[2] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 1
  model.I0[2] = -1

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([40, 810, 2000])

 #+begin_src ipython
  labels_pair = torch.ones((2 * model.N_BATCH, 2))
  labels_unpair = torch.zeros((2 * model.N_BATCH, 2))

  labels = torch.cat((labels_pair, labels_unpair))
  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([40, 2])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).detach()
  print(rates.shape)
#+end_src

#+RESULTS:
: torch.Size([40, 71, 1000])

#+begin_src ipython
  perf = performance_score(model, rates, labels.to('cuda:1'))
  print(perf)
#+end_src

#+RESULTS:
: torch.Size([40, 71, 1000])
: torch.Size([40, 2])
: 0.525

#+begin_src ipython
  rates = rates.cpu().numpy()
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]
  plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_naive_overlap.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/3352f493928e6b27280e5849422d7dd5c4078540.png]]

#+begin_src ipython
  idx = get_idx(model, -1)
  plot_rates_selec(rates, idx, figname='dual_naive_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([3, 1000])
[[file:./.ob-jupyter/f98144103a6e2939e2e4e027a50aa4b2f4c48736.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx, figname='dual_naive_fourier.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/f14a3216249041b82fd2863ff9fa06096b2619e6.png]]

#+begin_src ipython
    from matplotlib.patches import Circle
    m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

    x = m1 / m0 * np.cos(phi)
    y = m1 / m0 * np.sin(phi)

    xA = x
    yA = y

    fig, ax = plt.subplots(1, 1, figsize=[height, height])

    ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
    ax.plot(xA.T, yA.T, '-', alpha=.5)
    ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=10)
    # ax.set_xlim([-.9, .9])
    # ax.set_ylim([-.9, .9])
    circle = Circle((0., 0.), 1, fill=False, edgecolor='k')
    ax.add_patch(circle)

    # Set the aspect of the plot to equal to make the circle circular
    ax.set_aspect('equal')

    plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/5742dbc360f9011cabd8f110bbdcef4afb9f95f3.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

** Training

#+begin_src ipython
  model.LR_TRAIN = 1
  model.LR_READOUT = 1
#+end_src

#+RESULTS:

#+begin_src ipython
  steps = np.arange(0, model.N_STEPS - model.N_STEADY, model.N_WINDOW)

  mask_rwd = (steps >= (model.N_STIM_OFF[2] - model.N_STEADY)) & (steps <= (model.N_STEPS - model.N_STEADY))
  rwd_idx = np.where(mask_rwd)[0]
  print('rwd', rwd_idx)

  mask_cue = (steps >= (model.N_STIM_OFF[1] - model.N_STEADY)) & (steps <= (model.N_STIM_ON[2] - model.N_STEADY))
  cue_idx = np.where(mask_cue)[0]
  print('cue', cue_idx)

  # stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[0] - model.N_STEADY))
  stim_mask = (steps >= (model.N_STIM_ON[0] - model.N_STEADY)) & (steps < (model.N_STIM_ON[1] - model.N_STEADY))
  stim_mask1 = (steps >= (model.N_STIM_ON[1] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[1] - model.N_STEADY))
  stim_mask2 = (steps >= (model.N_STIM_ON[2] - model.N_STEADY)) & (steps < (model.N_STIM_OFF[2] - model.N_STEADY))

  mask_zero = ~mask_rwd & ~mask_cue & ~stim_mask & ~stim_mask1 & ~stim_mask2
  zero_idx = np.where(mask_zero)[0]
  print('zero', zero_idx)
#+end_src

#+RESULTS:
: rwd [60 61 62 63 64 65 66 67 68 69 70]
: cue [40 41 42 43 44 45 46 47 48 49 50]
: zero [0 1 2 3 4 5 6 7 8 9]

#+begin_src ipython
  model.N_BATCH = 64

  model.lr_eval_win = np.max( (rwd_idx.shape[0], cue_idx.shape[0]))

  ff_input = []
  labels = np.zeros((2, 12, model.N_BATCH, model.lr_eval_win))
  l=0
  for i in [-1, 1]:
      for j in [-1, 0, 1]:
          for k in [1, -1]:

              model.I0[0] = i
              model.I0[1] = j
              model.I0[2] = k

              if i==k: # Pair Trials
                  labels[0, l] = np.ones((model.N_BATCH, model.lr_eval_win))
              # else: # Unpair Trials
              #     labels[0, l] = np.zeros((model.N_BATCH, model.lr_eval_win))

              if j==1: # Go
                  labels[1, l] = np.ones((model.N_BATCH, model.lr_eval_win))
              # if j==-1: # NoGo
              #     labels[1, l] = np.zeros((model.N_BATCH, model.lr_eval_win))

              l+=1

              ff_input.append(model.init_ff_input())

  labels = torch.tensor(labels, dtype=torch.float, device=DEVICE).reshape(2, -1, model.lr_eval_win).transpose(0, 1)
  ff_input = torch.vstack(ff_input)
  print('ff_input', ff_input.shape, 'labels', labels.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([768, 810, 2000]) labels torch.Size([768, 2, 11])

#+begin_src ipython
  batch_size = 16
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)
#+end_src

#+RESULTS:
: torch.Size([614, 810, 2000]) torch.Size([154, 810, 2000])
: torch.Size([614, 2, 11]) torch.Size([154, 2, 11])

#+begin_src ipython
  # criterion = nn.BCEWithLogitsLoss()
  criterion = DualLoss(alpha=1.0, thresh=2.0, N=model.Na[0], cue_idx=cue_idx, rwd_idx=rwd_idx, zero_idx=zero_idx)

  # SGD, Adam, AdamW
  learning_rate = 0.05
  optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
#+end_src

#+RESULTS:

#+begin_src ipython
  num_epochs = 30
  start = perf_counter()
  loss, val_loss = run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)
  end = perf_counter()
  print("Elapsed (with compilation) = %dh %dm %ds" % convert_seconds(end - start))
#+end_src
#+RESULTS:
#+begin_example
  Epoch 1/30, Training Loss: 0.5015, Validation Loss: 0.5428
  Angle(U, W) : 93.0 Â°
  Epoch 2/30, Training Loss: 0.1558, Validation Loss: 0.2556
  Angle(U, W) : 93.0 Â°
  Epoch 3/30, Training Loss: 0.0733, Validation Loss: 0.0629
  Angle(U, W) : 93.0 Â°
  Epoch 4/30, Training Loss: 0.0088, Validation Loss: 0.0265
  Angle(U, W) : 93.0 Â°
  Epoch 5/30, Training Loss: 0.0110, Validation Loss: 0.0134
  Angle(U, W) : 93.0 Â°
  Epoch 6/30, Training Loss: 0.0013, Validation Loss: 0.0084
  Angle(U, W) : 93.0 Â°
  Epoch 7/30, Training Loss: 0.0043, Validation Loss: 0.0096
  Angle(U, W) : 92.0 Â°
  Epoch 8/30, Training Loss: 0.0086, Validation Loss: 0.0128
  Angle(U, W) : 92.0 Â°
  Epoch 9/30, Training Loss: 0.0028, Validation Loss: 0.0051
  Angle(U, W) : 92.0 Â°
  Epoch 10/30, Training Loss: 0.0003, Validation Loss: 0.0085
  Angle(U, W) : 92.0 Â°
  Epoch 11/30, Training Loss: 0.0005, Validation Loss: 0.0114
  Angle(U, W) : 92.0 Â°
  Epoch 12/30, Training Loss: 0.0000, Validation Loss: 0.0044
  Angle(U, W) : 92.0 Â°
  Stopping training as loss has fallen below the threshold: 0.004406882762189277
  Elapsed (with compilation) = 0h 9m 45s
#+end_example

#+begin_src ipython
  torch.save(model.state_dict(), 'models/dual_train_%d.pth' % seed)
#+end_src

#+RESULTS:

#+begin_src ipython
  odors = model.odors.cpu().numpy()
  U = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  V = model.low_rank.V.cpu().detach().numpy()[model.slices[0], 0]
  W = model.low_rank.linear.weight.data.cpu().detach().numpy()[0]

  print('   U  V  W  S  D')
  print('U ', angle_AB(U, U), angle_AB(U, V), angle_AB(U, W), angle_AB(U, odors[0]), angle_AB(U, odors[1]))
  print('V ', 'XXX', angle_AB(V, V), angle_AB(V, W), angle_AB(V, odors[0]), angle_AB(V, odors[1]))
  print('W ', 'XXX', 'XXX', angle_AB(W, W), angle_AB(W, odors[0]), angle_AB(W, odors[1]))
  print('S ', 'XXX', 'XXX', 'XXX', angle_AB(odors[0], odors[0]), angle_AB(odors[0], odors[1]))
  print('D ', 'XXX', 'XXX', 'XXX', 'XXX', angle_AB(odors[1], odors[1]))

#+end_src

#+RESULTS:
:    U  V  W  S  D
: U  0 73 92 89 87
: V  XXX 0 97 98 92
: W  XXX XXX 0 89 74
: S  XXX XXX XXX 0 88
: D  XXX XXX XXX XXX 0

** Re-Testing

#+begin_src ipython
  model.DURATION = 7
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.eval()
  model.LR_READOUT = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 10

  model.I0[0] = 1
  model.I0[1] = 1
  model.I0[2] = 1

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 1
  model.I0[2] = -1

  AD_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 1
  model.I0[2] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 1
  model.I0[2] = -1

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([40, 810, 2000])

#+begin_src ipython
  labels_A = torch.ones((2*model.N_BATCH, 2))
  labels_B = torch.zeros((2*model.N_BATCH, 2))
  labels = torch.cat((labels_A, labels_B))

  print('labels', labels.shape)
#+end_src

#+RESULTS:
: labels torch.Size([40, 2])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).detach()
  print(rates.shape)
#+end_src

#+RESULTS:
: torch.Size([40, 71, 1000])

#+begin_src ipython
  perf = performance_score(model, rates, labels.to(DEVICE))
#+end_src

#+RESULTS:
: torch.Size([40, 71, 1000])
: torch.Size([40, 2])

#+begin_src ipython
  print(perf)
#+end_src

#+RESULTS:
: 1.0

#+begin_src ipython
  rates = rates.cpu().detach().numpy()
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.linear.weight.data[0].cpu().detach().numpy()
  plot_overlap(rates, memory, readout, labels=['pair', 'unpair'], figname='dual_train_overlap.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/fb8e2d7bf9bed7ce26648e6aef14c7c7b5e9985d.png]]

#+begin_src ipython
  idx = get_idx(model, -1)
  plot_rates_selec(rates, idx, figname='dual_train_raster.svg')
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([3, 1000])
[[file:./.ob-jupyter/e2fe6585423ec9c33aaab630fcd1c836bc400e96.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx, figname='dual_train_fourier.svg')
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/e0de3f7325ce0287cc39c47724e3a7f40df7fb3a.png]]

#+begin_src ipython
    from matplotlib.patches import Circle
    m0, m1, phi = decode_bump(rates[..., idx], axis=-1)

    x = m1 / m0 * np.cos(phi)
    y = m1 / m0 * np.sin(phi)

    xA = x
    yA = y

    fig, ax = plt.subplots(1, 1, figsize=[height, height])

    ax.plot(xA.T[0], yA.T[0], 'x', alpha=.5, ms=10)
    ax.plot(xA.T, yA.T, '-', alpha=.5)
    ax.plot(xA.T[-1], yA.T[-1], 'o', alpha=.5, ms=10)
    # ax.set_xlim([-.9, .9])
    # ax.set_ylim([-.9, .9])
    circle = Circle((0., 0.), 1, fill=False, edgecolor='k')
    ax.add_patch(circle)

    # Set the aspect of the plot to equal to make the circle circular
    ax.set_aspect('equal')

    plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/e90438b62ba0e4aedec6089959c3e7e4b14bce6d.png]]

#+begin_src ipython

#+end_src

#+RESULTS:

** Re-Testing

#+begin_src ipython
  model.DURATION = 20
  model.N_STEPS = int(model.DURATION / model.DT) + model.N_STEADY + model.N_WINDOW
#+end_src

#+RESULTS:

#+begin_src ipython
  model.eval()
  model.LR_READOUT = 0
#+end_src

#+RESULTS:

#+begin_src ipython
  model.N_BATCH = 10

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 0

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = 0
  model.I0[2] = 0

  AD_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 0

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 0
  model.I0[2] = 0

  BD_pair = model.init_ff_input()

  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print('ff_input', ff_input.shape)
#+end_src

#+RESULTS:
: ff_input torch.Size([40, 2110, 2000])

#+begin_src ipython
  rates = model.forward(ff_input=ff_input).cpu().detach().numpy()
  print(rates.shape)
#+end_src

#+RESULTS:
: (40, 201, 1000)

#+begin_src ipython
  memory = model.low_rank.U.cpu().detach().numpy()[model.slices[0], 0]
  readout = model.low_rank.linear.weight.data[0].cpu().detach().numpy()
  plot_overlap(rates, memory, readout, labels=['pair', 'unpair'])
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/dc9669b95ce7f04e7d1e44687566da3dc375d2ff.png]]

#+begin_src ipython
  idx = get_idx(model, -1)
  plot_rates_selec(rates, idx)
#+end_src

#+RESULTS:
:RESULTS:
: ksi torch.Size([3, 1000])
[[file:./.ob-jupyter/6ce48ec76a5cd9d76f1b9e9e4903b3287747b4c3.png]]
:END:

#+begin_src ipython
  plot_m0_m1_phi(rates, idx)
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/d0d95deb0de44f496ccb202d5ec28e17a9ac3e46.png]]


#+begin_src ipython
  print(rates.shape)
#+end_src

#+RESULTS:
: (40, 201, 1000)

#+begin_src ipython
  plt.plot(rates[:, :,0].T)
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/b707a93432e332d601d933bb42ab31e5feeb0b7c.png]]
