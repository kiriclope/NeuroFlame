#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session dual :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroTorch"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Helpers
** Training
*** split data

#+begin_src ipython
  def split_data(X, Y, train_perc=0.8, batch_size=32):

    # Split the dataset into training and validation sets
    train_size = int(train_perc * X.shape[0])

    X_train = X[:train_size]
    X_test = X[train_size:]

    # X_train, X_mean, X_std = standard_scaler(X_train, IF_RETURN=1)
    # X_test = (X_test - X_mean) / X_std

    Y_train = Y[:train_size]    
    Y_test = Y[train_size:]

    # Y_train, Y_mean, Y_std = standard_scaler(Y_train, IF_RETURN=1)
    # Y_test = (Y_test - Y_mean) / Y_std

    # Create data sets
    # train_dataset = TensorDataset(X_train_scaled, Y_train_scaled)
    # val_dataset = TensorDataset(X_test_scaled, Y_test_scaled)

    # print('X_train', X_train.shape, 'y_train', Y_train.shape)
    train_dataset = TensorDataset(X_train, Y_train)

    # print('X_test', X_test.shape, 'y_test', Y_test.shape)
    val_dataset = TensorDataset(X_test, Y_test)

    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    # sequence_length = 14  # or any other sequence length you want
    # stride = 1  # or any other stride you want

    # sliding_window_dataset = SlidingWindowDataset(X, sequence_length, stride)
    # train_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)
    # val_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)

    return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
  def train(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1):
      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          optimizer.zero_grad()

          X, y = X.to(device), y.to(device)
          # Compute prediction error
          y_pred = model(X)
          loss = loss_fn(y_pred, y)

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()
          optimizer.step()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def test(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0
      with torch.no_grad():
          for data, targets in dataloader:
              data, targets = data.to(device), targets.to(device)
              
              outputs = model(data)
              loss = loss_fn(outputs, targets)
              val_loss += loss.item() * data.size(0)
          val_loss /= size

      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def run_optim(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1):

    # scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)

    # Training loop.
    for epoch in range(num_epochs):
        loss = train(train_loader, model, loss_fn, optimizer, penalty, lbd)
        val_loss = test(val_loader, model, loss_fn)
        scheduler.step(val_loss)
        
        # if epoch % int(num_epochs  / 10) == 0:
        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
  def correlation_loss(output, target):
      # Subtract the mean of each vector
      output_mean = output - torch.mean(output)
      target_mean = target - torch.mean(target)
    
      # Compute the covariance between output and target
      covariance = torch.mean(output_mean * target_mean)
      
      # Compute the standard deviations of the vectors
      output_std = torch.std(output)
      target_std = torch.std(target)
    
      # Calculate the Pearson correlation coefficient
      correlation = covariance / (output_std * target_std)
    
      # Since we want to increase the correlation, we minimize its negative
      loss = -correlation  # Maximizing correlation by minimizing its negative
    
      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
    import torch
    import torch.nn as nn

    def sign_constrained_loss(output, xi, target_sign):
        dot_product = torch.dot(output.flatten(), xi.flatten())
        if target_sign > 0:
            loss = torch.relu(-dot_product)  # Encourages positive dot product
        else:
            loss = torch.relu(dot_product)   # Encourages negative dot product
        return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  class CosineLoss(nn.Module):
      def __init__(self):
          super(CosineLoss, self).__init__()
          self.cosine_similarity = nn.CosineSimilarity(dim=-1)
          
      def forward(self, input1, input2):
          # Calculate cosine similarity
          cosine_sim = self.cosine_similarity(input1, input2)
          # Calculate the loss as 1 - cosine_similarity
          loss = 1 - cosine_sim
          # Return the mean loss over the batch
          return loss.mean()
#+end_src

#+RESULTS:


#+RESULTS:

** Other

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      if GM:          
          b = b - np.dot(b, a) / np.dot(a, a) * a

      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)
      else:
          u=a
          v=b

      return np.arctan2(v, u)
#+end_src

#+RESULTS:


#+begin_src ipython
  import scipy.stats as stats

  def plot_smooth(data, ax, color):
      mean = data.mean(axis=0)  
      ci = smooth.std(axis=0, ddof=1) * 1.96
      
      # Plot
      ax.plot(mean, color=color)
      ax.fill_between(range(data.shape[1]), mean - ci, mean + ci, alpha=0.25, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter  
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl
#+end_src

#+RESULTS:

* Train RNN
** Parameters

#+Begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroTorch"
  conf_name = "config_I.yml"
  name = "dual"
#+end_src

#+RESULTS:

** Training

#+begin_src ipython
  start = perf_counter()
  name = "dual_single"
  model = Network(conf_name, name, REPO_ROOT, VERBOSE=0, DEVICE='cuda')
#+end_src

#+RESULTS:

#+begin_src ipython
  output = model.forward()
  print(output)
#+end_src

#+RESULTS:
: tensor([0.3281], device='cuda:0', grad_fn=<SqueezeBackward1>)

#+begin_src ipython
for name, param in model.named_parameters():
    if param.requires_grad:
        print(name, param.data)
#+end_src

#+RESULTS:
#+begin_example
  U tensor([[ 1.4004, -1.8255],
          [-0.1364, -1.2565],
          [-0.3649, -2.0425],
          ...,
          [-0.5555,  0.3720],
          [ 2.1568,  0.6320],
          [-0.4446,  1.2113]], device='cuda:0')
  linear.weight tensor([[ 2.4614e-02,  4.6007e-03,  4.2876e-04,  3.0197e-02, -1.9008e-02,
           -2.8179e-02, -3.0784e-02,  1.0527e-02, -1.1722e-02, -2.5231e-02,
           -2.4834e-02, -1.3015e-02, -2.9966e-03, -2.0829e-02,  1.5576e-02,
            2.8358e-02, -1.5324e-02, -1.4912e-02, -2.8646e-02,  1.5756e-02,
           -1.2836e-02, -2.7819e-02,  2.8096e-02,  1.0394e-02, -1.9106e-02,
            1.9461e-02, -1.6018e-02,  7.7075e-03, -1.2033e-02,  2.6135e-02,
           -2.2698e-02, -2.7904e-02, -1.8391e-02,  7.4767e-03,  2.3939e-02,
           -3.9106e-03, -2.6965e-02,  1.4115e-02, -6.2171e-03, -2.0729e-02,
           -2.3537e-02, -1.3804e-03, -2.4213e-02, -3.0907e-02, -5.0977e-03,
            2.8516e-02,  1.2566e-02, -2.1094e-02, -1.4854e-02,  2.0427e-03,
            2.4075e-02,  4.9249e-03,  7.7909e-03,  2.8641e-02,  1.7987e-02,
            3.9698e-03, -3.0520e-02,  7.9146e-03,  2.3883e-02, -2.6644e-02,
           -2.8776e-02, -2.2294e-02, -2.9793e-02, -2.2470e-02,  2.2027e-02,
            2.7644e-02,  1.6931e-02, -4.8333e-03,  4.2303e-03, -1.1882e-02,
           -2.7310e-02,  2.2620e-03,  4.6516e-03, -1.7183e-03, -1.6124e-02,
            1.3476e-02, -3.6465e-03,  2.2638e-02,  2.8444e-03,  1.8766e-02,
           -1.9265e-02,  9.8633e-03,  3.1492e-02, -9.5928e-03,  1.4076e-02,
           -3.7077e-03, -1.9591e-02,  3.8736e-03,  1.1674e-02,  1.7439e-02,
           -3.9834e-03,  2.0865e-02,  2.2733e-02, -9.3948e-03, -6.6300e-03,
           -2.7794e-02, -5.2290e-03, -1.7749e-02, -2.1604e-02, -2.4491e-02,
            1.0288e-02,  1.2376e-02, -3.1401e-03, -3.0585e-02, -1.6986e-02,
            1.4529e-02,  9.9885e-03,  1.4309e-02, -1.4428e-02,  1.7588e-02,
            1.0654e-02,  1.4902e-02, -2.6770e-02, -2.7135e-03,  1.7723e-02,
           -4.8933e-03, -6.0700e-03, -2.5039e-02,  3.0690e-02, -2.0534e-02,
            9.6153e-03, -2.9312e-02, -3.8189e-03,  1.8804e-02,  2.6315e-02,
            2.5204e-02,  2.9986e-02,  2.6092e-02, -3.1213e-03,  1.0005e-02,
            1.5004e-02,  2.8274e-02, -4.8216e-03,  5.9731e-04, -6.0092e-03,
            1.8609e-02,  1.5825e-02,  1.0120e-02, -2.5116e-02,  1.5298e-02,
            3.3861e-04,  1.2775e-03, -1.5783e-03, -2.2613e-02,  2.8974e-02,
           -1.7052e-02, -9.0422e-03, -2.4917e-03,  7.2856e-03,  2.2433e-02,
            2.5488e-02,  1.7602e-04,  1.5997e-03,  1.6506e-02, -2.8633e-04,
            1.1659e-03, -1.3238e-02, -1.5990e-02, -2.8391e-02,  2.9983e-02,
            2.0194e-02, -1.1714e-02, -1.0430e-02, -2.4071e-02,  1.5803e-02,
           -2.6788e-02,  2.7751e-02,  1.7810e-02, -2.9609e-02,  6.5761e-03,
           -3.0066e-02, -2.1501e-02,  2.6271e-02,  1.0871e-02, -2.4893e-02,
            1.3944e-02,  7.2106e-03,  2.3099e-02,  1.4587e-02, -1.5038e-02,
            2.1619e-02, -1.9779e-02,  2.9037e-02,  2.8485e-02, -1.4332e-02,
            2.6226e-02,  1.5013e-02,  1.5827e-02, -4.4039e-03,  6.2069e-03,
            2.3850e-02, -2.3224e-02,  2.8481e-02,  1.5794e-02,  2.6790e-02,
           -2.3059e-02,  7.9190e-04,  1.7764e-03,  1.0406e-02,  5.6221e-04,
           -2.5514e-02, -1.4700e-02, -4.1191e-03, -8.1572e-03, -1.6223e-02,
            1.1422e-02, -5.0754e-03, -1.7344e-02, -2.7897e-02,  1.2273e-03,
            1.4873e-02,  1.8632e-02, -2.4880e-02, -7.7605e-03, -1.2516e-02,
           -1.4794e-02, -1.3248e-02, -2.5352e-02,  3.1419e-02,  7.6337e-03,
           -2.8845e-03,  2.3176e-02,  1.0456e-02,  2.1574e-02, -1.5792e-02,
            2.1413e-02, -1.9253e-02, -1.6284e-02, -1.4183e-02,  8.2149e-04,
           -1.0412e-02, -1.6969e-02,  3.7552e-03, -1.2721e-02,  1.7824e-02,
            1.2709e-03, -2.4153e-02,  2.4585e-02, -2.4631e-04, -8.2294e-03,
           -2.0340e-05,  3.1333e-02, -3.9770e-03,  5.5988e-03,  2.8310e-02,
           -2.0441e-03,  6.4946e-04, -8.7673e-03, -2.7201e-02, -5.8375e-03,
           -2.5804e-02, -1.8313e-02, -8.6099e-03,  1.6742e-02,  8.0359e-03,
           -2.8464e-02,  2.9306e-02, -1.4008e-02, -3.0440e-02,  1.2038e-02,
            1.5704e-02, -1.0768e-02, -1.0001e-02, -2.2233e-02,  2.4960e-02,
            2.1826e-02, -2.5637e-02, -2.1427e-02, -5.6965e-03, -1.8672e-02,
           -1.2292e-02, -2.7286e-02, -7.9281e-03, -2.5420e-02,  9.4679e-03,
            7.7021e-03, -6.3460e-03, -3.0531e-02, -1.5460e-02, -2.9606e-02,
           -1.0564e-02,  4.1236e-03,  2.8487e-02,  1.4517e-03,  2.3733e-02,
           -3.7762e-03, -1.4146e-02, -2.4835e-02, -1.7385e-02, -1.8293e-02,
            1.8524e-02,  6.8383e-03, -1.9815e-02, -2.2382e-03,  2.9632e-02,
            3.1446e-02,  4.7257e-05,  1.7918e-02,  3.0546e-02,  1.7123e-02,
           -1.7374e-02, -1.3942e-02,  9.3177e-03, -2.7585e-02, -1.0935e-03,
           -1.5806e-02, -2.5154e-02, -1.2251e-02, -2.2513e-02, -1.7745e-02,
           -2.4675e-02, -2.0858e-02,  1.4969e-02,  6.1950e-03, -4.6467e-03,
            2.1378e-02,  7.6314e-03,  2.5583e-02,  1.7237e-02,  2.1893e-02,
            1.5888e-02,  2.7793e-02,  1.1000e-02, -1.8107e-02,  6.6967e-03,
           -2.4194e-02,  1.9838e-02,  1.2019e-03,  1.6447e-03, -2.6229e-02,
            8.5451e-03, -1.0307e-02, -1.1272e-02, -3.0189e-02,  6.3571e-03,
            2.1506e-03,  6.1604e-03,  3.2317e-03, -2.3359e-02, -2.7204e-02,
           -6.1895e-03, -1.8499e-03, -2.5387e-02, -1.7247e-02,  1.2311e-03,
           -2.8510e-02, -5.2356e-03,  1.7575e-02, -1.9096e-03, -3.0287e-02,
            8.2627e-03, -2.6718e-02,  4.9736e-03,  1.1736e-02, -1.8586e-02,
            7.3811e-03, -6.5754e-03,  3.0351e-02,  8.7367e-03, -2.2929e-02,
           -2.9985e-02, -1.7765e-02, -1.4877e-02, -1.8294e-02,  8.8808e-03,
           -7.0685e-03, -1.7798e-02,  1.3332e-02, -1.2320e-02,  1.3323e-02,
            2.1472e-02,  2.3906e-02, -3.3914e-03,  1.6070e-02,  2.0793e-02,
            9.0342e-03, -1.1720e-02, -1.7658e-03,  5.9149e-03,  1.7896e-02,
            2.1416e-02,  2.8957e-02, -3.0444e-02, -1.6744e-02,  7.6544e-03,
           -2.9895e-02, -3.4378e-03, -3.9504e-04, -9.3107e-03,  9.7749e-04,
           -3.8422e-03,  9.6907e-03,  6.2698e-03, -1.6938e-02,  1.9959e-02,
           -2.6834e-02, -1.6729e-02, -1.6199e-02,  1.8735e-02, -1.8432e-02,
            1.9141e-04, -2.3181e-02, -1.3823e-03,  1.4281e-03,  1.9459e-02,
           -2.2359e-02, -1.3129e-02,  2.0214e-02,  7.8236e-03, -3.0321e-02,
           -5.3523e-03,  4.1287e-03, -1.2785e-02, -1.6064e-02,  1.8562e-02,
           -1.2635e-02, -1.2635e-03,  1.4554e-03,  2.0713e-02, -9.3247e-03,
            2.0625e-02,  2.4459e-02, -1.8765e-02,  8.9285e-03,  1.3926e-02,
           -2.7631e-02,  1.1832e-02,  2.4118e-02,  1.4777e-02, -5.5744e-03,
           -2.2471e-02, -1.8039e-02, -4.4535e-03, -8.9493e-03, -1.7982e-02,
            1.5802e-02, -1.1638e-03, -2.6707e-02,  2.2173e-02,  2.0945e-02,
           -1.3283e-02,  3.1018e-02,  1.4089e-02, -5.7690e-03, -5.5892e-03,
            6.2944e-03, -2.4917e-02,  2.4427e-02,  1.5643e-02,  1.5396e-02,
           -1.7205e-02,  2.0506e-02, -1.9519e-03, -3.8683e-03, -3.0518e-02,
           -2.3808e-02,  1.6974e-02, -9.3267e-03,  3.0061e-03,  1.6147e-02,
            4.1286e-03,  3.7555e-03,  6.2202e-03,  2.0401e-02,  1.5332e-03,
            5.6532e-03, -8.4972e-03, -3.0882e-02,  1.4877e-02,  6.2536e-03,
            1.0196e-02,  2.2067e-02,  1.7355e-02, -1.4986e-02,  2.6219e-02,
            2.4191e-02, -9.4359e-03, -5.7599e-03,  1.9497e-03, -1.5921e-02,
            1.6285e-02,  1.1929e-02,  2.8357e-02,  1.0794e-02,  2.0534e-02,
            1.1808e-02,  1.2899e-03,  2.1443e-03, -1.4997e-02,  2.3411e-02,
           -2.9892e-02, -1.6805e-02, -1.8468e-02,  3.6819e-04,  2.3506e-02,
            5.7981e-03,  9.3679e-03,  2.8277e-03, -1.9930e-02, -1.5137e-02,
           -2.3405e-02,  2.7570e-04,  1.7826e-03,  2.3184e-02,  2.0079e-02,
           -1.7028e-02,  2.8507e-03,  1.6072e-02,  2.8707e-02,  1.9398e-02,
           -1.7232e-02,  9.5471e-03,  1.1906e-02,  7.6070e-03,  3.3451e-03,
           -1.7063e-02, -6.7781e-04,  2.7194e-02,  2.7144e-02,  5.2759e-03,
           -1.8891e-02,  1.7522e-02, -2.7846e-02, -2.8161e-04, -1.9306e-03,
           -9.7854e-03,  1.9908e-02,  2.2051e-02,  2.0559e-02,  1.0145e-02,
            2.1454e-02, -1.3966e-02, -2.0105e-02,  3.0653e-02,  3.9545e-03,
            2.8578e-02,  6.7711e-03,  2.6136e-03, -2.9715e-02, -1.8710e-02,
            1.1336e-02, -2.3927e-02, -2.5033e-02, -7.5448e-03,  2.9410e-02,
            2.1489e-02, -2.5535e-02, -2.1827e-02, -2.0580e-02,  1.4450e-02,
           -9.7555e-03,  2.6553e-04, -2.9943e-02, -1.4007e-02,  1.9904e-02,
           -1.4724e-02, -4.4739e-03, -3.1173e-02,  7.2689e-03,  2.9223e-02,
           -1.7290e-02,  2.4317e-02,  1.3455e-02, -2.7130e-02,  6.1529e-03,
            1.4586e-02, -1.9455e-03, -1.9521e-02, -5.7558e-03, -1.8702e-02,
            1.5228e-02, -2.3712e-02, -2.3379e-02,  8.8897e-03, -2.2217e-02,
            1.8496e-02,  2.7002e-02, -3.0878e-02,  1.8235e-02, -5.8359e-03,
            7.4575e-03,  2.4818e-03,  1.5706e-02, -2.8652e-02, -2.0999e-02,
           -2.4903e-02,  2.5343e-02,  2.2837e-02, -3.2360e-03, -1.8184e-02,
            5.3788e-03, -8.6948e-03,  3.0126e-02, -1.4757e-02,  5.5215e-03,
            2.5092e-02,  1.3223e-02, -2.1344e-02,  7.4957e-03, -2.7992e-03,
            1.6555e-02, -1.3957e-04, -2.5191e-02,  2.1691e-02, -2.9779e-02,
           -2.0039e-02, -5.2356e-03,  2.7107e-02,  3.0121e-02, -2.3876e-02,
           -1.0321e-02,  7.1453e-03, -2.6230e-02, -4.4717e-03,  2.8331e-02,
           -2.5919e-02,  1.7987e-02, -9.7869e-03, -2.3867e-02, -2.0996e-02,
            4.6582e-03, -1.8913e-02,  2.9246e-02,  1.0272e-03, -3.0766e-02,
           -1.3962e-02,  4.1096e-03,  2.2960e-02,  8.1701e-03,  1.2092e-02,
           -1.2053e-02, -2.7150e-02,  3.0137e-02,  4.4495e-03,  1.1762e-02,
           -2.1599e-03, -2.1452e-03,  2.6669e-04,  2.2006e-02,  1.0493e-02,
            8.0732e-03,  9.1934e-03,  1.2737e-02, -4.0371e-03,  2.6292e-02,
           -1.9533e-02,  7.9419e-03,  1.4665e-02, -2.9543e-02,  2.5820e-03,
            7.5699e-03, -3.8344e-03,  2.5779e-02,  3.2318e-03,  1.7983e-02,
            2.4114e-02, -1.7012e-02, -1.7501e-02, -3.1886e-03,  1.5091e-02,
           -1.3619e-02, -1.6652e-02, -1.3543e-02,  7.6873e-03,  2.6438e-02,
            1.7179e-03,  2.1675e-02,  5.7018e-03,  1.6398e-02,  8.4782e-03,
            2.3799e-02,  2.2872e-02,  3.9585e-03,  2.8611e-02,  1.4145e-02,
           -2.7765e-02, -8.0419e-03, -9.4375e-03, -1.5594e-02, -6.7968e-03,
            8.7875e-03, -1.9945e-02, -5.9187e-04, -8.5239e-03,  9.2968e-04,
           -7.1770e-03,  2.6975e-02,  3.0469e-02, -8.8782e-03,  1.9657e-02,
           -1.9322e-02,  2.2844e-03, -2.1654e-02,  1.4620e-02, -1.7857e-02,
           -1.9841e-02,  4.2241e-03, -9.7789e-03, -1.0405e-02,  1.8989e-02,
            6.2938e-03,  2.2866e-02,  5.9999e-03, -2.5530e-02, -1.4319e-02,
           -1.9271e-02,  1.9607e-02,  2.1784e-02,  4.9267e-04,  2.1345e-02,
            1.7745e-02,  2.3281e-02,  1.7149e-02, -5.5931e-03,  1.9954e-04,
            8.4925e-03, -1.8252e-02,  1.2548e-02, -3.4974e-03, -2.4812e-02,
           -1.9454e-02, -7.1188e-03, -3.2777e-03, -2.7351e-02,  6.0687e-03,
            3.0715e-02,  1.8172e-02, -3.1529e-02,  1.9131e-04, -1.0631e-03,
           -2.6868e-02, -9.6340e-03, -2.6004e-02,  1.9038e-02,  1.2556e-03,
           -1.4621e-02,  2.3129e-02, -1.4643e-02,  4.4539e-03, -2.8966e-02,
           -7.8189e-03,  2.0691e-02,  1.2852e-02,  1.5584e-02, -7.5332e-03,
           -1.8324e-02, -2.7819e-02, -1.5680e-02, -4.2330e-03,  1.8121e-02,
           -1.4510e-03,  1.8284e-02, -1.3117e-02, -2.7164e-02,  2.4633e-02,
            1.2834e-02, -2.3768e-02, -1.5011e-02,  1.9269e-02,  1.4765e-02,
           -2.1349e-02, -1.4161e-03, -6.0891e-03, -9.1981e-04, -1.1502e-02,
            8.2370e-03,  1.7182e-02,  7.0254e-03,  9.7752e-03, -2.8210e-02,
           -2.9810e-02, -2.7814e-02, -8.0185e-03, -7.0987e-03,  4.4334e-03,
            1.2784e-04, -1.0700e-02,  9.4797e-03,  1.3407e-02,  1.4312e-02,
            3.4230e-03, -8.1055e-03, -9.8404e-03, -1.4773e-02,  1.8372e-02,
           -8.7872e-03, -4.5619e-03, -2.5576e-02,  2.7026e-02, -2.1668e-02,
           -7.5277e-03, -2.2270e-02,  6.9195e-03,  2.4333e-02,  4.4172e-03,
            1.6518e-02,  1.1954e-02,  7.1091e-03,  2.2294e-02,  2.1881e-03,
           -2.5684e-03,  2.8834e-02, -1.1145e-02, -6.4395e-03,  1.4247e-02,
           -1.5374e-02,  7.0493e-03, -4.4728e-03,  9.6582e-03,  2.3495e-02,
           -2.2108e-02,  2.1743e-02,  1.5707e-02,  8.8355e-03,  1.9891e-03,
           -2.0671e-02,  1.6501e-02,  6.6786e-04, -2.0516e-02, -2.8110e-02,
           -3.0565e-02,  7.2165e-03, -1.3784e-02,  1.4377e-02, -1.2449e-02,
            9.8905e-03,  2.4804e-02, -9.8006e-03, -2.5304e-03,  2.7188e-02,
           -2.4188e-02,  2.1579e-02, -3.0848e-03, -2.1083e-02, -2.2285e-02,
            3.0322e-02, -1.8625e-02,  5.9554e-03, -2.2840e-02,  1.0964e-02,
           -3.2953e-03, -8.5996e-03,  2.2027e-02,  4.0299e-03,  1.9365e-02,
            3.0674e-02, -1.2910e-02, -2.1756e-02, -1.8569e-02, -1.0802e-02,
           -1.6140e-02,  5.2633e-03,  1.5387e-02,  2.9540e-02,  5.5869e-03,
           -1.9191e-02, -2.5272e-02,  2.0403e-02,  3.0683e-02,  3.1485e-02,
            2.4344e-02,  7.1243e-03,  2.2752e-02,  3.0401e-03, -5.1803e-03,
            3.2442e-03, -2.7977e-02, -3.0984e-02, -4.8499e-03, -2.8103e-02,
           -1.9253e-02, -1.9314e-02,  3.0526e-02, -6.6825e-03, -3.0974e-02,
           -6.5989e-03,  1.9729e-02,  2.9106e-03, -1.3215e-02,  1.7037e-02,
           -1.7882e-02,  2.3327e-02,  2.6878e-02,  1.6422e-02,  1.0555e-02,
           -2.0252e-02,  1.8742e-02, -2.8090e-02,  2.9106e-02,  3.0567e-02,
            1.3028e-02,  2.0381e-02, -1.8160e-02, -2.7465e-03, -1.0062e-02,
            3.3652e-03, -3.0567e-02, -2.5420e-02,  2.5205e-02,  9.7038e-03,
            2.2709e-02, -7.0443e-03,  1.5452e-02, -1.3244e-02, -2.5700e-02,
           -1.1164e-02,  1.5658e-02, -2.4792e-02, -1.2466e-02, -2.3374e-02,
            6.1933e-03,  1.5903e-02,  1.5369e-02, -6.3213e-03, -1.9283e-02,
           -2.9454e-02, -3.8285e-03,  2.2272e-03,  2.5464e-02,  3.5005e-03,
           -2.7187e-02, -2.0867e-02,  4.4292e-03, -1.0455e-02,  1.9138e-02,
            2.4620e-02,  2.1279e-04,  1.2345e-02,  2.5950e-02, -1.0762e-02,
           -6.9845e-03, -2.1853e-02, -2.1741e-02, -1.5284e-02, -8.9996e-04,
           -8.3508e-03,  4.3189e-03, -5.0517e-03, -9.3328e-03, -2.5671e-02,
           -2.8343e-02,  6.8205e-03, -8.5820e-04, -1.4961e-03,  2.1637e-02,
            2.3664e-02,  1.5622e-02, -2.4247e-02, -7.0997e-03, -2.9678e-02,
           -1.9878e-02,  1.4823e-02, -3.0661e-02,  2.7851e-03, -2.7529e-02,
            1.7124e-02,  1.5475e-02,  1.1812e-02, -2.0636e-02,  1.4491e-02,
           -2.6385e-02,  3.9963e-03,  1.3316e-02,  2.5703e-02, -2.9512e-03,
            1.8900e-02,  2.8945e-02, -2.7574e-02, -2.5791e-02, -8.7951e-03,
           -7.1584e-03,  4.1844e-03, -2.3473e-02,  2.2803e-02,  6.6717e-03,
           -1.2323e-02,  6.8468e-03, -1.5814e-02,  1.0393e-02, -1.5075e-02,
            3.8689e-03,  4.8293e-03, -1.4114e-02, -1.5771e-02, -2.2561e-03,
           -2.9435e-02, -1.2512e-02,  1.2613e-03,  9.9052e-03, -7.6752e-03,
            2.1771e-02,  2.6214e-02, -1.1343e-02,  2.2221e-02, -7.8791e-03,
           -1.5343e-03, -7.2647e-03,  1.5750e-02, -4.8295e-03,  1.2341e-02]],
         device='cuda:0')
  linear.bias tensor([0.0146], device='cuda:0')
#+end_example

#+begin_src ipython
  model.N_BATCH = 32
  model.I0[0] = 1
  model.I0[1] = 1 

  AC_pair = model.init_ff_input()

  model.I0[0] = 1
  model.I0[1] = -1 

  AD_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = 1

  BC_pair = model.init_ff_input()

  model.I0[0] = -1
  model.I0[1] = -1 
  
  BD_pair = model.init_ff_input()
  
  ff_input = torch.cat((AC_pair, BD_pair, AD_pair, BC_pair))
  print(ff_input.shape)
#+end_src

#+RESULTS:
: torch.Size([128, 1275, 1000])

#+begin_src ipython
  labels_pair = torch.zeros(2 * model.N_BATCH)
  labels_unpair = torch.ones(2 * model.N_BATCH)
  
  labels = torch.cat((labels_pair, labels_unpair))
  print(ff_input.shape, labels.shape)
#+end_src

#+RESULTS:
: torch.Size([128, 1275, 1000]) torch.Size([128])

#+begin_src ipython
  # labels = torch.zeros((ff_input.shape[0]), device=model.device)
  # labels_A = model.xi[0].unsqueeze(0).expand(int(ff_input.shape[0]/2), -1)
  # labels_B = model.xi[1].unsqueeze(0).expand(int(ff_input.shape[0]/2), -1)
  # labels = torch.cat((labels_A, labels_B))
  print(ff_input.shape, labels.shape)
#+end_src

#+RESULTS:
: torch.Size([128, 1275, 1000]) torch.Size([128, 1000])

#+RESULTS:

#+begin_src ipython
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  batch_size = 32
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)

  learning_rate = 0.01
  # criterion = CosineLoss()
  criterion = nn.BCELoss()
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
  # optimizer = optim.SGD(model.parameters(), lr=learning_rate)

  num_epochs = 20
  run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)  
#+end_src

#+RESULTS:
#+begin_example
  Epoch 1/100, Training Loss: 0.8494, Validation Loss: 5.2812
  Epoch 2/100, Training Loss: 0.2963, Validation Loss: 1.3762
  Epoch 3/100, Training Loss: 0.2137, Validation Loss: 1.1542
  Epoch 4/100, Training Loss: 0.0191, Validation Loss: 3.4697
  Epoch 5/100, Training Loss: 0.0017, Validation Loss: 4.6988
  Epoch 6/100, Training Loss: 0.0001, Validation Loss: 4.5383
  Epoch 7/100, Training Loss: 0.0024, Validation Loss: 3.8818
  Epoch 8/100, Training Loss: 0.0041, Validation Loss: 3.3471
  Epoch 9/100, Training Loss: 0.0008, Validation Loss: 2.9841
  Epoch 10/100, Training Loss: 0.0009, Validation Loss: 2.7866
  Epoch 11/100, Training Loss: 0.0010, Validation Loss: 2.7269
  Epoch 12/100, Training Loss: 0.0013, Validation Loss: 2.7575
  Epoch 13/100, Training Loss: 0.0023, Validation Loss: 2.8622
  Epoch 00014: reducing learning rate of group 0 to 1.0000e-03.
  Epoch 14/100, Training Loss: 0.0016, Validation Loss: 3.0047
  Epoch 15/100, Training Loss: 0.0023, Validation Loss: 3.0192
  Epoch 16/100, Training Loss: 0.0017, Validation Loss: 3.0353
  Epoch 17/100, Training Loss: 0.0016, Validation Loss: 3.0528
  Epoch 18/100, Training Loss: 0.0004, Validation Loss: 3.0689
  Epoch 19/100, Training Loss: 0.0020, Validation Loss: 3.0848
  Epoch 20/100, Training Loss: 0.0003, Validation Loss: 3.1008
  Epoch 21/100, Training Loss: 0.0026, Validation Loss: 3.1155
  Epoch 22/100, Training Loss: 0.0004, Validation Loss: 3.1326
  Epoch 23/100, Training Loss: 0.0012, Validation Loss: 3.1473
  Epoch 24/100, Training Loss: 0.0024, Validation Loss: 3.1620
  Epoch 00025: reducing learning rate of group 0 to 1.0000e-04.
  Epoch 25/100, Training Loss: 0.0010, Validation Loss: 3.1759
  Epoch 26/100, Training Loss: 0.0020, Validation Loss: 3.1773
  Epoch 27/100, Training Loss: 0.0006, Validation Loss: 3.1786
  Epoch 28/100, Training Loss: 0.0005, Validation Loss: 3.1797
  Epoch 29/100, Training Loss: 0.0003, Validation Loss: 3.1807
  Epoch 30/100, Training Loss: 0.0015, Validation Loss: 3.1818
  Epoch 31/100, Training Loss: 0.0017, Validation Loss: 3.1830
  Epoch 32/100, Training Loss: 0.0003, Validation Loss: 3.1845
  Epoch 33/100, Training Loss: 0.0005, Validation Loss: 3.1859
  Epoch 34/100, Training Loss: 0.0011, Validation Loss: 3.1873
  Epoch 35/100, Training Loss: 0.0015, Validation Loss: 3.1888
  Epoch 00036: reducing learning rate of group 0 to 1.0000e-05.
  Epoch 36/100, Training Loss: 0.0003, Validation Loss: 3.1903
  Epoch 37/100, Training Loss: 0.0009, Validation Loss: 3.1905
  Epoch 38/100, Training Loss: 0.0014, Validation Loss: 3.1906
  Epoch 39/100, Training Loss: 0.0007, Validation Loss: 3.1908
  Epoch 40/100, Training Loss: 0.0020, Validation Loss: 3.1909
  Epoch 41/100, Training Loss: 0.0013, Validation Loss: 3.1911
  Epoch 42/100, Training Loss: 0.0012, Validation Loss: 3.1913
  Epoch 43/100, Training Loss: 0.0019, Validation Loss: 3.1914
  Epoch 44/100, Training Loss: 0.0024, Validation Loss: 3.1916
  Epoch 45/100, Training Loss: 0.0010, Validation Loss: 3.1918
  Epoch 46/100, Training Loss: 0.0002, Validation Loss: 3.1920
  Epoch 00047: reducing learning rate of group 0 to 1.0000e-06.
  Epoch 47/100, Training Loss: 0.0004, Validation Loss: 3.1921
  Epoch 48/100, Training Loss: 0.0003, Validation Loss: 3.1921
  Epoch 49/100, Training Loss: 0.0015, Validation Loss: 3.1921
  Epoch 50/100, Training Loss: 0.0009, Validation Loss: 3.1922
  Epoch 51/100, Training Loss: 0.0018, Validation Loss: 3.1922
  Epoch 52/100, Training Loss: 0.0009, Validation Loss: 3.1922
  Epoch 53/100, Training Loss: 0.0004, Validation Loss: 3.1922
  Epoch 54/100, Training Loss: 0.0017, Validation Loss: 3.1922
  Epoch 55/100, Training Loss: 0.0016, Validation Loss: 3.1922
  Epoch 56/100, Training Loss: 0.0007, Validation Loss: 3.1922
  Epoch 57/100, Training Loss: 0.0014, Validation Loss: 3.1923
  Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
  Epoch 58/100, Training Loss: 0.0006, Validation Loss: 3.1923
  Epoch 59/100, Training Loss: 0.0004, Validation Loss: 3.1923
  Epoch 60/100, Training Loss: 0.0021, Validation Loss: 3.1923
  Epoch 61/100, Training Loss: 0.0008, Validation Loss: 3.1923
  Epoch 62/100, Training Loss: 0.0001, Validation Loss: 3.1923
  Epoch 63/100, Training Loss: 0.0004, Validation Loss: 3.1923
  Epoch 64/100, Training Loss: 0.0005, Validation Loss: 3.1923
  Epoch 65/100, Training Loss: 0.0008, Validation Loss: 3.1923
  Epoch 66/100, Training Loss: 0.0010, Validation Loss: 3.1923
  Epoch 67/100, Training Loss: 0.0006, Validation Loss: 3.1923
  Epoch 68/100, Training Loss: 0.0020, Validation Loss: 3.1923
  Epoch 00069: reducing learning rate of group 0 to 1.0000e-08.
  Epoch 69/100, Training Loss: 0.0013, Validation Loss: 3.1923
  Epoch 70/100, Training Loss: 0.0008, Validation Loss: 3.1923
  Epoch 71/100, Training Loss: 0.0008, Validation Loss: 3.1923
  Epoch 72/100, Training Loss: 0.0002, Validation Loss: 3.1923
  Epoch 73/100, Training Loss: 0.0004, Validation Loss: 3.1923
  Epoch 74/100, Training Loss: 0.0006, Validation Loss: 3.1923
  Epoch 75/100, Training Loss: 0.0002, Validation Loss: 3.1923
  Epoch 76/100, Training Loss: 0.0003, Validation Loss: 3.1923
  Epoch 77/100, Training Loss: 0.0012, Validation Loss: 3.1923
  Epoch 78/100, Training Loss: 0.0006, Validation Loss: 3.1923
  Epoch 79/100, Training Loss: 0.0011, Validation Loss: 3.1923
  Epoch 80/100, Training Loss: 0.0017, Validation Loss: 3.1923
  Epoch 81/100, Training Loss: 0.0030, Validation Loss: 3.1923
  Epoch 82/100, Training Loss: 0.0017, Validation Loss: 3.1923
  Epoch 83/100, Training Loss: 0.0008, Validation Loss: 3.1923
  Epoch 84/100, Training Loss: 0.0008, Validation Loss: 3.1923
  Epoch 85/100, Training Loss: 0.0005, Validation Loss: 3.1923
  Epoch 86/100, Training Loss: 0.0003, Validation Loss: 3.1923
  Epoch 87/100, Training Loss: 0.0025, Validation Loss: 3.1923
  Epoch 88/100, Training Loss: 0.0007, Validation Loss: 3.1923
  Epoch 89/100, Training Loss: 0.0012, Validation Loss: 3.1923
  Epoch 90/100, Training Loss: 0.0008, Validation Loss: 3.1923
  Epoch 91/100, Training Loss: 0.0005, Validation Loss: 3.1923
  Epoch 92/100, Training Loss: 0.0006, Validation Loss: 3.1923
  Epoch 93/100, Training Loss: 0.0014, Validation Loss: 3.1923
  Epoch 94/100, Training Loss: 0.0008, Validation Loss: 3.1923
  Epoch 95/100, Training Loss: 0.0013, Validation Loss: 3.1923
  Epoch 96/100, Training Loss: 0.0010, Validation Loss: 3.1923
  Epoch 97/100, Training Loss: 0.0011, Validation Loss: 3.1923
  Epoch 98/100, Training Loss: 0.0005, Validation Loss: 3.1923
  Epoch 99/100, Training Loss: 0.0019, Validation Loss: 3.1923
  Epoch 100/100, Training Loss: 0.0010, Validation Loss: 3.1923
#+end_example

#+begin_src ipython
  cosine_similarity = nn.CosineSimilarity(dim=0)(model.U[:,0], model.U[:,1])
  print(cosine_similarity)
#+end_src

#+RESULTS:
: tensor(-0.0151, device='cuda:0', grad_fn=<SumBackward1>)

#+begin_src ipython
  lr = model.mask * (1.0 + model.U @ model.U.T / torch.sqrt(model.Ka[0]))
  weights = model.Wab.T * lr  
#+end_src

#+RESULTS:

#+begin_src ipython  
  plot_con(weights.cpu().detach().numpy())
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/ead6f335fd682d3055ad5915e7cd33d285f0415c.png]]

#+begin_src ipython
  readout = model.linear.weight.data[0]
  print(readout.shape)
#+end_src

#+RESULTS:
: torch.Size([1000])

#+begin_src ipython
  read0 = nn.CosineSimilarity(dim=0)(model.U[:,0], readout)
  read1 = nn.CosineSimilarity(dim=0)(model.U[:,1], readout)

  print(read0, read1)
#+end_src

#+RESULTS:
: tensor(0.0302, device='cuda:0', grad_fn=<SumBackward1>) tensor(0.0105, device='cuda:0', grad_fn=<SumBackward1>)

#+begin_src ipython
  model.eval()
  model.N_BATCH = 1
  model.VERBOSE=1
  model.LR_TRAIN=0
  rates = model.forward(REC_LAST_ONLY=0)
#+end_src

#+RESULTS:
#+begin_example
  generating ff input
  times (s) 0.0 rates (Hz) [0.21]
  times (s) 0.24 rates (Hz) [0.21]
  times (s) 0.47 rates (Hz) [0.19]
  times (s) 0.71 rates (Hz) [0.22]
  times (s) 0.94 rates (Hz) [16.31]
  times (s) 1.18 rates (Hz) [1.59]
  times (s) 1.41 rates (Hz) [1.64]
  times (s) 1.65 rates (Hz) [1.71]
  times (s) 1.88 rates (Hz) [0.09]
  times (s) 2.12 rates (Hz) [0.93]
  times (s) 2.35 rates (Hz) [0.85]
  times (s) 2.59 rates (Hz) [0.85]
  times (s) 2.82 rates (Hz) [0.71]
  times (s) 3.06 rates (Hz) [0.8]
  times (s) 3.29 rates (Hz) [6.18]
  times (s) 3.53 rates (Hz) [1.6]
  times (s) 3.76 rates (Hz) [1.62]
  times (s) 4.0 rates (Hz) [1.61]
  times (s) 4.24 rates (Hz) [0.16]
  times (s) 4.47 rates (Hz) [0.74]
  times (s) 4.71 rates (Hz) [0.82]
  times (s) 4.94 rates (Hz) [0.74]
  times (s) 5.18 rates (Hz) [0.89]
  times (s) 5.41 rates (Hz) [0.75]
  times (s) 5.65 rates (Hz) [0.76]
  times (s) 5.88 rates (Hz) [0.83]
  times (s) 6.12 rates (Hz) [0.82]
  times (s) 6.35 rates (Hz) [0.95]
  times (s) 6.59 rates (Hz) [0.71]
  times (s) 6.82 rates (Hz) [0.64]
  times (s) 7.06 rates (Hz) [0.76]
  times (s) 7.29 rates (Hz) [0.87]
  times (s) 7.53 rates (Hz) [0.78]
  times (s) 7.76 rates (Hz) [0.87]
  times (s) 8.0 rates (Hz) [0.91]
  times (s) 8.24 rates (Hz) [0.84]
  times (s) 8.47 rates (Hz) [0.85]
  times (s) 8.71 rates (Hz) [0.85]
  times (s) 8.94 rates (Hz) [0.77]
  times (s) 9.18 rates (Hz) [0.7]
  times (s) 9.41 rates (Hz) [0.85]
  times (s) 9.65 rates (Hz) [0.73]
  times (s) 9.88 rates (Hz) [0.83]
  times (s) 10.12 rates (Hz) [0.82]
  times (s) 10.35 rates (Hz) [0.78]
  times (s) 10.59 rates (Hz) [0.71]
  times (s) 10.82 rates (Hz) [0.91]
  times (s) 11.06 rates (Hz) [0.94]
  times (s) 11.29 rates (Hz) [0.84]
  Elapsed (with compilation) = 0.19496272318065166s
#+end_example

#+begin_src ipython
  print(rates.shape)
  plt.imshow(rates[:, 0].T, aspect='auto', cmap='jet')
#+end_src

#+RESULTS:
:RESULTS:
: (49, 1, 1000)
: <matplotlib.image.AxesImage at 0x7faad0ef1ae0>
[[file:./.ob-jupyter/9cbce8a2307a46bfe9279950e9add17654246ad8.png]]
:END:

** Evaluation
*** dynamics

#+begin_src ipython
  model.N_BATCH = 1  
  rates = model.forward(REC_LAST_ONLY=0)
#+end_src

#+RESULTS:

#+begin_src ipython
  overlap_1 = rates @ model.xi[0].cpu().detach().numpy() / 1000.0 
  overlap_2 = rates @ model.xi[1].cpu().detach().numpy() / 1000.0
  overlap = np.stack((overlap_1, overlap_2))[...,0]
  print(overlap.shape)
#+end_src

#+RESULTS:
: (2, 13)

#+begin_src ipython
  loss = 1 - CosineLoss()( model.U.T[0], model.U.T[1])
  angle = np.arccos(loss.cpu().detach().numpy()) * 180 / np.pi

  plt.plot(overlap[0])
  plt.plot(overlap[1])
  plt.title('$\\alpha(U_1, U_2)=$ %.0f °' % angle)
  plt.xlabel('step')
  plt.ylabel('Overlap')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/22ee2e7a12c798dd3799acf674e81039c1499e31.png]]

#+begin_src ipython
  print(rates.shape)
#+end_src

#+RESULTS:
: (13, 1, 1000)

#+begin_src ipython
  plt.plot(np.mean(rates[:,0], -1))
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/72b4f5162521ffc9058cd8a9de7135f355e11ceb.png]]

#+begin_src ipython
  loss = 1 - CosineLoss()( model.xi[0], model.xi[1])
  print(loss)
#+end_src

#+RESULTS:
: tensor(0.0315, device='cuda:0')

#+begin_src ipython
  loss = 1 - CosineLoss()( model.U.T[0], model.U.T[1])
  print(np.arccos(loss.cpu().detach().numpy()) * 180 / np.pi)
#+end_src

#+RESULTS:
: 90.38890664562952

*** Connectivity

#+begin_src ipython
  print(model.Wab)
#+end_src

#+RESULTS:
: tensor([[-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],
:         [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],
:         [-0.0000, -0.3000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],
:         ...,
:         [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],
:         [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],
:         [-0.0000, -0.3000, -0.0000,  ..., -0.3000, -0.0000, -0.0000]],
:        device='cuda:0')

#+begin_src ipython
  # Cij = model.Wab.weight.data.cpu().detach().numpy()
  Cij = model.Wab.cpu().detach().numpy()
  plot_con(Cij.T)
#+end_src

#+RESULTS:
: 8d67eafc-ee75-4ba3-bd1f-bc3064742c01

* Single

#+begin_src ipython
  conf_name = "config_I.yml"
  name = "dual_single"
  model = Network(conf_name, name, REPO_ROOT, VERBOSE=1, DEVICE='cuda')
  rates = model.forward(REC_LAST_ONLY=0)
#+end_src

#+RESULTS:
:RESULTS:
: Na tensor([1000], device='cuda:0', dtype=torch.int32) Ka tensor([1.], device='cuda:0') csumNa tensor([   0, 1000], device='cuda:0')
: Jab [-2.75]
: Ja0 [10.0]
# [goto error]
#+begin_example
  ---------------------------------------------------------------------------
  OutOfMemoryError                          Traceback (most recent call last)
  Cell In[48], line 3
        1 conf_name = "config_bump.yml"
        2 name = "dual_single"
  ----> 3 model = Network(conf_name, name, REPO_ROOT, VERBOSE=1, DEVICE='cuda')
        4 rates = model.forward(REC_LAST_ONLY=0)

  File ~/models/NeuroTorch/org/../src/network.py:47, in Network.__init__(self, conf_file, sim_name, repo_root, **kwargs)
       44     self.stp = STP_Model(self.N_NEURON, self.csumNa, self.DT, self.FLOAT, self.device)
       46 # initialize network
  ---> 47 self.init_network()
       49 self.U = nn.Parameter(torch.randn((self.N_NEURON, int(self.RANK)), device=self.device, dtype=self.FLOAT))
       50 # self.V = nn.Parameter(torch.randn((int(self.RANK), self.N_NEURON), device=self.device, dtype=self.FLOAT))

  File ~/models/NeuroTorch/org/../src/network.py:73, in Network.init_network(self)
       67 for i_pop in range(self.N_POP):
       68     for j_pop in range(self.N_POP):
       69         
       70         # self.Wab.weight.data[self.csumNa[i_pop] : self.csumNa[i_pop + 1],
       71         #                     self.csumNa[j_pop] : self.csumNa[j_pop + 1]] = self.initWeights(i_pop, j_pop)
  ---> 73         weights = self.initWeights(i_pop, j_pop)
       75         self.Wab[self.csumNa[i_pop] : self.csumNa[i_pop + 1],
       76                  self.csumNa[j_pop] : self.csumNa[j_pop + 1]] = weights
       78 # only train first pop
       79 # if i_pop==0 or j_pop==0:
       80 # self.Wab.requires_grad_(True)
       81 
       82 # resets the seed

  File ~/models/NeuroTorch/org/../src/network.py:319, in Network.initWeights(self, i_pop, j_pop)
      316 if 'cos' in self.STRUCTURE[i_pop, j_pop]:
      318     theta_i, theta_j = torch.meshgrid(self.theta_list[i_pop], self.theta_list[j_pop], indexing="ij")
  --> 319     theta_diff = theta_i - theta_j
      321     if 'spec' in self.STRUCTURE[i_pop, j_pop]:
      322         self.KAPPA[i_pop, j_pop] = self.KAPPA[i_pop, j_pop] / torch.sqrt(Kb)

  OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.50 GiB of which 6.19 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 23.14 GiB is allocated by PyTorch, and 18.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
#+end_example
:END:
#+RESULTS:
#+RESULTS:

#+begin_src ipython
  lr = model.U @ model.U.T
  print(lr.shape)
#+end_src

#+RESULTS:
: torch.Size([1000, 1000])

* Rates

#+begin_src ipython
  print(rates.shape)
#+end_src

#+RESULTS:
: (13, 1, 750)

#+begin_src ipython
  loss = cosine_distance_loss(rates, labels)
  print(loss)  
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
  ---------------------------------------------------------------------------
  AttributeError                            Traceback (most recent call last)
  Cell In[134], line 1
  ----> 1 loss = cosine_distance_loss(rates, labels)
        2 print(loss)  

  Cell In[35], line 6, in cosine_distance_loss(output, target)
        4 def cosine_distance_loss(output, target):
        5     # Normalize the vectors to unit length
  ----> 6     output_norm = F.normalize(output, p=2, dim=1)
        7     target_norm = F.normalize(target, p=2, dim=1)
        9     # Calculate the cosine similarity

  File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/nn/functional.py:4719, in normalize(input, p, dim, eps, out)
     4717     return handle_torch_function(normalize, (input, out), input, p=p, dim=dim, eps=eps, out=out)
     4718 if out is None:
  -> 4719     denom = input.norm(p, dim, keepdim=True).clamp_min(eps).expand_as(input)
     4720     return input / denom
     4721 else:

  AttributeError: 'numpy.ndarray' object has no attribute 'norm'
#+end_example
:END:

#+begin_src ipython
  print(rates.shape)
#+end_src

#+RESULTS:
: (13, 1, 750)

#+begin_src ipython
  rates_single = rates[:,0]
  width = 7
  golden_ratio = (5**.5 - 1) / 2
  fig, ax = plt.subplots()

  # times = np.linspace(0, 5, rates.shape[0])  
  times = np.arange(0, 5.1, .1)

  N_E = 750
  r_min = 0
  r_max = 1.5 * np.mean(rates_single)
  r_max = 15

  im = ax.imshow(rates_single.T, aspect='auto', cmap='jet',vmin=0, vmax=r_max, extent=[times[0], times[-1], 0, N_E])

  ax.set_xlabel('Time (s)')
  ax.set_xticks([0, 1, 2, 3, 4, 5])
  ax.set_ylabel('Prefered Location (°)')
  ax.set_yticks([0, N_E/4, N_E/2, 3*N_E/4, N_E], [0, 90, 180, 270, 360])
  ax.set_xlim([0, 5])

  ax.axvline(1, 0, 1000, ls='--', color='w', lw=2)
  ax.axvline(1.5, 0, 1000, ls='--', color='w', lw=2)
  ax.axvline(2.5, 0, 1000, ls='--', color='w', lw=2)
  ax.axvline(3, 0, 1000, ls='--', color='w', lw=2)

  cbar = plt.colorbar(im, ax=ax)
  cbar.set_label("Activity (Hz)")
  cbar.set_ticks([0, 5, 10, 15])
  plt.savefig('./neurons.svg', dpi=300)
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/f62ae3f665cd2ca8e53f81dd390fbe214fcb6486.png]]

#+begin_src ipython
  ksi = model.U.cpu().detach().numpy().T
  print(ksi.shape)
  
  theta = get_theta(ksi[0][:750], ksi[1][:750], GM=0, IF_NORM=1)
  # theta = np.arctan2(ksi[1], ksi[0])
  index_order = theta.argsort()
  print(index_order.shape)
  rates_ordered = rates[:, 0, index_order]
#+end_src

#+RESULTS:
: (2, 1000)
: (750,)

#+begin_src ipython
  plt.imshow(rates_ordered.T, aspect='auto', cmap='jet', vmin=0, vmax=15)
  plt.ylabel('Pref. Location (°)')
  plt.xlabel('Time (au)')
  plt.yticks(np.linspace(0, 700, 5), np.linspace(0, 360, 5).astype(int))
  plt.colorbar()
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/ec1385382d2471b5b636fa206df0a5a6d3e48e10.png]]

#+begin_src ipython

#+end_src
