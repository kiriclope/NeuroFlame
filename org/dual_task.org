#+STARTUP: fold
#+PROPERTY: header-args:ipython :results both :exports both :async yes :session dual :kernel torch

* Notebook Settings

#+begin_src ipython
  %load_ext autoreload
  %autoreload 2
  %reload_ext autoreload

  %run ../notebooks/setup.py
  %matplotlib inline
  %config InlineBackend.figure_format = 'png'

  REPO_ROOT = "/home/leon/models/NeuroTorch"
  pal = sns.color_palette("tab10")
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload
: Python exe
: /home/leon/mambaforge/envs/torch/bin/python

* Helpers
** Training
*** split data

#+begin_src ipython
  def split_data(X, Y, train_perc=0.8, batch_size=32):

    # Split the dataset into training and validation sets
    train_size = int(train_perc * X.shape[0])

    X_train = X[:train_size]
    X_test = X[train_size:]

    # X_train, X_mean, X_std = standard_scaler(X_train, IF_RETURN=1)
    # X_test = (X_test - X_mean) / X_std

    Y_train = Y[:train_size]    
    Y_test = Y[train_size:]

    # Y_train, Y_mean, Y_std = standard_scaler(Y_train, IF_RETURN=1)
    # Y_test = (Y_test - Y_mean) / Y_std

    # Create data sets
    # train_dataset = TensorDataset(X_train_scaled, Y_train_scaled)
    # val_dataset = TensorDataset(X_test_scaled, Y_test_scaled)

    # print('X_train', X_train.shape, 'y_train', Y_train.shape)
    train_dataset = TensorDataset(X_train, Y_train)

    # print('X_test', X_test.shape, 'y_test', Y_test.shape)
    val_dataset = TensorDataset(X_test, Y_test)

    # Create data loaders
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)

    # sequence_length = 14  # or any other sequence length you want
    # stride = 1  # or any other stride you want

    # sliding_window_dataset = SlidingWindowDataset(X, sequence_length, stride)
    # train_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)
    # val_loader = torch.utils.data.DataLoader(sliding_window_dataset, batch_size=5, shuffle=True)

    return train_loader, val_loader
#+end_src

#+RESULTS:

** Optimization

#+begin_src ipython
  def train(dataloader, model, loss_fn, optimizer, penalty=None, lbd=1):
      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      model.train()
      for batch, (X, y) in enumerate(dataloader):
          optimizer.zero_grad()

          X, y = X.to(device), y.to(device)
          # Compute prediction error
          y_pred = model(X)
          loss = loss_fn(y_pred, y)

          if penalty is not None:
              reg_loss = 0
              for param in model.parameters():
                  if penalty=='l1':
                      reg_loss += torch.sum(torch.abs(param))
                  else:
                      reg_loss += torch.sum(torch.square(param))

                  loss = loss + lbd * reg_loss

          # Backpropagation
          loss.backward()
          optimizer.step()

      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def test(dataloader, model, loss_fn):
      size = len(dataloader.dataset)
      num_batches = len(dataloader)

      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      # Validation loop.
      model.eval()
      val_loss = 0.0
      with torch.no_grad():
          for data, targets in dataloader:
              data, targets = data.to(device), targets.to(device)
              
              outputs = model(data)
              loss = loss_fn(outputs, targets)
              val_loss += loss.item() * data.size(0)
          val_loss /= size

      return val_loss
#+end_src

#+RESULTS:

#+begin_src ipython
  def run_optim(model, train_loader, val_loader, loss_fn, optimizer, num_epochs=100, penalty=None, lbd=1):

    # scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1, verbose=True)
    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)

    # Training loop.
    for epoch in range(num_epochs):
        loss = train(train_loader, model, loss_fn, optimizer, penalty, lbd)
        val_loss = test(val_loader, model, loss_fn)
        scheduler.step(val_loss)
        
        # if epoch % int(num_epochs  / 10) == 0:
        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}')

#+end_src

#+RESULTS:

** Loss

#+begin_src ipython
  def correlation_loss(output, target):
      # Subtract the mean of each vector
      output_mean = output - torch.mean(output)
      target_mean = target - torch.mean(target)
    
      # Compute the covariance between output and target
      covariance = torch.mean(output_mean * target_mean)
      
      # Compute the standard deviations of the vectors
      output_std = torch.std(output)
      target_std = torch.std(target)
    
      # Calculate the Pearson correlation coefficient
      correlation = covariance / (output_std * target_std)
    
      # Since we want to increase the correlation, we minimize its negative
      loss = -correlation  # Maximizing correlation by minimizing its negative
    
      return loss
#+end_src

#+RESULTS:

#+begin_src ipython
    import torch
    import torch.nn as nn

    def sign_constrained_loss(output, xi, target_sign):
        dot_product = torch.dot(output.flatten(), xi.flatten())
        if target_sign > 0:
            loss = torch.relu(-dot_product)  # Encourages positive dot product
        else:
            loss = torch.relu(dot_product)   # Encourages negative dot product
        return loss
#+end_src

#+RESULTS:

#+begin_src ipython
  class CosineLoss(nn.Module):
      def __init__(self):
          super(CosineLoss, self).__init__()
          self.cosine_similarity = nn.CosineSimilarity(dim=-1)
          
      def forward(self, input1, input2):
          # Calculate cosine similarity
          cosine_sim = self.cosine_similarity(input1, input2)
          # Calculate the loss as 1 - cosine_similarity
          loss = 1 - cosine_sim
          # Return the mean loss over the batch
          return loss.mean()
#+end_src

#+RESULTS:


#+RESULTS:

** Other

#+begin_src ipython
  def get_theta(a, b, GM=0, IF_NORM=0):

      if GM:          
          b = b - np.dot(b, a) / np.dot(a, a) * a

      if IF_NORM:
          u = a / np.linalg.norm(a)
          v = b / np.linalg.norm(b)
      else:
          u=a
          v=b

      return np.arctan2(v, u)
#+end_src

#+RESULTS:


#+begin_src ipython
  import scipy.stats as stats

  def plot_smooth(data, ax, color):
      mean = data.mean(axis=0)  
      ci = smooth.std(axis=0, ddof=1) * 1.96
      
      # Plot
      ax.plot(mean, color=color)
      ax.fill_between(range(data.shape[1]), mean - ci, mean + ci, alpha=0.25, color=color)

#+end_src

#+RESULTS:

#+begin_src ipython
  def convert_seconds(seconds):
      h = seconds // 3600
      m = (seconds % 3600) // 60
      s = seconds % 60
      return h, m, s
#+end_src

#+RESULTS:

* Imports

#+begin_src ipython
  import torch
  import torch.nn as nn
  import torch.optim as optim
  from torch.utils.data import Dataset, TensorDataset, DataLoader
#+end_src

#+RESULTS:

#+begin_src ipython
  import sys
  sys.path.insert(0, '../')

  import pandas as pd
  import torch.nn as nn
  from time import perf_counter  
  from scipy.stats import circmean

  from src.network import Network
  from src.plot_utils import plot_con
  from src.decode import decode_bump, circcvl
#+end_src

#+RESULTS:

* Train RNN
** Parameters

#+Begin_src ipython
  REPO_ROOT = "/home/leon/models/NeuroTorch"
  conf_name = "config_I.yml"
  name = "dual"
#+end_src

#+RESULTS:

** Training

#+begin_src ipython
  start = perf_counter()
  name = "dual_single"
  model = Network(conf_name, name, REPO_ROOT, VERBOSE=0, DEVICE='cuda')
#+end_src

#+RESULTS:

#+begin_src ipython
for name, param in model.named_parameters():
    if param.requires_grad:
        print(name, param.data)
#+end_src

#+RESULTS:
: U tensor([[-0.6816,  1.0141],
:         [ 0.9102, -0.2812],
:         [-0.2934,  0.3176],
:         ...,
:         [ 1.3498,  1.5706],
:         [-1.8183, -1.0473],
:         [-0.7804,  0.6590]], device='cuda:0')

#+begin_src ipython
  import torch
  model.N_BATCH = 256
  dum = model.N_BATCH // 2
  
  noise = torch.randn((model.N_BATCH, model.N_STEPS, model.N_NEURON), dtype=model.FLOAT, device=model.DEVICE) * model.VAR_FF[0]
  ff_input = torch.zeros((model.N_BATCH, model.N_STEPS, model.N_NEURON), dtype=model.FLOAT, device=model.DEVICE)

  for i in range(model.N_POP):
      ff_input[..., model.csumNa[i]:model.csumNa[i+1]] = model.Ja0[i]

  print(ff_input.shape)  
#+end_src

#+RESULTS:
: torch.Size([256, 700, 1000])

#+begin_src ipython
  ff_input[:dum] = model.init_ff_input(ff_input[:dum], 0) + noise[:dum]
  ff_input[dum:] = model.init_ff_input(ff_input[dum:], 1) + noise[dum:]
#+end_src

#+RESULTS:

#+begin_src ipython
  # labels = torch.zeros((ff_input.shape[0]), device=model.device)
  labels_A = model.xi[0].unsqueeze(0).expand(int(ff_input.shape[0]/2), -1)
  labels_B = model.xi[1].unsqueeze(0).expand(int(ff_input.shape[0]/2), -1)
  labels = torch.cat((labels_A, labels_B))
  print(ff_input.shape, labels.shape)
#+end_src

#+RESULTS:
: torch.Size([256, 700, 1000]) torch.Size([256, 1000])

#+RESULTS:

#+begin_src ipython
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  batch_size = 32
  train_loader, val_loader = split_data(ff_input, labels, train_perc=0.8, batch_size=batch_size)

  learning_rate = 0.1
  criterion = CosineLoss()
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)
  # optimizer = optim.SGD(model.parameters(), lr=learning_rate)

  num_epochs = 100
  run_optim(model, train_loader, val_loader, criterion, optimizer, num_epochs)  
#+end_src

#+RESULTS:
#+begin_example
  Epoch 1/100, Training Loss: 0.6451, Validation Loss: 0.7586
  Epoch 2/100, Training Loss: 0.6694, Validation Loss: 0.7407
  Epoch 3/100, Training Loss: 0.5663, Validation Loss: 0.7246
  Epoch 4/100, Training Loss: 0.5785, Validation Loss: 0.7154
  Epoch 5/100, Training Loss: 0.5548, Validation Loss: 0.7193
  Epoch 6/100, Training Loss: 0.5693, Validation Loss: 0.7174
  Epoch 7/100, Training Loss: 0.5690, Validation Loss: 0.7182
  Epoch 8/100, Training Loss: 0.5838, Validation Loss: 0.7135
  Epoch 9/100, Training Loss: 0.5434, Validation Loss: 0.7133
  Epoch 10/100, Training Loss: 0.5623, Validation Loss: 0.7092
  Epoch 11/100, Training Loss: 0.5975, Validation Loss: 0.7033
  Epoch 12/100, Training Loss: 0.5611, Validation Loss: 0.7049
  Epoch 13/100, Training Loss: 0.5930, Validation Loss: 0.6972
  Epoch 14/100, Training Loss: 0.6110, Validation Loss: 0.6946
  Epoch 15/100, Training Loss: 0.5401, Validation Loss: 0.6996
  Epoch 16/100, Training Loss: 0.5568, Validation Loss: 0.7033
  Epoch 17/100, Training Loss: 0.6267, Validation Loss: 0.6900
  Epoch 18/100, Training Loss: 0.5730, Validation Loss: 0.6982
  Epoch 19/100, Training Loss: 0.5026, Validation Loss: 0.6992
  Epoch 20/100, Training Loss: 0.5536, Validation Loss: 0.7068
  Epoch 21/100, Training Loss: 0.5669, Validation Loss: 0.6969
  Epoch 22/100, Training Loss: 0.5889, Validation Loss: 0.6929
  Epoch 23/100, Training Loss: 0.5329, Validation Loss: 0.7022
  Epoch 24/100, Training Loss: 0.5495, Validation Loss: 0.6937
  Epoch 25/100, Training Loss: 0.5864, Validation Loss: 0.6879
  Epoch 26/100, Training Loss: 0.5856, Validation Loss: 0.6921
  Epoch 27/100, Training Loss: 0.5660, Validation Loss: 0.6865
  Epoch 28/100, Training Loss: 0.5336, Validation Loss: 0.6981
  Epoch 29/100, Training Loss: 0.5663, Validation Loss: 0.6908
  Epoch 30/100, Training Loss: 0.5480, Validation Loss: 0.6888
  Epoch 31/100, Training Loss: 0.5302, Validation Loss: 0.6914
  Epoch 32/100, Training Loss: 0.4947, Validation Loss: 0.6976
  Epoch 33/100, Training Loss: 0.5832, Validation Loss: 0.6904
  Epoch 34/100, Training Loss: 0.5642, Validation Loss: 0.6928
  Epoch 35/100, Training Loss: 0.5273, Validation Loss: 0.6953
  Epoch 36/100, Training Loss: 0.5491, Validation Loss: 0.6882
  Epoch 37/100, Training Loss: 0.5824, Validation Loss: 0.6892
  Epoch 00038: reducing learning rate of group 0 to 1.0000e-02.
  Epoch 38/100, Training Loss: 0.5642, Validation Loss: 0.6972
  Epoch 39/100, Training Loss: 0.5604, Validation Loss: 0.6869
  Epoch 40/100, Training Loss: 0.5448, Validation Loss: 0.6841
  Epoch 41/100, Training Loss: 0.5645, Validation Loss: 0.6879
  Epoch 42/100, Training Loss: 0.5438, Validation Loss: 0.6876
  Epoch 43/100, Training Loss: 0.5414, Validation Loss: 0.6874
  Epoch 44/100, Training Loss: 0.5953, Validation Loss: 0.6866
  Epoch 45/100, Training Loss: 0.5063, Validation Loss: 0.6865
  Epoch 46/100, Training Loss: 0.5430, Validation Loss: 0.6884
  Epoch 47/100, Training Loss: 0.5427, Validation Loss: 0.6901
  Epoch 48/100, Training Loss: 0.5787, Validation Loss: 0.6861
  Epoch 49/100, Training Loss: 0.5235, Validation Loss: 0.6891
  Epoch 50/100, Training Loss: 0.5418, Validation Loss: 0.6902
  Epoch 00051: reducing learning rate of group 0 to 1.0000e-03.
  Epoch 51/100, Training Loss: 0.5600, Validation Loss: 0.6854
  Epoch 52/100, Training Loss: 0.5410, Validation Loss: 0.6871
  Epoch 53/100, Training Loss: 0.5575, Validation Loss: 0.6887
  Epoch 54/100, Training Loss: 0.5609, Validation Loss: 0.6887
  Epoch 55/100, Training Loss: 0.5379, Validation Loss: 0.6876
  Epoch 56/100, Training Loss: 0.5412, Validation Loss: 0.6882
  Epoch 57/100, Training Loss: 0.5251, Validation Loss: 0.6882
  Epoch 58/100, Training Loss: 0.5757, Validation Loss: 0.6880
  Epoch 59/100, Training Loss: 0.5230, Validation Loss: 0.6875
  Epoch 60/100, Training Loss: 0.5059, Validation Loss: 0.6893
  Epoch 61/100, Training Loss: 0.5796, Validation Loss: 0.6901
  Epoch 00062: reducing learning rate of group 0 to 1.0000e-04.
  Epoch 62/100, Training Loss: 0.5421, Validation Loss: 0.6879
  Epoch 63/100, Training Loss: 0.5391, Validation Loss: 0.6879
  Epoch 64/100, Training Loss: 0.5795, Validation Loss: 0.6880
  Epoch 65/100, Training Loss: 0.5387, Validation Loss: 0.6881
  Epoch 66/100, Training Loss: 0.5399, Validation Loss: 0.6882
  Epoch 67/100, Training Loss: 0.5768, Validation Loss: 0.6884
  Epoch 68/100, Training Loss: 0.5612, Validation Loss: 0.6885
  Epoch 69/100, Training Loss: 0.5398, Validation Loss: 0.6884
  Epoch 70/100, Training Loss: 0.5635, Validation Loss: 0.6884
  Epoch 71/100, Training Loss: 0.5402, Validation Loss: 0.6884
  Epoch 72/100, Training Loss: 0.5617, Validation Loss: 0.6884
  Epoch 00073: reducing learning rate of group 0 to 1.0000e-05.
  Epoch 73/100, Training Loss: 0.5759, Validation Loss: 0.6883
  Epoch 74/100, Training Loss: 0.5400, Validation Loss: 0.6883
  Epoch 75/100, Training Loss: 0.5413, Validation Loss: 0.6883
  Epoch 76/100, Training Loss: 0.5577, Validation Loss: 0.6883
  Epoch 77/100, Training Loss: 0.5254, Validation Loss: 0.6883
  Epoch 78/100, Training Loss: 0.5569, Validation Loss: 0.6883
  Epoch 79/100, Training Loss: 0.5598, Validation Loss: 0.6883
  Epoch 80/100, Training Loss: 0.5595, Validation Loss: 0.6883
  Epoch 81/100, Training Loss: 0.5958, Validation Loss: 0.6883
  Epoch 82/100, Training Loss: 0.5391, Validation Loss: 0.6883
  Epoch 83/100, Training Loss: 0.5398, Validation Loss: 0.6883
  Epoch 00084: reducing learning rate of group 0 to 1.0000e-06.
  Epoch 84/100, Training Loss: 0.5766, Validation Loss: 0.6883
  Epoch 85/100, Training Loss: 0.5594, Validation Loss: 0.6883
  Epoch 86/100, Training Loss: 0.6123, Validation Loss: 0.6883
  Epoch 87/100, Training Loss: 0.5572, Validation Loss: 0.6883
  Epoch 88/100, Training Loss: 0.5071, Validation Loss: 0.6883
  Epoch 89/100, Training Loss: 0.5603, Validation Loss: 0.6883
  Epoch 90/100, Training Loss: 0.6316, Validation Loss: 0.6883
  Epoch 91/100, Training Loss: 0.5051, Validation Loss: 0.6883
  Epoch 92/100, Training Loss: 0.5572, Validation Loss: 0.6883
  Epoch 93/100, Training Loss: 0.5410, Validation Loss: 0.6883
  Epoch 94/100, Training Loss: 0.5574, Validation Loss: 0.6883
  Epoch 00095: reducing learning rate of group 0 to 1.0000e-07.  loss = 1 - CosineLoss()( model.U.T[0], model.U.T[1])
  print(np.arccos(loss.cpu().detach().numpy()) * 180 / np.pi)

  Epoch 95/100, Training Loss: 0.5422, Validation Loss: 0.6883
  Epoch 96/100, Training Loss: 0.5230, Validation Loss: 0.6883
  Epoch 97/100, Training Loss: 0.5572, Validation Loss: 0.6883
  Epoch 98/100, Training Loss: 0.5420, Validation Loss: 0.6883
  Epoch 99/100, Training Loss: 0.5405, Validation Loss: 0.6883
  Epoch 100/100, Training Loss: 0.5422, Validation Loss: 0.6883
#+end_example

** Evaluation

#+begin_src ipython
  model.N_BATCH = 1  
  rates = model.forward(REC_LAST_ONLY=0)
#+end_src

#+RESULTS:

#+begin_src ipython
  overlap_1 = rates @ model.xi[0].cpu().detach().numpy() / 1000.0 
  overlap_2 = rates @ model.xi[1].cpu().detach().numpy() / 1000.0
  overlap = np.stack((overlap_1, overlap_2))[...,0]
  print(overlap.shape)
#+end_src

#+RESULTS:
: (2, 13)

#+begin_src ipython
  loss = 1 - CosineLoss()( model.U.T[0], model.U.T[1])
  angle = np.arccos(loss.cpu().detach().numpy()) * 180 / np.pi

  plt.plot(overlap[0])
  plt.plot(overlap[1])
  plt.title('$\\alpha(U_1, U_2)=$ %.0f °' % angle)
  plt.xlabel('step')
  plt.ylabel('Overlap')
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/22ee2e7a12c798dd3799acf674e81039c1499e31.png]]

#+begin_src ipython
  print(rates.shape)
#+end_src

#+RESULTS:
: (13, 1, 1000)

#+begin_src ipython
  plt.plot(np.mean(rates[:,0], -1))
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/72b4f5162521ffc9058cd8a9de7135f355e11ceb.png]]

#+begin_src ipython
  loss = 1 - CosineLoss()( model.xi[0], model.xi[1])
  print(loss)
#+end_src

#+RESULTS:
: tensor(0.0315, device='cuda:0')

#+begin_src ipython
  loss = 1 - CosineLoss()( model.U.T[0], model.U.T[1])
  print(np.arccos(loss.cpu().detach().numpy()) * 180 / np.pi)
#+end_src

#+RESULTS:
: 90.38890664562952

*** Connectivity

#+begin_src ipython
  print(model.Wab)
#+end_src

#+RESULTS:
: 0cc08367-56d2-4aa6-bff7-cd39a79b57ab

#+begin_src ipython
  # Cij = model.Wab.weight.data.cpu().detach().numpy()
  Cij = model.Wab.cpu().detach().numpy()
  plot_con(Cij.T)
#+end_src

#+RESULTS:
: 8d67eafc-ee75-4ba3-bd1f-bc3064742c01

* Single

#+begin_src ipython
  conf_name = "config_I.yml"
  name = "dual_single"
  model = Network(conf_name, name, REPO_ROOT, VERBOSE=1, DEVICE='cuda')
  rates = model.forward(REC_LAST_ONLY=0)
#+end_src

#+RESULTS:
:RESULTS:
: Na tensor([1000], device='cuda:0', dtype=torch.int32) Ka tensor([1.], device='cuda:0') csumNa tensor([   0, 1000], device='cuda:0')
: Jab [-2.75]
: Ja0 [10.0]
# [goto error]
#+begin_example
  ---------------------------------------------------------------------------
  OutOfMemoryError                          Traceback (most recent call last)
  Cell In[48], line 3
        1 conf_name = "config_bump.yml"
        2 name = "dual_single"
  ----> 3 model = Network(conf_name, name, REPO_ROOT, VERBOSE=1, DEVICE='cuda')
        4 rates = model.forward(REC_LAST_ONLY=0)

  File ~/models/NeuroTorch/org/../src/network.py:47, in Network.__init__(self, conf_file, sim_name, repo_root, **kwargs)
       44     self.stp = STP_Model(self.N_NEURON, self.csumNa, self.DT, self.FLOAT, self.device)
       46 # initialize network
  ---> 47 self.init_network()
       49 self.U = nn.Parameter(torch.randn((self.N_NEURON, int(self.RANK)), device=self.device, dtype=self.FLOAT))
       50 # self.V = nn.Parameter(torch.randn((int(self.RANK), self.N_NEURON), device=self.device, dtype=self.FLOAT))

  File ~/models/NeuroTorch/org/../src/network.py:73, in Network.init_network(self)
       67 for i_pop in range(self.N_POP):
       68     for j_pop in range(self.N_POP):
       69         
       70         # self.Wab.weight.data[self.csumNa[i_pop] : self.csumNa[i_pop + 1],
       71         #                     self.csumNa[j_pop] : self.csumNa[j_pop + 1]] = self.initWeights(i_pop, j_pop)
  ---> 73         weights = self.initWeights(i_pop, j_pop)
       75         self.Wab[self.csumNa[i_pop] : self.csumNa[i_pop + 1],
       76                  self.csumNa[j_pop] : self.csumNa[j_pop + 1]] = weights
       78 # only train first pop
       79 # if i_pop==0 or j_pop==0:
       80 # self.Wab.requires_grad_(True)
       81 
       82 # resets the seed

  File ~/models/NeuroTorch/org/../src/network.py:319, in Network.initWeights(self, i_pop, j_pop)
      316 if 'cos' in self.STRUCTURE[i_pop, j_pop]:
      318     theta_i, theta_j = torch.meshgrid(self.theta_list[i_pop], self.theta_list[j_pop], indexing="ij")
  --> 319     theta_diff = theta_i - theta_j
      321     if 'spec' in self.STRUCTURE[i_pop, j_pop]:
      322         self.KAPPA[i_pop, j_pop] = self.KAPPA[i_pop, j_pop] / torch.sqrt(Kb)

  OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.50 GiB of which 6.19 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 23.14 GiB is allocated by PyTorch, and 18.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
#+end_example
:END:
#+RESULTS:
#+RESULTS:

#+begin_src ipython
  lr = model.U @ model.U.T
  print(lr.shape)
#+end_src

#+RESULTS:
: torch.Size([1000, 1000])

* Rates

#+begin_src ipython
  print(rates.shape)
#+end_src

#+RESULTS:
: (13, 1, 750)

#+begin_src ipython
  loss = cosine_distance_loss(rates, labels)
  print(loss)  
#+end_src

#+RESULTS:
:RESULTS:
# [goto error]
#+begin_example
  ---------------------------------------------------------------------------
  AttributeError                            Traceback (most recent call last)
  Cell In[134], line 1
  ----> 1 loss = cosine_distance_loss(rates, labels)
        2 print(loss)  

  Cell In[35], line 6, in cosine_distance_loss(output, target)
        4 def cosine_distance_loss(output, target):
        5     # Normalize the vectors to unit length
  ----> 6     output_norm = F.normalize(output, p=2, dim=1)
        7     target_norm = F.normalize(target, p=2, dim=1)
        9     # Calculate the cosine similarity

  File ~/mambaforge/envs/torch/lib/python3.10/site-packages/torch/nn/functional.py:4719, in normalize(input, p, dim, eps, out)
     4717     return handle_torch_function(normalize, (input, out), input, p=p, dim=dim, eps=eps, out=out)
     4718 if out is None:
  -> 4719     denom = input.norm(p, dim, keepdim=True).clamp_min(eps).expand_as(input)
     4720     return input / denom
     4721 else:

  AttributeError: 'numpy.ndarray' object has no attribute 'norm'
#+end_example
:END:

#+begin_src ipython
  print(rates.shape)
#+end_src

#+RESULTS:
: (13, 1, 750)

#+begin_src ipython
  rates_single = rates[:,0]
  width = 7
  golden_ratio = (5**.5 - 1) / 2
  fig, ax = plt.subplots()

  # times = np.linspace(0, 5, rates.shape[0])  
  times = np.arange(0, 5.1, .1)

  N_E = 750
  r_min = 0
  r_max = 1.5 * np.mean(rates_single)
  r_max = 15

  im = ax.imshow(rates_single.T, aspect='auto', cmap='jet',vmin=0, vmax=r_max, extent=[times[0], times[-1], 0, N_E])

  ax.set_xlabel('Time (s)')
  ax.set_xticks([0, 1, 2, 3, 4, 5])
  ax.set_ylabel('Prefered Location (°)')
  ax.set_yticks([0, N_E/4, N_E/2, 3*N_E/4, N_E], [0, 90, 180, 270, 360])
  ax.set_xlim([0, 5])

  ax.axvline(1, 0, 1000, ls='--', color='w', lw=2)
  ax.axvline(1.5, 0, 1000, ls='--', color='w', lw=2)
  ax.axvline(2.5, 0, 1000, ls='--', color='w', lw=2)
  ax.axvline(3, 0, 1000, ls='--', color='w', lw=2)

  cbar = plt.colorbar(im, ax=ax)
  cbar.set_label("Activity (Hz)")
  cbar.set_ticks([0, 5, 10, 15])
  plt.savefig('./neurons.svg', dpi=300)
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/f62ae3f665cd2ca8e53f81dd390fbe214fcb6486.png]]

#+begin_src ipython
  ksi = model.U.cpu().detach().numpy().T
  print(ksi.shape)
  
  theta = get_theta(ksi[0][:750], ksi[1][:750], GM=0, IF_NORM=1)
  # theta = np.arctan2(ksi[1], ksi[0])
  index_order = theta.argsort()
  print(index_order.shape)
  rates_ordered = rates[:, 0, index_order]
#+end_src

#+RESULTS:
: (2, 1000)
: (750,)

#+begin_src ipython
  plt.imshow(rates_ordered.T, aspect='auto', cmap='jet', vmin=0, vmax=15)
  plt.ylabel('Pref. Location (°)')
  plt.xlabel('Time (au)')
  plt.yticks(np.linspace(0, 700, 5), np.linspace(0, 360, 5).astype(int))
  plt.colorbar()
  plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/ec1385382d2471b5b636fa206df0a5a6d3e48e10.png]]

#+begin_src ipython

#+end_src
